/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/awaitqueue/lib/Logger.js":
/*!***********************************************!*\
  !*** ./node_modules/awaitqueue/lib/Logger.js ***!
  \***********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Logger = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\");\nconst LIB_NAME = 'awaitqueue';\nclass Logger {\n    constructor(prefix) {\n        if (prefix) {\n            this._debug = (0, debug_1.default)(`${LIB_NAME}:${prefix}`);\n            this._warn = (0, debug_1.default)(`${LIB_NAME}:WARN:${prefix}`);\n            this._error = (0, debug_1.default)(`${LIB_NAME}:ERROR:${prefix}`);\n        }\n        else {\n            this._debug = (0, debug_1.default)(LIB_NAME);\n            this._warn = (0, debug_1.default)(`${LIB_NAME}:WARN`);\n            this._error = (0, debug_1.default)(`${LIB_NAME}:ERROR`);\n        }\n        /* eslint-disable no-console */\n        this._debug.log = console.info.bind(console);\n        this._warn.log = console.warn.bind(console);\n        this._error.log = console.error.bind(console);\n        /* eslint-enable no-console */\n    }\n    get debug() {\n        return this._debug;\n    }\n    get warn() {\n        return this._warn;\n    }\n    get error() {\n        return this._error;\n    }\n}\nexports.Logger = Logger;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/awaitqueue/lib/Logger.js?");

/***/ }),

/***/ "./node_modules/awaitqueue/lib/index.js":
/*!**********************************************!*\
  !*** ./node_modules/awaitqueue/lib/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AwaitQueue = exports.AwaitQueueRemovedTaskError = exports.AwaitQueueStoppedError = void 0;\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/awaitqueue/lib/Logger.js\");\nconst logger = new Logger_1.Logger();\n/**\n * Custom Error derived class used to reject pending tasks once stop() method\n * has been called.\n */\nclass AwaitQueueStoppedError extends Error {\n    constructor(message) {\n        super(message ?? 'AwaitQueue stopped');\n        this.name = 'AwaitQueueStoppedError';\n        // @ts-ignore\n        if (typeof Error.captureStackTrace === 'function') {\n            // @ts-ignore\n            Error.captureStackTrace(this, AwaitQueueStoppedError);\n        }\n    }\n}\nexports.AwaitQueueStoppedError = AwaitQueueStoppedError;\n/**\n * Custom Error derived class used to reject pending tasks once removeTask()\n * method has been called.\n */\nclass AwaitQueueRemovedTaskError extends Error {\n    constructor(message) {\n        super(message ?? 'AwaitQueue task removed');\n        this.name = 'AwaitQueueRemovedTaskError';\n        // @ts-ignore\n        if (typeof Error.captureStackTrace === 'function') {\n            // @ts-ignore\n            Error.captureStackTrace(this, AwaitQueueRemovedTaskError);\n        }\n    }\n}\nexports.AwaitQueueRemovedTaskError = AwaitQueueRemovedTaskError;\nclass AwaitQueue {\n    constructor() {\n        // Queue of pending tasks (map of PendingTasks indexed by id).\n        this.pendingTasks = new Map();\n        // Incrementing PendingTask id.\n        this.nextTaskId = 0;\n        // Whether stop() method is stopping all pending tasks.\n        this.stopping = false;\n    }\n    get size() {\n        return this.pendingTasks.size;\n    }\n    async push(task, name) {\n        name = name ?? task.name;\n        logger.debug(`push() [name:${name}]`);\n        if (typeof task !== 'function') {\n            throw new TypeError('given task is not a function');\n        }\n        if (name) {\n            try {\n                Object.defineProperty(task, 'name', { value: name });\n            }\n            catch (error) { }\n        }\n        return new Promise((resolve, reject) => {\n            const pendingTask = {\n                id: this.nextTaskId++,\n                task: task,\n                name: name,\n                enqueuedAt: Date.now(),\n                executedAt: undefined,\n                completed: false,\n                resolve: (result) => {\n                    // pendingTask.resolve() can only be called in execute() method. Since\n                    // resolve() was called it means that the task successfully completed.\n                    // However the task may have been stopped before it completed (via\n                    // stop() or remove()) so its completed flag was already set. If this\n                    // is the case, abort here since next task (if any) is already being\n                    // executed.\n                    if (pendingTask.completed) {\n                        return;\n                    }\n                    pendingTask.completed = true;\n                    // Remove the task from the queue.\n                    this.pendingTasks.delete(pendingTask.id);\n                    logger.debug(`resolving task [name:${pendingTask.name}]`);\n                    // Resolve the task with the obtained result.\n                    resolve(result);\n                    // Execute the next pending task (if any).\n                    const [nextPendingTask] = this.pendingTasks.values();\n                    // NOTE: During the resolve() callback the user app may have interacted\n                    // with the queue. For instance, the app may have pushed a task while\n                    // the queue was empty so such a task is already being executed. If so,\n                    // don't execute it twice.\n                    if (nextPendingTask && !nextPendingTask.executedAt) {\n                        void this.execute(nextPendingTask);\n                    }\n                },\n                reject: (error) => {\n                    // pendingTask.reject() can be called within execute() method if the\n                    // task completed with error. However it may have also been called in\n                    // stop() or remove() methods (before or while being executed) so its\n                    // completed flag was already set. If so, abort here since next task\n                    // (if any) is already being executed.\n                    if (pendingTask.completed) {\n                        return;\n                    }\n                    pendingTask.completed = true;\n                    // Remove the task from the queue.\n                    this.pendingTasks.delete(pendingTask.id);\n                    logger.debug(`rejecting task [name:${pendingTask.name}]: %s`, String(error));\n                    // Reject the task with the obtained error.\n                    reject(error);\n                    // Execute the next pending task (if any) unless stop() is running.\n                    if (!this.stopping) {\n                        const [nextPendingTask] = this.pendingTasks.values();\n                        // NOTE: During the reject() callback the user app may have interacted\n                        // with the queue. For instance, the app may have pushed a task while\n                        // the queue was empty so such a task is already being executed. If so,\n                        // don't execute it twice.\n                        if (nextPendingTask && !nextPendingTask.executedAt) {\n                            void this.execute(nextPendingTask);\n                        }\n                    }\n                }\n            };\n            // Append task to the queue.\n            this.pendingTasks.set(pendingTask.id, pendingTask);\n            // And execute it if this is the only task in the queue.\n            if (this.pendingTasks.size === 1) {\n                void this.execute(pendingTask);\n            }\n        });\n    }\n    stop() {\n        logger.debug('stop()');\n        this.stopping = true;\n        for (const pendingTask of this.pendingTasks.values()) {\n            logger.debug(`stop() | stopping task [name:${pendingTask.name}]`);\n            pendingTask.reject(new AwaitQueueStoppedError());\n        }\n        this.stopping = false;\n    }\n    remove(taskIdx) {\n        logger.debug(`remove() [taskIdx:${taskIdx}]`);\n        const pendingTask = Array.from(this.pendingTasks.values())[taskIdx];\n        if (!pendingTask) {\n            logger.debug(`stop() | no task with given idx [taskIdx:${taskIdx}]`);\n            return;\n        }\n        pendingTask.reject(new AwaitQueueRemovedTaskError());\n    }\n    dump() {\n        const now = Date.now();\n        let idx = 0;\n        return Array.from(this.pendingTasks.values()).map((pendingTask) => ({\n            idx: idx++,\n            task: pendingTask.task,\n            name: pendingTask.name,\n            enqueuedTime: pendingTask.executedAt\n                ? pendingTask.executedAt - pendingTask.enqueuedAt\n                : now - pendingTask.enqueuedAt,\n            executionTime: pendingTask.executedAt\n                ? now - pendingTask.executedAt\n                : 0\n        }));\n    }\n    async execute(pendingTask) {\n        logger.debug(`execute() [name:${pendingTask.name}]`);\n        if (pendingTask.executedAt) {\n            throw new Error('task already being executed');\n        }\n        pendingTask.executedAt = Date.now();\n        try {\n            const result = await pendingTask.task();\n            // Resolve the task with its resolved result (if any).\n            pendingTask.resolve(result);\n        }\n        catch (error) {\n            // Reject the task with its rejected error.\n            pendingTask.reject(error);\n        }\n    }\n}\nexports.AwaitQueue = AwaitQueue;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/awaitqueue/lib/index.js?");

/***/ }),

/***/ "./node_modules/debug/src/browser.js":
/*!*******************************************!*\
  !*** ./node_modules/debug/src/browser.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t'#0000CC',\n\t'#0000FF',\n\t'#0033CC',\n\t'#0033FF',\n\t'#0066CC',\n\t'#0066FF',\n\t'#0099CC',\n\t'#0099FF',\n\t'#00CC00',\n\t'#00CC33',\n\t'#00CC66',\n\t'#00CC99',\n\t'#00CCCC',\n\t'#00CCFF',\n\t'#3300CC',\n\t'#3300FF',\n\t'#3333CC',\n\t'#3333FF',\n\t'#3366CC',\n\t'#3366FF',\n\t'#3399CC',\n\t'#3399FF',\n\t'#33CC00',\n\t'#33CC33',\n\t'#33CC66',\n\t'#33CC99',\n\t'#33CCCC',\n\t'#33CCFF',\n\t'#6600CC',\n\t'#6600FF',\n\t'#6633CC',\n\t'#6633FF',\n\t'#66CC00',\n\t'#66CC33',\n\t'#9900CC',\n\t'#9900FF',\n\t'#9933CC',\n\t'#9933FF',\n\t'#99CC00',\n\t'#99CC33',\n\t'#CC0000',\n\t'#CC0033',\n\t'#CC0066',\n\t'#CC0099',\n\t'#CC00CC',\n\t'#CC00FF',\n\t'#CC3300',\n\t'#CC3333',\n\t'#CC3366',\n\t'#CC3399',\n\t'#CC33CC',\n\t'#CC33FF',\n\t'#CC6600',\n\t'#CC6633',\n\t'#CC9900',\n\t'#CC9933',\n\t'#CCCC00',\n\t'#CCCC33',\n\t'#FF0000',\n\t'#FF0033',\n\t'#FF0066',\n\t'#FF0099',\n\t'#FF00CC',\n\t'#FF00FF',\n\t'#FF3300',\n\t'#FF3333',\n\t'#FF3366',\n\t'#FF3399',\n\t'#FF33CC',\n\t'#FF33FF',\n\t'#FF6600',\n\t'#FF6633',\n\t'#FF9900',\n\t'#FF9933',\n\t'#FFCC00',\n\t'#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t// explicitly\n\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? '%c' : '') +\n\t\tthis.namespace +\n\t\t(this.useColors ? ' %c' : ' ') +\n\t\targs[0] +\n\t\t(this.useColors ? '%c ' : ' ') +\n\t\t'+' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = 'color: ' + this.color;\n\targs.splice(1, 0, c, 'color: inherit');\n\n\t// The final \"%c\" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === '%%') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === '%c') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem('debug', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem('debug');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem('debug');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\tr = process.env.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/debug/src/browser.js?");

/***/ }),

/***/ "./node_modules/debug/src/common.js":
/*!******************************************!*\
  !*** ./node_modules/debug/src/common.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"./node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/debug/src/common.js?");

/***/ }),

/***/ "./node_modules/h264-profile-level-id/lib/Logger.js":
/*!**********************************************************!*\
  !*** ./node_modules/h264-profile-level-id/lib/Logger.js ***!
  \**********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Logger = void 0;\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\"));\nconst APP_NAME = 'h264-profile-level-id';\nclass Logger {\n    constructor(prefix) {\n        if (prefix) {\n            this._debug = (0, debug_1.default)(`${APP_NAME}:${prefix}`);\n            this._warn = (0, debug_1.default)(`${APP_NAME}:WARN:${prefix}`);\n            this._error = (0, debug_1.default)(`${APP_NAME}:ERROR:${prefix}`);\n        }\n        else {\n            this._debug = (0, debug_1.default)(APP_NAME);\n            this._warn = (0, debug_1.default)(`${APP_NAME}:WARN`);\n            this._error = (0, debug_1.default)(`${APP_NAME}:ERROR`);\n        }\n        /* eslint-disable no-console */\n        this._debug.log = console.info.bind(console);\n        this._warn.log = console.warn.bind(console);\n        this._error.log = console.error.bind(console);\n        /* eslint-enable no-console */\n    }\n    get debug() {\n        return this._debug;\n    }\n    get warn() {\n        return this._warn;\n    }\n    get error() {\n        return this._error;\n    }\n}\nexports.Logger = Logger;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/h264-profile-level-id/lib/Logger.js?");

/***/ }),

/***/ "./node_modules/h264-profile-level-id/lib/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/h264-profile-level-id/lib/index.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.generateProfileLevelIdStringForAnswer = exports.isSameProfile = exports.parseSdpProfileLevelId = exports.levelToString = exports.profileToString = exports.profileLevelIdToString = exports.parseProfileLevelId = exports.ProfileLevelId = exports.Level = exports.Profile = void 0;\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/h264-profile-level-id/lib/Logger.js\");\nconst logger = new Logger_1.Logger();\n/**\n * Supported profiles.\n */\n// ESLint absurdly complains about \"'Profile' is already declared in\n// the upper scope\".\n// eslint-disable-next-line no-shadow\nvar Profile;\n(function (Profile) {\n    Profile[Profile[\"ConstrainedBaseline\"] = 1] = \"ConstrainedBaseline\";\n    Profile[Profile[\"Baseline\"] = 2] = \"Baseline\";\n    Profile[Profile[\"Main\"] = 3] = \"Main\";\n    Profile[Profile[\"ConstrainedHigh\"] = 4] = \"ConstrainedHigh\";\n    Profile[Profile[\"High\"] = 5] = \"High\";\n    Profile[Profile[\"PredictiveHigh444\"] = 6] = \"PredictiveHigh444\";\n})(Profile || (exports.Profile = Profile = {}));\n/**\n * Supported levels.\n */\n// ESLint absurdly complains about \"'Level' is already declared in\n// the upper scope\".\n// eslint-disable-next-line no-shadow\nvar Level;\n(function (Level) {\n    Level[Level[\"L1_b\"] = 0] = \"L1_b\";\n    Level[Level[\"L1\"] = 10] = \"L1\";\n    Level[Level[\"L1_1\"] = 11] = \"L1_1\";\n    Level[Level[\"L1_2\"] = 12] = \"L1_2\";\n    Level[Level[\"L1_3\"] = 13] = \"L1_3\";\n    Level[Level[\"L2\"] = 20] = \"L2\";\n    Level[Level[\"L2_1\"] = 21] = \"L2_1\";\n    Level[Level[\"L2_2\"] = 22] = \"L2_2\";\n    Level[Level[\"L3\"] = 30] = \"L3\";\n    Level[Level[\"L3_1\"] = 31] = \"L3_1\";\n    Level[Level[\"L3_2\"] = 32] = \"L3_2\";\n    Level[Level[\"L4\"] = 40] = \"L4\";\n    Level[Level[\"L4_1\"] = 41] = \"L4_1\";\n    Level[Level[\"L4_2\"] = 42] = \"L4_2\";\n    Level[Level[\"L5\"] = 50] = \"L5\";\n    Level[Level[\"L5_1\"] = 51] = \"L5_1\";\n    Level[Level[\"L5_2\"] = 52] = \"L5_2\";\n})(Level || (exports.Level = Level = {}));\n/**\n * Represents a parsed h264 profile-level-id value.\n */\nclass ProfileLevelId {\n    constructor(profile, level) {\n        this.profile = profile;\n        this.level = level;\n    }\n}\nexports.ProfileLevelId = ProfileLevelId;\n// Default ProfileLevelId.\n//\n// TODO: The default should really be profile Baseline and level 1 according to\n// the spec: https://tools.ietf.org/html/rfc6184#section-8.1. In order to not\n// break backwards compatibility with older versions of WebRTC where external\n// codecs don't have any parameters, use profile ConstrainedBaseline level 3_1\n// instead. This workaround will only be done in an interim period to allow\n// external clients to update their code.\n//\n// http://crbug/webrtc/6337.\nconst DefaultProfileLevelId = new ProfileLevelId(Profile.ConstrainedBaseline, Level.L3_1);\n/**\n * Class for matching bit patterns such as \"x1xx0000\" where 'x' is allowed to\n * be either 0 or 1.\n */\nclass BitPattern {\n    constructor(str) {\n        this.mask = ~byteMaskString('x', str);\n        this.masked_value = byteMaskString('1', str);\n    }\n    isMatch(value) {\n        return this.masked_value === (value & this.mask);\n    }\n}\n/**\n * Class for converting between profile_idc/profile_iop to Profile.\n */\nclass ProfilePattern {\n    constructor(profile_idc, profile_iop, profile) {\n        this.profile_idc = profile_idc;\n        this.profile_iop = profile_iop;\n        this.profile = profile;\n    }\n}\n// This is from https://tools.ietf.org/html/rfc6184#section-8.1.\nconst ProfilePatterns = [\n    new ProfilePattern(0x42, new BitPattern('x1xx0000'), Profile.ConstrainedBaseline),\n    new ProfilePattern(0x4D, new BitPattern('1xxx0000'), Profile.ConstrainedBaseline),\n    new ProfilePattern(0x58, new BitPattern('11xx0000'), Profile.ConstrainedBaseline),\n    new ProfilePattern(0x42, new BitPattern('x0xx0000'), Profile.Baseline),\n    new ProfilePattern(0x58, new BitPattern('10xx0000'), Profile.Baseline),\n    new ProfilePattern(0x4D, new BitPattern('0x0x0000'), Profile.Main),\n    new ProfilePattern(0x64, new BitPattern('00000000'), Profile.High),\n    new ProfilePattern(0x64, new BitPattern('00001100'), Profile.ConstrainedHigh),\n    new ProfilePattern(0xF4, new BitPattern('00000000'), Profile.PredictiveHigh444)\n];\n/**\n * Parse profile level id that is represented as a string of 3 hex bytes.\n * Nothing will be returned if the string is not a recognized H264 profile\n * level id.\n */\nfunction parseProfileLevelId(str) {\n    // For level_idc=11 and profile_idc=0x42, 0x4D, or 0x58, the constraint set3\n    // flag specifies if level 1b or level 1.1 is used.\n    const ConstraintSet3Flag = 0x10;\n    // The string should consist of 3 bytes in hexadecimal format.\n    if (typeof str !== 'string' || str.length !== 6) {\n        return undefined;\n    }\n    const profile_level_id_numeric = parseInt(str, 16);\n    if (profile_level_id_numeric === 0) {\n        return undefined;\n    }\n    // Separate into three bytes.\n    const level_idc = (profile_level_id_numeric & 0xFF);\n    const profile_iop = (profile_level_id_numeric >> 8) & 0xFF;\n    const profile_idc = (profile_level_id_numeric >> 16) & 0xFF;\n    // Parse level based on level_idc and constraint set 3 flag.\n    let level;\n    switch (level_idc) {\n        case Level.L1_1:\n            {\n                level = (profile_iop & ConstraintSet3Flag) !== 0\n                    ? Level.L1_b\n                    : Level.L1_1;\n                break;\n            }\n        case Level.L1:\n        case Level.L1_2:\n        case Level.L1_3:\n        case Level.L2:\n        case Level.L2_1:\n        case Level.L2_2:\n        case Level.L3:\n        case Level.L3_1:\n        case Level.L3_2:\n        case Level.L4:\n        case Level.L4_1:\n        case Level.L4_2:\n        case Level.L5:\n        case Level.L5_1:\n        case Level.L5_2:\n            {\n                level = level_idc;\n                break;\n            }\n        // Unrecognized level_idc.\n        default:\n            {\n                logger.warn(`parseProfileLevelId() | unrecognized level_idc [str:${str}, level_idc:${level_idc}]`);\n                return undefined;\n            }\n    }\n    // Parse profile_idc/profile_iop into a Profile enum.\n    for (const pattern of ProfilePatterns) {\n        if (profile_idc === pattern.profile_idc &&\n            pattern.profile_iop.isMatch(profile_iop)) {\n            return new ProfileLevelId(pattern.profile, level);\n        }\n    }\n    logger.warn(`parseProfileLevelId() | unrecognized profile_idc/profile_iop combination [str:${str}, profile_idc:${profile_idc}, profile_iop:${profile_iop}]`);\n    return undefined;\n}\nexports.parseProfileLevelId = parseProfileLevelId;\n/**\n * Returns canonical string representation as three hex bytes of the profile\n * level id, or returns nothing for invalid profile level ids.\n */\nfunction profileLevelIdToString(profile_level_id) {\n    // Handle special case level == 1b.\n    if (profile_level_id.level == Level.L1_b) {\n        switch (profile_level_id.profile) {\n            case Profile.ConstrainedBaseline:\n                {\n                    return '42f00b';\n                }\n            case Profile.Baseline:\n                {\n                    return '42100b';\n                }\n            case Profile.Main:\n                {\n                    return '4d100b';\n                }\n            // Level 1_b is not allowed for other profiles.\n            default:\n                {\n                    logger.warn(`profileLevelIdToString() | Level 1_b not is allowed for profile ${profile_level_id.profile}`);\n                    return undefined;\n                }\n        }\n    }\n    let profile_idc_iop_string;\n    switch (profile_level_id.profile) {\n        case Profile.ConstrainedBaseline:\n            {\n                profile_idc_iop_string = '42e0';\n                break;\n            }\n        case Profile.Baseline:\n            {\n                profile_idc_iop_string = '4200';\n                break;\n            }\n        case Profile.Main:\n            {\n                profile_idc_iop_string = '4d00';\n                break;\n            }\n        case Profile.ConstrainedHigh:\n            {\n                profile_idc_iop_string = '640c';\n                break;\n            }\n        case Profile.High:\n            {\n                profile_idc_iop_string = '6400';\n                break;\n            }\n        case Profile.PredictiveHigh444:\n            {\n                profile_idc_iop_string = 'f400';\n                break;\n            }\n        default:\n            {\n                logger.warn(`profileLevelIdToString() | unrecognized profile ${profile_level_id.profile}`);\n                return undefined;\n            }\n    }\n    let levelStr = (profile_level_id.level).toString(16);\n    if (levelStr.length === 1) {\n        levelStr = `0${levelStr}`;\n    }\n    return `${profile_idc_iop_string}${levelStr}`;\n}\nexports.profileLevelIdToString = profileLevelIdToString;\n/**\n * Returns a human friendly name for the given profile.\n */\nfunction profileToString(profile) {\n    switch (profile) {\n        case Profile.ConstrainedBaseline:\n            {\n                return 'ConstrainedBaseline';\n            }\n        case Profile.Baseline:\n            {\n                return 'Baseline';\n            }\n        case Profile.Main:\n            {\n                return 'Main';\n            }\n        case Profile.ConstrainedHigh:\n            {\n                return 'ConstrainedHigh';\n            }\n        case Profile.High:\n            {\n                return 'High';\n            }\n        case Profile.PredictiveHigh444:\n            {\n                return 'PredictiveHigh444';\n            }\n        default:\n            {\n                logger.warn(`profileToString() | unrecognized profile ${profile}`);\n                return undefined;\n            }\n    }\n}\nexports.profileToString = profileToString;\n/**\n * Returns a human friendly name for the given level.\n */\nfunction levelToString(level) {\n    switch (level) {\n        case Level.L1_b:\n            {\n                return '1b';\n            }\n        case Level.L1:\n            {\n                return '1';\n            }\n        case Level.L1_1:\n            {\n                return '1.1';\n            }\n        case Level.L1_2:\n            {\n                return '1.2';\n            }\n        case Level.L1_3:\n            {\n                return '1.3';\n            }\n        case Level.L2:\n            {\n                return '2';\n            }\n        case Level.L2_1:\n            {\n                return '2.1';\n            }\n        case Level.L2_2:\n            {\n                return '2.2';\n            }\n        case Level.L3:\n            {\n                return '3';\n            }\n        case Level.L3_1:\n            {\n                return '3.1';\n            }\n        case Level.L3_2:\n            {\n                return '3.2';\n            }\n        case Level.L4:\n            {\n                return '4';\n            }\n        case Level.L4_1:\n            {\n                return '4.1';\n            }\n        case Level.L4_2:\n            {\n                return '4.2';\n            }\n        case Level.L5:\n            {\n                return '5';\n            }\n        case Level.L5_1:\n            {\n                return '5.1';\n            }\n        case Level.L5_2:\n            {\n                return '5.2';\n            }\n        default:\n            {\n                logger.warn(`levelToString() | unrecognized level ${level}`);\n                return undefined;\n            }\n    }\n}\nexports.levelToString = levelToString;\n/**\n * Parse profile level id that is represented as a string of 3 hex bytes\n * contained in an SDP key-value map. A default profile level id will be\n * returned if the profile-level-id key is missing. Nothing will be returned\n * if the key is present but the string is invalid.\n */\nfunction parseSdpProfileLevelId(params = {}) {\n    const profile_level_id = params['profile-level-id'];\n    return profile_level_id\n        ? parseProfileLevelId(profile_level_id)\n        : DefaultProfileLevelId;\n}\nexports.parseSdpProfileLevelId = parseSdpProfileLevelId;\n/**\n * Returns true if the parameters have the same H264 profile, i.e. the same\n * H264 profile (Baseline, High, etc).\n */\nfunction isSameProfile(params1 = {}, params2 = {}) {\n    const profile_level_id_1 = parseSdpProfileLevelId(params1);\n    const profile_level_id_2 = parseSdpProfileLevelId(params2);\n    // Compare H264 profiles, but not levels.\n    return Boolean(profile_level_id_1 &&\n        profile_level_id_2 &&\n        profile_level_id_1.profile === profile_level_id_2.profile);\n}\nexports.isSameProfile = isSameProfile;\n/**\n * Generate codec parameters that will be used as answer in an SDP negotiation\n * based on local supported parameters and remote offered parameters. Both\n * local_supported_params and remote_offered_params represent sendrecv media\n * descriptions, i.e they are a mix of both encode and decode capabilities. In\n * theory, when the profile in local_supported_params represent a strict\n * superset of the profile in remote_offered_params, we could limit the profile\n * in the answer to the profile in remote_offered_params.\n *\n * However, to simplify the code, each supported H264 profile should be listed\n * explicitly in the list of local supported codecs, even if they are redundant.\n * Then each local codec in the list should be tested one at a time against the\n * remote codec, and only when the profiles are equal should this function be\n * called. Therefore, this function does not need to handle profile intersection,\n * and the profile of local_supported_params and remote_offered_params must be\n * equal before calling this function. The parameters that are used when\n * negotiating are the level part of profile-level-id and\n * level-asymmetry-allowed.\n */\nfunction generateProfileLevelIdStringForAnswer(local_supported_params = {}, remote_offered_params = {}) {\n    // If both local and remote params do not contain profile-level-id, they are\n    // both using the default profile. In this case, don't return anything.\n    if (!local_supported_params['profile-level-id'] &&\n        !remote_offered_params['profile-level-id']) {\n        logger.warn('generateProfileLevelIdStringForAnswer() | profile-level-id missing in local and remote params');\n        return undefined;\n    }\n    // Parse profile-level-ids.\n    const local_profile_level_id = parseSdpProfileLevelId(local_supported_params);\n    const remote_profile_level_id = parseSdpProfileLevelId(remote_offered_params);\n    // The local and remote codec must have valid and equal H264 Profiles.\n    if (!local_profile_level_id) {\n        throw new TypeError('invalid local_profile_level_id');\n    }\n    if (!remote_profile_level_id) {\n        throw new TypeError('invalid remote_profile_level_id');\n    }\n    if (local_profile_level_id.profile !== remote_profile_level_id.profile) {\n        throw new TypeError('H264 Profile mismatch');\n    }\n    // Parse level information.\n    const level_asymmetry_allowed = (isLevelAsymmetryAllowed(local_supported_params) &&\n        isLevelAsymmetryAllowed(remote_offered_params));\n    const local_level = local_profile_level_id.level;\n    const remote_level = remote_profile_level_id.level;\n    const min_level = minLevel(local_level, remote_level);\n    // Determine answer level. When level asymmetry is not allowed, level upgrade\n    // is not allowed, i.e., the level in the answer must be equal to or lower\n    // than the level in the offer.\n    const answer_level = level_asymmetry_allowed\n        ? local_level\n        : min_level;\n    logger.debug(`generateProfileLevelIdStringForAnswer() | result [profile:${local_profile_level_id.profile}, level:${answer_level}]`);\n    // Return the resulting profile-level-id for the answer parameters.\n    return profileLevelIdToString(new ProfileLevelId(local_profile_level_id.profile, answer_level));\n}\nexports.generateProfileLevelIdStringForAnswer = generateProfileLevelIdStringForAnswer;\n/**\n * Convert a string of 8 characters into a byte where the positions containing\n * character c will have their bit set. For example, c = 'x', str = \"x1xx0000\"\n * will return 0b10110000.\n */\nfunction byteMaskString(c, str) {\n    return ((Number(str[0] === c) << 7) | (Number(str[1] === c) << 6) |\n        (Number(str[2] === c) << 5) | (Number(str[3] === c) << 4) |\n        (Number(str[4] === c) << 3) | (Number(str[5] === c) << 2) |\n        (Number(str[6] === c) << 1) | (Number(str[7] === c) << 0));\n}\n// Compare H264 levels and handle the level 1b case.\nfunction isLessLevel(a, b) {\n    if (a === Level.L1_b) {\n        return b !== Level.L1 && b !== Level.L1_b;\n    }\n    if (b === Level.L1_b) {\n        return a !== Level.L1;\n    }\n    return a < b;\n}\nfunction minLevel(a, b) {\n    return isLessLevel(a, b) ? a : b;\n}\nfunction isLevelAsymmetryAllowed(params = {}) {\n    const level_asymmetry_allowed = params['level-asymmetry-allowed'];\n    return (level_asymmetry_allowed === true ||\n        level_asymmetry_allowed === 1 ||\n        level_asymmetry_allowed === '1');\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/h264-profile-level-id/lib/index.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/Consumer.js":
/*!*******************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/Consumer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Consumer = void 0;\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ./EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst logger = new Logger_1.Logger('Consumer');\nclass Consumer extends EnhancedEventEmitter_1.EnhancedEventEmitter {\n    constructor({ id, localId, producerId, rtpReceiver, track, rtpParameters, appData, }) {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Observer instance.\n        this._observer = new EnhancedEventEmitter_1.EnhancedEventEmitter();\n        logger.debug('constructor()');\n        this._id = id;\n        this._localId = localId;\n        this._producerId = producerId;\n        this._rtpReceiver = rtpReceiver;\n        this._track = track;\n        this._rtpParameters = rtpParameters;\n        this._paused = !track.enabled;\n        this._appData = appData || {};\n        this.onTrackEnded = this.onTrackEnded.bind(this);\n        this.handleTrack();\n    }\n    /**\n     * Consumer id.\n     */\n    get id() {\n        return this._id;\n    }\n    /**\n     * Local id.\n     */\n    get localId() {\n        return this._localId;\n    }\n    /**\n     * Associated Producer id.\n     */\n    get producerId() {\n        return this._producerId;\n    }\n    /**\n     * Whether the Consumer is closed.\n     */\n    get closed() {\n        return this._closed;\n    }\n    /**\n     * Media kind.\n     */\n    get kind() {\n        return this._track.kind;\n    }\n    /**\n     * Associated RTCRtpReceiver.\n     */\n    get rtpReceiver() {\n        return this._rtpReceiver;\n    }\n    /**\n     * The associated track.\n     */\n    get track() {\n        return this._track;\n    }\n    /**\n     * RTP parameters.\n     */\n    get rtpParameters() {\n        return this._rtpParameters;\n    }\n    /**\n     * Whether the Consumer is paused.\n     */\n    get paused() {\n        return this._paused;\n    }\n    /**\n     * App custom data.\n     */\n    get appData() {\n        return this._appData;\n    }\n    /**\n     * App custom data setter.\n     */\n    set appData(appData) {\n        this._appData = appData;\n    }\n    get observer() {\n        return this._observer;\n    }\n    /**\n     * Closes the Consumer.\n     */\n    close() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('close()');\n        this._closed = true;\n        this.destroyTrack();\n        this.emit('@close');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Transport was closed.\n     */\n    transportClosed() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('transportClosed()');\n        this._closed = true;\n        this.destroyTrack();\n        this.safeEmit('transportclose');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Get associated RTCRtpReceiver stats.\n     */\n    async getStats() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        return new Promise((resolve, reject) => {\n            this.safeEmit('@getstats', resolve, reject);\n        });\n    }\n    /**\n     * Pauses receiving media.\n     */\n    pause() {\n        logger.debug('pause()');\n        if (this._closed) {\n            logger.error('pause() | Consumer closed');\n            return;\n        }\n        if (this._paused) {\n            logger.debug('pause() | Consumer is already paused');\n            return;\n        }\n        this._paused = true;\n        this._track.enabled = false;\n        this.emit('@pause');\n        // Emit observer event.\n        this._observer.safeEmit('pause');\n    }\n    /**\n     * Resumes receiving media.\n     */\n    resume() {\n        logger.debug('resume()');\n        if (this._closed) {\n            logger.error('resume() | Consumer closed');\n            return;\n        }\n        if (!this._paused) {\n            logger.debug('resume() | Consumer is already resumed');\n            return;\n        }\n        this._paused = false;\n        this._track.enabled = true;\n        this.emit('@resume');\n        // Emit observer event.\n        this._observer.safeEmit('resume');\n    }\n    onTrackEnded() {\n        logger.debug('track \"ended\" event');\n        this.safeEmit('trackended');\n        // Emit observer event.\n        this._observer.safeEmit('trackended');\n    }\n    handleTrack() {\n        this._track.addEventListener('ended', this.onTrackEnded);\n    }\n    destroyTrack() {\n        try {\n            this._track.removeEventListener('ended', this.onTrackEnded);\n            this._track.stop();\n        }\n        catch (error) { }\n    }\n}\nexports.Consumer = Consumer;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/Consumer.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/DataConsumer.js":
/*!***********************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/DataConsumer.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DataConsumer = void 0;\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ./EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nconst logger = new Logger_1.Logger('DataConsumer');\nclass DataConsumer extends EnhancedEventEmitter_1.EnhancedEventEmitter {\n    constructor({ id, dataProducerId, dataChannel, sctpStreamParameters, appData, }) {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Observer instance.\n        this._observer = new EnhancedEventEmitter_1.EnhancedEventEmitter();\n        logger.debug('constructor()');\n        this._id = id;\n        this._dataProducerId = dataProducerId;\n        this._dataChannel = dataChannel;\n        this._sctpStreamParameters = sctpStreamParameters;\n        this._appData = appData || {};\n        this.handleDataChannel();\n    }\n    /**\n     * DataConsumer id.\n     */\n    get id() {\n        return this._id;\n    }\n    /**\n     * Associated DataProducer id.\n     */\n    get dataProducerId() {\n        return this._dataProducerId;\n    }\n    /**\n     * Whether the DataConsumer is closed.\n     */\n    get closed() {\n        return this._closed;\n    }\n    /**\n     * SCTP stream parameters.\n     */\n    get sctpStreamParameters() {\n        return this._sctpStreamParameters;\n    }\n    /**\n     * DataChannel readyState.\n     */\n    get readyState() {\n        return this._dataChannel.readyState;\n    }\n    /**\n     * DataChannel label.\n     */\n    get label() {\n        return this._dataChannel.label;\n    }\n    /**\n     * DataChannel protocol.\n     */\n    get protocol() {\n        return this._dataChannel.protocol;\n    }\n    /**\n     * DataChannel binaryType.\n     */\n    get binaryType() {\n        return this._dataChannel.binaryType;\n    }\n    /**\n     * Set DataChannel binaryType.\n     */\n    set binaryType(binaryType) {\n        this._dataChannel.binaryType = binaryType;\n    }\n    /**\n     * App custom data.\n     */\n    get appData() {\n        return this._appData;\n    }\n    /**\n     * App custom data setter.\n     */\n    set appData(appData) {\n        this._appData = appData;\n    }\n    get observer() {\n        return this._observer;\n    }\n    /**\n     * Closes the DataConsumer.\n     */\n    close() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('close()');\n        this._closed = true;\n        this._dataChannel.close();\n        this.emit('@close');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Transport was closed.\n     */\n    transportClosed() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('transportClosed()');\n        this._closed = true;\n        this._dataChannel.close();\n        this.safeEmit('transportclose');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    handleDataChannel() {\n        this._dataChannel.addEventListener('open', () => {\n            if (this._closed) {\n                return;\n            }\n            logger.debug('DataChannel \"open\" event');\n            this.safeEmit('open');\n        });\n        this._dataChannel.addEventListener('error', (event) => {\n            if (this._closed) {\n                return;\n            }\n            let { error } = event;\n            if (!error) {\n                error = new Error('unknown DataChannel error');\n            }\n            if (error.errorDetail === 'sctp-failure') {\n                logger.error('DataChannel SCTP error [sctpCauseCode:%s]: %s', error.sctpCauseCode, error.message);\n            }\n            else {\n                logger.error('DataChannel \"error\" event: %o', error);\n            }\n            this.safeEmit('error', error);\n        });\n        this._dataChannel.addEventListener('close', () => {\n            if (this._closed) {\n                return;\n            }\n            logger.warn('DataChannel \"close\" event');\n            this._closed = true;\n            this.emit('@close');\n            this.safeEmit('close');\n            // Emit observer event.\n            this._observer.safeEmit('close');\n        });\n        this._dataChannel.addEventListener('message', (event) => {\n            if (this._closed) {\n                return;\n            }\n            this.safeEmit('message', event.data);\n        });\n    }\n}\nexports.DataConsumer = DataConsumer;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/DataConsumer.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/DataProducer.js":
/*!***********************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/DataProducer.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DataProducer = void 0;\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ./EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst logger = new Logger_1.Logger('DataProducer');\nclass DataProducer extends EnhancedEventEmitter_1.EnhancedEventEmitter {\n    constructor({ id, dataChannel, sctpStreamParameters, appData, }) {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Observer instance.\n        this._observer = new EnhancedEventEmitter_1.EnhancedEventEmitter();\n        logger.debug('constructor()');\n        this._id = id;\n        this._dataChannel = dataChannel;\n        this._sctpStreamParameters = sctpStreamParameters;\n        this._appData = appData || {};\n        this.handleDataChannel();\n    }\n    /**\n     * DataProducer id.\n     */\n    get id() {\n        return this._id;\n    }\n    /**\n     * Whether the DataProducer is closed.\n     */\n    get closed() {\n        return this._closed;\n    }\n    /**\n     * SCTP stream parameters.\n     */\n    get sctpStreamParameters() {\n        return this._sctpStreamParameters;\n    }\n    /**\n     * DataChannel readyState.\n     */\n    get readyState() {\n        return this._dataChannel.readyState;\n    }\n    /**\n     * DataChannel label.\n     */\n    get label() {\n        return this._dataChannel.label;\n    }\n    /**\n     * DataChannel protocol.\n     */\n    get protocol() {\n        return this._dataChannel.protocol;\n    }\n    /**\n     * DataChannel bufferedAmount.\n     */\n    get bufferedAmount() {\n        return this._dataChannel.bufferedAmount;\n    }\n    /**\n     * DataChannel bufferedAmountLowThreshold.\n     */\n    get bufferedAmountLowThreshold() {\n        return this._dataChannel.bufferedAmountLowThreshold;\n    }\n    /**\n     * Set DataChannel bufferedAmountLowThreshold.\n     */\n    set bufferedAmountLowThreshold(bufferedAmountLowThreshold) {\n        this._dataChannel.bufferedAmountLowThreshold = bufferedAmountLowThreshold;\n    }\n    /**\n     * App custom data.\n     */\n    get appData() {\n        return this._appData;\n    }\n    /**\n     * App custom data setter.\n     */\n    set appData(appData) {\n        this._appData = appData;\n    }\n    get observer() {\n        return this._observer;\n    }\n    /**\n     * Closes the DataProducer.\n     */\n    close() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('close()');\n        this._closed = true;\n        this._dataChannel.close();\n        this.emit('@close');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Transport was closed.\n     */\n    transportClosed() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('transportClosed()');\n        this._closed = true;\n        this._dataChannel.close();\n        this.safeEmit('transportclose');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Send a message.\n     *\n     * @param {String|Blob|ArrayBuffer|ArrayBufferView} data.\n     */\n    send(data) {\n        logger.debug('send()');\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        this._dataChannel.send(data);\n    }\n    handleDataChannel() {\n        this._dataChannel.addEventListener('open', () => {\n            if (this._closed) {\n                return;\n            }\n            logger.debug('DataChannel \"open\" event');\n            this.safeEmit('open');\n        });\n        this._dataChannel.addEventListener('error', (event) => {\n            if (this._closed) {\n                return;\n            }\n            let { error } = event;\n            if (!error) {\n                error = new Error('unknown DataChannel error');\n            }\n            if (error.errorDetail === 'sctp-failure') {\n                logger.error('DataChannel SCTP error [sctpCauseCode:%s]: %s', error.sctpCauseCode, error.message);\n            }\n            else {\n                logger.error('DataChannel \"error\" event: %o', error);\n            }\n            this.safeEmit('error', error);\n        });\n        this._dataChannel.addEventListener('close', () => {\n            if (this._closed) {\n                return;\n            }\n            logger.warn('DataChannel \"close\" event');\n            this._closed = true;\n            this.emit('@close');\n            this.safeEmit('close');\n            // Emit observer event.\n            this._observer.safeEmit('close');\n        });\n        this._dataChannel.addEventListener('message', () => {\n            if (this._closed) {\n                return;\n            }\n            logger.warn('DataChannel \"message\" event in a DataProducer, message discarded');\n        });\n        this._dataChannel.addEventListener('bufferedamountlow', () => {\n            if (this._closed) {\n                return;\n            }\n            this.safeEmit('bufferedamountlow');\n        });\n    }\n}\nexports.DataProducer = DataProducer;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/DataProducer.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/Device.js":
/*!*****************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/Device.js ***!
  \*****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Device = void 0;\nexports.detectDevice = detectDevice;\nconst ua_parser_js_1 = __webpack_require__(/*! ua-parser-js */ \"./node_modules/ua-parser-js/src/ua-parser.js\");\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ./EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ./utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ./ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst Transport_1 = __webpack_require__(/*! ./Transport */ \"./node_modules/mediasoup-client/lib/Transport.js\");\nconst Chrome111_1 = __webpack_require__(/*! ./handlers/Chrome111 */ \"./node_modules/mediasoup-client/lib/handlers/Chrome111.js\");\nconst Chrome74_1 = __webpack_require__(/*! ./handlers/Chrome74 */ \"./node_modules/mediasoup-client/lib/handlers/Chrome74.js\");\nconst Chrome70_1 = __webpack_require__(/*! ./handlers/Chrome70 */ \"./node_modules/mediasoup-client/lib/handlers/Chrome70.js\");\nconst Chrome67_1 = __webpack_require__(/*! ./handlers/Chrome67 */ \"./node_modules/mediasoup-client/lib/handlers/Chrome67.js\");\nconst Chrome55_1 = __webpack_require__(/*! ./handlers/Chrome55 */ \"./node_modules/mediasoup-client/lib/handlers/Chrome55.js\");\nconst Firefox120_1 = __webpack_require__(/*! ./handlers/Firefox120 */ \"./node_modules/mediasoup-client/lib/handlers/Firefox120.js\");\nconst Firefox60_1 = __webpack_require__(/*! ./handlers/Firefox60 */ \"./node_modules/mediasoup-client/lib/handlers/Firefox60.js\");\nconst Safari12_1 = __webpack_require__(/*! ./handlers/Safari12 */ \"./node_modules/mediasoup-client/lib/handlers/Safari12.js\");\nconst Safari11_1 = __webpack_require__(/*! ./handlers/Safari11 */ \"./node_modules/mediasoup-client/lib/handlers/Safari11.js\");\nconst Edge11_1 = __webpack_require__(/*! ./handlers/Edge11 */ \"./node_modules/mediasoup-client/lib/handlers/Edge11.js\");\nconst ReactNativeUnifiedPlan_1 = __webpack_require__(/*! ./handlers/ReactNativeUnifiedPlan */ \"./node_modules/mediasoup-client/lib/handlers/ReactNativeUnifiedPlan.js\");\nconst ReactNative_1 = __webpack_require__(/*! ./handlers/ReactNative */ \"./node_modules/mediasoup-client/lib/handlers/ReactNative.js\");\nconst logger = new Logger_1.Logger('Device');\nfunction detectDevice() {\n    // React-Native.\n    // NOTE: react-native-webrtc >= 1.75.0 is required.\n    // NOTE: react-native-webrtc with Unified Plan requires version >= 106.0.0.\n    if (typeof navigator === 'object' && navigator.product === 'ReactNative') {\n        logger.debug('detectDevice() | React-Native detected');\n        if (typeof RTCPeerConnection === 'undefined') {\n            logger.warn('detectDevice() | unsupported react-native-webrtc without RTCPeerConnection, forgot to call registerGlobals()?');\n            return undefined;\n        }\n        if (typeof RTCRtpTransceiver !== 'undefined') {\n            logger.debug('detectDevice() | ReactNative UnifiedPlan handler chosen');\n            return 'ReactNativeUnifiedPlan';\n        }\n        else {\n            logger.debug('detectDevice() | ReactNative PlanB handler chosen');\n            return 'ReactNative';\n        }\n    }\n    // Browser.\n    else if (typeof navigator === 'object' &&\n        typeof navigator.userAgent === 'string') {\n        const ua = navigator.userAgent;\n        const uaParser = new ua_parser_js_1.UAParser(ua);\n        logger.debug('detectDevice() | browser detected [ua:%s, parsed:%o]', ua, uaParser.getResult());\n        const browser = uaParser.getBrowser();\n        const browserName = browser.name?.toLowerCase();\n        const browserVersion = parseInt(browser.major ?? '0');\n        const engine = uaParser.getEngine();\n        const engineName = engine.name?.toLowerCase();\n        const os = uaParser.getOS();\n        const osName = os.name?.toLowerCase();\n        const osVersion = parseFloat(os.version ?? '0');\n        const device = uaParser.getDevice();\n        const deviceModel = device.model?.toLowerCase();\n        const isIOS = osName === 'ios' || deviceModel === 'ipad';\n        const isChrome = browserName &&\n            [\n                'chrome',\n                'chromium',\n                'mobile chrome',\n                'chrome webview',\n                'chrome headless',\n            ].includes(browserName);\n        const isFirefox = browserName &&\n            ['firefox', 'mobile firefox', 'mobile focus'].includes(browserName);\n        const isSafari = browserName && ['safari', 'mobile safari'].includes(browserName);\n        const isEdge = browserName && ['edge'].includes(browserName);\n        // Chrome, Chromium, and Edge.\n        if ((isChrome || isEdge) && !isIOS && browserVersion >= 111) {\n            return 'Chrome111';\n        }\n        else if ((isChrome && !isIOS && browserVersion >= 74) ||\n            (isEdge && !isIOS && browserVersion >= 88)) {\n            return 'Chrome74';\n        }\n        else if (isChrome && !isIOS && browserVersion >= 70) {\n            return 'Chrome70';\n        }\n        else if (isChrome && !isIOS && browserVersion >= 67) {\n            return 'Chrome67';\n        }\n        else if (isChrome && !isIOS && browserVersion >= 55) {\n            return 'Chrome55';\n        }\n        // Firefox.\n        else if (isFirefox && !isIOS && browserVersion >= 120) {\n            return 'Firefox120';\n        }\n        else if (isFirefox && !isIOS && browserVersion >= 60) {\n            return 'Firefox60';\n        }\n        // Firefox on iOS (so Safari).\n        else if (isFirefox && isIOS && osVersion >= 14.3) {\n            return 'Safari12';\n        }\n        // Safari with Unified-Plan support enabled.\n        else if (isSafari &&\n            browserVersion >= 12 &&\n            typeof RTCRtpTransceiver !== 'undefined' &&\n            RTCRtpTransceiver.prototype.hasOwnProperty('currentDirection')) {\n            return 'Safari12';\n        }\n        // Safari with Plab-B support.\n        else if (isSafari && browserVersion >= 11) {\n            return 'Safari11';\n        }\n        // Old Edge with ORTC support.\n        else if (isEdge && !isIOS && browserVersion >= 11 && browserVersion <= 18) {\n            return 'Edge11';\n        }\n        // Best effort for WebKit based browsers in iOS.\n        else if (engineName === 'webkit' &&\n            isIOS &&\n            typeof RTCRtpTransceiver !== 'undefined' &&\n            RTCRtpTransceiver.prototype.hasOwnProperty('currentDirection')) {\n            return 'Safari12';\n        }\n        // Best effort for Chromium based browsers.\n        else if (engineName === 'blink') {\n            const match = ua.match(/(?:(?:Chrome|Chromium))[ /](\\w+)/i);\n            if (match) {\n                const version = Number(match[1]);\n                if (version >= 111) {\n                    return 'Chrome111';\n                }\n                else if (version >= 74) {\n                    return 'Chrome74';\n                }\n                else if (version >= 70) {\n                    return 'Chrome70';\n                }\n                else if (version >= 67) {\n                    return 'Chrome67';\n                }\n                else {\n                    return 'Chrome55';\n                }\n            }\n            else {\n                return 'Chrome111';\n            }\n        }\n        // Unsupported browser.\n        else {\n            logger.warn('detectDevice() | browser not supported [name:%s, version:%s]', browserName, browserVersion);\n            return undefined;\n        }\n    }\n    // Unknown device.\n    else {\n        logger.warn('detectDevice() | unknown device');\n        return undefined;\n    }\n}\nclass Device {\n    /**\n     * Create a new Device to connect to mediasoup server.\n     *\n     * @throws {UnsupportedError} if device is not supported.\n     */\n    constructor({ handlerName, handlerFactory, Handler } = {}) {\n        // Loaded flag.\n        this._loaded = false;\n        // Observer instance.\n        this._observer = new EnhancedEventEmitter_1.EnhancedEventEmitter();\n        logger.debug('constructor()');\n        // Handle deprecated option.\n        if (Handler) {\n            logger.warn('constructor() | Handler option is DEPRECATED, use handlerName or handlerFactory instead');\n            if (typeof Handler === 'string') {\n                handlerName = Handler;\n            }\n            else {\n                throw new TypeError('non string Handler option no longer supported, use handlerFactory instead');\n            }\n        }\n        if (handlerName && handlerFactory) {\n            throw new TypeError('just one of handlerName or handlerInterface can be given');\n        }\n        if (handlerFactory) {\n            this._handlerFactory = handlerFactory;\n        }\n        else {\n            if (handlerName) {\n                logger.debug('constructor() | handler given: %s', handlerName);\n            }\n            else {\n                handlerName = detectDevice();\n                if (handlerName) {\n                    logger.debug('constructor() | detected handler: %s', handlerName);\n                }\n                else {\n                    throw new errors_1.UnsupportedError('device not supported');\n                }\n            }\n            switch (handlerName) {\n                case 'Chrome111': {\n                    this._handlerFactory = Chrome111_1.Chrome111.createFactory();\n                    break;\n                }\n                case 'Chrome74': {\n                    this._handlerFactory = Chrome74_1.Chrome74.createFactory();\n                    break;\n                }\n                case 'Chrome70': {\n                    this._handlerFactory = Chrome70_1.Chrome70.createFactory();\n                    break;\n                }\n                case 'Chrome67': {\n                    this._handlerFactory = Chrome67_1.Chrome67.createFactory();\n                    break;\n                }\n                case 'Chrome55': {\n                    this._handlerFactory = Chrome55_1.Chrome55.createFactory();\n                    break;\n                }\n                case 'Firefox120': {\n                    this._handlerFactory = Firefox120_1.Firefox120.createFactory();\n                    break;\n                }\n                case 'Firefox60': {\n                    this._handlerFactory = Firefox60_1.Firefox60.createFactory();\n                    break;\n                }\n                case 'Safari12': {\n                    this._handlerFactory = Safari12_1.Safari12.createFactory();\n                    break;\n                }\n                case 'Safari11': {\n                    this._handlerFactory = Safari11_1.Safari11.createFactory();\n                    break;\n                }\n                case 'Edge11': {\n                    this._handlerFactory = Edge11_1.Edge11.createFactory();\n                    break;\n                }\n                case 'ReactNativeUnifiedPlan': {\n                    this._handlerFactory = ReactNativeUnifiedPlan_1.ReactNativeUnifiedPlan.createFactory();\n                    break;\n                }\n                case 'ReactNative': {\n                    this._handlerFactory = ReactNative_1.ReactNative.createFactory();\n                    break;\n                }\n                default: {\n                    throw new TypeError(`unknown handlerName \"${handlerName}\"`);\n                }\n            }\n        }\n        // Create a temporal handler to get its name.\n        const handler = this._handlerFactory();\n        this._handlerName = handler.name;\n        handler.close();\n        this._extendedRtpCapabilities = undefined;\n        this._recvRtpCapabilities = undefined;\n        this._canProduceByKind = {\n            audio: false,\n            video: false,\n        };\n        this._sctpCapabilities = undefined;\n    }\n    /**\n     * The RTC handler name.\n     */\n    get handlerName() {\n        return this._handlerName;\n    }\n    /**\n     * Whether the Device is loaded.\n     */\n    get loaded() {\n        return this._loaded;\n    }\n    /**\n     * RTP capabilities of the Device for receiving media.\n     *\n     * @throws {InvalidStateError} if not loaded.\n     */\n    get rtpCapabilities() {\n        if (!this._loaded) {\n            throw new errors_1.InvalidStateError('not loaded');\n        }\n        return this._recvRtpCapabilities;\n    }\n    /**\n     * SCTP capabilities of the Device.\n     *\n     * @throws {InvalidStateError} if not loaded.\n     */\n    get sctpCapabilities() {\n        if (!this._loaded) {\n            throw new errors_1.InvalidStateError('not loaded');\n        }\n        return this._sctpCapabilities;\n    }\n    get observer() {\n        return this._observer;\n    }\n    /**\n     * Initialize the Device.\n     */\n    async load({ routerRtpCapabilities, }) {\n        logger.debug('load() [routerRtpCapabilities:%o]', routerRtpCapabilities);\n        // Temporal handler to get its capabilities.\n        let handler;\n        try {\n            if (this._loaded) {\n                throw new errors_1.InvalidStateError('already loaded');\n            }\n            // Clone given router RTP capabilities to not modify input data.\n            const clonedRouterRtpCapabilities = utils.clone(routerRtpCapabilities);\n            // This may throw.\n            ortc.validateRtpCapabilities(clonedRouterRtpCapabilities);\n            handler = this._handlerFactory();\n            const nativeRtpCapabilities = await handler.getNativeRtpCapabilities();\n            logger.debug('load() | got native RTP capabilities:%o', nativeRtpCapabilities);\n            // Clone obtained native RTP capabilities to not modify input data.\n            const clonedNativeRtpCapabilities = utils.clone(nativeRtpCapabilities);\n            // This may throw.\n            ortc.validateRtpCapabilities(clonedNativeRtpCapabilities);\n            // Get extended RTP capabilities.\n            this._extendedRtpCapabilities = ortc.getExtendedRtpCapabilities(clonedNativeRtpCapabilities, clonedRouterRtpCapabilities);\n            logger.debug('load() | got extended RTP capabilities:%o', this._extendedRtpCapabilities);\n            // Check whether we can produce audio/video.\n            this._canProduceByKind.audio = ortc.canSend('audio', this._extendedRtpCapabilities);\n            this._canProduceByKind.video = ortc.canSend('video', this._extendedRtpCapabilities);\n            // Generate our receiving RTP capabilities for receiving media.\n            this._recvRtpCapabilities = ortc.getRecvRtpCapabilities(this._extendedRtpCapabilities);\n            // This may throw.\n            ortc.validateRtpCapabilities(this._recvRtpCapabilities);\n            logger.debug('load() | got receiving RTP capabilities:%o', this._recvRtpCapabilities);\n            // Generate our SCTP capabilities.\n            this._sctpCapabilities = await handler.getNativeSctpCapabilities();\n            logger.debug('load() | got native SCTP capabilities:%o', this._sctpCapabilities);\n            // This may throw.\n            ortc.validateSctpCapabilities(this._sctpCapabilities);\n            logger.debug('load() succeeded');\n            this._loaded = true;\n            handler.close();\n        }\n        catch (error) {\n            if (handler) {\n                handler.close();\n            }\n            throw error;\n        }\n    }\n    /**\n     * Whether we can produce audio/video.\n     *\n     * @throws {InvalidStateError} if not loaded.\n     * @throws {TypeError} if wrong arguments.\n     */\n    canProduce(kind) {\n        if (!this._loaded) {\n            throw new errors_1.InvalidStateError('not loaded');\n        }\n        else if (kind !== 'audio' && kind !== 'video') {\n            throw new TypeError(`invalid kind \"${kind}\"`);\n        }\n        return this._canProduceByKind[kind];\n    }\n    /**\n     * Creates a Transport for sending media.\n     *\n     * @throws {InvalidStateError} if not loaded.\n     * @throws {TypeError} if wrong arguments.\n     */\n    createSendTransport({ id, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, appData, }) {\n        logger.debug('createSendTransport()');\n        return this.createTransport({\n            direction: 'send',\n            id: id,\n            iceParameters: iceParameters,\n            iceCandidates: iceCandidates,\n            dtlsParameters: dtlsParameters,\n            sctpParameters: sctpParameters,\n            iceServers: iceServers,\n            iceTransportPolicy: iceTransportPolicy,\n            additionalSettings: additionalSettings,\n            proprietaryConstraints: proprietaryConstraints,\n            appData: appData,\n        });\n    }\n    /**\n     * Creates a Transport for receiving media.\n     *\n     * @throws {InvalidStateError} if not loaded.\n     * @throws {TypeError} if wrong arguments.\n     */\n    createRecvTransport({ id, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, appData, }) {\n        logger.debug('createRecvTransport()');\n        return this.createTransport({\n            direction: 'recv',\n            id: id,\n            iceParameters: iceParameters,\n            iceCandidates: iceCandidates,\n            dtlsParameters: dtlsParameters,\n            sctpParameters: sctpParameters,\n            iceServers: iceServers,\n            iceTransportPolicy: iceTransportPolicy,\n            additionalSettings: additionalSettings,\n            proprietaryConstraints: proprietaryConstraints,\n            appData: appData,\n        });\n    }\n    createTransport({ direction, id, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, appData, }) {\n        if (!this._loaded) {\n            throw new errors_1.InvalidStateError('not loaded');\n        }\n        else if (typeof id !== 'string') {\n            throw new TypeError('missing id');\n        }\n        else if (typeof iceParameters !== 'object') {\n            throw new TypeError('missing iceParameters');\n        }\n        else if (!Array.isArray(iceCandidates)) {\n            throw new TypeError('missing iceCandidates');\n        }\n        else if (typeof dtlsParameters !== 'object') {\n            throw new TypeError('missing dtlsParameters');\n        }\n        else if (sctpParameters && typeof sctpParameters !== 'object') {\n            throw new TypeError('wrong sctpParameters');\n        }\n        else if (appData && typeof appData !== 'object') {\n            throw new TypeError('if given, appData must be an object');\n        }\n        // Create a new Transport.\n        const transport = new Transport_1.Transport({\n            direction,\n            id,\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n            iceServers,\n            iceTransportPolicy,\n            additionalSettings,\n            proprietaryConstraints,\n            appData,\n            handlerFactory: this._handlerFactory,\n            extendedRtpCapabilities: this._extendedRtpCapabilities,\n            canProduceByKind: this._canProduceByKind,\n        });\n        // Emit observer event.\n        this._observer.safeEmit('newtransport', transport);\n        return transport;\n    }\n}\nexports.Device = Device;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/Device.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.EnhancedEventEmitter = void 0;\nconst npm_events_package_1 = __webpack_require__(/*! npm-events-package */ \"./node_modules/npm-events-package/events.js\");\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst logger = new Logger_1.Logger('EnhancedEventEmitter');\nclass EnhancedEventEmitter extends npm_events_package_1.EventEmitter {\n    constructor() {\n        super();\n        this.setMaxListeners(Infinity);\n    }\n    emit(eventName, ...args) {\n        return super.emit(eventName, ...args);\n    }\n    /**\n     * Special addition to the EventEmitter API.\n     */\n    safeEmit(eventName, ...args) {\n        const numListeners = super.listenerCount(eventName);\n        try {\n            return super.emit(eventName, ...args);\n        }\n        catch (error) {\n            logger.error('safeEmit() | event listener threw an error [eventName:%s]:%o', eventName, error);\n            return Boolean(numListeners);\n        }\n    }\n    on(eventName, listener) {\n        super.on(eventName, listener);\n        return this;\n    }\n    off(eventName, listener) {\n        super.off(eventName, listener);\n        return this;\n    }\n    addListener(eventName, listener) {\n        super.on(eventName, listener);\n        return this;\n    }\n    prependListener(eventName, listener) {\n        super.prependListener(eventName, listener);\n        return this;\n    }\n    once(eventName, listener) {\n        super.once(eventName, listener);\n        return this;\n    }\n    prependOnceListener(eventName, listener) {\n        super.prependOnceListener(eventName, listener);\n        return this;\n    }\n    removeListener(eventName, listener) {\n        super.off(eventName, listener);\n        return this;\n    }\n    removeAllListeners(eventName) {\n        super.removeAllListeners(eventName);\n        return this;\n    }\n    listenerCount(eventName) {\n        return super.listenerCount(eventName);\n    }\n    listeners(eventName) {\n        return super.listeners(eventName);\n    }\n    rawListeners(eventName) {\n        return super.rawListeners(eventName);\n    }\n}\nexports.EnhancedEventEmitter = EnhancedEventEmitter;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/Logger.js":
/*!*****************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/Logger.js ***!
  \*****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Logger = void 0;\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\"));\nconst APP_NAME = 'mediasoup-client';\nclass Logger {\n    constructor(prefix) {\n        if (prefix) {\n            this._debug = (0, debug_1.default)(`${APP_NAME}:${prefix}`);\n            this._warn = (0, debug_1.default)(`${APP_NAME}:WARN:${prefix}`);\n            this._error = (0, debug_1.default)(`${APP_NAME}:ERROR:${prefix}`);\n        }\n        else {\n            this._debug = (0, debug_1.default)(APP_NAME);\n            this._warn = (0, debug_1.default)(`${APP_NAME}:WARN`);\n            this._error = (0, debug_1.default)(`${APP_NAME}:ERROR`);\n        }\n        /* eslint-disable no-console */\n        this._debug.log = console.info.bind(console);\n        this._warn.log = console.warn.bind(console);\n        this._error.log = console.error.bind(console);\n        /* eslint-enable no-console */\n    }\n    get debug() {\n        return this._debug;\n    }\n    get warn() {\n        return this._warn;\n    }\n    get error() {\n        return this._error;\n    }\n}\nexports.Logger = Logger;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/Logger.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/Producer.js":
/*!*******************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/Producer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Producer = void 0;\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ./EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst logger = new Logger_1.Logger('Producer');\nclass Producer extends EnhancedEventEmitter_1.EnhancedEventEmitter {\n    constructor({ id, localId, rtpSender, track, rtpParameters, stopTracks, disableTrackOnPause, zeroRtpOnPause, appData, }) {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Observer instance.\n        this._observer = new EnhancedEventEmitter_1.EnhancedEventEmitter();\n        logger.debug('constructor()');\n        this._id = id;\n        this._localId = localId;\n        this._rtpSender = rtpSender;\n        this._track = track;\n        this._kind = track.kind;\n        this._rtpParameters = rtpParameters;\n        this._paused = disableTrackOnPause ? !track.enabled : false;\n        this._maxSpatialLayer = undefined;\n        this._stopTracks = stopTracks;\n        this._disableTrackOnPause = disableTrackOnPause;\n        this._zeroRtpOnPause = zeroRtpOnPause;\n        this._appData = appData || {};\n        this.onTrackEnded = this.onTrackEnded.bind(this);\n        // NOTE: Minor issue. If zeroRtpOnPause is true, we cannot emit the\n        // '@replacetrack' event here, so RTCRtpSender.track won't be null.\n        this.handleTrack();\n    }\n    /**\n     * Producer id.\n     */\n    get id() {\n        return this._id;\n    }\n    /**\n     * Local id.\n     */\n    get localId() {\n        return this._localId;\n    }\n    /**\n     * Whether the Producer is closed.\n     */\n    get closed() {\n        return this._closed;\n    }\n    /**\n     * Media kind.\n     */\n    get kind() {\n        return this._kind;\n    }\n    /**\n     * Associated RTCRtpSender.\n     */\n    get rtpSender() {\n        return this._rtpSender;\n    }\n    /**\n     * The associated track.\n     */\n    get track() {\n        return this._track;\n    }\n    /**\n     * RTP parameters.\n     */\n    get rtpParameters() {\n        return this._rtpParameters;\n    }\n    /**\n     * Whether the Producer is paused.\n     */\n    get paused() {\n        return this._paused;\n    }\n    /**\n     * Max spatial layer.\n     *\n     * @type {Number | undefined}\n     */\n    get maxSpatialLayer() {\n        return this._maxSpatialLayer;\n    }\n    /**\n     * App custom data.\n     */\n    get appData() {\n        return this._appData;\n    }\n    /**\n     * App custom data setter.\n     */\n    set appData(appData) {\n        this._appData = appData;\n    }\n    get observer() {\n        return this._observer;\n    }\n    /**\n     * Closes the Producer.\n     */\n    close() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('close()');\n        this._closed = true;\n        this.destroyTrack();\n        this.emit('@close');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Transport was closed.\n     */\n    transportClosed() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('transportClosed()');\n        this._closed = true;\n        this.destroyTrack();\n        this.safeEmit('transportclose');\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Get associated RTCRtpSender stats.\n     */\n    async getStats() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        return new Promise((resolve, reject) => {\n            this.safeEmit('@getstats', resolve, reject);\n        });\n    }\n    /**\n     * Pauses sending media.\n     */\n    pause() {\n        logger.debug('pause()');\n        if (this._closed) {\n            logger.error('pause() | Producer closed');\n            return;\n        }\n        this._paused = true;\n        if (this._track && this._disableTrackOnPause) {\n            this._track.enabled = false;\n        }\n        if (this._zeroRtpOnPause) {\n            new Promise((resolve, reject) => {\n                this.safeEmit('@pause', resolve, reject);\n            }).catch(() => { });\n        }\n        // Emit observer event.\n        this._observer.safeEmit('pause');\n    }\n    /**\n     * Resumes sending media.\n     */\n    resume() {\n        logger.debug('resume()');\n        if (this._closed) {\n            logger.error('resume() | Producer closed');\n            return;\n        }\n        this._paused = false;\n        if (this._track && this._disableTrackOnPause) {\n            this._track.enabled = true;\n        }\n        if (this._zeroRtpOnPause) {\n            new Promise((resolve, reject) => {\n                this.safeEmit('@resume', resolve, reject);\n            }).catch(() => { });\n        }\n        // Emit observer event.\n        this._observer.safeEmit('resume');\n    }\n    /**\n     * Replaces the current track with a new one or null.\n     */\n    async replaceTrack({ track, }) {\n        logger.debug('replaceTrack() [track:%o]', track);\n        if (this._closed) {\n            // This must be done here. Otherwise there is no chance to stop the given\n            // track.\n            if (track && this._stopTracks) {\n                try {\n                    track.stop();\n                }\n                catch (error) { }\n            }\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (track && track.readyState === 'ended') {\n            throw new errors_1.InvalidStateError('track ended');\n        }\n        // Do nothing if this is the same track as the current handled one.\n        if (track === this._track) {\n            logger.debug('replaceTrack() | same track, ignored');\n            return;\n        }\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@replacetrack', track, resolve, reject);\n        });\n        // Destroy the previous track.\n        this.destroyTrack();\n        // Set the new track.\n        this._track = track;\n        // If this Producer was paused/resumed and the state of the new\n        // track does not match, fix it.\n        if (this._track && this._disableTrackOnPause) {\n            if (!this._paused) {\n                this._track.enabled = true;\n            }\n            else if (this._paused) {\n                this._track.enabled = false;\n            }\n        }\n        // Handle the effective track.\n        this.handleTrack();\n    }\n    /**\n     * Sets the video max spatial layer to be sent.\n     */\n    async setMaxSpatialLayer(spatialLayer) {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (this._kind !== 'video') {\n            throw new errors_1.UnsupportedError('not a video Producer');\n        }\n        else if (typeof spatialLayer !== 'number') {\n            throw new TypeError('invalid spatialLayer');\n        }\n        if (spatialLayer === this._maxSpatialLayer) {\n            return;\n        }\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@setmaxspatiallayer', spatialLayer, resolve, reject);\n        }).catch(() => { });\n        this._maxSpatialLayer = spatialLayer;\n    }\n    async setRtpEncodingParameters(params) {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (typeof params !== 'object') {\n            throw new TypeError('invalid params');\n        }\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@setrtpencodingparameters', params, resolve, reject);\n        });\n    }\n    onTrackEnded() {\n        logger.debug('track \"ended\" event');\n        this.safeEmit('trackended');\n        // Emit observer event.\n        this._observer.safeEmit('trackended');\n    }\n    handleTrack() {\n        if (!this._track) {\n            return;\n        }\n        this._track.addEventListener('ended', this.onTrackEnded);\n    }\n    destroyTrack() {\n        if (!this._track) {\n            return;\n        }\n        try {\n            this._track.removeEventListener('ended', this.onTrackEnded);\n            // Just stop the track unless the app set stopTracks: false.\n            if (this._stopTracks) {\n                this._track.stop();\n            }\n        }\n        catch (error) { }\n    }\n}\nexports.Producer = Producer;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/Producer.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/RtpParameters.js":
/*!************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/RtpParameters.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n/**\n * The RTP capabilities define what mediasoup or an endpoint can receive at\n * media level.\n */\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/RtpParameters.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/SctpParameters.js":
/*!*************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/SctpParameters.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/SctpParameters.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/Transport.js":
/*!********************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/Transport.js ***!
  \********************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Transport = void 0;\nconst awaitqueue_1 = __webpack_require__(/*! awaitqueue */ \"./node_modules/awaitqueue/lib/index.js\");\nconst queue_microtask_1 = __importDefault(__webpack_require__(/*! queue-microtask */ \"./node_modules/queue-microtask/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ./Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ./EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nconst errors_1 = __webpack_require__(/*! ./errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ./utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ./ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst Producer_1 = __webpack_require__(/*! ./Producer */ \"./node_modules/mediasoup-client/lib/Producer.js\");\nconst Consumer_1 = __webpack_require__(/*! ./Consumer */ \"./node_modules/mediasoup-client/lib/Consumer.js\");\nconst DataProducer_1 = __webpack_require__(/*! ./DataProducer */ \"./node_modules/mediasoup-client/lib/DataProducer.js\");\nconst DataConsumer_1 = __webpack_require__(/*! ./DataConsumer */ \"./node_modules/mediasoup-client/lib/DataConsumer.js\");\nconst logger = new Logger_1.Logger('Transport');\nclass ConsumerCreationTask {\n    constructor(consumerOptions) {\n        this.consumerOptions = consumerOptions;\n        this.promise = new Promise((resolve, reject) => {\n            this.resolve = resolve;\n            this.reject = reject;\n        });\n    }\n}\nclass Transport extends EnhancedEventEmitter_1.EnhancedEventEmitter {\n    constructor({ direction, id, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, appData, handlerFactory, extendedRtpCapabilities, canProduceByKind, }) {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Transport ICE gathering state.\n        this._iceGatheringState = 'new';\n        // Transport connection state.\n        this._connectionState = 'new';\n        // Map of Producers indexed by id.\n        this._producers = new Map();\n        // Map of Consumers indexed by id.\n        this._consumers = new Map();\n        // Map of DataProducers indexed by id.\n        this._dataProducers = new Map();\n        // Map of DataConsumers indexed by id.\n        this._dataConsumers = new Map();\n        // Whether the Consumer for RTP probation has been created.\n        this._probatorConsumerCreated = false;\n        // AwaitQueue instance to make async tasks happen sequentially.\n        this._awaitQueue = new awaitqueue_1.AwaitQueue();\n        // Consumer creation tasks awaiting to be processed.\n        this._pendingConsumerTasks = [];\n        // Consumer creation in progress flag.\n        this._consumerCreationInProgress = false;\n        // Consumers pending to be paused.\n        this._pendingPauseConsumers = new Map();\n        // Consumer pause in progress flag.\n        this._consumerPauseInProgress = false;\n        // Consumers pending to be resumed.\n        this._pendingResumeConsumers = new Map();\n        // Consumer resume in progress flag.\n        this._consumerResumeInProgress = false;\n        // Consumers pending to be closed.\n        this._pendingCloseConsumers = new Map();\n        // Consumer close in progress flag.\n        this._consumerCloseInProgress = false;\n        // Observer instance.\n        this._observer = new EnhancedEventEmitter_1.EnhancedEventEmitter();\n        logger.debug('constructor() [id:%s, direction:%s]', id, direction);\n        this._id = id;\n        this._direction = direction;\n        this._extendedRtpCapabilities = extendedRtpCapabilities;\n        this._canProduceByKind = canProduceByKind;\n        this._maxSctpMessageSize = sctpParameters\n            ? sctpParameters.maxMessageSize\n            : null;\n        // Clone and sanitize additionalSettings.\n        const clonedAdditionalSettings = utils.clone(additionalSettings) || {};\n        delete clonedAdditionalSettings.iceServers;\n        delete clonedAdditionalSettings.iceTransportPolicy;\n        delete clonedAdditionalSettings.bundlePolicy;\n        delete clonedAdditionalSettings.rtcpMuxPolicy;\n        delete clonedAdditionalSettings.sdpSemantics;\n        this._handler = handlerFactory();\n        this._handler.run({\n            direction,\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n            iceServers,\n            iceTransportPolicy,\n            additionalSettings: clonedAdditionalSettings,\n            proprietaryConstraints,\n            extendedRtpCapabilities,\n        });\n        this._appData = appData || {};\n        this.handleHandler();\n    }\n    /**\n     * Transport id.\n     */\n    get id() {\n        return this._id;\n    }\n    /**\n     * Whether the Transport is closed.\n     */\n    get closed() {\n        return this._closed;\n    }\n    /**\n     * Transport direction.\n     */\n    get direction() {\n        return this._direction;\n    }\n    /**\n     * RTC handler instance.\n     */\n    get handler() {\n        return this._handler;\n    }\n    /**\n     * ICE gathering state.\n     */\n    get iceGatheringState() {\n        return this._iceGatheringState;\n    }\n    /**\n     * Connection state.\n     */\n    get connectionState() {\n        return this._connectionState;\n    }\n    /**\n     * App custom data.\n     */\n    get appData() {\n        return this._appData;\n    }\n    /**\n     * App custom data setter.\n     */\n    set appData(appData) {\n        this._appData = appData;\n    }\n    get observer() {\n        return this._observer;\n    }\n    /**\n     * Close the Transport.\n     */\n    close() {\n        if (this._closed) {\n            return;\n        }\n        logger.debug('close()');\n        this._closed = true;\n        // Stop the AwaitQueue.\n        this._awaitQueue.stop();\n        // Close the handler.\n        this._handler.close();\n        // Change connection state to 'closed' since the handler may not emit\n        // '@connectionstatechange' event.\n        this._connectionState = 'closed';\n        // Close all Producers.\n        for (const producer of this._producers.values()) {\n            producer.transportClosed();\n        }\n        this._producers.clear();\n        // Close all Consumers.\n        for (const consumer of this._consumers.values()) {\n            consumer.transportClosed();\n        }\n        this._consumers.clear();\n        // Close all DataProducers.\n        for (const dataProducer of this._dataProducers.values()) {\n            dataProducer.transportClosed();\n        }\n        this._dataProducers.clear();\n        // Close all DataConsumers.\n        for (const dataConsumer of this._dataConsumers.values()) {\n            dataConsumer.transportClosed();\n        }\n        this._dataConsumers.clear();\n        // Emit observer event.\n        this._observer.safeEmit('close');\n    }\n    /**\n     * Get associated Transport (RTCPeerConnection) stats.\n     *\n     * @returns {RTCStatsReport}\n     */\n    async getStats() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        return this._handler.getTransportStats();\n    }\n    /**\n     * Restart ICE connection.\n     */\n    async restartIce({ iceParameters, }) {\n        logger.debug('restartIce()');\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (!iceParameters) {\n            throw new TypeError('missing iceParameters');\n        }\n        // Enqueue command.\n        return this._awaitQueue.push(async () => await this._handler.restartIce(iceParameters), 'transport.restartIce()');\n    }\n    /**\n     * Update ICE servers.\n     */\n    async updateIceServers({ iceServers, } = {}) {\n        logger.debug('updateIceServers()');\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (!Array.isArray(iceServers)) {\n            throw new TypeError('missing iceServers');\n        }\n        // Enqueue command.\n        return this._awaitQueue.push(async () => this._handler.updateIceServers(iceServers), 'transport.updateIceServers()');\n    }\n    /**\n     * Create a Producer.\n     */\n    async produce({ track, encodings, codecOptions, codec, stopTracks = true, disableTrackOnPause = true, zeroRtpOnPause = false, onRtpSender, appData = {}, } = {}) {\n        logger.debug('produce() [track:%o]', track);\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (!track) {\n            throw new TypeError('missing track');\n        }\n        else if (this._direction !== 'send') {\n            throw new errors_1.UnsupportedError('not a sending Transport');\n        }\n        else if (!this._canProduceByKind[track.kind]) {\n            throw new errors_1.UnsupportedError(`cannot produce ${track.kind}`);\n        }\n        else if (track.readyState === 'ended') {\n            throw new errors_1.InvalidStateError('track ended');\n        }\n        else if (this.listenerCount('connect') === 0 &&\n            this._connectionState === 'new') {\n            throw new TypeError('no \"connect\" listener set into this transport');\n        }\n        else if (this.listenerCount('produce') === 0) {\n            throw new TypeError('no \"produce\" listener set into this transport');\n        }\n        else if (appData && typeof appData !== 'object') {\n            throw new TypeError('if given, appData must be an object');\n        }\n        // Enqueue command.\n        return (this._awaitQueue\n            .push(async () => {\n            let normalizedEncodings;\n            if (encodings && !Array.isArray(encodings)) {\n                throw TypeError('encodings must be an array');\n            }\n            else if (encodings && encodings.length === 0) {\n                normalizedEncodings = undefined;\n            }\n            else if (encodings) {\n                normalizedEncodings = encodings.map((encoding) => {\n                    const normalizedEncoding = { active: true };\n                    if (encoding.active === false) {\n                        normalizedEncoding.active = false;\n                    }\n                    if (typeof encoding.dtx === 'boolean') {\n                        normalizedEncoding.dtx = encoding.dtx;\n                    }\n                    if (typeof encoding.scalabilityMode === 'string') {\n                        normalizedEncoding.scalabilityMode = encoding.scalabilityMode;\n                    }\n                    if (typeof encoding.scaleResolutionDownBy === 'number') {\n                        normalizedEncoding.scaleResolutionDownBy =\n                            encoding.scaleResolutionDownBy;\n                    }\n                    if (typeof encoding.maxBitrate === 'number') {\n                        normalizedEncoding.maxBitrate = encoding.maxBitrate;\n                    }\n                    if (typeof encoding.maxFramerate === 'number') {\n                        normalizedEncoding.maxFramerate = encoding.maxFramerate;\n                    }\n                    if (typeof encoding.adaptivePtime === 'boolean') {\n                        normalizedEncoding.adaptivePtime = encoding.adaptivePtime;\n                    }\n                    if (typeof encoding.priority === 'string') {\n                        normalizedEncoding.priority = encoding.priority;\n                    }\n                    if (typeof encoding.networkPriority === 'string') {\n                        normalizedEncoding.networkPriority = encoding.networkPriority;\n                    }\n                    return normalizedEncoding;\n                });\n            }\n            const { localId, rtpParameters, rtpSender } = await this._handler.send({\n                track,\n                encodings: normalizedEncodings,\n                codecOptions,\n                codec,\n                onRtpSender,\n            });\n            try {\n                // This will fill rtpParameters's missing fields with default values.\n                ortc.validateRtpParameters(rtpParameters);\n                const { id } = await new Promise((resolve, reject) => {\n                    this.safeEmit('produce', {\n                        kind: track.kind,\n                        rtpParameters,\n                        appData,\n                    }, resolve, reject);\n                });\n                const producer = new Producer_1.Producer({\n                    id,\n                    localId,\n                    rtpSender,\n                    track,\n                    rtpParameters,\n                    stopTracks,\n                    disableTrackOnPause,\n                    zeroRtpOnPause,\n                    appData,\n                });\n                this._producers.set(producer.id, producer);\n                this.handleProducer(producer);\n                // Emit observer event.\n                this._observer.safeEmit('newproducer', producer);\n                return producer;\n            }\n            catch (error) {\n                this._handler.stopSending(localId).catch(() => { });\n                throw error;\n            }\n        }, 'transport.produce()')\n            // This catch is needed to stop the given track if the command above\n            // failed due to closed Transport.\n            .catch((error) => {\n            if (stopTracks) {\n                try {\n                    track.stop();\n                }\n                catch (error2) { }\n            }\n            throw error;\n        }));\n    }\n    /**\n     * Create a Consumer to consume a remote Producer.\n     */\n    async consume({ id, producerId, kind, rtpParameters, streamId, onRtpReceiver, appData = {}, }) {\n        logger.debug('consume()');\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (this._direction !== 'recv') {\n            throw new errors_1.UnsupportedError('not a receiving Transport');\n        }\n        else if (typeof id !== 'string') {\n            throw new TypeError('missing id');\n        }\n        else if (typeof producerId !== 'string') {\n            throw new TypeError('missing producerId');\n        }\n        else if (kind !== 'audio' && kind !== 'video') {\n            throw new TypeError(`invalid kind '${kind}'`);\n        }\n        else if (this.listenerCount('connect') === 0 &&\n            this._connectionState === 'new') {\n            throw new TypeError('no \"connect\" listener set into this transport');\n        }\n        else if (appData && typeof appData !== 'object') {\n            throw new TypeError('if given, appData must be an object');\n        }\n        // Clone given RTP parameters to not modify input data.\n        const clonedRtpParameters = utils.clone(rtpParameters);\n        // Ensure the device can consume it.\n        const canConsume = ortc.canReceive(clonedRtpParameters, this._extendedRtpCapabilities);\n        if (!canConsume) {\n            throw new errors_1.UnsupportedError('cannot consume this Producer');\n        }\n        const consumerCreationTask = new ConsumerCreationTask({\n            id,\n            producerId,\n            kind,\n            rtpParameters: clonedRtpParameters,\n            streamId,\n            onRtpReceiver,\n            appData,\n        });\n        // Store the Consumer creation task.\n        this._pendingConsumerTasks.push(consumerCreationTask);\n        // There is no Consumer creation in progress, create it now.\n        (0, queue_microtask_1.default)(() => {\n            if (this._closed) {\n                return;\n            }\n            if (this._consumerCreationInProgress === false) {\n                this.createPendingConsumers();\n            }\n        });\n        return consumerCreationTask.promise;\n    }\n    /**\n     * Create a DataProducer\n     */\n    async produceData({ ordered = true, maxPacketLifeTime, maxRetransmits, label = '', protocol = '', appData = {}, } = {}) {\n        logger.debug('produceData()');\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (this._direction !== 'send') {\n            throw new errors_1.UnsupportedError('not a sending Transport');\n        }\n        else if (!this._maxSctpMessageSize) {\n            throw new errors_1.UnsupportedError('SCTP not enabled by remote Transport');\n        }\n        else if (this.listenerCount('connect') === 0 &&\n            this._connectionState === 'new') {\n            throw new TypeError('no \"connect\" listener set into this transport');\n        }\n        else if (this.listenerCount('producedata') === 0) {\n            throw new TypeError('no \"producedata\" listener set into this transport');\n        }\n        else if (appData && typeof appData !== 'object') {\n            throw new TypeError('if given, appData must be an object');\n        }\n        if (maxPacketLifeTime || maxRetransmits) {\n            ordered = false;\n        }\n        // Enqueue command.\n        return this._awaitQueue.push(async () => {\n            const { dataChannel, sctpStreamParameters } = await this._handler.sendDataChannel({\n                ordered,\n                maxPacketLifeTime,\n                maxRetransmits,\n                label,\n                protocol,\n            });\n            // This will fill sctpStreamParameters's missing fields with default values.\n            ortc.validateSctpStreamParameters(sctpStreamParameters);\n            const { id } = await new Promise((resolve, reject) => {\n                this.safeEmit('producedata', {\n                    sctpStreamParameters,\n                    label,\n                    protocol,\n                    appData,\n                }, resolve, reject);\n            });\n            const dataProducer = new DataProducer_1.DataProducer({\n                id,\n                dataChannel,\n                sctpStreamParameters,\n                appData,\n            });\n            this._dataProducers.set(dataProducer.id, dataProducer);\n            this.handleDataProducer(dataProducer);\n            // Emit observer event.\n            this._observer.safeEmit('newdataproducer', dataProducer);\n            return dataProducer;\n        }, 'transport.produceData()');\n    }\n    /**\n     * Create a DataConsumer\n     */\n    async consumeData({ id, dataProducerId, sctpStreamParameters, label = '', protocol = '', appData = {}, }) {\n        logger.debug('consumeData()');\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('closed');\n        }\n        else if (this._direction !== 'recv') {\n            throw new errors_1.UnsupportedError('not a receiving Transport');\n        }\n        else if (!this._maxSctpMessageSize) {\n            throw new errors_1.UnsupportedError('SCTP not enabled by remote Transport');\n        }\n        else if (typeof id !== 'string') {\n            throw new TypeError('missing id');\n        }\n        else if (typeof dataProducerId !== 'string') {\n            throw new TypeError('missing dataProducerId');\n        }\n        else if (this.listenerCount('connect') === 0 &&\n            this._connectionState === 'new') {\n            throw new TypeError('no \"connect\" listener set into this transport');\n        }\n        else if (appData && typeof appData !== 'object') {\n            throw new TypeError('if given, appData must be an object');\n        }\n        // Clone given SCTP stream parameters to not modify input data.\n        const clonedSctpStreamParameters = utils.clone(sctpStreamParameters);\n        // This may throw.\n        ortc.validateSctpStreamParameters(clonedSctpStreamParameters);\n        // Enqueue command.\n        return this._awaitQueue.push(async () => {\n            const { dataChannel } = await this._handler.receiveDataChannel({\n                sctpStreamParameters: clonedSctpStreamParameters,\n                label,\n                protocol,\n            });\n            const dataConsumer = new DataConsumer_1.DataConsumer({\n                id,\n                dataProducerId,\n                dataChannel,\n                sctpStreamParameters: clonedSctpStreamParameters,\n                appData,\n            });\n            this._dataConsumers.set(dataConsumer.id, dataConsumer);\n            this.handleDataConsumer(dataConsumer);\n            // Emit observer event.\n            this._observer.safeEmit('newdataconsumer', dataConsumer);\n            return dataConsumer;\n        }, 'transport.consumeData()');\n    }\n    // This method is guaranteed to never throw.\n    async createPendingConsumers() {\n        this._consumerCreationInProgress = true;\n        this._awaitQueue\n            .push(async () => {\n            if (this._pendingConsumerTasks.length === 0) {\n                logger.debug('createPendingConsumers() | there is no Consumer to be created');\n                return;\n            }\n            const pendingConsumerTasks = [...this._pendingConsumerTasks];\n            // Clear pending Consumer tasks.\n            this._pendingConsumerTasks = [];\n            // Video Consumer in order to create the probator.\n            let videoConsumerForProbator = undefined;\n            // Fill options list.\n            const optionsList = [];\n            for (const task of pendingConsumerTasks) {\n                const { id, kind, rtpParameters, streamId, onRtpReceiver } = task.consumerOptions;\n                optionsList.push({\n                    trackId: id,\n                    kind: kind,\n                    rtpParameters,\n                    streamId,\n                    onRtpReceiver,\n                });\n            }\n            try {\n                const results = await this._handler.receive(optionsList);\n                for (let idx = 0; idx < results.length; ++idx) {\n                    const task = pendingConsumerTasks[idx];\n                    const result = results[idx];\n                    const { id, producerId, kind, rtpParameters, appData } = task.consumerOptions;\n                    const { localId, rtpReceiver, track } = result;\n                    const consumer = new Consumer_1.Consumer({\n                        id: id,\n                        localId,\n                        producerId: producerId,\n                        rtpReceiver,\n                        track,\n                        rtpParameters,\n                        appData: appData,\n                    });\n                    this._consumers.set(consumer.id, consumer);\n                    this.handleConsumer(consumer);\n                    // If this is the first video Consumer and the Consumer for RTP probation\n                    // has not yet been created, it's time to create it.\n                    if (!this._probatorConsumerCreated &&\n                        !videoConsumerForProbator &&\n                        kind === 'video') {\n                        videoConsumerForProbator = consumer;\n                    }\n                    // Emit observer event.\n                    this._observer.safeEmit('newconsumer', consumer);\n                    task.resolve(consumer);\n                }\n            }\n            catch (error) {\n                for (const task of pendingConsumerTasks) {\n                    task.reject(error);\n                }\n            }\n            // If RTP probation must be handled, do it now.\n            if (videoConsumerForProbator) {\n                try {\n                    const probatorRtpParameters = ortc.generateProbatorRtpParameters(videoConsumerForProbator.rtpParameters);\n                    await this._handler.receive([\n                        {\n                            trackId: 'probator',\n                            kind: 'video',\n                            rtpParameters: probatorRtpParameters,\n                        },\n                    ]);\n                    logger.debug('createPendingConsumers() | Consumer for RTP probation created');\n                    this._probatorConsumerCreated = true;\n                }\n                catch (error) {\n                    logger.error('createPendingConsumers() | failed to create Consumer for RTP probation:%o', error);\n                }\n            }\n        }, 'transport.createPendingConsumers()')\n            .then(() => {\n            this._consumerCreationInProgress = false;\n            // There are pending Consumer tasks, enqueue their creation.\n            if (this._pendingConsumerTasks.length > 0) {\n                this.createPendingConsumers();\n            }\n        })\n            // NOTE: We only get here when the await queue is closed.\n            .catch(() => { });\n    }\n    pausePendingConsumers() {\n        this._consumerPauseInProgress = true;\n        this._awaitQueue\n            .push(async () => {\n            if (this._pendingPauseConsumers.size === 0) {\n                logger.debug('pausePendingConsumers() | there is no Consumer to be paused');\n                return;\n            }\n            const pendingPauseConsumers = Array.from(this._pendingPauseConsumers.values());\n            // Clear pending pause Consumer map.\n            this._pendingPauseConsumers.clear();\n            try {\n                const localIds = pendingPauseConsumers.map(consumer => consumer.localId);\n                await this._handler.pauseReceiving(localIds);\n            }\n            catch (error) {\n                logger.error('pausePendingConsumers() | failed to pause Consumers:', error);\n            }\n        }, 'transport.pausePendingConsumers')\n            .then(() => {\n            this._consumerPauseInProgress = false;\n            // There are pending Consumers to be paused, do it.\n            if (this._pendingPauseConsumers.size > 0) {\n                this.pausePendingConsumers();\n            }\n        })\n            // NOTE: We only get here when the await queue is closed.\n            .catch(() => { });\n    }\n    resumePendingConsumers() {\n        this._consumerResumeInProgress = true;\n        this._awaitQueue\n            .push(async () => {\n            if (this._pendingResumeConsumers.size === 0) {\n                logger.debug('resumePendingConsumers() | there is no Consumer to be resumed');\n                return;\n            }\n            const pendingResumeConsumers = Array.from(this._pendingResumeConsumers.values());\n            // Clear pending resume Consumer map.\n            this._pendingResumeConsumers.clear();\n            try {\n                const localIds = pendingResumeConsumers.map(consumer => consumer.localId);\n                await this._handler.resumeReceiving(localIds);\n            }\n            catch (error) {\n                logger.error('resumePendingConsumers() | failed to resume Consumers:', error);\n            }\n        }, 'transport.resumePendingConsumers')\n            .then(() => {\n            this._consumerResumeInProgress = false;\n            // There are pending Consumer to be resumed, do it.\n            if (this._pendingResumeConsumers.size > 0) {\n                this.resumePendingConsumers();\n            }\n        })\n            // NOTE: We only get here when the await queue is closed.\n            .catch(() => { });\n    }\n    closePendingConsumers() {\n        this._consumerCloseInProgress = true;\n        this._awaitQueue\n            .push(async () => {\n            if (this._pendingCloseConsumers.size === 0) {\n                logger.debug('closePendingConsumers() | there is no Consumer to be closed');\n                return;\n            }\n            const pendingCloseConsumers = Array.from(this._pendingCloseConsumers.values());\n            // Clear pending close Consumer map.\n            this._pendingCloseConsumers.clear();\n            try {\n                await this._handler.stopReceiving(pendingCloseConsumers.map(consumer => consumer.localId));\n            }\n            catch (error) {\n                logger.error('closePendingConsumers() | failed to close Consumers:', error);\n            }\n        }, 'transport.closePendingConsumers')\n            .then(() => {\n            this._consumerCloseInProgress = false;\n            // There are pending Consumer to be resumed, do it.\n            if (this._pendingCloseConsumers.size > 0) {\n                this.closePendingConsumers();\n            }\n        })\n            // NOTE: We only get here when the await queue is closed.\n            .catch(() => { });\n    }\n    handleHandler() {\n        const handler = this._handler;\n        handler.on('@connect', ({ dtlsParameters }, callback, errback) => {\n            if (this._closed) {\n                errback(new errors_1.InvalidStateError('closed'));\n                return;\n            }\n            this.safeEmit('connect', { dtlsParameters }, callback, errback);\n        });\n        handler.on('@icegatheringstatechange', (iceGatheringState) => {\n            if (iceGatheringState === this._iceGatheringState) {\n                return;\n            }\n            logger.debug('ICE gathering state changed to %s', iceGatheringState);\n            this._iceGatheringState = iceGatheringState;\n            if (!this._closed) {\n                this.safeEmit('icegatheringstatechange', iceGatheringState);\n            }\n        });\n        handler.on('@connectionstatechange', (connectionState) => {\n            if (connectionState === this._connectionState) {\n                return;\n            }\n            logger.debug('connection state changed to %s', connectionState);\n            this._connectionState = connectionState;\n            if (!this._closed) {\n                this.safeEmit('connectionstatechange', connectionState);\n            }\n        });\n    }\n    handleProducer(producer) {\n        producer.on('@close', () => {\n            this._producers.delete(producer.id);\n            if (this._closed) {\n                return;\n            }\n            this._awaitQueue\n                .push(async () => await this._handler.stopSending(producer.localId), 'producer @close event')\n                .catch((error) => logger.warn('producer.close() failed:%o', error));\n        });\n        producer.on('@pause', (callback, errback) => {\n            this._awaitQueue\n                .push(async () => await this._handler.pauseSending(producer.localId), 'producer @pause event')\n                .then(callback)\n                .catch(errback);\n        });\n        producer.on('@resume', (callback, errback) => {\n            this._awaitQueue\n                .push(async () => await this._handler.resumeSending(producer.localId), 'producer @resume event')\n                .then(callback)\n                .catch(errback);\n        });\n        producer.on('@replacetrack', (track, callback, errback) => {\n            this._awaitQueue\n                .push(async () => await this._handler.replaceTrack(producer.localId, track), 'producer @replacetrack event')\n                .then(callback)\n                .catch(errback);\n        });\n        producer.on('@setmaxspatiallayer', (spatialLayer, callback, errback) => {\n            this._awaitQueue\n                .push(async () => await this._handler.setMaxSpatialLayer(producer.localId, spatialLayer), 'producer @setmaxspatiallayer event')\n                .then(callback)\n                .catch(errback);\n        });\n        producer.on('@setrtpencodingparameters', (params, callback, errback) => {\n            this._awaitQueue\n                .push(async () => await this._handler.setRtpEncodingParameters(producer.localId, params), 'producer @setrtpencodingparameters event')\n                .then(callback)\n                .catch(errback);\n        });\n        producer.on('@getstats', (callback, errback) => {\n            if (this._closed) {\n                return errback(new errors_1.InvalidStateError('closed'));\n            }\n            this._handler\n                .getSenderStats(producer.localId)\n                .then(callback)\n                .catch(errback);\n        });\n    }\n    handleConsumer(consumer) {\n        consumer.on('@close', () => {\n            this._consumers.delete(consumer.id);\n            this._pendingPauseConsumers.delete(consumer.id);\n            this._pendingResumeConsumers.delete(consumer.id);\n            if (this._closed) {\n                return;\n            }\n            // Store the Consumer into the close list.\n            this._pendingCloseConsumers.set(consumer.id, consumer);\n            // There is no Consumer close in progress, do it now.\n            if (this._consumerCloseInProgress === false) {\n                this.closePendingConsumers();\n            }\n        });\n        consumer.on('@pause', () => {\n            // If Consumer is pending to be resumed, remove from pending resume list.\n            if (this._pendingResumeConsumers.has(consumer.id)) {\n                this._pendingResumeConsumers.delete(consumer.id);\n            }\n            // Store the Consumer into the pending list.\n            this._pendingPauseConsumers.set(consumer.id, consumer);\n            // There is no Consumer pause in progress, do it now.\n            (0, queue_microtask_1.default)(() => {\n                if (this._closed) {\n                    return;\n                }\n                if (this._consumerPauseInProgress === false) {\n                    this.pausePendingConsumers();\n                }\n            });\n        });\n        consumer.on('@resume', () => {\n            // If Consumer is pending to be paused, remove from pending pause list.\n            if (this._pendingPauseConsumers.has(consumer.id)) {\n                this._pendingPauseConsumers.delete(consumer.id);\n            }\n            // Store the Consumer into the pending list.\n            this._pendingResumeConsumers.set(consumer.id, consumer);\n            // There is no Consumer resume in progress, do it now.\n            (0, queue_microtask_1.default)(() => {\n                if (this._closed) {\n                    return;\n                }\n                if (this._consumerResumeInProgress === false) {\n                    this.resumePendingConsumers();\n                }\n            });\n        });\n        consumer.on('@getstats', (callback, errback) => {\n            if (this._closed) {\n                return errback(new errors_1.InvalidStateError('closed'));\n            }\n            this._handler\n                .getReceiverStats(consumer.localId)\n                .then(callback)\n                .catch(errback);\n        });\n    }\n    handleDataProducer(dataProducer) {\n        dataProducer.on('@close', () => {\n            this._dataProducers.delete(dataProducer.id);\n        });\n    }\n    handleDataConsumer(dataConsumer) {\n        dataConsumer.on('@close', () => {\n            this._dataConsumers.delete(dataConsumer.id);\n        });\n    }\n}\nexports.Transport = Transport;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/Transport.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/errors.js":
/*!*****************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/errors.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.InvalidStateError = exports.UnsupportedError = void 0;\n/**\n * Error indicating not support for something.\n */\nclass UnsupportedError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = 'UnsupportedError';\n        if (Error.hasOwnProperty('captureStackTrace')) {\n            // Just in V8.\n            // @ts-ignore\n            Error.captureStackTrace(this, UnsupportedError);\n        }\n        else {\n            this.stack = new Error(message).stack;\n        }\n    }\n}\nexports.UnsupportedError = UnsupportedError;\n/**\n * Error produced when calling a method in an invalid state.\n */\nclass InvalidStateError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = 'InvalidStateError';\n        if (Error.hasOwnProperty('captureStackTrace')) {\n            // Just in V8.\n            // @ts-ignore\n            Error.captureStackTrace(this, InvalidStateError);\n        }\n        else {\n            this.stack = new Error(message).stack;\n        }\n    }\n}\nexports.InvalidStateError = InvalidStateError;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/errors.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Chrome111.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Chrome111.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Chrome111 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst ortcUtils = __importStar(__webpack_require__(/*! ./ortc/utils */ \"./node_modules/mediasoup-client/lib/handlers/ortc/utils.js\"));\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('Chrome111');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Chrome111 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Chrome111();\n    }\n    constructor() {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Chrome111';\n    }\n    close() {\n        logger.debug('close()');\n        if (this._closed) {\n            return;\n        }\n        this._closed = true;\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n        });\n        try {\n            pc.addTransceiver('audio');\n            pc.addTransceiver('video');\n            const offer = await pc.createOffer();\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            // libwebrtc supports NACK for OPUS but doesn't announce it.\n            ortcUtils.addNackSuppportForOpus(nativeRtpCapabilities);\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        this.assertNotClosed();\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        this.assertNotClosed();\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        this.assertNotClosed();\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        this.assertNotClosed();\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, onRtpSender, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (encodings && encodings.length > 1) {\n            // Set rid and verify scalabilityMode in each encoding.\n            // NOTE: Even if WebRTC allows different scalabilityMode (different number\n            // of temporal layers) per simulcast stream, we need that those are the\n            // same in all them, so let's pick up the highest value.\n            // NOTE: If scalabilityMode is not given, Chrome will use L1T3.\n            let maxTemporalLayers = 1;\n            for (const encoding of encodings) {\n                const temporalLayers = encoding.scalabilityMode\n                    ? (0, scalabilityModes_1.parse)(encoding.scalabilityMode).temporalLayers\n                    : 3;\n                if (temporalLayers > maxTemporalLayers) {\n                    maxTemporalLayers = temporalLayers;\n                }\n            }\n            encodings.forEach((encoding, idx) => {\n                encoding.rid = `r${idx}`;\n                encoding.scalabilityMode = `L1T${maxTemporalLayers}`;\n            });\n        }\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        const mediaSectionIdx = this._remoteSdp.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n            sendEncodings: encodings,\n        });\n        if (onRtpSender) {\n            onRtpSender(transceiver.sender);\n        }\n        const offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // We can now get the transceiver.mid.\n        const localId = transceiver.mid;\n        // Set MID.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        const offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings by parsing the SDP offer if no encodings are given.\n        if (!encodings) {\n            sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n        }\n        // Set RTP encodings by parsing the SDP offer and complete them with given\n        // one if just a single encoding has been given.\n        else if (encodings.length === 1) {\n            const newEncodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n            Object.assign(newEncodings[0], encodings[0]);\n            sendingRtpParameters.encodings = newEncodings;\n        }\n        // Otherwise if more than 1 encoding are given use them verbatim.\n        else {\n            sendingRtpParameters.encodings = encodings;\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            reuseMid: mediaSectionIdx.reuseMid,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n            extmapAllowMixed: true,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        if (this._closed) {\n            return;\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        this._pc.removeTrack(transceiver.sender);\n        const mediaSectionClosed = this._remoteSdp.closeMediaSection(transceiver.mid);\n        if (mediaSectionClosed) {\n            try {\n                transceiver.stop();\n            }\n            catch (error) { }\n        }\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    async pauseSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('pauseSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'inactive';\n        this._remoteSdp.pauseMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('pauseSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async resumeSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('resumeSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        this._remoteSdp.resumeSendingMediaSection(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'sendonly';\n        const offer = await this._pc.createOffer();\n        logger.debug('resumeSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async replaceTrack(localId, track) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        for (const options of optionsList) {\n            const { trackId, onRtpReceiver } = options;\n            if (onRtpReceiver) {\n                const localId = mapLocalId.get(trackId);\n                const transceiver = this._pc\n                    .getTransceivers()\n                    .find((t) => t.mid === localId);\n                if (!transceiver) {\n                    throw new Error('transceiver not found');\n                }\n                onRtpReceiver(transceiver.receiver);\n            }\n        }\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            else {\n                // Store in the map.\n                this._mapMidTransceiver.set(localId, transceiver);\n                results.push({\n                    localId,\n                    track: transceiver.receiver.track,\n                    rtpReceiver: transceiver.receiver,\n                });\n            }\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        if (this._closed) {\n            return;\n        }\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('pauseReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'inactive';\n            this._remoteSdp.pauseMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('pauseReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async resumeReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('resumeReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'recvonly';\n            this._remoteSdp.resumeReceivingMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('resumeReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertNotClosed() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('method called in a closed handler');\n        }\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Chrome111 = Chrome111;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Chrome111.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Chrome55.js":
/*!****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Chrome55.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Chrome55 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpPlanBUtils = __importStar(__webpack_require__(/*! ./sdp/planBUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst logger = new Logger_1.Logger('Chrome55');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Chrome55 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Chrome55();\n    }\n    constructor() {\n        super();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Map of sending MediaStreamTracks indexed by localId.\n        this._mapSendLocalIdTrack = new Map();\n        // Next sending localId.\n        this._nextSendLocalId = 0;\n        // Map of MID, RTP parameters and RTCRtpReceiver indexed by local id.\n        // Value is an Object with mid, rtpParameters and rtpReceiver.\n        this._mapRecvLocalIdInfo = new Map();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Chrome55';\n    }\n    close() {\n        logger.debug('close()');\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n        });\n        try {\n            const offer = await pc.createOffer({\n                offerToReceiveAudio: true,\n                offerToReceiveVideo: true,\n            });\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n            planB: true,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (codec) {\n            logger.warn('send() | codec selection is not available in %s handler', this.name);\n        }\n        this._sendStream.addTrack(track);\n        this._pc.addStream(this._sendStream);\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs);\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        if (track.kind === 'video' && encodings && encodings.length > 1) {\n            logger.debug('send() | enabling simulcast');\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media.find((m) => m.type === 'video');\n            sdpPlanBUtils.addLegacySimulcast({\n                offerMediaObject,\n                track,\n                numStreams: encodings.length,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media.find((m) => m.type === track.kind);\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings.\n        sendingRtpParameters.encodings = sdpPlanBUtils.getRtpEncodings({\n            offerMediaObject,\n            track,\n        });\n        // Complete encodings with given values.\n        if (encodings) {\n            for (let idx = 0; idx < sendingRtpParameters.encodings.length; ++idx) {\n                if (encodings[idx]) {\n                    Object.assign(sendingRtpParameters.encodings[idx], encodings[idx]);\n                }\n            }\n        }\n        // If VP8 and there is effective simulcast, add scalabilityMode to each\n        // encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8') {\n            for (const encoding of sendingRtpParameters.encodings) {\n                encoding.scalabilityMode = 'L1T3';\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        const localId = String(this._nextSendLocalId);\n        this._nextSendLocalId++;\n        // Insert into the map.\n        this._mapSendLocalIdTrack.set(localId, track);\n        return {\n            localId: localId,\n            rtpParameters: sendingRtpParameters,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        const track = this._mapSendLocalIdTrack.get(localId);\n        if (!track) {\n            throw new Error('track not found');\n        }\n        this._mapSendLocalIdTrack.delete(localId);\n        this._sendStream.removeTrack(track);\n        this._pc.addStream(this._sendStream);\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        try {\n            await this._pc.setLocalDescription(offer);\n        }\n        catch (error) {\n            // NOTE: If there are no sending tracks, setLocalDescription() will fail with\n            // \"Failed to create channels\". If so, ignore it.\n            if (this._sendStream.getTracks().length === 0) {\n                logger.warn('stopSending() | ignoring expected error due no sending tracks: %s', error.toString());\n                return;\n            }\n            throw error;\n        }\n        if (this._pc.signalingState === 'stable') {\n            return;\n        }\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        // Unimplemented.\n    }\n    async replaceTrack(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localId, \n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    track) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async setMaxSpatialLayer(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localId, \n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    spatialLayer) {\n        throw new errors_1.UnsupportedError(' not implemented');\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async setRtpEncodingParameters(localId, params) {\n        throw new errors_1.UnsupportedError('not supported');\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async getSenderStats(localId) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertRecvDirection();\n        const results = [];\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const mid = kind;\n            this._remoteSdp.receive({\n                mid,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { kind, rtpParameters } = options;\n            const mid = kind;\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === mid);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { kind, trackId, rtpParameters } = options;\n            const mid = kind;\n            const localId = trackId;\n            const streamId = options.streamId || rtpParameters.rtcp.cname;\n            const stream = this._pc\n                .getRemoteStreams()\n                .find((s) => s.id === streamId);\n            const track = stream.getTrackById(localId);\n            if (!track) {\n                throw new Error('remote track not found');\n            }\n            // Insert into the map.\n            this._mapRecvLocalIdInfo.set(localId, { mid, rtpParameters });\n            results.push({ localId, track });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const { mid, rtpParameters } = this._mapRecvLocalIdInfo.get(localId) || {};\n            // Remove from the map.\n            this._mapRecvLocalIdInfo.delete(localId);\n            this._remoteSdp.planBStopReceiving({\n                mid: mid,\n                offerRtpParameters: rtpParameters,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async pauseReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async resumeReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async getReceiverStats(localId) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation({ oldDataChannelSpec: true });\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Chrome55 = Chrome55;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Chrome55.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Chrome67.js":
/*!****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Chrome67.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Chrome67 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpPlanBUtils = __importStar(__webpack_require__(/*! ./sdp/planBUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst logger = new Logger_1.Logger('Chrome67');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Chrome67 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Chrome67();\n    }\n    constructor() {\n        super();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Map of RTCRtpSender indexed by localId.\n        this._mapSendLocalIdRtpSender = new Map();\n        // Next sending localId.\n        this._nextSendLocalId = 0;\n        // Map of MID, RTP parameters and RTCRtpReceiver indexed by local id.\n        // Value is an Object with mid, rtpParameters and rtpReceiver.\n        this._mapRecvLocalIdInfo = new Map();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Chrome67';\n    }\n    close() {\n        logger.debug('close()');\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n        });\n        try {\n            const offer = await pc.createOffer({\n                offerToReceiveAudio: true,\n                offerToReceiveVideo: true,\n            });\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n            planB: true,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (codec) {\n            logger.warn('send() | codec selection is not available in %s handler', this.name);\n        }\n        this._sendStream.addTrack(track);\n        this._pc.addTrack(track, this._sendStream);\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs);\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        if (track.kind === 'video' && encodings && encodings.length > 1) {\n            logger.debug('send() | enabling simulcast');\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media.find((m) => m.type === 'video');\n            sdpPlanBUtils.addLegacySimulcast({\n                offerMediaObject,\n                track,\n                numStreams: encodings.length,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media.find((m) => m.type === track.kind);\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings.\n        sendingRtpParameters.encodings = sdpPlanBUtils.getRtpEncodings({\n            offerMediaObject,\n            track,\n        });\n        // Complete encodings with given values.\n        if (encodings) {\n            for (let idx = 0; idx < sendingRtpParameters.encodings.length; ++idx) {\n                if (encodings[idx]) {\n                    Object.assign(sendingRtpParameters.encodings[idx], encodings[idx]);\n                }\n            }\n        }\n        // If VP8 and there is effective simulcast, add scalabilityMode to each\n        // encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8') {\n            for (const encoding of sendingRtpParameters.encodings) {\n                encoding.scalabilityMode = 'L1T3';\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        const localId = String(this._nextSendLocalId);\n        this._nextSendLocalId++;\n        const rtpSender = this._pc\n            .getSenders()\n            .find((s) => s.track === track);\n        // Insert into the map.\n        this._mapSendLocalIdRtpSender.set(localId, rtpSender);\n        return {\n            localId: localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        this._pc.removeTrack(rtpSender);\n        if (rtpSender.track) {\n            this._sendStream.removeTrack(rtpSender.track);\n        }\n        this._mapSendLocalIdRtpSender.delete(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        try {\n            await this._pc.setLocalDescription(offer);\n        }\n        catch (error) {\n            // NOTE: If there are no sending tracks, setLocalDescription() will fail with\n            // \"Failed to create channels\". If so, ignore it.\n            if (this._sendStream.getTracks().length === 0) {\n                logger.warn('stopSending() | ignoring expected error due no sending tracks: %s', error.toString());\n                return;\n            }\n            throw error;\n        }\n        if (this._pc.signalingState === 'stable') {\n            return;\n        }\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        // Unimplemented.\n    }\n    async replaceTrack(localId, track) {\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        const oldTrack = rtpSender.track;\n        await rtpSender.replaceTrack(track);\n        // Remove the old track from the local stream.\n        if (oldTrack) {\n            this._sendStream.removeTrack(oldTrack);\n        }\n        // Add the new track to the local stream.\n        if (track) {\n            this._sendStream.addTrack(track);\n        }\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        const parameters = rtpSender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await rtpSender.setParameters(parameters);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        const parameters = rtpSender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await rtpSender.setParameters(parameters);\n    }\n    async getSenderStats(localId) {\n        this.assertSendDirection();\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        return rtpSender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertRecvDirection();\n        const results = [];\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const mid = kind;\n            this._remoteSdp.receive({\n                mid,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { kind, rtpParameters } = options;\n            const mid = kind;\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === mid);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { kind, trackId, rtpParameters } = options;\n            const localId = trackId;\n            const mid = kind;\n            const rtpReceiver = this._pc\n                .getReceivers()\n                .find((r) => r.track && r.track.id === localId);\n            if (!rtpReceiver) {\n                throw new Error('new RTCRtpReceiver not');\n            }\n            // Insert into the map.\n            this._mapRecvLocalIdInfo.set(localId, {\n                mid,\n                rtpParameters,\n                rtpReceiver,\n            });\n            results.push({\n                localId,\n                track: rtpReceiver.track,\n                rtpReceiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const { mid, rtpParameters } = this._mapRecvLocalIdInfo.get(localId) || {};\n            // Remove from the map.\n            this._mapRecvLocalIdInfo.delete(localId);\n            this._remoteSdp.planBStopReceiving({\n                mid: mid,\n                offerRtpParameters: rtpParameters,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async pauseReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async resumeReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async getReceiverStats(localId) {\n        this.assertRecvDirection();\n        const { rtpReceiver } = this._mapRecvLocalIdInfo.get(localId) || {};\n        if (!rtpReceiver) {\n            throw new Error('associated RTCRtpReceiver not found');\n        }\n        return rtpReceiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation({ oldDataChannelSpec: true });\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Chrome67 = Chrome67;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Chrome67.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Chrome70.js":
/*!****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Chrome70.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Chrome70 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('Chrome70');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Chrome70 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Chrome70();\n    }\n    constructor() {\n        super();\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Chrome70';\n    }\n    close() {\n        logger.debug('close()');\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n        });\n        try {\n            pc.addTransceiver('audio');\n            pc.addTransceiver('video');\n            const offer = await pc.createOffer();\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        const mediaSectionIdx = this._remoteSdp.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n        });\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        if (encodings && encodings.length > 1) {\n            logger.debug('send() | enabling legacy simulcast');\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n            sdpUnifiedPlanUtils.addLegacySimulcast({\n                offerMediaObject,\n                numStreams: encodings.length,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        // Special case for VP9 with SVC.\n        let hackVp9Svc = false;\n        const layers = (0, scalabilityModes_1.parse)((encodings || [{}])[0].scalabilityMode);\n        if (encodings &&\n            encodings.length === 1 &&\n            layers.spatialLayers > 1 &&\n            sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp9') {\n            logger.debug('send() | enabling legacy simulcast for VP9 SVC');\n            hackVp9Svc = true;\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n            sdpUnifiedPlanUtils.addLegacySimulcast({\n                offerMediaObject,\n                numStreams: layers.spatialLayers,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // If encodings are given, apply them now.\n        if (encodings) {\n            logger.debug('send() | applying given encodings');\n            const parameters = transceiver.sender.getParameters();\n            for (let idx = 0; idx < (parameters.encodings || []).length; ++idx) {\n                const encoding = parameters.encodings[idx];\n                const desiredEncoding = encodings[idx];\n                // Should not happen but just in case.\n                if (!desiredEncoding) {\n                    break;\n                }\n                parameters.encodings[idx] = Object.assign(encoding, desiredEncoding);\n            }\n            await transceiver.sender.setParameters(parameters);\n        }\n        // We can now get the transceiver.mid.\n        const localId = transceiver.mid;\n        // Set MID.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings.\n        sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n            offerMediaObject,\n        });\n        // Complete encodings with given values.\n        if (encodings) {\n            for (let idx = 0; idx < sendingRtpParameters.encodings.length; ++idx) {\n                if (encodings[idx]) {\n                    Object.assign(sendingRtpParameters.encodings[idx], encodings[idx]);\n                }\n            }\n        }\n        // Hack for VP9 SVC.\n        if (hackVp9Svc) {\n            sendingRtpParameters.encodings = [sendingRtpParameters.encodings[0]];\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                encoding.scalabilityMode = 'L1T3';\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            reuseMid: mediaSectionIdx.reuseMid,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        this._pc.removeTrack(transceiver.sender);\n        const mediaSectionClosed = this._remoteSdp.closeMediaSection(transceiver.mid);\n        if (mediaSectionClosed) {\n            try {\n                transceiver.stop();\n            }\n            catch (error) { }\n        }\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        // Unimplemented.\n    }\n    async replaceTrack(localId, track) {\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            // Store in the map.\n            this._mapMidTransceiver.set(localId, transceiver);\n            results.push({\n                localId,\n                track: transceiver.receiver.track,\n                rtpReceiver: transceiver.receiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async resumeReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async getReceiverStats(localId) {\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Chrome70 = Chrome70;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Chrome70.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Chrome74.js":
/*!****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Chrome74.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Chrome74 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst ortcUtils = __importStar(__webpack_require__(/*! ./ortc/utils */ \"./node_modules/mediasoup-client/lib/handlers/ortc/utils.js\"));\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('Chrome74');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Chrome74 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Chrome74();\n    }\n    constructor() {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Chrome74';\n    }\n    close() {\n        logger.debug('close()');\n        if (this._closed) {\n            return;\n        }\n        this._closed = true;\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n        });\n        try {\n            pc.addTransceiver('audio');\n            pc.addTransceiver('video');\n            const offer = await pc.createOffer();\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            // libwebrtc supports NACK for OPUS but doesn't announce it.\n            ortcUtils.addNackSuppportForOpus(nativeRtpCapabilities);\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        this.assertNotClosed();\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        this.assertNotClosed();\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        this.assertNotClosed();\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (encodings && encodings.length > 1) {\n            encodings.forEach((encoding, idx) => {\n                encoding.rid = `r${idx}`;\n            });\n        }\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        const mediaSectionIdx = this._remoteSdp.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n            sendEncodings: encodings,\n        });\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        // Special case for VP9 with SVC.\n        let hackVp9Svc = false;\n        const layers = (0, scalabilityModes_1.parse)((encodings || [{}])[0].scalabilityMode);\n        if (encodings &&\n            encodings.length === 1 &&\n            layers.spatialLayers > 1 &&\n            sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp9') {\n            logger.debug('send() | enabling legacy simulcast for VP9 SVC');\n            hackVp9Svc = true;\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n            sdpUnifiedPlanUtils.addLegacySimulcast({\n                offerMediaObject,\n                numStreams: layers.spatialLayers,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // We can now get the transceiver.mid.\n        const localId = transceiver.mid;\n        // Set MID.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings by parsing the SDP offer if no encodings are given.\n        if (!encodings) {\n            sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n        }\n        // Set RTP encodings by parsing the SDP offer and complete them with given\n        // one if just a single encoding has been given.\n        else if (encodings.length === 1) {\n            let newEncodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n            Object.assign(newEncodings[0], encodings[0]);\n            // Hack for VP9 SVC.\n            if (hackVp9Svc) {\n                newEncodings = [newEncodings[0]];\n            }\n            sendingRtpParameters.encodings = newEncodings;\n        }\n        // Otherwise if more than 1 encoding are given use them verbatim.\n        else {\n            sendingRtpParameters.encodings = encodings;\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                if (encoding.scalabilityMode) {\n                    encoding.scalabilityMode = `L1T${layers.temporalLayers}`;\n                }\n                else {\n                    encoding.scalabilityMode = 'L1T3';\n                }\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            reuseMid: mediaSectionIdx.reuseMid,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n            extmapAllowMixed: true,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        if (this._closed) {\n            return;\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        this._pc.removeTrack(transceiver.sender);\n        const mediaSectionClosed = this._remoteSdp.closeMediaSection(transceiver.mid);\n        if (mediaSectionClosed) {\n            try {\n                transceiver.stop();\n            }\n            catch (error) { }\n        }\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    async pauseSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('pauseSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'inactive';\n        this._remoteSdp.pauseMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('pauseSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async resumeSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('resumeSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        this._remoteSdp.resumeSendingMediaSection(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'sendonly';\n        const offer = await this._pc.createOffer();\n        logger.debug('resumeSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async replaceTrack(localId, track) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            else {\n                // Store in the map.\n                this._mapMidTransceiver.set(localId, transceiver);\n                results.push({\n                    localId,\n                    track: transceiver.receiver.track,\n                    rtpReceiver: transceiver.receiver,\n                });\n            }\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        if (this._closed) {\n            return;\n        }\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('pauseReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'inactive';\n            this._remoteSdp.pauseMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('pauseReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async resumeReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('resumeReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'recvonly';\n            this._remoteSdp.resumeReceivingMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('resumeReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertNotClosed() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('method called in a closed handler');\n        }\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Chrome74 = Chrome74;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Chrome74.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Edge11.js":
/*!**************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Edge11.js ***!
  \**************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Edge11 = void 0;\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst edgeUtils = __importStar(__webpack_require__(/*! ./ortc/edgeUtils */ \"./node_modules/mediasoup-client/lib/handlers/ortc/edgeUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst logger = new Logger_1.Logger('Edge11');\nclass Edge11 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Edge11();\n    }\n    constructor() {\n        super();\n        // Map of RTCRtpSenders indexed by id.\n        this._rtpSenders = new Map();\n        // Map of RTCRtpReceivers indexed by id.\n        this._rtpReceivers = new Map();\n        // Next localId for sending tracks.\n        this._nextSendLocalId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Edge11';\n    }\n    close() {\n        logger.debug('close()');\n        // Close the ICE gatherer.\n        // NOTE: Not yet implemented by Edge.\n        try {\n            this._iceGatherer.close();\n        }\n        catch (error) { }\n        // Close the ICE transport.\n        try {\n            this._iceTransport.stop();\n        }\n        catch (error) { }\n        // Close the DTLS transport.\n        try {\n            this._dtlsTransport.stop();\n        }\n        catch (error) { }\n        // Close RTCRtpSenders.\n        for (const rtpSender of this._rtpSenders.values()) {\n            try {\n                rtpSender.stop();\n            }\n            catch (error) { }\n        }\n        // Close RTCRtpReceivers.\n        for (const rtpReceiver of this._rtpReceivers.values()) {\n            try {\n                rtpReceiver.stop();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        return edgeUtils.getCapabilities();\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: { OS: 0, MIS: 0 },\n        };\n    }\n    run({ direction, // eslint-disable-line @typescript-eslint/no-unused-vars\n    iceParameters, iceCandidates, dtlsParameters, sctpParameters, // eslint-disable-line @typescript-eslint/no-unused-vars\n    iceServers, iceTransportPolicy, additionalSettings, // eslint-disable-line @typescript-eslint/no-unused-vars\n    proprietaryConstraints, // eslint-disable-line @typescript-eslint/no-unused-vars\n    extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._remoteIceParameters = iceParameters;\n        this._remoteIceCandidates = iceCandidates;\n        this._remoteDtlsParameters = dtlsParameters;\n        this._cname = `CNAME-${utils.generateRandomNumber()}`;\n        this.setIceGatherer({ iceServers, iceTransportPolicy });\n        this.setIceTransport();\n        this.setDtlsTransport();\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async updateIceServers(iceServers) {\n        // NOTE: Edge 11 does not implement iceGatherer.gater().\n        throw new errors_1.UnsupportedError('not supported');\n    }\n    async restartIce(iceParameters) {\n        logger.debug('restartIce()');\n        this._remoteIceParameters = iceParameters;\n        if (!this._transportReady) {\n            return;\n        }\n        logger.debug('restartIce() | calling iceTransport.start()');\n        this._iceTransport.start(this._iceGatherer, iceParameters, 'controlling');\n        for (const candidate of this._remoteIceCandidates) {\n            this._iceTransport.addRemoteCandidate(candidate);\n        }\n        this._iceTransport.addRemoteCandidate({});\n    }\n    async getTransportStats() {\n        return this._iceTransport.getStats();\n    }\n    async send(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    { track, encodings, codecOptions, codec }) {\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (!this._transportReady) {\n            await this.setupTransport({ localDtlsRole: 'server' });\n        }\n        logger.debug('send() | calling new RTCRtpSender()');\n        const rtpSender = new RTCRtpSender(track, this._dtlsTransport);\n        const rtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        rtpParameters.codecs = ortc.reduceCodecs(rtpParameters.codecs, codec);\n        const useRtx = rtpParameters.codecs.some((_codec) => /.+\\/rtx$/i.test(_codec.mimeType));\n        if (!encodings) {\n            encodings = [{}];\n        }\n        for (const encoding of encodings) {\n            encoding.ssrc = utils.generateRandomNumber();\n            if (useRtx) {\n                encoding.rtx = { ssrc: utils.generateRandomNumber() };\n            }\n        }\n        rtpParameters.encodings = encodings;\n        // Fill RTCRtpParameters.rtcp.\n        rtpParameters.rtcp = {\n            cname: this._cname,\n            reducedSize: true,\n            mux: true,\n        };\n        // NOTE: Convert our standard RTCRtpParameters into those that Edge\n        // expects.\n        const edgeRtpParameters = edgeUtils.mangleRtpParameters(rtpParameters);\n        logger.debug('send() | calling rtpSender.send() [params:%o]', edgeRtpParameters);\n        await rtpSender.send(edgeRtpParameters);\n        const localId = String(this._nextSendLocalId);\n        this._nextSendLocalId++;\n        // Store it.\n        this._rtpSenders.set(localId, rtpSender);\n        return { localId, rtpParameters, rtpSender };\n    }\n    async stopSending(localId) {\n        logger.debug('stopSending() [localId:%s]', localId);\n        const rtpSender = this._rtpSenders.get(localId);\n        if (!rtpSender) {\n            throw new Error('RTCRtpSender not found');\n        }\n        this._rtpSenders.delete(localId);\n        try {\n            logger.debug('stopSending() | calling rtpSender.stop()');\n            rtpSender.stop();\n        }\n        catch (error) {\n            logger.warn('stopSending() | rtpSender.stop() failed:%o', error);\n            throw error;\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        // Unimplemented.\n    }\n    async replaceTrack(localId, track) {\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const rtpSender = this._rtpSenders.get(localId);\n        if (!rtpSender) {\n            throw new Error('RTCRtpSender not found');\n        }\n        rtpSender.setTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const rtpSender = this._rtpSenders.get(localId);\n        if (!rtpSender) {\n            throw new Error('RTCRtpSender not found');\n        }\n        const parameters = rtpSender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await rtpSender.setParameters(parameters);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const rtpSender = this._rtpSenders.get(localId);\n        if (!rtpSender) {\n            throw new Error('RTCRtpSender not found');\n        }\n        const parameters = rtpSender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await rtpSender.setParameters(parameters);\n    }\n    async getSenderStats(localId) {\n        const rtpSender = this._rtpSenders.get(localId);\n        if (!rtpSender) {\n            throw new Error('RTCRtpSender not found');\n        }\n        return rtpSender.getStats();\n    }\n    async sendDataChannel(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    options) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async receive(optionsList) {\n        const results = [];\n        for (const options of optionsList) {\n            const { trackId, kind } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n        }\n        if (!this._transportReady) {\n            await this.setupTransport({ localDtlsRole: 'server' });\n        }\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters } = options;\n            logger.debug('receive() | calling new RTCRtpReceiver()');\n            const rtpReceiver = new RTCRtpReceiver(this._dtlsTransport, kind);\n            rtpReceiver.addEventListener('error', (event) => {\n                logger.error('rtpReceiver \"error\" event [event:%o]', event);\n            });\n            // NOTE: Convert our standard RTCRtpParameters into those that Edge\n            // expects.\n            const edgeRtpParameters = edgeUtils.mangleRtpParameters(rtpParameters);\n            logger.debug('receive() | calling rtpReceiver.receive() [params:%o]', edgeRtpParameters);\n            await rtpReceiver.receive(edgeRtpParameters);\n            const localId = trackId;\n            // Store it.\n            this._rtpReceivers.set(localId, rtpReceiver);\n            results.push({\n                localId,\n                track: rtpReceiver.track,\n                rtpReceiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const rtpReceiver = this._rtpReceivers.get(localId);\n            if (!rtpReceiver) {\n                throw new Error('RTCRtpReceiver not found');\n            }\n            this._rtpReceivers.delete(localId);\n            try {\n                logger.debug('stopReceiving() | calling rtpReceiver.stop()');\n                rtpReceiver.stop();\n            }\n            catch (error) {\n                logger.warn('stopReceiving() | rtpReceiver.stop() failed:%o', error);\n            }\n        }\n    }\n    async pauseReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async resumeReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async getReceiverStats(localId) {\n        const rtpReceiver = this._rtpReceivers.get(localId);\n        if (!rtpReceiver) {\n            throw new Error('RTCRtpReceiver not found');\n        }\n        return rtpReceiver.getStats();\n    }\n    async receiveDataChannel(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    options) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    setIceGatherer({ iceServers, iceTransportPolicy, }) {\n        // @ts-ignore\n        const iceGatherer = new RTCIceGatherer({\n            iceServers: iceServers || [],\n            gatherPolicy: iceTransportPolicy || 'all',\n        });\n        iceGatherer.addEventListener('error', (event) => {\n            logger.error('iceGatherer \"error\" event [event:%o]', event);\n        });\n        // NOTE: Not yet implemented by Edge, which starts gathering automatically.\n        try {\n            iceGatherer.gather();\n        }\n        catch (error) {\n            logger.debug('setIceGatherer() | iceGatherer.gather() failed: %s', error.toString());\n        }\n        this._iceGatherer = iceGatherer;\n    }\n    setIceTransport() {\n        const iceTransport = new RTCIceTransport(this._iceGatherer);\n        // NOTE: Not yet implemented by Edge.\n        iceTransport.addEventListener('statechange', () => {\n            switch (iceTransport.state) {\n                case 'checking': {\n                    this.emit('@connectionstatechange', 'connecting');\n                    break;\n                }\n                case 'connected':\n                case 'completed': {\n                    this.emit('@connectionstatechange', 'connected');\n                    break;\n                }\n                case 'failed': {\n                    this.emit('@connectionstatechange', 'failed');\n                    break;\n                }\n                case 'disconnected': {\n                    this.emit('@connectionstatechange', 'disconnected');\n                    break;\n                }\n                case 'closed': {\n                    this.emit('@connectionstatechange', 'closed');\n                    break;\n                }\n            }\n        });\n        // NOTE: Not standard, but implemented by Edge.\n        iceTransport.addEventListener('icestatechange', () => {\n            switch (iceTransport.state) {\n                case 'checking': {\n                    this.emit('@connectionstatechange', 'connecting');\n                    break;\n                }\n                case 'connected':\n                case 'completed': {\n                    this.emit('@connectionstatechange', 'connected');\n                    break;\n                }\n                case 'failed': {\n                    this.emit('@connectionstatechange', 'failed');\n                    break;\n                }\n                case 'disconnected': {\n                    this.emit('@connectionstatechange', 'disconnected');\n                    break;\n                }\n                case 'closed': {\n                    this.emit('@connectionstatechange', 'closed');\n                    break;\n                }\n            }\n        });\n        iceTransport.addEventListener('candidatepairchange', (event) => {\n            logger.debug('iceTransport \"candidatepairchange\" event [pair:%o]', event.pair);\n        });\n        this._iceTransport = iceTransport;\n    }\n    setDtlsTransport() {\n        const dtlsTransport = new RTCDtlsTransport(this._iceTransport);\n        // NOTE: Not yet implemented by Edge.\n        dtlsTransport.addEventListener('statechange', () => {\n            logger.debug('dtlsTransport \"statechange\" event [state:%s]', dtlsTransport.state);\n        });\n        // NOTE: Not standard, but implemented by Edge.\n        dtlsTransport.addEventListener('dtlsstatechange', () => {\n            logger.debug('dtlsTransport \"dtlsstatechange\" event [state:%s]', dtlsTransport.state);\n            if (dtlsTransport.state === 'closed') {\n                this.emit('@connectionstatechange', 'closed');\n            }\n        });\n        dtlsTransport.addEventListener('error', (event) => {\n            logger.error('dtlsTransport \"error\" event [event:%o]', event);\n        });\n        this._dtlsTransport = dtlsTransport;\n    }\n    async setupTransport({ localDtlsRole, }) {\n        logger.debug('setupTransport()');\n        // Get our local DTLS parameters.\n        const dtlsParameters = this._dtlsTransport.getLocalParameters();\n        dtlsParameters.role = localDtlsRole;\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        // Start the RTCIceTransport.\n        this._iceTransport.start(this._iceGatherer, this._remoteIceParameters, 'controlling');\n        // Add remote ICE candidates.\n        for (const candidate of this._remoteIceCandidates) {\n            this._iceTransport.addRemoteCandidate(candidate);\n        }\n        // Also signal a 'complete' candidate as per spec.\n        // NOTE: It should be {complete: true} but Edge prefers {}.\n        // NOTE: If we don't signal end of candidates, the Edge RTCIceTransport\n        // won't enter the 'completed' state.\n        this._iceTransport.addRemoteCandidate({});\n        // NOTE: Edge does not like SHA less than 256.\n        this._remoteDtlsParameters.fingerprints =\n            this._remoteDtlsParameters.fingerprints.filter((fingerprint) => {\n                return (fingerprint.algorithm === 'sha-256' ||\n                    fingerprint.algorithm === 'sha-384' ||\n                    fingerprint.algorithm === 'sha-512');\n            });\n        // Start the RTCDtlsTransport.\n        this._dtlsTransport.start(this._remoteDtlsParameters);\n        this._transportReady = true;\n    }\n}\nexports.Edge11 = Edge11;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Edge11.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Firefox120.js":
/*!******************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Firefox120.js ***!
  \******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Firefox120 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('Firefox120');\nconst SCTP_NUM_STREAMS = { OS: 16, MIS: 2048 };\nclass Firefox120 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Firefox120();\n    }\n    constructor() {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Firefox120';\n    }\n    close() {\n        logger.debug('close()');\n        if (this._closed) {\n            return;\n        }\n        this._closed = true;\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n        });\n        // NOTE: We need to add a real video track to get the RID extension mapping,\n        // otherwiser Firefox doesn't include it in the SDP.\n        const canvas = document.createElement('canvas');\n        // NOTE: Otherwise Firefox fails in next line.\n        canvas.getContext('2d');\n        const fakeStream = canvas.captureStream();\n        const fakeVideoTrack = fakeStream.getVideoTracks()[0];\n        try {\n            pc.addTransceiver('audio', { direction: 'sendrecv' });\n            pc.addTransceiver(fakeVideoTrack, {\n                direction: 'sendrecv',\n                sendEncodings: [\n                    { rid: 'r0', maxBitrate: 100000 },\n                    { rid: 'r1', maxBitrate: 500000 },\n                ],\n            });\n            const offer = await pc.createOffer();\n            try {\n                canvas.remove();\n            }\n            catch (error) { }\n            try {\n                fakeVideoTrack.stop();\n            }\n            catch (error) { }\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                canvas.remove();\n            }\n            catch (error2) { }\n            try {\n                fakeVideoTrack.stop();\n            }\n            catch (error2) { }\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        this.assertNotClosed();\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async updateIceServers(iceServers) {\n        this.assertNotClosed();\n        // NOTE: Firefox does not implement pc.setConfiguration().\n        throw new errors_1.UnsupportedError('not supported');\n    }\n    async restartIce(iceParameters) {\n        this.assertNotClosed();\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        this.assertNotClosed();\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, onRtpSender, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (encodings && encodings.length > 1) {\n            encodings.forEach((encoding, idx) => {\n                encoding.rid = `r${idx}`;\n            });\n        }\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        // NOTE: Firefox fails sometimes to properly anticipate the closed media\n        // section that it should use, so don't reuse closed media sections.\n        //   https://github.com/versatica/mediasoup-client/issues/104\n        //\n        // const mediaSectionIdx = this._remoteSdp!.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n            sendEncodings: encodings,\n        });\n        if (onRtpSender) {\n            onRtpSender(transceiver.sender);\n        }\n        const offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        // In Firefox use DTLS role client even if we are the \"offerer\" since\n        // Firefox does not respect ICE-Lite.\n        if (!this._transportReady) {\n            await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n        }\n        const layers = (0, scalabilityModes_1.parse)((encodings || [{}])[0].scalabilityMode);\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // We can now get the transceiver.mid.\n        const localId = transceiver.mid;\n        // Set MID.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        const offerMediaObject = localSdpObject.media[localSdpObject.media.length - 1];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings by parsing the SDP offer if no encodings are given.\n        if (!encodings) {\n            sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n        }\n        // Set RTP encodings by parsing the SDP offer and complete them with given\n        // one if just a single encoding has been given.\n        else if (encodings.length === 1) {\n            const newEncodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n            Object.assign(newEncodings[0], encodings[0]);\n            sendingRtpParameters.encodings = newEncodings;\n        }\n        // Otherwise if more than 1 encoding are given use them verbatim.\n        else {\n            sendingRtpParameters.encodings = encodings;\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                if (encoding.scalabilityMode) {\n                    encoding.scalabilityMode = `L1T${layers.temporalLayers}`;\n                }\n                else {\n                    encoding.scalabilityMode = 'L1T3';\n                }\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n            extmapAllowMixed: true,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        if (this._closed) {\n            return;\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated transceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        // NOTE: Cannot use stop() the transceiver due to the the note above in\n        // send() method.\n        // try\n        // {\n        // \ttransceiver.stop();\n        // }\n        // catch (error)\n        // {}\n        this._pc.removeTrack(transceiver.sender);\n        // NOTE: Cannot use closeMediaSection() due to the the note above in send()\n        // method.\n        // this._remoteSdp!.closeMediaSection(transceiver.mid);\n        this._remoteSdp.disableMediaSection(transceiver.mid);\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('pauseSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'inactive';\n        this._remoteSdp.pauseMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('pauseSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('resumeSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'sendonly';\n        this._remoteSdp.resumeSendingMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('resumeSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async replaceTrack(localId, track) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated transceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    optionsList) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        for (const options of optionsList) {\n            const { trackId, onRtpReceiver } = options;\n            if (onRtpReceiver) {\n                const localId = mapLocalId.get(trackId);\n                const transceiver = this._pc\n                    .getTransceivers()\n                    .find((t) => t.mid === localId);\n                if (!transceiver) {\n                    throw new Error('transceiver not found');\n                }\n                onRtpReceiver(transceiver.receiver);\n            }\n        }\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n            answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        if (!this._transportReady) {\n            await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            // Store in the map.\n            this._mapMidTransceiver.set(localId, transceiver);\n            results.push({\n                localId,\n                track: transceiver.receiver.track,\n                rtpReceiver: transceiver.receiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        if (this._closed) {\n            return;\n        }\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('pauseReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'inactive';\n            this._remoteSdp.pauseMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('pauseReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async resumeReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('resumeReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'recvonly';\n            this._remoteSdp.resumeReceivingMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('resumeReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertNotClosed() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('method called in a closed handler');\n        }\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Firefox120 = Firefox120;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Firefox120.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Firefox60.js":
/*!*****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Firefox60.js ***!
  \*****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Firefox60 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('Firefox60');\nconst SCTP_NUM_STREAMS = { OS: 16, MIS: 2048 };\nclass Firefox60 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Firefox60();\n    }\n    constructor() {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Firefox60';\n    }\n    close() {\n        logger.debug('close()');\n        if (this._closed) {\n            return;\n        }\n        this._closed = true;\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n        });\n        // NOTE: We need to add a real video track to get the RID extension mapping.\n        const canvas = document.createElement('canvas');\n        // NOTE: Otherwise Firefox fails in next line.\n        canvas.getContext('2d');\n        const fakeStream = canvas.captureStream();\n        const fakeVideoTrack = fakeStream.getVideoTracks()[0];\n        try {\n            pc.addTransceiver('audio', { direction: 'sendrecv' });\n            const videoTransceiver = pc.addTransceiver(fakeVideoTrack, {\n                direction: 'sendrecv',\n            });\n            const parameters = videoTransceiver.sender.getParameters();\n            const encodings = [\n                { rid: 'r0', maxBitrate: 100000 },\n                { rid: 'r1', maxBitrate: 500000 },\n            ];\n            parameters.encodings = encodings;\n            await videoTransceiver.sender.setParameters(parameters);\n            const offer = await pc.createOffer();\n            try {\n                canvas.remove();\n            }\n            catch (error) { }\n            try {\n                fakeVideoTrack.stop();\n            }\n            catch (error) { }\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                canvas.remove();\n            }\n            catch (error2) { }\n            try {\n                fakeVideoTrack.stop();\n            }\n            catch (error2) { }\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        this.assertNotClosed();\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async updateIceServers(iceServers) {\n        this.assertNotClosed();\n        // NOTE: Firefox does not implement pc.setConfiguration().\n        throw new errors_1.UnsupportedError('not supported');\n    }\n    async restartIce(iceParameters) {\n        this.assertNotClosed();\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        this.assertNotClosed();\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (encodings) {\n            encodings = utils.clone(encodings);\n            if (encodings.length > 1) {\n                encodings.forEach((encoding, idx) => {\n                    encoding.rid = `r${idx}`;\n                });\n                // Clone the encodings and reverse them because Firefox likes them\n                // from high to low.\n                encodings.reverse();\n            }\n        }\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        // NOTE: Firefox fails sometimes to properly anticipate the closed media\n        // section that it should use, so don't reuse closed media sections.\n        //   https://github.com/versatica/mediasoup-client/issues/104\n        //\n        // const mediaSectionIdx = this._remoteSdp!.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n        });\n        // NOTE: This is not spec compliants. Encodings should be given in addTransceiver\n        // second argument, but Firefox does not support it.\n        if (encodings) {\n            const parameters = transceiver.sender.getParameters();\n            parameters.encodings = encodings;\n            await transceiver.sender.setParameters(parameters);\n        }\n        const offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        // In Firefox use DTLS role client even if we are the \"offerer\" since\n        // Firefox does not respect ICE-Lite.\n        if (!this._transportReady) {\n            await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n        }\n        const layers = (0, scalabilityModes_1.parse)((encodings || [{}])[0].scalabilityMode);\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // We can now get the transceiver.mid.\n        const localId = transceiver.mid;\n        // Set MID.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        const offerMediaObject = localSdpObject.media[localSdpObject.media.length - 1];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings by parsing the SDP offer if no encodings are given.\n        if (!encodings) {\n            sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n        }\n        // Set RTP encodings by parsing the SDP offer and complete them with given\n        // one if just a single encoding has been given.\n        else if (encodings.length === 1) {\n            const newEncodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n            Object.assign(newEncodings[0], encodings[0]);\n            sendingRtpParameters.encodings = newEncodings;\n        }\n        // Otherwise if more than 1 encoding are given use them verbatim (but\n        // reverse them back since we reversed them above to satisfy Firefox).\n        else {\n            sendingRtpParameters.encodings = encodings.reverse();\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                if (encoding.scalabilityMode) {\n                    encoding.scalabilityMode = `L1T${layers.temporalLayers}`;\n                }\n                else {\n                    encoding.scalabilityMode = 'L1T3';\n                }\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n            extmapAllowMixed: true,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        if (this._closed) {\n            return;\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated transceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        // NOTE: Cannot use stop() the transceiver due to the the note above in\n        // send() method.\n        // try\n        // {\n        // \ttransceiver.stop();\n        // }\n        // catch (error)\n        // {}\n        this._pc.removeTrack(transceiver.sender);\n        // NOTE: Cannot use closeMediaSection() due to the the note above in send()\n        // method.\n        // this._remoteSdp!.closeMediaSection(transceiver.mid);\n        this._remoteSdp.disableMediaSection(transceiver.mid);\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('pauseSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'inactive';\n        this._remoteSdp.pauseMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('pauseSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('resumeSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'sendonly';\n        this._remoteSdp.resumeSendingMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('resumeSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async replaceTrack(localId, track) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated transceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        // NOTE: We require encodings given from low to high, however Firefox\n        // requires them in reverse order, so do magic here.\n        spatialLayer = parameters.encodings.length - 1 - spatialLayer;\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx >= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    optionsList) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n            answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        if (!this._transportReady) {\n            await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            // Store in the map.\n            this._mapMidTransceiver.set(localId, transceiver);\n            results.push({\n                localId,\n                track: transceiver.receiver.track,\n                rtpReceiver: transceiver.receiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        if (this._closed) {\n            return;\n        }\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('pauseReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'inactive';\n            this._remoteSdp.pauseMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('pauseReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async resumeReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('resumeReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'recvonly';\n            this._remoteSdp.resumeReceivingMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('resumeReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({ localDtlsRole: 'client', localSdpObject });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertNotClosed() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('method called in a closed handler');\n        }\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Firefox60 = Firefox60;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Firefox60.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js":
/*!************************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.HandlerInterface = void 0;\nconst EnhancedEventEmitter_1 = __webpack_require__(/*! ../EnhancedEventEmitter */ \"./node_modules/mediasoup-client/lib/EnhancedEventEmitter.js\");\nclass HandlerInterface extends EnhancedEventEmitter_1.EnhancedEventEmitter {\n    constructor() {\n        super();\n    }\n}\nexports.HandlerInterface = HandlerInterface;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/ReactNative.js":
/*!*******************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/ReactNative.js ***!
  \*******************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReactNative = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpPlanBUtils = __importStar(__webpack_require__(/*! ./sdp/planBUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst logger = new Logger_1.Logger('ReactNative');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass ReactNative extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new ReactNative();\n    }\n    constructor() {\n        super();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Map of sending MediaStreamTracks indexed by localId.\n        this._mapSendLocalIdTrack = new Map();\n        // Next sending localId.\n        this._nextSendLocalId = 0;\n        // Map of MID, RTP parameters and RTCRtpReceiver indexed by local id.\n        // Value is an Object with mid, rtpParameters and rtpReceiver.\n        this._mapRecvLocalIdInfo = new Map();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'ReactNative';\n    }\n    close() {\n        logger.debug('close()');\n        // Free/dispose native MediaStream but DO NOT free/dispose native\n        // MediaStreamTracks (that is parent's business).\n        // @ts-ignore (proprietary API in react-native-webrtc).\n        this._sendStream.release(/* releaseTracks */ false);\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n        });\n        try {\n            const offer = await pc.createOffer({\n                offerToReceiveAudio: true,\n                offerToReceiveVideo: true,\n            });\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n            planB: true,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (codec) {\n            logger.warn('send() | codec selection is not available in %s handler', this.name);\n        }\n        this._sendStream.addTrack(track);\n        this._pc.addStream(this._sendStream);\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs);\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        if (track.kind === 'video' && encodings && encodings.length > 1) {\n            logger.debug('send() | enabling simulcast');\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media.find((m) => m.type === 'video');\n            sdpPlanBUtils.addLegacySimulcast({\n                offerMediaObject,\n                track,\n                numStreams: encodings.length,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media.find((m) => m.type === track.kind);\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings.\n        sendingRtpParameters.encodings = sdpPlanBUtils.getRtpEncodings({\n            offerMediaObject,\n            track,\n        });\n        // Complete encodings with given values.\n        if (encodings) {\n            for (let idx = 0; idx < sendingRtpParameters.encodings.length; ++idx) {\n                if (encodings[idx]) {\n                    Object.assign(sendingRtpParameters.encodings[idx], encodings[idx]);\n                }\n            }\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                encoding.scalabilityMode = 'L1T3';\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        const localId = String(this._nextSendLocalId);\n        this._nextSendLocalId++;\n        // Insert into the map.\n        this._mapSendLocalIdTrack.set(localId, track);\n        return {\n            localId: localId,\n            rtpParameters: sendingRtpParameters,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        logger.debug('stopSending() [localId:%s]', localId);\n        const track = this._mapSendLocalIdTrack.get(localId);\n        if (!track) {\n            throw new Error('track not found');\n        }\n        this._mapSendLocalIdTrack.delete(localId);\n        this._sendStream.removeTrack(track);\n        this._pc.addStream(this._sendStream);\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        try {\n            await this._pc.setLocalDescription(offer);\n        }\n        catch (error) {\n            // NOTE: If there are no sending tracks, setLocalDescription() will fail with\n            // \"Failed to create channels\". If so, ignore it.\n            if (this._sendStream.getTracks().length === 0) {\n                logger.warn('stopSending() | ignoring expected error due no sending tracks: %s', error.toString());\n                return;\n            }\n            throw error;\n        }\n        if (this._pc.signalingState === 'stable') {\n            return;\n        }\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        // Unimplemented.\n    }\n    async replaceTrack(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localId, \n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    track) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async setMaxSpatialLayer(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localId, \n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    spatialLayer) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async setRtpEncodingParameters(localId, params) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async getSenderStats(localId) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertRecvDirection();\n        const results = [];\n        const mapStreamId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const mid = kind;\n            let streamId = options.streamId || rtpParameters.rtcp.cname;\n            // NOTE: In React-Native we cannot reuse the same remote MediaStream for new\n            // remote tracks. This is because react-native-webrtc does not react on new\n            // tracks generated within already existing streams, so force the streamId\n            // to be different. See:\n            // https://github.com/react-native-webrtc/react-native-webrtc/issues/401\n            logger.debug('receive() | forcing a random remote streamId to avoid well known bug in react-native-webrtc');\n            streamId += `-hack-${utils.generateRandomNumber()}`;\n            mapStreamId.set(trackId, streamId);\n            this._remoteSdp.receive({\n                mid,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { kind, rtpParameters } = options;\n            const mid = kind;\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === mid);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { kind, trackId, rtpParameters } = options;\n            const localId = trackId;\n            const mid = kind;\n            const streamId = mapStreamId.get(trackId);\n            const stream = this._pc\n                .getRemoteStreams()\n                .find((s) => s.id === streamId);\n            const track = stream.getTrackById(localId);\n            if (!track) {\n                throw new Error('remote track not found');\n            }\n            // Insert into the map.\n            this._mapRecvLocalIdInfo.set(localId, { mid, rtpParameters });\n            results.push({ localId, track });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const { mid, rtpParameters } = this._mapRecvLocalIdInfo.get(localId) || {};\n            // Remove from the map.\n            this._mapRecvLocalIdInfo.delete(localId);\n            this._remoteSdp.planBStopReceiving({\n                mid: mid,\n                offerRtpParameters: rtpParameters,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async pauseReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async resumeReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async getReceiverStats(localId) {\n        throw new errors_1.UnsupportedError('not implemented');\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmitTime: maxPacketLifeTime, // NOTE: Old spec.\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation({ oldDataChannelSpec: true });\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.ReactNative = ReactNative;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/ReactNative.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/ReactNativeUnifiedPlan.js":
/*!******************************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/ReactNativeUnifiedPlan.js ***!
  \******************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReactNativeUnifiedPlan = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst ortcUtils = __importStar(__webpack_require__(/*! ./ortc/utils */ \"./node_modules/mediasoup-client/lib/handlers/ortc/utils.js\"));\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('ReactNativeUnifiedPlan');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass ReactNativeUnifiedPlan extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new ReactNativeUnifiedPlan();\n    }\n    constructor() {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'ReactNativeUnifiedPlan';\n    }\n    close() {\n        logger.debug('close()');\n        if (this._closed) {\n            return;\n        }\n        this._closed = true;\n        // Free/dispose native MediaStream but DO NOT free/dispose native\n        // MediaStreamTracks (that is parent's business).\n        // @ts-ignore (proprietary API in react-native-webrtc).\n        this._sendStream.release(/* releaseTracks */ false);\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n        });\n        try {\n            pc.addTransceiver('audio');\n            pc.addTransceiver('video');\n            const offer = await pc.createOffer();\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            // libwebrtc supports NACK for OPUS but doesn't announce it.\n            ortcUtils.addNackSuppportForOpus(nativeRtpCapabilities);\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        this.assertNotClosed();\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'unified-plan',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        this.assertNotClosed();\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        this.assertNotClosed();\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        this.assertNotClosed();\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, onRtpSender, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (encodings && encodings.length > 1) {\n            encodings.forEach((encoding, idx) => {\n                encoding.rid = `r${idx}`;\n            });\n        }\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        const mediaSectionIdx = this._remoteSdp.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n            sendEncodings: encodings,\n        });\n        if (onRtpSender) {\n            onRtpSender(transceiver.sender);\n        }\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        // Special case for VP9 with SVC.\n        let hackVp9Svc = false;\n        const layers = (0, scalabilityModes_1.parse)((encodings || [{}])[0].scalabilityMode);\n        if (encodings &&\n            encodings.length === 1 &&\n            layers.spatialLayers > 1 &&\n            sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp9') {\n            logger.debug('send() | enabling legacy simulcast for VP9 SVC');\n            hackVp9Svc = true;\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n            sdpUnifiedPlanUtils.addLegacySimulcast({\n                offerMediaObject,\n                numStreams: layers.spatialLayers,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // We can now get the transceiver.mid.\n        // NOTE: We cannot read generated MID on iOS react-native-webrtc 111.0.0\n        // because transceiver.mid is not available until setRemoteDescription()\n        // is called, so this is best effort.\n        // Issue: https://github.com/react-native-webrtc/react-native-webrtc/issues/1404\n        // NOTE: So let's fill MID in sendingRtpParameters later.\n        // NOTE: This is fixed in react-native-webrtc 111.0.3.\n        let localId = transceiver.mid ?? undefined;\n        if (!localId) {\n            logger.warn('send() | missing transceiver.mid (bug in react-native-webrtc, using a workaround');\n        }\n        // Set MID.\n        // NOTE: As per above, it could be unset yet.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings by parsing the SDP offer if no encodings are given.\n        if (!encodings) {\n            sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n        }\n        // Set RTP encodings by parsing the SDP offer and complete them with given\n        // one if just a single encoding has been given.\n        else if (encodings.length === 1) {\n            let newEncodings = sdpUnifiedPlanUtils.getRtpEncodings({\n                offerMediaObject,\n            });\n            Object.assign(newEncodings[0], encodings[0]);\n            // Hack for VP9 SVC.\n            if (hackVp9Svc) {\n                newEncodings = [newEncodings[0]];\n            }\n            sendingRtpParameters.encodings = newEncodings;\n        }\n        // Otherwise if more than 1 encoding are given use them verbatim.\n        else {\n            sendingRtpParameters.encodings = encodings;\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                if (encoding.scalabilityMode) {\n                    encoding.scalabilityMode = `L1T${layers.temporalLayers}`;\n                }\n                else {\n                    encoding.scalabilityMode = 'L1T3';\n                }\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            reuseMid: mediaSectionIdx.reuseMid,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n            extmapAllowMixed: true,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Follow up of iOS react-native-webrtc 111.0.0 issue told above. Now yes,\n        // we can read generated MID (if not done above) and fill sendingRtpParameters.\n        // NOTE: This is fixed in react-native-webrtc 111.0.3 so this block isn't\n        // needed starting from that version.\n        if (!localId) {\n            localId = transceiver.mid;\n            sendingRtpParameters.mid = localId;\n        }\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        if (this._closed) {\n            return;\n        }\n        logger.debug('stopSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        this._pc.removeTrack(transceiver.sender);\n        const mediaSectionClosed = this._remoteSdp.closeMediaSection(transceiver.mid);\n        if (mediaSectionClosed) {\n            try {\n                transceiver.stop();\n            }\n            catch (error) { }\n        }\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    async pauseSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('pauseSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'inactive';\n        this._remoteSdp.pauseMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('pauseSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async resumeSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('resumeSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        this._remoteSdp.resumeSendingMediaSection(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'sendonly';\n        const offer = await this._pc.createOffer();\n        logger.debug('resumeSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async replaceTrack(localId, track) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        for (const options of optionsList) {\n            const { trackId, onRtpReceiver } = options;\n            if (onRtpReceiver) {\n                const localId = mapLocalId.get(trackId);\n                const transceiver = this._pc\n                    .getTransceivers()\n                    .find((t) => t.mid === localId);\n                if (!transceiver) {\n                    throw new Error('transceiver not found');\n                }\n                onRtpReceiver(transceiver.receiver);\n            }\n        }\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            else {\n                // Store in the map.\n                this._mapMidTransceiver.set(localId, transceiver);\n                results.push({\n                    localId,\n                    track: transceiver.receiver.track,\n                    rtpReceiver: transceiver.receiver,\n                });\n            }\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        if (this._closed) {\n            return;\n        }\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('pauseReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'inactive';\n            this._remoteSdp.pauseMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('pauseReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async resumeReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('resumeReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'recvonly';\n            this._remoteSdp.resumeReceivingMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('resumeReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertNotClosed() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('method called in a closed handler');\n        }\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.ReactNativeUnifiedPlan = ReactNativeUnifiedPlan;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/ReactNativeUnifiedPlan.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Safari11.js":
/*!****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Safari11.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Safari11 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpPlanBUtils = __importStar(__webpack_require__(/*! ./sdp/planBUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js\"));\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst logger = new Logger_1.Logger('Safari11');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Safari11 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Safari11();\n    }\n    constructor() {\n        super();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Map of RTCRtpSender indexed by localId.\n        this._mapSendLocalIdRtpSender = new Map();\n        // Next sending localId.\n        this._nextSendLocalId = 0;\n        // Map of MID, RTP parameters and RTCRtpReceiver indexed by local id.\n        // Value is an Object with mid, rtpParameters and rtpReceiver.\n        this._mapRecvLocalIdInfo = new Map();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Safari11';\n    }\n    close() {\n        logger.debug('close()');\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            sdpSemantics: 'plan-b',\n        });\n        try {\n            const offer = await pc.createOffer({\n                offerToReceiveAudio: true,\n                offerToReceiveVideo: true,\n            });\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n            planB: true,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, }) {\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        if (codec) {\n            logger.warn('send() | codec selection is not available in %s handler', this.name);\n        }\n        this._sendStream.addTrack(track);\n        this._pc.addTrack(track, this._sendStream);\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs);\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        if (track.kind === 'video' && encodings && encodings.length > 1) {\n            logger.debug('send() | enabling simulcast');\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media.find((m) => m.type === 'video');\n            sdpPlanBUtils.addLegacySimulcast({\n                offerMediaObject,\n                track,\n                numStreams: encodings.length,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media.find((m) => m.type === track.kind);\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings.\n        sendingRtpParameters.encodings = sdpPlanBUtils.getRtpEncodings({\n            offerMediaObject,\n            track,\n        });\n        // Complete encodings with given values.\n        if (encodings) {\n            for (let idx = 0; idx < sendingRtpParameters.encodings.length; ++idx) {\n                if (encodings[idx]) {\n                    Object.assign(sendingRtpParameters.encodings[idx], encodings[idx]);\n                }\n            }\n        }\n        // If VP8 and there is effective simulcast, add scalabilityMode to each\n        // encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8') {\n            for (const encoding of sendingRtpParameters.encodings) {\n                encoding.scalabilityMode = 'L1T3';\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        const localId = String(this._nextSendLocalId);\n        this._nextSendLocalId++;\n        const rtpSender = this._pc\n            .getSenders()\n            .find((s) => s.track === track);\n        // Insert into the map.\n        this._mapSendLocalIdRtpSender.set(localId, rtpSender);\n        return {\n            localId: localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        if (rtpSender.track) {\n            this._sendStream.removeTrack(rtpSender.track);\n        }\n        this._mapSendLocalIdRtpSender.delete(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        try {\n            await this._pc.setLocalDescription(offer);\n        }\n        catch (error) {\n            // NOTE: If there are no sending tracks, setLocalDescription() will fail with\n            // \"Failed to create channels\". If so, ignore it.\n            if (this._sendStream.getTracks().length === 0) {\n                logger.warn('stopSending() | ignoring expected error due no sending tracks: %s', error.toString());\n                return;\n            }\n            throw error;\n        }\n        if (this._pc.signalingState === 'stable') {\n            return;\n        }\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        // Unimplemented.\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        // Unimplemented.\n    }\n    async replaceTrack(localId, track) {\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        const oldTrack = rtpSender.track;\n        await rtpSender.replaceTrack(track);\n        // Remove the old track from the local stream.\n        if (oldTrack) {\n            this._sendStream.removeTrack(oldTrack);\n        }\n        // Add the new track to the local stream.\n        if (track) {\n            this._sendStream.addTrack(track);\n        }\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        const parameters = rtpSender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await rtpSender.setParameters(parameters);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        const parameters = rtpSender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await rtpSender.setParameters(parameters);\n    }\n    async getSenderStats(localId) {\n        this.assertSendDirection();\n        const rtpSender = this._mapSendLocalIdRtpSender.get(localId);\n        if (!rtpSender) {\n            throw new Error('associated RTCRtpSender not found');\n        }\n        return rtpSender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertRecvDirection();\n        const results = [];\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const mid = kind;\n            this._remoteSdp.receive({\n                mid,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { kind, rtpParameters } = options;\n            const mid = kind;\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === mid);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { kind, trackId, rtpParameters } = options;\n            const mid = kind;\n            const localId = trackId;\n            const rtpReceiver = this._pc\n                .getReceivers()\n                .find((r) => r.track && r.track.id === localId);\n            if (!rtpReceiver) {\n                throw new Error('new RTCRtpReceiver not');\n            }\n            // Insert into the map.\n            this._mapRecvLocalIdInfo.set(localId, {\n                mid,\n                rtpParameters,\n                rtpReceiver,\n            });\n            results.push({\n                localId,\n                track: rtpReceiver.track,\n                rtpReceiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const { mid, rtpParameters } = this._mapRecvLocalIdInfo.get(localId) || {};\n            // Remove from the map.\n            this._mapRecvLocalIdInfo.delete(localId);\n            this._remoteSdp.planBStopReceiving({\n                mid: mid,\n                offerRtpParameters: rtpParameters,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertRecvDirection();\n        const { rtpReceiver } = this._mapRecvLocalIdInfo.get(localId) || {};\n        if (!rtpReceiver) {\n            throw new Error('associated RTCRtpReceiver not found');\n        }\n        return rtpReceiver.getStats();\n    }\n    async pauseReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async resumeReceiving(\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    localIds) {\n        // Unimplemented.\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation({ oldDataChannelSpec: true });\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Safari11 = Safari11;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Safari11.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/Safari12.js":
/*!****************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/Safari12.js ***!
  \****************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Safari12 = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst utils = __importStar(__webpack_require__(/*! ../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst ortc = __importStar(__webpack_require__(/*! ../ortc */ \"./node_modules/mediasoup-client/lib/ortc.js\"));\nconst sdpCommonUtils = __importStar(__webpack_require__(/*! ./sdp/commonUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js\"));\nconst sdpUnifiedPlanUtils = __importStar(__webpack_require__(/*! ./sdp/unifiedPlanUtils */ \"./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js\"));\nconst ortcUtils = __importStar(__webpack_require__(/*! ./ortc/utils */ \"./node_modules/mediasoup-client/lib/handlers/ortc/utils.js\"));\nconst errors_1 = __webpack_require__(/*! ../errors */ \"./node_modules/mediasoup-client/lib/errors.js\");\nconst HandlerInterface_1 = __webpack_require__(/*! ./HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\");\nconst RemoteSdp_1 = __webpack_require__(/*! ./sdp/RemoteSdp */ \"./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js\");\nconst scalabilityModes_1 = __webpack_require__(/*! ../scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nconst logger = new Logger_1.Logger('Safari12');\nconst SCTP_NUM_STREAMS = { OS: 1024, MIS: 1024 };\nclass Safari12 extends HandlerInterface_1.HandlerInterface {\n    /**\n     * Creates a factory function.\n     */\n    static createFactory() {\n        return () => new Safari12();\n    }\n    constructor() {\n        super();\n        // Closed flag.\n        this._closed = false;\n        // Map of RTCTransceivers indexed by MID.\n        this._mapMidTransceiver = new Map();\n        // Local stream for sending.\n        this._sendStream = new MediaStream();\n        // Whether a DataChannel m=application section has been created.\n        this._hasDataChannelMediaSection = false;\n        // Sending DataChannel id value counter. Incremented for each new DataChannel.\n        this._nextSendSctpStreamId = 0;\n        // Got transport local and remote parameters.\n        this._transportReady = false;\n    }\n    get name() {\n        return 'Safari12';\n    }\n    close() {\n        logger.debug('close()');\n        if (this._closed) {\n            return;\n        }\n        this._closed = true;\n        // Close RTCPeerConnection.\n        if (this._pc) {\n            try {\n                this._pc.close();\n            }\n            catch (error) { }\n        }\n        this.emit('@close');\n    }\n    async getNativeRtpCapabilities() {\n        logger.debug('getNativeRtpCapabilities()');\n        const pc = new RTCPeerConnection({\n            iceServers: [],\n            iceTransportPolicy: 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n        });\n        try {\n            pc.addTransceiver('audio');\n            pc.addTransceiver('video');\n            const offer = await pc.createOffer();\n            try {\n                pc.close();\n            }\n            catch (error) { }\n            const sdpObject = sdpTransform.parse(offer.sdp);\n            const nativeRtpCapabilities = sdpCommonUtils.extractRtpCapabilities({\n                sdpObject,\n            });\n            // libwebrtc supports NACK for OPUS but doesn't announce it.\n            ortcUtils.addNackSuppportForOpus(nativeRtpCapabilities);\n            return nativeRtpCapabilities;\n        }\n        catch (error) {\n            try {\n                pc.close();\n            }\n            catch (error2) { }\n            throw error;\n        }\n    }\n    async getNativeSctpCapabilities() {\n        logger.debug('getNativeSctpCapabilities()');\n        return {\n            numStreams: SCTP_NUM_STREAMS,\n        };\n    }\n    run({ direction, iceParameters, iceCandidates, dtlsParameters, sctpParameters, iceServers, iceTransportPolicy, additionalSettings, proprietaryConstraints, extendedRtpCapabilities, }) {\n        this.assertNotClosed();\n        logger.debug('run()');\n        this._direction = direction;\n        this._remoteSdp = new RemoteSdp_1.RemoteSdp({\n            iceParameters,\n            iceCandidates,\n            dtlsParameters,\n            sctpParameters,\n        });\n        this._sendingRtpParametersByKind = {\n            audio: ortc.getSendingRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRtpParameters('video', extendedRtpCapabilities),\n        };\n        this._sendingRemoteRtpParametersByKind = {\n            audio: ortc.getSendingRemoteRtpParameters('audio', extendedRtpCapabilities),\n            video: ortc.getSendingRemoteRtpParameters('video', extendedRtpCapabilities),\n        };\n        if (dtlsParameters.role && dtlsParameters.role !== 'auto') {\n            this._forcedLocalDtlsRole =\n                dtlsParameters.role === 'server' ? 'client' : 'server';\n        }\n        this._pc = new RTCPeerConnection({\n            iceServers: iceServers || [],\n            iceTransportPolicy: iceTransportPolicy || 'all',\n            bundlePolicy: 'max-bundle',\n            rtcpMuxPolicy: 'require',\n            ...additionalSettings,\n        }, proprietaryConstraints);\n        this._pc.addEventListener('icegatheringstatechange', () => {\n            this.emit('@icegatheringstatechange', this._pc.iceGatheringState);\n        });\n        if (this._pc.connectionState) {\n            this._pc.addEventListener('connectionstatechange', () => {\n                this.emit('@connectionstatechange', this._pc.connectionState);\n            });\n        }\n        else {\n            this._pc.addEventListener('iceconnectionstatechange', () => {\n                logger.warn('run() | pc.connectionState not supported, using pc.iceConnectionState');\n                switch (this._pc.iceConnectionState) {\n                    case 'checking': {\n                        this.emit('@connectionstatechange', 'connecting');\n                        break;\n                    }\n                    case 'connected':\n                    case 'completed': {\n                        this.emit('@connectionstatechange', 'connected');\n                        break;\n                    }\n                    case 'failed': {\n                        this.emit('@connectionstatechange', 'failed');\n                        break;\n                    }\n                    case 'disconnected': {\n                        this.emit('@connectionstatechange', 'disconnected');\n                        break;\n                    }\n                    case 'closed': {\n                        this.emit('@connectionstatechange', 'closed');\n                        break;\n                    }\n                }\n            });\n        }\n    }\n    async updateIceServers(iceServers) {\n        this.assertNotClosed();\n        logger.debug('updateIceServers()');\n        const configuration = this._pc.getConfiguration();\n        configuration.iceServers = iceServers;\n        this._pc.setConfiguration(configuration);\n    }\n    async restartIce(iceParameters) {\n        this.assertNotClosed();\n        logger.debug('restartIce()');\n        // Provide the remote SDP handler with new remote ICE parameters.\n        this._remoteSdp.updateIceParameters(iceParameters);\n        if (!this._transportReady) {\n            return;\n        }\n        if (this._direction === 'send') {\n            const offer = await this._pc.createOffer({ iceRestart: true });\n            logger.debug('restartIce() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n        }\n        else {\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('restartIce() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            logger.debug('restartIce() | calling pc.setLocalDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n        }\n    }\n    async getTransportStats() {\n        this.assertNotClosed();\n        return this._pc.getStats();\n    }\n    async send({ track, encodings, codecOptions, codec, onRtpSender, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('send() [kind:%s, track.id:%s]', track.kind, track.id);\n        const sendingRtpParameters = utils.clone(this._sendingRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRtpParameters.codecs = ortc.reduceCodecs(sendingRtpParameters.codecs, codec);\n        const sendingRemoteRtpParameters = utils.clone(this._sendingRemoteRtpParametersByKind[track.kind]);\n        // This may throw.\n        sendingRemoteRtpParameters.codecs = ortc.reduceCodecs(sendingRemoteRtpParameters.codecs, codec);\n        const mediaSectionIdx = this._remoteSdp.getNextMediaSectionIdx();\n        const transceiver = this._pc.addTransceiver(track, {\n            direction: 'sendonly',\n            streams: [this._sendStream],\n        });\n        if (onRtpSender) {\n            onRtpSender(transceiver.sender);\n        }\n        let offer = await this._pc.createOffer();\n        let localSdpObject = sdpTransform.parse(offer.sdp);\n        let offerMediaObject;\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        const layers = (0, scalabilityModes_1.parse)((encodings || [{}])[0].scalabilityMode);\n        if (encodings && encodings.length > 1) {\n            logger.debug('send() | enabling legacy simulcast');\n            localSdpObject = sdpTransform.parse(offer.sdp);\n            offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n            sdpUnifiedPlanUtils.addLegacySimulcast({\n                offerMediaObject,\n                numStreams: encodings.length,\n            });\n            offer = { type: 'offer', sdp: sdpTransform.write(localSdpObject) };\n        }\n        logger.debug('send() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        // We can now get the transceiver.mid.\n        const localId = transceiver.mid;\n        // Set MID.\n        sendingRtpParameters.mid = localId;\n        localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        offerMediaObject = localSdpObject.media[mediaSectionIdx.idx];\n        // Set RTCP CNAME.\n        sendingRtpParameters.rtcp.cname = sdpCommonUtils.getCname({\n            offerMediaObject,\n        });\n        // Set RTP encodings.\n        sendingRtpParameters.encodings = sdpUnifiedPlanUtils.getRtpEncodings({\n            offerMediaObject,\n        });\n        // Complete encodings with given values.\n        if (encodings) {\n            for (let idx = 0; idx < sendingRtpParameters.encodings.length; ++idx) {\n                if (encodings[idx]) {\n                    Object.assign(sendingRtpParameters.encodings[idx], encodings[idx]);\n                }\n            }\n        }\n        // If VP8 or H264 and there is effective simulcast, add scalabilityMode to\n        // each encoding.\n        if (sendingRtpParameters.encodings.length > 1 &&\n            (sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/vp8' ||\n                sendingRtpParameters.codecs[0].mimeType.toLowerCase() === 'video/h264')) {\n            for (const encoding of sendingRtpParameters.encodings) {\n                if (encoding.scalabilityMode) {\n                    encoding.scalabilityMode = `L1T${layers.temporalLayers}`;\n                }\n                else {\n                    encoding.scalabilityMode = 'L1T3';\n                }\n            }\n        }\n        this._remoteSdp.send({\n            offerMediaObject,\n            reuseMid: mediaSectionIdx.reuseMid,\n            offerRtpParameters: sendingRtpParameters,\n            answerRtpParameters: sendingRemoteRtpParameters,\n            codecOptions,\n        });\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('send() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        // Store in the map.\n        this._mapMidTransceiver.set(localId, transceiver);\n        return {\n            localId,\n            rtpParameters: sendingRtpParameters,\n            rtpSender: transceiver.sender,\n        };\n    }\n    async stopSending(localId) {\n        this.assertSendDirection();\n        if (this._closed) {\n            return;\n        }\n        logger.debug('stopSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.sender.replaceTrack(null);\n        this._pc.removeTrack(transceiver.sender);\n        const mediaSectionClosed = this._remoteSdp.closeMediaSection(transceiver.mid);\n        if (mediaSectionClosed) {\n            try {\n                transceiver.stop();\n            }\n            catch (error) { }\n        }\n        const offer = await this._pc.createOffer();\n        logger.debug('stopSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n        this._mapMidTransceiver.delete(localId);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async pauseSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('pauseSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'inactive';\n        this._remoteSdp.pauseMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('pauseSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    async resumeSending(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('resumeSending() [localId:%s]', localId);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        transceiver.direction = 'sendonly';\n        this._remoteSdp.resumeSendingMediaSection(localId);\n        const offer = await this._pc.createOffer();\n        logger.debug('resumeSending() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeSending() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async replaceTrack(localId, track) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        if (track) {\n            logger.debug('replaceTrack() [localId:%s, track.id:%s]', localId, track.id);\n        }\n        else {\n            logger.debug('replaceTrack() [localId:%s, no track]', localId);\n        }\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        await transceiver.sender.replaceTrack(track);\n    }\n    async setMaxSpatialLayer(localId, spatialLayer) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setMaxSpatialLayer() [localId:%s, spatialLayer:%s]', localId, spatialLayer);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            if (idx <= spatialLayer) {\n                encoding.active = true;\n            }\n            else {\n                encoding.active = false;\n            }\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setMaxSpatialLayer() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setMaxSpatialLayer() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async setRtpEncodingParameters(localId, params) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        logger.debug('setRtpEncodingParameters() [localId:%s, params:%o]', localId, params);\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        const parameters = transceiver.sender.getParameters();\n        parameters.encodings.forEach((encoding, idx) => {\n            parameters.encodings[idx] = { ...encoding, ...params };\n        });\n        await transceiver.sender.setParameters(parameters);\n        this._remoteSdp.muxMediaSectionSimulcast(localId, parameters.encodings);\n        const offer = await this._pc.createOffer();\n        logger.debug('setRtpEncodingParameters() | calling pc.setLocalDescription() [offer:%o]', offer);\n        await this._pc.setLocalDescription(offer);\n        const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('setRtpEncodingParameters() | calling pc.setRemoteDescription() [answer:%o]', answer);\n        await this._pc.setRemoteDescription(answer);\n    }\n    async getSenderStats(localId) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.sender.getStats();\n    }\n    async sendDataChannel({ ordered, maxPacketLifeTime, maxRetransmits, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertSendDirection();\n        const options = {\n            negotiated: true,\n            id: this._nextSendSctpStreamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('sendDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // Increase next id.\n        this._nextSendSctpStreamId =\n            ++this._nextSendSctpStreamId % SCTP_NUM_STREAMS.MIS;\n        // If this is the first DataChannel we need to create the SDP answer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            const offer = await this._pc.createOffer();\n            const localSdpObject = sdpTransform.parse(offer.sdp);\n            const offerMediaObject = localSdpObject.media.find((m) => m.type === 'application');\n            if (!this._transportReady) {\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('sendDataChannel() | calling pc.setLocalDescription() [offer:%o]', offer);\n            await this._pc.setLocalDescription(offer);\n            this._remoteSdp.sendSctpAssociation({ offerMediaObject });\n            const answer = { type: 'answer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('sendDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setRemoteDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        const sctpStreamParameters = {\n            streamId: options.id,\n            ordered: options.ordered,\n            maxPacketLifeTime: options.maxPacketLifeTime,\n            maxRetransmits: options.maxRetransmits,\n        };\n        return { dataChannel, sctpStreamParameters };\n    }\n    async receive(optionsList) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const results = [];\n        const mapLocalId = new Map();\n        for (const options of optionsList) {\n            const { trackId, kind, rtpParameters, streamId } = options;\n            logger.debug('receive() [trackId:%s, kind:%s]', trackId, kind);\n            const localId = rtpParameters.mid || String(this._mapMidTransceiver.size);\n            mapLocalId.set(trackId, localId);\n            this._remoteSdp.receive({\n                mid: localId,\n                kind,\n                offerRtpParameters: rtpParameters,\n                streamId: streamId || rtpParameters.rtcp.cname,\n                trackId,\n            });\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('receive() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        for (const options of optionsList) {\n            const { trackId, onRtpReceiver } = options;\n            if (onRtpReceiver) {\n                const localId = mapLocalId.get(trackId);\n                const transceiver = this._pc\n                    .getTransceivers()\n                    .find((t) => t.mid === localId);\n                if (!transceiver) {\n                    throw new Error('transceiver not found');\n                }\n                onRtpReceiver(transceiver.receiver);\n            }\n        }\n        let answer = await this._pc.createAnswer();\n        const localSdpObject = sdpTransform.parse(answer.sdp);\n        for (const options of optionsList) {\n            const { trackId, rtpParameters } = options;\n            const localId = mapLocalId.get(trackId);\n            const answerMediaObject = localSdpObject.media.find((m) => String(m.mid) === localId);\n            // May need to modify codec parameters in the answer based on codec\n            // parameters in the offer.\n            sdpCommonUtils.applyCodecParameters({\n                offerRtpParameters: rtpParameters,\n                answerMediaObject,\n            });\n        }\n        answer = { type: 'answer', sdp: sdpTransform.write(localSdpObject) };\n        if (!this._transportReady) {\n            await this.setupTransport({\n                localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                localSdpObject,\n            });\n        }\n        logger.debug('receive() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const options of optionsList) {\n            const { trackId } = options;\n            const localId = mapLocalId.get(trackId);\n            const transceiver = this._pc\n                .getTransceivers()\n                .find((t) => t.mid === localId);\n            if (!transceiver) {\n                throw new Error('new RTCRtpTransceiver not found');\n            }\n            // Store in the map.\n            this._mapMidTransceiver.set(localId, transceiver);\n            results.push({\n                localId,\n                track: transceiver.receiver.track,\n                rtpReceiver: transceiver.receiver,\n            });\n        }\n        return results;\n    }\n    async stopReceiving(localIds) {\n        this.assertRecvDirection();\n        if (this._closed) {\n            return;\n        }\n        for (const localId of localIds) {\n            logger.debug('stopReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            this._remoteSdp.closeMediaSection(transceiver.mid);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('stopReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('stopReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n        for (const localId of localIds) {\n            this._mapMidTransceiver.delete(localId);\n        }\n    }\n    async pauseReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('pauseReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'inactive';\n            this._remoteSdp.pauseMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('pauseReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('pauseReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async resumeReceiving(localIds) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        for (const localId of localIds) {\n            logger.debug('resumeReceiving() [localId:%s]', localId);\n            const transceiver = this._mapMidTransceiver.get(localId);\n            if (!transceiver) {\n                throw new Error('associated RTCRtpTransceiver not found');\n            }\n            transceiver.direction = 'recvonly';\n            this._remoteSdp.resumeReceivingMediaSection(localId);\n        }\n        const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n        logger.debug('resumeReceiving() | calling pc.setRemoteDescription() [offer:%o]', offer);\n        await this._pc.setRemoteDescription(offer);\n        const answer = await this._pc.createAnswer();\n        logger.debug('resumeReceiving() | calling pc.setLocalDescription() [answer:%o]', answer);\n        await this._pc.setLocalDescription(answer);\n    }\n    async getReceiverStats(localId) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const transceiver = this._mapMidTransceiver.get(localId);\n        if (!transceiver) {\n            throw new Error('associated RTCRtpTransceiver not found');\n        }\n        return transceiver.receiver.getStats();\n    }\n    async receiveDataChannel({ sctpStreamParameters, label, protocol, }) {\n        this.assertNotClosed();\n        this.assertRecvDirection();\n        const { streamId, ordered, maxPacketLifeTime, maxRetransmits, } = sctpStreamParameters;\n        const options = {\n            negotiated: true,\n            id: streamId,\n            ordered,\n            maxPacketLifeTime,\n            maxRetransmits,\n            protocol,\n        };\n        logger.debug('receiveDataChannel() [options:%o]', options);\n        const dataChannel = this._pc.createDataChannel(label, options);\n        // If this is the first DataChannel we need to create the SDP offer with\n        // m=application section.\n        if (!this._hasDataChannelMediaSection) {\n            this._remoteSdp.receiveSctpAssociation();\n            const offer = { type: 'offer', sdp: this._remoteSdp.getSdp() };\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [offer:%o]', offer);\n            await this._pc.setRemoteDescription(offer);\n            const answer = await this._pc.createAnswer();\n            if (!this._transportReady) {\n                const localSdpObject = sdpTransform.parse(answer.sdp);\n                await this.setupTransport({\n                    localDtlsRole: this._forcedLocalDtlsRole ?? 'client',\n                    localSdpObject,\n                });\n            }\n            logger.debug('receiveDataChannel() | calling pc.setRemoteDescription() [answer:%o]', answer);\n            await this._pc.setLocalDescription(answer);\n            this._hasDataChannelMediaSection = true;\n        }\n        return { dataChannel };\n    }\n    async setupTransport({ localDtlsRole, localSdpObject, }) {\n        if (!localSdpObject) {\n            localSdpObject = sdpTransform.parse(this._pc.localDescription.sdp);\n        }\n        // Get our local DTLS parameters.\n        const dtlsParameters = sdpCommonUtils.extractDtlsParameters({\n            sdpObject: localSdpObject,\n        });\n        // Set our DTLS role.\n        dtlsParameters.role = localDtlsRole;\n        // Update the remote DTLS role in the SDP.\n        this._remoteSdp.updateDtlsRole(localDtlsRole === 'client' ? 'server' : 'client');\n        // Need to tell the remote transport about our parameters.\n        await new Promise((resolve, reject) => {\n            this.safeEmit('@connect', { dtlsParameters }, resolve, reject);\n        });\n        this._transportReady = true;\n    }\n    assertNotClosed() {\n        if (this._closed) {\n            throw new errors_1.InvalidStateError('method called in a closed handler');\n        }\n    }\n    assertSendDirection() {\n        if (this._direction !== 'send') {\n            throw new Error('method can just be called for handlers with \"send\" direction');\n        }\n    }\n    assertRecvDirection() {\n        if (this._direction !== 'recv') {\n            throw new Error('method can just be called for handlers with \"recv\" direction');\n        }\n    }\n}\nexports.Safari12 = Safari12;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/Safari12.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/ortc/edgeUtils.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/ortc/edgeUtils.js ***!
  \**********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getCapabilities = getCapabilities;\nexports.mangleRtpParameters = mangleRtpParameters;\nconst utils = __importStar(__webpack_require__(/*! ../../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\n/**\n * Normalize ORTC based Edge's RTCRtpReceiver.getCapabilities() to produce a full\n * compliant ORTC RTCRtpCapabilities.\n */\nfunction getCapabilities() {\n    const nativeCaps = RTCRtpReceiver.getCapabilities();\n    const caps = utils.clone(nativeCaps);\n    for (const codec of caps.codecs ?? []) {\n        // Rename numChannels to channels.\n        // @ts-ignore\n        codec.channels = codec.numChannels;\n        // @ts-ignore\n        delete codec.numChannels;\n        // Add mimeType.\n        // @ts-ignore (due to codec.name).\n        codec.mimeType = codec.mimeType || `${codec.kind}/${codec.name}`;\n        // NOTE: Edge sets some numeric parameters as string rather than number. Fix them.\n        if (codec.parameters) {\n            const parameters = codec.parameters;\n            if (parameters.apt) {\n                parameters.apt = Number(parameters.apt);\n            }\n            if (parameters['packetization-mode']) {\n                parameters['packetization-mode'] = Number(parameters['packetization-mode']);\n            }\n        }\n        // Delete emty parameter String in rtcpFeedback.\n        for (const feedback of codec.rtcpFeedback || []) {\n            if (!feedback.parameter) {\n                feedback.parameter = '';\n            }\n        }\n    }\n    return caps;\n}\n/**\n * Generate RTCRtpParameters as ORTC based Edge likes.\n */\nfunction mangleRtpParameters(rtpParameters) {\n    const params = utils.clone(rtpParameters);\n    // Rename mid to muxId.\n    if (params.mid) {\n        // @ts-ignore (due to muxId).\n        params.muxId = params.mid;\n        delete params.mid;\n    }\n    for (const codec of params.codecs) {\n        // Rename channels to numChannels.\n        if (codec.channels) {\n            // @ts-ignore.\n            codec.numChannels = codec.channels;\n            delete codec.channels;\n        }\n        // Add codec.name (requried by Edge).\n        // @ts-ignore (due to name).\n        if (codec.mimeType && !codec.name) {\n            // @ts-ignore (due to name).\n            codec.name = codec.mimeType.split('/')[1];\n        }\n        // Remove mimeType.\n        // @ts-ignore\n        delete codec.mimeType;\n    }\n    return params;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/ortc/edgeUtils.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/ortc/utils.js":
/*!******************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/ortc/utils.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.addNackSuppportForOpus = addNackSuppportForOpus;\n/**\n * This function adds RTCP NACK support for OPUS codec in given capabilities.\n */\nfunction addNackSuppportForOpus(rtpCapabilities) {\n    for (const codec of rtpCapabilities.codecs || []) {\n        if ((codec.mimeType.toLowerCase() === 'audio/opus' ||\n            codec.mimeType.toLowerCase() === 'audio/multiopus') &&\n            !codec.rtcpFeedback?.some(fb => fb.type === 'nack' && !fb.parameter)) {\n            if (!codec.rtcpFeedback) {\n                codec.rtcpFeedback = [];\n            }\n            codec.rtcpFeedback.push({ type: 'nack' });\n        }\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/ortc/utils.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/sdp/MediaSection.js":
/*!************************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/sdp/MediaSection.js ***!
  \************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OfferMediaSection = exports.AnswerMediaSection = exports.MediaSection = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst utils = __importStar(__webpack_require__(/*! ../../utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nclass MediaSection {\n    constructor({ iceParameters, iceCandidates, dtlsParameters, planB = false, }) {\n        this._mediaObject = {};\n        this._planB = planB;\n        if (iceParameters) {\n            this.setIceParameters(iceParameters);\n        }\n        if (iceCandidates) {\n            this._mediaObject.candidates = [];\n            for (const candidate of iceCandidates) {\n                const candidateObject = {};\n                // mediasoup does mandates rtcp-mux so candidates component is always\n                // RTP (1).\n                candidateObject.component = 1;\n                candidateObject.foundation = candidate.foundation;\n                // Be ready for new candidate.address field in mediasoup server side\n                // field and keep backward compatibility with deprecated candidate.ip.\n                candidateObject.ip = candidate.address ?? candidate.ip;\n                candidateObject.port = candidate.port;\n                candidateObject.priority = candidate.priority;\n                candidateObject.transport = candidate.protocol;\n                candidateObject.type = candidate.type;\n                if (candidate.tcpType) {\n                    candidateObject.tcptype = candidate.tcpType;\n                }\n                this._mediaObject.candidates.push(candidateObject);\n            }\n            this._mediaObject.endOfCandidates = 'end-of-candidates';\n            this._mediaObject.iceOptions = 'renomination';\n        }\n        if (dtlsParameters) {\n            this.setDtlsRole(dtlsParameters.role);\n        }\n    }\n    get mid() {\n        return String(this._mediaObject.mid);\n    }\n    get closed() {\n        return this._mediaObject.port === 0;\n    }\n    getObject() {\n        return this._mediaObject;\n    }\n    setIceParameters(iceParameters) {\n        this._mediaObject.iceUfrag = iceParameters.usernameFragment;\n        this._mediaObject.icePwd = iceParameters.password;\n    }\n    pause() {\n        this._mediaObject.direction = 'inactive';\n    }\n    disable() {\n        this.pause();\n        delete this._mediaObject.ext;\n        delete this._mediaObject.ssrcs;\n        delete this._mediaObject.ssrcGroups;\n        delete this._mediaObject.simulcast;\n        delete this._mediaObject.simulcast_03;\n        delete this._mediaObject.rids;\n        delete this._mediaObject.extmapAllowMixed;\n    }\n    close() {\n        this.disable();\n        this._mediaObject.port = 0;\n    }\n}\nexports.MediaSection = MediaSection;\nclass AnswerMediaSection extends MediaSection {\n    constructor({ iceParameters, iceCandidates, dtlsParameters, sctpParameters, plainRtpParameters, planB = false, offerMediaObject, offerRtpParameters, answerRtpParameters, codecOptions, extmapAllowMixed = false, }) {\n        super({ iceParameters, iceCandidates, dtlsParameters, planB });\n        this._mediaObject.mid = String(offerMediaObject.mid);\n        this._mediaObject.type = offerMediaObject.type;\n        this._mediaObject.protocol = offerMediaObject.protocol;\n        if (!plainRtpParameters) {\n            this._mediaObject.connection = { ip: '127.0.0.1', version: 4 };\n            this._mediaObject.port = 7;\n        }\n        else {\n            this._mediaObject.connection = {\n                ip: plainRtpParameters.ip,\n                version: plainRtpParameters.ipVersion,\n            };\n            this._mediaObject.port = plainRtpParameters.port;\n        }\n        switch (offerMediaObject.type) {\n            case 'audio':\n            case 'video': {\n                this._mediaObject.direction = 'recvonly';\n                this._mediaObject.rtp = [];\n                this._mediaObject.rtcpFb = [];\n                this._mediaObject.fmtp = [];\n                for (const codec of answerRtpParameters.codecs) {\n                    const rtp = {\n                        payload: codec.payloadType,\n                        codec: getCodecName(codec),\n                        rate: codec.clockRate,\n                    };\n                    if (codec.channels > 1) {\n                        rtp.encoding = codec.channels;\n                    }\n                    this._mediaObject.rtp.push(rtp);\n                    const codecParameters = utils.clone(codec.parameters) ?? {};\n                    let codecRtcpFeedback = utils.clone(codec.rtcpFeedback) ?? [];\n                    if (codecOptions) {\n                        const { opusStereo, opusFec, opusDtx, opusMaxPlaybackRate, opusMaxAverageBitrate, opusPtime, opusNack, videoGoogleStartBitrate, videoGoogleMaxBitrate, videoGoogleMinBitrate, } = codecOptions;\n                        const offerCodec = offerRtpParameters.codecs.find((c) => c.payloadType === codec.payloadType);\n                        switch (codec.mimeType.toLowerCase()) {\n                            case 'audio/opus':\n                            case 'audio/multiopus': {\n                                if (opusStereo !== undefined) {\n                                    offerCodec.parameters['sprop-stereo'] = opusStereo ? 1 : 0;\n                                    codecParameters.stereo = opusStereo ? 1 : 0;\n                                }\n                                if (opusFec !== undefined) {\n                                    offerCodec.parameters.useinbandfec = opusFec ? 1 : 0;\n                                    codecParameters.useinbandfec = opusFec ? 1 : 0;\n                                }\n                                if (opusDtx !== undefined) {\n                                    offerCodec.parameters.usedtx = opusDtx ? 1 : 0;\n                                    codecParameters.usedtx = opusDtx ? 1 : 0;\n                                }\n                                if (opusMaxPlaybackRate !== undefined) {\n                                    codecParameters.maxplaybackrate = opusMaxPlaybackRate;\n                                }\n                                if (opusMaxAverageBitrate !== undefined) {\n                                    codecParameters.maxaveragebitrate = opusMaxAverageBitrate;\n                                }\n                                if (opusPtime !== undefined) {\n                                    offerCodec.parameters.ptime = opusPtime;\n                                    codecParameters.ptime = opusPtime;\n                                }\n                                // If opusNack is not set, we must remove NACK support for OPUS.\n                                // Otherwise it would be enabled for those handlers that artificially\n                                // announce it in their RTP capabilities.\n                                if (!opusNack) {\n                                    offerCodec.rtcpFeedback = offerCodec.rtcpFeedback.filter(fb => fb.type !== 'nack' || fb.parameter);\n                                    codecRtcpFeedback = codecRtcpFeedback.filter(fb => fb.type !== 'nack' || fb.parameter);\n                                }\n                                break;\n                            }\n                            case 'video/vp8':\n                            case 'video/vp9':\n                            case 'video/h264':\n                            case 'video/h265': {\n                                if (videoGoogleStartBitrate !== undefined) {\n                                    codecParameters['x-google-start-bitrate'] =\n                                        videoGoogleStartBitrate;\n                                }\n                                if (videoGoogleMaxBitrate !== undefined) {\n                                    codecParameters['x-google-max-bitrate'] =\n                                        videoGoogleMaxBitrate;\n                                }\n                                if (videoGoogleMinBitrate !== undefined) {\n                                    codecParameters['x-google-min-bitrate'] =\n                                        videoGoogleMinBitrate;\n                                }\n                                break;\n                            }\n                        }\n                    }\n                    const fmtp = {\n                        payload: codec.payloadType,\n                        config: '',\n                    };\n                    for (const key of Object.keys(codecParameters)) {\n                        if (fmtp.config) {\n                            fmtp.config += ';';\n                        }\n                        fmtp.config += `${key}=${codecParameters[key]}`;\n                    }\n                    if (fmtp.config) {\n                        this._mediaObject.fmtp.push(fmtp);\n                    }\n                    for (const fb of codecRtcpFeedback) {\n                        this._mediaObject.rtcpFb.push({\n                            payload: codec.payloadType,\n                            type: fb.type,\n                            subtype: fb.parameter,\n                        });\n                    }\n                }\n                this._mediaObject.payloads = answerRtpParameters.codecs\n                    .map((codec) => codec.payloadType)\n                    .join(' ');\n                this._mediaObject.ext = [];\n                for (const ext of answerRtpParameters.headerExtensions) {\n                    // Don't add a header extension if not present in the offer.\n                    const found = (offerMediaObject.ext || []).some((localExt) => localExt.uri === ext.uri);\n                    if (!found) {\n                        continue;\n                    }\n                    this._mediaObject.ext.push({\n                        uri: ext.uri,\n                        value: ext.id,\n                    });\n                }\n                // Allow both 1 byte and 2 bytes length header extensions.\n                if (extmapAllowMixed &&\n                    offerMediaObject.extmapAllowMixed === 'extmap-allow-mixed') {\n                    this._mediaObject.extmapAllowMixed = 'extmap-allow-mixed';\n                }\n                // Simulcast.\n                if (offerMediaObject.simulcast) {\n                    this._mediaObject.simulcast = {\n                        dir1: 'recv',\n                        list1: offerMediaObject.simulcast.list1,\n                    };\n                    this._mediaObject.rids = [];\n                    for (const rid of offerMediaObject.rids || []) {\n                        if (rid.direction !== 'send') {\n                            continue;\n                        }\n                        this._mediaObject.rids.push({\n                            id: rid.id,\n                            direction: 'recv',\n                        });\n                    }\n                }\n                // Simulcast (draft version 03).\n                else if (offerMediaObject.simulcast_03) {\n                    // eslint-disable-next-line camelcase\n                    this._mediaObject.simulcast_03 = {\n                        value: offerMediaObject.simulcast_03.value.replace(/send/g, 'recv'),\n                    };\n                    this._mediaObject.rids = [];\n                    for (const rid of offerMediaObject.rids || []) {\n                        if (rid.direction !== 'send') {\n                            continue;\n                        }\n                        this._mediaObject.rids.push({\n                            id: rid.id,\n                            direction: 'recv',\n                        });\n                    }\n                }\n                this._mediaObject.rtcpMux = 'rtcp-mux';\n                this._mediaObject.rtcpRsize = 'rtcp-rsize';\n                if (this._planB && this._mediaObject.type === 'video') {\n                    this._mediaObject.xGoogleFlag = 'conference';\n                }\n                break;\n            }\n            case 'application': {\n                // New spec.\n                if (typeof offerMediaObject.sctpPort === 'number') {\n                    this._mediaObject.payloads = 'webrtc-datachannel';\n                    this._mediaObject.sctpPort = sctpParameters.port;\n                    this._mediaObject.maxMessageSize = sctpParameters.maxMessageSize;\n                }\n                // Old spec.\n                else if (offerMediaObject.sctpmap) {\n                    this._mediaObject.payloads = sctpParameters.port;\n                    this._mediaObject.sctpmap = {\n                        app: 'webrtc-datachannel',\n                        sctpmapNumber: sctpParameters.port,\n                        maxMessageSize: sctpParameters.maxMessageSize,\n                    };\n                }\n                break;\n            }\n        }\n    }\n    setDtlsRole(role) {\n        switch (role) {\n            case 'client': {\n                this._mediaObject.setup = 'active';\n                break;\n            }\n            case 'server': {\n                this._mediaObject.setup = 'passive';\n                break;\n            }\n            case 'auto': {\n                this._mediaObject.setup = 'actpass';\n                break;\n            }\n        }\n    }\n    resume() {\n        this._mediaObject.direction = 'recvonly';\n    }\n    muxSimulcastStreams(encodings) {\n        if (!this._mediaObject.simulcast || !this._mediaObject.simulcast.list1) {\n            return;\n        }\n        const layers = {};\n        for (const encoding of encodings) {\n            if (encoding.rid) {\n                layers[encoding.rid] = encoding;\n            }\n        }\n        const raw = this._mediaObject.simulcast.list1;\n        const simulcastStreams = sdpTransform.parseSimulcastStreamList(raw);\n        for (const simulcastStream of simulcastStreams) {\n            for (const simulcastFormat of simulcastStream) {\n                simulcastFormat.paused = !layers[simulcastFormat.scid]?.active;\n            }\n        }\n        this._mediaObject.simulcast.list1 = simulcastStreams\n            .map(simulcastFormats => simulcastFormats.map(f => `${f.paused ? '~' : ''}${f.scid}`).join(','))\n            .join(';');\n    }\n}\nexports.AnswerMediaSection = AnswerMediaSection;\nclass OfferMediaSection extends MediaSection {\n    constructor({ iceParameters, iceCandidates, dtlsParameters, sctpParameters, plainRtpParameters, planB = false, mid, kind, offerRtpParameters, streamId, trackId, oldDataChannelSpec = false, }) {\n        super({ iceParameters, iceCandidates, dtlsParameters, planB });\n        this._mediaObject.mid = String(mid);\n        this._mediaObject.type = kind;\n        if (!plainRtpParameters) {\n            this._mediaObject.connection = { ip: '127.0.0.1', version: 4 };\n            if (!sctpParameters) {\n                this._mediaObject.protocol = 'UDP/TLS/RTP/SAVPF';\n            }\n            else {\n                this._mediaObject.protocol = 'UDP/DTLS/SCTP';\n            }\n            this._mediaObject.port = 7;\n        }\n        else {\n            this._mediaObject.connection = {\n                ip: plainRtpParameters.ip,\n                version: plainRtpParameters.ipVersion,\n            };\n            this._mediaObject.protocol = 'RTP/AVP';\n            this._mediaObject.port = plainRtpParameters.port;\n        }\n        switch (kind) {\n            case 'audio':\n            case 'video': {\n                this._mediaObject.direction = 'sendonly';\n                this._mediaObject.rtp = [];\n                this._mediaObject.rtcpFb = [];\n                this._mediaObject.fmtp = [];\n                if (!this._planB) {\n                    this._mediaObject.msid = `${streamId || '-'} ${trackId}`;\n                }\n                for (const codec of offerRtpParameters.codecs) {\n                    const rtp = {\n                        payload: codec.payloadType,\n                        codec: getCodecName(codec),\n                        rate: codec.clockRate,\n                    };\n                    if (codec.channels > 1) {\n                        rtp.encoding = codec.channels;\n                    }\n                    this._mediaObject.rtp.push(rtp);\n                    const fmtp = {\n                        payload: codec.payloadType,\n                        config: '',\n                    };\n                    for (const key of Object.keys(codec.parameters)) {\n                        if (fmtp.config) {\n                            fmtp.config += ';';\n                        }\n                        fmtp.config += `${key}=${codec.parameters[key]}`;\n                    }\n                    if (fmtp.config) {\n                        this._mediaObject.fmtp.push(fmtp);\n                    }\n                    for (const fb of codec.rtcpFeedback) {\n                        this._mediaObject.rtcpFb.push({\n                            payload: codec.payloadType,\n                            type: fb.type,\n                            subtype: fb.parameter,\n                        });\n                    }\n                }\n                this._mediaObject.payloads = offerRtpParameters.codecs\n                    .map((codec) => codec.payloadType)\n                    .join(' ');\n                this._mediaObject.ext = [];\n                for (const ext of offerRtpParameters.headerExtensions) {\n                    this._mediaObject.ext.push({\n                        uri: ext.uri,\n                        value: ext.id,\n                    });\n                }\n                this._mediaObject.rtcpMux = 'rtcp-mux';\n                this._mediaObject.rtcpRsize = 'rtcp-rsize';\n                const encoding = offerRtpParameters.encodings[0];\n                const ssrc = encoding.ssrc;\n                const rtxSsrc = encoding.rtx && encoding.rtx.ssrc ? encoding.rtx.ssrc : undefined;\n                this._mediaObject.ssrcs = [];\n                this._mediaObject.ssrcGroups = [];\n                if (offerRtpParameters.rtcp.cname) {\n                    this._mediaObject.ssrcs.push({\n                        id: ssrc,\n                        attribute: 'cname',\n                        value: offerRtpParameters.rtcp.cname,\n                    });\n                }\n                if (this._planB) {\n                    this._mediaObject.ssrcs.push({\n                        id: ssrc,\n                        attribute: 'msid',\n                        value: `${streamId || '-'} ${trackId}`,\n                    });\n                }\n                if (rtxSsrc) {\n                    if (offerRtpParameters.rtcp.cname) {\n                        this._mediaObject.ssrcs.push({\n                            id: rtxSsrc,\n                            attribute: 'cname',\n                            value: offerRtpParameters.rtcp.cname,\n                        });\n                    }\n                    if (this._planB) {\n                        this._mediaObject.ssrcs.push({\n                            id: rtxSsrc,\n                            attribute: 'msid',\n                            value: `${streamId || '-'} ${trackId}`,\n                        });\n                    }\n                    // Associate original and retransmission SSRCs.\n                    this._mediaObject.ssrcGroups.push({\n                        semantics: 'FID',\n                        ssrcs: `${ssrc} ${rtxSsrc}`,\n                    });\n                }\n                break;\n            }\n            case 'application': {\n                // New spec.\n                if (!oldDataChannelSpec) {\n                    this._mediaObject.payloads = 'webrtc-datachannel';\n                    this._mediaObject.sctpPort = sctpParameters.port;\n                    this._mediaObject.maxMessageSize = sctpParameters.maxMessageSize;\n                }\n                // Old spec.\n                else {\n                    this._mediaObject.payloads = sctpParameters.port;\n                    this._mediaObject.sctpmap = {\n                        app: 'webrtc-datachannel',\n                        sctpmapNumber: sctpParameters.port,\n                        maxMessageSize: sctpParameters.maxMessageSize,\n                    };\n                }\n                break;\n            }\n        }\n    }\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    setDtlsRole(role) {\n        // Always 'actpass'.\n        this._mediaObject.setup = 'actpass';\n    }\n    resume() {\n        this._mediaObject.direction = 'sendonly';\n    }\n    planBReceive({ offerRtpParameters, streamId, trackId, }) {\n        const encoding = offerRtpParameters.encodings[0];\n        const ssrc = encoding.ssrc;\n        const rtxSsrc = encoding.rtx && encoding.rtx.ssrc ? encoding.rtx.ssrc : undefined;\n        const payloads = this._mediaObject.payloads.split(' ');\n        for (const codec of offerRtpParameters.codecs) {\n            if (payloads.includes(String(codec.payloadType))) {\n                continue;\n            }\n            const rtp = {\n                payload: codec.payloadType,\n                codec: getCodecName(codec),\n                rate: codec.clockRate,\n            };\n            if (codec.channels > 1) {\n                rtp.encoding = codec.channels;\n            }\n            this._mediaObject.rtp.push(rtp);\n            const fmtp = {\n                payload: codec.payloadType,\n                config: '',\n            };\n            for (const key of Object.keys(codec.parameters)) {\n                if (fmtp.config) {\n                    fmtp.config += ';';\n                }\n                fmtp.config += `${key}=${codec.parameters[key]}`;\n            }\n            if (fmtp.config) {\n                this._mediaObject.fmtp.push(fmtp);\n            }\n            for (const fb of codec.rtcpFeedback) {\n                this._mediaObject.rtcpFb.push({\n                    payload: codec.payloadType,\n                    type: fb.type,\n                    subtype: fb.parameter,\n                });\n            }\n        }\n        this._mediaObject.payloads += ` ${offerRtpParameters.codecs\n            .filter((codec) => !this._mediaObject.payloads.includes(codec.payloadType))\n            .map((codec) => codec.payloadType)\n            .join(' ')}`;\n        this._mediaObject.payloads = this._mediaObject.payloads.trim();\n        if (offerRtpParameters.rtcp.cname) {\n            this._mediaObject.ssrcs.push({\n                id: ssrc,\n                attribute: 'cname',\n                value: offerRtpParameters.rtcp.cname,\n            });\n        }\n        this._mediaObject.ssrcs.push({\n            id: ssrc,\n            attribute: 'msid',\n            value: `${streamId || '-'} ${trackId}`,\n        });\n        if (rtxSsrc) {\n            if (offerRtpParameters.rtcp.cname) {\n                this._mediaObject.ssrcs.push({\n                    id: rtxSsrc,\n                    attribute: 'cname',\n                    value: offerRtpParameters.rtcp.cname,\n                });\n            }\n            this._mediaObject.ssrcs.push({\n                id: rtxSsrc,\n                attribute: 'msid',\n                value: `${streamId || '-'} ${trackId}`,\n            });\n            // Associate original and retransmission SSRCs.\n            this._mediaObject.ssrcGroups.push({\n                semantics: 'FID',\n                ssrcs: `${ssrc} ${rtxSsrc}`,\n            });\n        }\n    }\n    planBStopReceiving({ offerRtpParameters, }) {\n        const encoding = offerRtpParameters.encodings[0];\n        const ssrc = encoding.ssrc;\n        const rtxSsrc = encoding.rtx && encoding.rtx.ssrc ? encoding.rtx.ssrc : undefined;\n        this._mediaObject.ssrcs = this._mediaObject.ssrcs.filter((s) => s.id !== ssrc && s.id !== rtxSsrc);\n        if (rtxSsrc) {\n            this._mediaObject.ssrcGroups = this._mediaObject.ssrcGroups.filter((group) => group.ssrcs !== `${ssrc} ${rtxSsrc}`);\n        }\n    }\n}\nexports.OfferMediaSection = OfferMediaSection;\nfunction getCodecName(codec) {\n    const MimeTypeRegex = new RegExp('^(audio|video)/(.+)', 'i');\n    const mimeTypeMatch = MimeTypeRegex.exec(codec.mimeType);\n    if (!mimeTypeMatch) {\n        throw new TypeError('invalid codec.mimeType');\n    }\n    return mimeTypeMatch[2];\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/sdp/MediaSection.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js":
/*!*********************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RemoteSdp = void 0;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\nconst Logger_1 = __webpack_require__(/*! ../../Logger */ \"./node_modules/mediasoup-client/lib/Logger.js\");\nconst MediaSection_1 = __webpack_require__(/*! ./MediaSection */ \"./node_modules/mediasoup-client/lib/handlers/sdp/MediaSection.js\");\nconst logger = new Logger_1.Logger('RemoteSdp');\nclass RemoteSdp {\n    constructor({ iceParameters, iceCandidates, dtlsParameters, sctpParameters, plainRtpParameters, planB = false, }) {\n        // MediaSection instances with same order as in the SDP.\n        this._mediaSections = [];\n        // MediaSection indices indexed by MID.\n        this._midToIndex = new Map();\n        this._iceParameters = iceParameters;\n        this._iceCandidates = iceCandidates;\n        this._dtlsParameters = dtlsParameters;\n        this._sctpParameters = sctpParameters;\n        this._plainRtpParameters = plainRtpParameters;\n        this._planB = planB;\n        this._sdpObject = {\n            version: 0,\n            origin: {\n                address: '0.0.0.0',\n                ipVer: 4,\n                netType: 'IN',\n                sessionId: 10000,\n                sessionVersion: 0,\n                username: 'mediasoup-client',\n            },\n            name: '-',\n            timing: { start: 0, stop: 0 },\n            media: [],\n        };\n        // If ICE parameters are given, add ICE-Lite indicator.\n        if (iceParameters && iceParameters.iceLite) {\n            this._sdpObject.icelite = 'ice-lite';\n        }\n        // If DTLS parameters are given, assume WebRTC and BUNDLE.\n        if (dtlsParameters) {\n            this._sdpObject.msidSemantic = { semantic: 'WMS', token: '*' };\n            // NOTE: We take the latest fingerprint.\n            const numFingerprints = this._dtlsParameters.fingerprints.length;\n            this._sdpObject.fingerprint = {\n                type: dtlsParameters.fingerprints[numFingerprints - 1].algorithm,\n                hash: dtlsParameters.fingerprints[numFingerprints - 1].value,\n            };\n            this._sdpObject.groups = [{ type: 'BUNDLE', mids: '' }];\n        }\n        // If there are plain RPT parameters, override SDP origin.\n        if (plainRtpParameters) {\n            this._sdpObject.origin.address = plainRtpParameters.ip;\n            this._sdpObject.origin.ipVer = plainRtpParameters.ipVersion;\n        }\n    }\n    updateIceParameters(iceParameters) {\n        logger.debug('updateIceParameters() [iceParameters:%o]', iceParameters);\n        this._iceParameters = iceParameters;\n        this._sdpObject.icelite = iceParameters.iceLite ? 'ice-lite' : undefined;\n        for (const mediaSection of this._mediaSections) {\n            mediaSection.setIceParameters(iceParameters);\n        }\n    }\n    updateDtlsRole(role) {\n        logger.debug('updateDtlsRole() [role:%s]', role);\n        this._dtlsParameters.role = role;\n        for (const mediaSection of this._mediaSections) {\n            mediaSection.setDtlsRole(role);\n        }\n    }\n    getNextMediaSectionIdx() {\n        // If a closed media section is found, return its index.\n        for (let idx = 0; idx < this._mediaSections.length; ++idx) {\n            const mediaSection = this._mediaSections[idx];\n            if (mediaSection.closed) {\n                return { idx, reuseMid: mediaSection.mid };\n            }\n        }\n        // If no closed media section is found, return next one.\n        return { idx: this._mediaSections.length };\n    }\n    send({ offerMediaObject, reuseMid, offerRtpParameters, answerRtpParameters, codecOptions, extmapAllowMixed = false, }) {\n        const mediaSection = new MediaSection_1.AnswerMediaSection({\n            iceParameters: this._iceParameters,\n            iceCandidates: this._iceCandidates,\n            dtlsParameters: this._dtlsParameters,\n            plainRtpParameters: this._plainRtpParameters,\n            planB: this._planB,\n            offerMediaObject,\n            offerRtpParameters,\n            answerRtpParameters,\n            codecOptions,\n            extmapAllowMixed,\n        });\n        // Unified-Plan with closed media section replacement.\n        if (reuseMid) {\n            this._replaceMediaSection(mediaSection, reuseMid);\n        }\n        // Unified-Plan or Plan-B with different media kind.\n        else if (!this._midToIndex.has(mediaSection.mid)) {\n            this._addMediaSection(mediaSection);\n        }\n        // Plan-B with same media kind.\n        else {\n            this._replaceMediaSection(mediaSection);\n        }\n    }\n    receive({ mid, kind, offerRtpParameters, streamId, trackId, }) {\n        const idx = this._midToIndex.get(mid);\n        let mediaSection;\n        if (idx !== undefined) {\n            mediaSection = this._mediaSections[idx];\n        }\n        // Unified-Plan or different media kind.\n        if (!mediaSection) {\n            mediaSection = new MediaSection_1.OfferMediaSection({\n                iceParameters: this._iceParameters,\n                iceCandidates: this._iceCandidates,\n                dtlsParameters: this._dtlsParameters,\n                plainRtpParameters: this._plainRtpParameters,\n                planB: this._planB,\n                mid,\n                kind,\n                offerRtpParameters,\n                streamId,\n                trackId,\n            });\n            // Let's try to recycle a closed media section (if any).\n            // NOTE: Yes, we can recycle a closed m=audio section with a new m=video.\n            const oldMediaSection = this._mediaSections.find(m => m.closed);\n            if (oldMediaSection) {\n                this._replaceMediaSection(mediaSection, oldMediaSection.mid);\n            }\n            else {\n                this._addMediaSection(mediaSection);\n            }\n        }\n        // Plan-B.\n        else {\n            mediaSection.planBReceive({ offerRtpParameters, streamId, trackId });\n            this._replaceMediaSection(mediaSection);\n        }\n    }\n    pauseMediaSection(mid) {\n        const mediaSection = this._findMediaSection(mid);\n        mediaSection.pause();\n    }\n    resumeSendingMediaSection(mid) {\n        const mediaSection = this._findMediaSection(mid);\n        mediaSection.resume();\n    }\n    resumeReceivingMediaSection(mid) {\n        const mediaSection = this._findMediaSection(mid);\n        mediaSection.resume();\n    }\n    disableMediaSection(mid) {\n        const mediaSection = this._findMediaSection(mid);\n        mediaSection.disable();\n    }\n    /**\n     * Closes media section. Returns true if the given MID corresponds to a m\n     * section that has been indeed closed. False otherwise.\n     *\n     * NOTE: Closing the first m section is a pain since it invalidates the bundled\n     * transport, so instead closing it we just disable it.\n     */\n    closeMediaSection(mid) {\n        const mediaSection = this._findMediaSection(mid);\n        // NOTE: Closing the first m section is a pain since it invalidates the\n        // bundled transport, so let's avoid it.\n        if (mid === this._firstMid) {\n            logger.debug('closeMediaSection() | cannot close first media section, disabling it instead [mid:%s]', mid);\n            this.disableMediaSection(mid);\n            return false;\n        }\n        mediaSection.close();\n        // Regenerate BUNDLE mids.\n        this._regenerateBundleMids();\n        return true;\n    }\n    muxMediaSectionSimulcast(mid, encodings) {\n        const mediaSection = this._findMediaSection(mid);\n        mediaSection.muxSimulcastStreams(encodings);\n        this._replaceMediaSection(mediaSection);\n    }\n    planBStopReceiving({ mid, offerRtpParameters, }) {\n        const mediaSection = this._findMediaSection(mid);\n        mediaSection.planBStopReceiving({ offerRtpParameters });\n        this._replaceMediaSection(mediaSection);\n    }\n    sendSctpAssociation({ offerMediaObject }) {\n        const mediaSection = new MediaSection_1.AnswerMediaSection({\n            iceParameters: this._iceParameters,\n            iceCandidates: this._iceCandidates,\n            dtlsParameters: this._dtlsParameters,\n            sctpParameters: this._sctpParameters,\n            plainRtpParameters: this._plainRtpParameters,\n            offerMediaObject,\n        });\n        this._addMediaSection(mediaSection);\n    }\n    receiveSctpAssociation({ oldDataChannelSpec = false, } = {}) {\n        const mediaSection = new MediaSection_1.OfferMediaSection({\n            iceParameters: this._iceParameters,\n            iceCandidates: this._iceCandidates,\n            dtlsParameters: this._dtlsParameters,\n            sctpParameters: this._sctpParameters,\n            plainRtpParameters: this._plainRtpParameters,\n            mid: 'datachannel',\n            kind: 'application',\n            oldDataChannelSpec,\n        });\n        this._addMediaSection(mediaSection);\n    }\n    getSdp() {\n        // Increase SDP version.\n        this._sdpObject.origin.sessionVersion++;\n        return sdpTransform.write(this._sdpObject);\n    }\n    _addMediaSection(newMediaSection) {\n        if (!this._firstMid) {\n            this._firstMid = newMediaSection.mid;\n        }\n        // Add to the vector.\n        this._mediaSections.push(newMediaSection);\n        // Add to the map.\n        this._midToIndex.set(newMediaSection.mid, this._mediaSections.length - 1);\n        // Add to the SDP object.\n        this._sdpObject.media.push(newMediaSection.getObject());\n        // Regenerate BUNDLE mids.\n        this._regenerateBundleMids();\n    }\n    _replaceMediaSection(newMediaSection, reuseMid) {\n        // Store it in the map.\n        if (typeof reuseMid === 'string') {\n            const idx = this._midToIndex.get(reuseMid);\n            if (idx === undefined) {\n                throw new Error(`no media section found for reuseMid '${reuseMid}'`);\n            }\n            const oldMediaSection = this._mediaSections[idx];\n            // Replace the index in the vector with the new media section.\n            this._mediaSections[idx] = newMediaSection;\n            // Update the map.\n            this._midToIndex.delete(oldMediaSection.mid);\n            this._midToIndex.set(newMediaSection.mid, idx);\n            // Update the SDP object.\n            this._sdpObject.media[idx] = newMediaSection.getObject();\n            // Regenerate BUNDLE mids.\n            this._regenerateBundleMids();\n        }\n        else {\n            const idx = this._midToIndex.get(newMediaSection.mid);\n            if (idx === undefined) {\n                throw new Error(`no media section found with mid '${newMediaSection.mid}'`);\n            }\n            // Replace the index in the vector with the new media section.\n            this._mediaSections[idx] = newMediaSection;\n            // Update the SDP object.\n            this._sdpObject.media[idx] = newMediaSection.getObject();\n        }\n    }\n    _findMediaSection(mid) {\n        const idx = this._midToIndex.get(mid);\n        if (idx === undefined) {\n            throw new Error(`no media section found with mid '${mid}'`);\n        }\n        return this._mediaSections[idx];\n    }\n    _regenerateBundleMids() {\n        if (!this._dtlsParameters) {\n            return;\n        }\n        this._sdpObject.groups[0].mids = this._mediaSections\n            .filter((mediaSection) => !mediaSection.closed)\n            .map((mediaSection) => mediaSection.mid)\n            .join(' ');\n    }\n}\nexports.RemoteSdp = RemoteSdp;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/sdp/RemoteSdp.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js":
/*!***********************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js ***!
  \***********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.extractRtpCapabilities = extractRtpCapabilities;\nexports.extractDtlsParameters = extractDtlsParameters;\nexports.getCname = getCname;\nexports.applyCodecParameters = applyCodecParameters;\nconst sdpTransform = __importStar(__webpack_require__(/*! sdp-transform */ \"./node_modules/sdp-transform/lib/index.js\"));\n/**\n * This function must be called with an SDP with 1 m=audio and 1 m=video\n * sections.\n */\nfunction extractRtpCapabilities({ sdpObject, }) {\n    // Map of RtpCodecParameters indexed by payload type.\n    const codecsMap = new Map();\n    // Array of RtpHeaderExtensions.\n    const headerExtensions = [];\n    // Whether a m=audio/video section has been already found.\n    let gotAudio = false;\n    let gotVideo = false;\n    for (const m of sdpObject.media) {\n        const kind = m.type;\n        switch (kind) {\n            case 'audio': {\n                if (gotAudio) {\n                    continue;\n                }\n                gotAudio = true;\n                break;\n            }\n            case 'video': {\n                if (gotVideo) {\n                    continue;\n                }\n                gotVideo = true;\n                break;\n            }\n            default: {\n                continue;\n            }\n        }\n        // Get codecs.\n        for (const rtp of m.rtp) {\n            const codec = {\n                kind: kind,\n                mimeType: `${kind}/${rtp.codec}`,\n                preferredPayloadType: rtp.payload,\n                clockRate: rtp.rate,\n                channels: rtp.encoding,\n                parameters: {},\n                rtcpFeedback: [],\n            };\n            codecsMap.set(codec.preferredPayloadType, codec);\n        }\n        // Get codec parameters.\n        for (const fmtp of m.fmtp || []) {\n            const parameters = sdpTransform.parseParams(fmtp.config);\n            const codec = codecsMap.get(fmtp.payload);\n            if (!codec) {\n                continue;\n            }\n            // Specials case to convert parameter value to string.\n            if (parameters && parameters.hasOwnProperty('profile-level-id')) {\n                parameters['profile-level-id'] = String(parameters['profile-level-id']);\n            }\n            codec.parameters = parameters;\n        }\n        // Get RTCP feedback for each codec.\n        for (const fb of m.rtcpFb || []) {\n            const feedback = {\n                type: fb.type,\n                parameter: fb.subtype,\n            };\n            if (!feedback.parameter) {\n                delete feedback.parameter;\n            }\n            // rtcp-fb payload is not '*', so just apply it to its corresponding\n            // codec.\n            if (fb.payload !== '*') {\n                const codec = codecsMap.get(fb.payload);\n                if (!codec) {\n                    continue;\n                }\n                codec.rtcpFeedback.push(feedback);\n            }\n            // If rtcp-fb payload is '*' it must be applied to all codecs with same\n            // kind (with some exceptions such as RTX codec).\n            else {\n                for (const codec of codecsMap.values()) {\n                    if (codec.kind === kind && !/.+\\/rtx$/i.test(codec.mimeType)) {\n                        codec.rtcpFeedback.push(feedback);\n                    }\n                }\n            }\n        }\n        // Get RTP header extensions.\n        for (const ext of m.ext || []) {\n            // Ignore encrypted extensions (not yet supported in mediasoup).\n            if (ext['encrypt-uri']) {\n                continue;\n            }\n            const headerExtension = {\n                kind: kind,\n                uri: ext.uri,\n                preferredId: ext.value,\n            };\n            headerExtensions.push(headerExtension);\n        }\n    }\n    const rtpCapabilities = {\n        codecs: Array.from(codecsMap.values()),\n        headerExtensions: headerExtensions,\n    };\n    return rtpCapabilities;\n}\nfunction extractDtlsParameters({ sdpObject, }) {\n    let setup = sdpObject.setup;\n    let fingerprint = sdpObject.fingerprint;\n    if (!setup || !fingerprint) {\n        const mediaObject = (sdpObject.media || []).find((m) => m.port !== 0);\n        if (mediaObject) {\n            setup ?? (setup = mediaObject.setup);\n            fingerprint ?? (fingerprint = mediaObject.fingerprint);\n        }\n    }\n    if (!setup) {\n        throw new Error('no a=setup found at SDP session or media level');\n    }\n    else if (!fingerprint) {\n        throw new Error('no a=fingerprint found at SDP session or media level');\n    }\n    let role;\n    switch (setup) {\n        case 'active': {\n            role = 'client';\n            break;\n        }\n        case 'passive': {\n            role = 'server';\n            break;\n        }\n        case 'actpass': {\n            role = 'auto';\n            break;\n        }\n    }\n    const dtlsParameters = {\n        role,\n        fingerprints: [\n            {\n                algorithm: fingerprint.type,\n                value: fingerprint.hash,\n            },\n        ],\n    };\n    return dtlsParameters;\n}\nfunction getCname({ offerMediaObject, }) {\n    const ssrcCnameLine = (offerMediaObject.ssrcs || []).find((line) => line.attribute === 'cname');\n    if (!ssrcCnameLine) {\n        return '';\n    }\n    return ssrcCnameLine.value;\n}\n/**\n * Apply codec parameters in the given SDP m= section answer based on the\n * given RTP parameters of an offer.\n */\nfunction applyCodecParameters({ offerRtpParameters, answerMediaObject, }) {\n    for (const codec of offerRtpParameters.codecs) {\n        const mimeType = codec.mimeType.toLowerCase();\n        // Avoid parsing codec parameters for unhandled codecs.\n        if (mimeType !== 'audio/opus') {\n            continue;\n        }\n        const rtp = (answerMediaObject.rtp || []).find((r) => r.payload === codec.payloadType);\n        if (!rtp) {\n            continue;\n        }\n        // Just in case.\n        answerMediaObject.fmtp = answerMediaObject.fmtp || [];\n        let fmtp = answerMediaObject.fmtp.find((f) => f.payload === codec.payloadType);\n        if (!fmtp) {\n            fmtp = { payload: codec.payloadType, config: '' };\n            answerMediaObject.fmtp.push(fmtp);\n        }\n        const parameters = sdpTransform.parseParams(fmtp.config);\n        switch (mimeType) {\n            case 'audio/opus': {\n                const spropStereo = codec.parameters['sprop-stereo'];\n                if (spropStereo !== undefined) {\n                    parameters.stereo = spropStereo ? 1 : 0;\n                }\n                break;\n            }\n        }\n        // Write the codec fmtp.config back.\n        fmtp.config = '';\n        for (const key of Object.keys(parameters)) {\n            if (fmtp.config) {\n                fmtp.config += ';';\n            }\n            fmtp.config += `${key}=${parameters[key]}`;\n        }\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/sdp/commonUtils.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js":
/*!**********************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getRtpEncodings = getRtpEncodings;\nexports.addLegacySimulcast = addLegacySimulcast;\nfunction getRtpEncodings({ offerMediaObject, track, }) {\n    // First media SSRC (or the only one).\n    let firstSsrc;\n    const ssrcs = new Set();\n    for (const line of offerMediaObject.ssrcs || []) {\n        if (line.attribute !== 'msid') {\n            continue;\n        }\n        const trackId = line.value.split(' ')[1];\n        if (trackId === track.id) {\n            const ssrc = line.id;\n            ssrcs.add(ssrc);\n            if (!firstSsrc) {\n                firstSsrc = ssrc;\n            }\n        }\n    }\n    if (ssrcs.size === 0) {\n        throw new Error(`a=ssrc line with msid information not found [track.id:${track.id}]`);\n    }\n    const ssrcToRtxSsrc = new Map();\n    // First assume RTX is used.\n    for (const line of offerMediaObject.ssrcGroups || []) {\n        if (line.semantics !== 'FID') {\n            continue;\n        }\n        let [ssrc, rtxSsrc] = line.ssrcs.split(/\\s+/);\n        ssrc = Number(ssrc);\n        rtxSsrc = Number(rtxSsrc);\n        if (ssrcs.has(ssrc)) {\n            // Remove both the SSRC and RTX SSRC from the set so later we know that they\n            // are already handled.\n            ssrcs.delete(ssrc);\n            ssrcs.delete(rtxSsrc);\n            // Add to the map.\n            ssrcToRtxSsrc.set(ssrc, rtxSsrc);\n        }\n    }\n    // If the set of SSRCs is not empty it means that RTX is not being used, so take\n    // media SSRCs from there.\n    for (const ssrc of ssrcs) {\n        // Add to the map.\n        ssrcToRtxSsrc.set(ssrc, null);\n    }\n    const encodings = [];\n    for (const [ssrc, rtxSsrc] of ssrcToRtxSsrc) {\n        const encoding = { ssrc };\n        if (rtxSsrc) {\n            encoding.rtx = { ssrc: rtxSsrc };\n        }\n        encodings.push(encoding);\n    }\n    return encodings;\n}\n/**\n * Adds multi-ssrc based simulcast into the given SDP media section offer.\n */\nfunction addLegacySimulcast({ offerMediaObject, track, numStreams, }) {\n    if (numStreams <= 1) {\n        throw new TypeError('numStreams must be greater than 1');\n    }\n    let firstSsrc;\n    let firstRtxSsrc;\n    let streamId;\n    // Get the SSRC.\n    const ssrcMsidLine = (offerMediaObject.ssrcs || []).find((line) => {\n        if (line.attribute !== 'msid') {\n            return false;\n        }\n        const trackId = line.value.split(' ')[1];\n        if (trackId === track.id) {\n            firstSsrc = line.id;\n            streamId = line.value.split(' ')[0];\n            return true;\n        }\n        else {\n            return false;\n        }\n    });\n    if (!ssrcMsidLine) {\n        throw new Error(`a=ssrc line with msid information not found [track.id:${track.id}]`);\n    }\n    // Get the SSRC for RTX.\n    (offerMediaObject.ssrcGroups || []).some((line) => {\n        if (line.semantics !== 'FID') {\n            return false;\n        }\n        const ssrcs = line.ssrcs.split(/\\s+/);\n        if (Number(ssrcs[0]) === firstSsrc) {\n            firstRtxSsrc = Number(ssrcs[1]);\n            return true;\n        }\n        else {\n            return false;\n        }\n    });\n    const ssrcCnameLine = offerMediaObject.ssrcs.find((line) => line.attribute === 'cname' && line.id === firstSsrc);\n    if (!ssrcCnameLine) {\n        throw new Error(`a=ssrc line with cname information not found [track.id:${track.id}]`);\n    }\n    const cname = ssrcCnameLine.value;\n    const ssrcs = [];\n    const rtxSsrcs = [];\n    for (let i = 0; i < numStreams; ++i) {\n        ssrcs.push(firstSsrc + i);\n        if (firstRtxSsrc) {\n            rtxSsrcs.push(firstRtxSsrc + i);\n        }\n    }\n    offerMediaObject.ssrcGroups = offerMediaObject.ssrcGroups || [];\n    offerMediaObject.ssrcs = offerMediaObject.ssrcs || [];\n    offerMediaObject.ssrcGroups.push({\n        semantics: 'SIM',\n        ssrcs: ssrcs.join(' '),\n    });\n    for (let i = 0; i < ssrcs.length; ++i) {\n        const ssrc = ssrcs[i];\n        offerMediaObject.ssrcs.push({\n            id: ssrc,\n            attribute: 'cname',\n            value: cname,\n        });\n        offerMediaObject.ssrcs.push({\n            id: ssrc,\n            attribute: 'msid',\n            value: `${streamId} ${track.id}`,\n        });\n    }\n    for (let i = 0; i < rtxSsrcs.length; ++i) {\n        const ssrc = ssrcs[i];\n        const rtxSsrc = rtxSsrcs[i];\n        offerMediaObject.ssrcs.push({\n            id: rtxSsrc,\n            attribute: 'cname',\n            value: cname,\n        });\n        offerMediaObject.ssrcs.push({\n            id: rtxSsrc,\n            attribute: 'msid',\n            value: `${streamId} ${track.id}`,\n        });\n        offerMediaObject.ssrcGroups.push({\n            semantics: 'FID',\n            ssrcs: `${ssrc} ${rtxSsrc}`,\n        });\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/sdp/planBUtils.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js":
/*!****************************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.getRtpEncodings = getRtpEncodings;\nexports.addLegacySimulcast = addLegacySimulcast;\nfunction getRtpEncodings({ offerMediaObject, }) {\n    const ssrcs = new Set();\n    for (const line of offerMediaObject.ssrcs || []) {\n        const ssrc = line.id;\n        ssrcs.add(ssrc);\n    }\n    if (ssrcs.size === 0) {\n        throw new Error('no a=ssrc lines found');\n    }\n    const ssrcToRtxSsrc = new Map();\n    // First assume RTX is used.\n    for (const line of offerMediaObject.ssrcGroups || []) {\n        if (line.semantics !== 'FID') {\n            continue;\n        }\n        let [ssrc, rtxSsrc] = line.ssrcs.split(/\\s+/);\n        ssrc = Number(ssrc);\n        rtxSsrc = Number(rtxSsrc);\n        if (ssrcs.has(ssrc)) {\n            // Remove both the SSRC and RTX SSRC from the set so later we know\n            // that they are already handled.\n            ssrcs.delete(ssrc);\n            ssrcs.delete(rtxSsrc);\n            // Add to the map.\n            ssrcToRtxSsrc.set(ssrc, rtxSsrc);\n        }\n    }\n    // If the set of SSRCs is not empty it means that RTX is not being used, so\n    // take media SSRCs from there.\n    for (const ssrc of ssrcs) {\n        // Add to the map.\n        ssrcToRtxSsrc.set(ssrc, null);\n    }\n    const encodings = [];\n    for (const [ssrc, rtxSsrc] of ssrcToRtxSsrc) {\n        const encoding = { ssrc };\n        if (rtxSsrc) {\n            encoding.rtx = { ssrc: rtxSsrc };\n        }\n        encodings.push(encoding);\n    }\n    return encodings;\n}\n/**\n * Adds multi-ssrc based simulcast into the given SDP media section offer.\n */\nfunction addLegacySimulcast({ offerMediaObject, numStreams, }) {\n    if (numStreams <= 1) {\n        throw new TypeError('numStreams must be greater than 1');\n    }\n    // Get the SSRC.\n    const ssrcMsidLine = (offerMediaObject.ssrcs || []).find((line) => line.attribute === 'msid');\n    if (!ssrcMsidLine) {\n        throw new Error('a=ssrc line with msid information not found');\n    }\n    const [streamId, trackId] = ssrcMsidLine.value.split(' ');\n    const firstSsrc = ssrcMsidLine.id;\n    let firstRtxSsrc;\n    // Get the SSRC for RTX.\n    (offerMediaObject.ssrcGroups || []).some((line) => {\n        if (line.semantics !== 'FID') {\n            return false;\n        }\n        const ssrcs = line.ssrcs.split(/\\s+/);\n        if (Number(ssrcs[0]) === firstSsrc) {\n            firstRtxSsrc = Number(ssrcs[1]);\n            return true;\n        }\n        else {\n            return false;\n        }\n    });\n    const ssrcCnameLine = offerMediaObject.ssrcs.find((line) => line.attribute === 'cname');\n    if (!ssrcCnameLine) {\n        throw new Error('a=ssrc line with cname information not found');\n    }\n    const cname = ssrcCnameLine.value;\n    const ssrcs = [];\n    const rtxSsrcs = [];\n    for (let i = 0; i < numStreams; ++i) {\n        ssrcs.push(firstSsrc + i);\n        if (firstRtxSsrc) {\n            rtxSsrcs.push(firstRtxSsrc + i);\n        }\n    }\n    offerMediaObject.ssrcGroups = [];\n    offerMediaObject.ssrcs = [];\n    offerMediaObject.ssrcGroups.push({\n        semantics: 'SIM',\n        ssrcs: ssrcs.join(' '),\n    });\n    for (let i = 0; i < ssrcs.length; ++i) {\n        const ssrc = ssrcs[i];\n        offerMediaObject.ssrcs.push({\n            id: ssrc,\n            attribute: 'cname',\n            value: cname,\n        });\n        offerMediaObject.ssrcs.push({\n            id: ssrc,\n            attribute: 'msid',\n            value: `${streamId} ${trackId}`,\n        });\n    }\n    for (let i = 0; i < rtxSsrcs.length; ++i) {\n        const ssrc = ssrcs[i];\n        const rtxSsrc = rtxSsrcs[i];\n        offerMediaObject.ssrcs.push({\n            id: rtxSsrc,\n            attribute: 'cname',\n            value: cname,\n        });\n        offerMediaObject.ssrcs.push({\n            id: rtxSsrc,\n            attribute: 'msid',\n            value: `${streamId} ${trackId}`,\n        });\n        offerMediaObject.ssrcGroups.push({\n            semantics: 'FID',\n            ssrcs: `${ssrc} ${rtxSsrc}`,\n        });\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/handlers/sdp/unifiedPlanUtils.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/index.js":
/*!****************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/index.js ***!
  \****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.debug = exports.parseScalabilityMode = exports.detectDevice = exports.Device = exports.version = exports.types = void 0;\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\"));\nexports.debug = debug_1.default;\nconst Device_1 = __webpack_require__(/*! ./Device */ \"./node_modules/mediasoup-client/lib/Device.js\");\nObject.defineProperty(exports, \"Device\", ({ enumerable: true, get: function () { return Device_1.Device; } }));\nObject.defineProperty(exports, \"detectDevice\", ({ enumerable: true, get: function () { return Device_1.detectDevice; } }));\nconst types = __importStar(__webpack_require__(/*! ./types */ \"./node_modules/mediasoup-client/lib/types.js\"));\nexports.types = types;\n/**\n * Expose mediasoup-client version.\n */\nexports.version = '3.7.12';\n/**\n * Expose parseScalabilityMode() function.\n */\nvar scalabilityModes_1 = __webpack_require__(/*! ./scalabilityModes */ \"./node_modules/mediasoup-client/lib/scalabilityModes.js\");\nObject.defineProperty(exports, \"parseScalabilityMode\", ({ enumerable: true, get: function () { return scalabilityModes_1.parse; } }));\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/index.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/ortc.js":
/*!***************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/ortc.js ***!
  \***************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.validateRtpCapabilities = validateRtpCapabilities;\nexports.validateRtpParameters = validateRtpParameters;\nexports.validateSctpStreamParameters = validateSctpStreamParameters;\nexports.validateSctpCapabilities = validateSctpCapabilities;\nexports.getExtendedRtpCapabilities = getExtendedRtpCapabilities;\nexports.getRecvRtpCapabilities = getRecvRtpCapabilities;\nexports.getSendingRtpParameters = getSendingRtpParameters;\nexports.getSendingRemoteRtpParameters = getSendingRemoteRtpParameters;\nexports.reduceCodecs = reduceCodecs;\nexports.generateProbatorRtpParameters = generateProbatorRtpParameters;\nexports.canSend = canSend;\nexports.canReceive = canReceive;\nconst h264 = __importStar(__webpack_require__(/*! h264-profile-level-id */ \"./node_modules/h264-profile-level-id/lib/index.js\"));\nconst utils = __importStar(__webpack_require__(/*! ./utils */ \"./node_modules/mediasoup-client/lib/utils.js\"));\nconst RTP_PROBATOR_MID = 'probator';\nconst RTP_PROBATOR_SSRC = 1234;\nconst RTP_PROBATOR_CODEC_PAYLOAD_TYPE = 127;\n/**\n * Validates RtpCapabilities. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpCapabilities(caps) {\n    if (typeof caps !== 'object') {\n        throw new TypeError('caps is not an object');\n    }\n    // codecs is optional. If unset, fill with an empty array.\n    if (caps.codecs && !Array.isArray(caps.codecs)) {\n        throw new TypeError('caps.codecs is not an array');\n    }\n    else if (!caps.codecs) {\n        caps.codecs = [];\n    }\n    for (const codec of caps.codecs) {\n        validateRtpCodecCapability(codec);\n    }\n    // headerExtensions is optional. If unset, fill with an empty array.\n    if (caps.headerExtensions && !Array.isArray(caps.headerExtensions)) {\n        throw new TypeError('caps.headerExtensions is not an array');\n    }\n    else if (!caps.headerExtensions) {\n        caps.headerExtensions = [];\n    }\n    for (const ext of caps.headerExtensions) {\n        validateRtpHeaderExtension(ext);\n    }\n}\n/**\n * Validates RtpParameters. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpParameters(params) {\n    if (typeof params !== 'object') {\n        throw new TypeError('params is not an object');\n    }\n    // mid is optional.\n    if (params.mid && typeof params.mid !== 'string') {\n        throw new TypeError('params.mid is not a string');\n    }\n    // codecs is mandatory.\n    if (!Array.isArray(params.codecs)) {\n        throw new TypeError('missing params.codecs');\n    }\n    for (const codec of params.codecs) {\n        validateRtpCodecParameters(codec);\n    }\n    // headerExtensions is optional. If unset, fill with an empty array.\n    if (params.headerExtensions && !Array.isArray(params.headerExtensions)) {\n        throw new TypeError('params.headerExtensions is not an array');\n    }\n    else if (!params.headerExtensions) {\n        params.headerExtensions = [];\n    }\n    for (const ext of params.headerExtensions) {\n        validateRtpHeaderExtensionParameters(ext);\n    }\n    // encodings is optional. If unset, fill with an empty array.\n    if (params.encodings && !Array.isArray(params.encodings)) {\n        throw new TypeError('params.encodings is not an array');\n    }\n    else if (!params.encodings) {\n        params.encodings = [];\n    }\n    for (const encoding of params.encodings) {\n        validateRtpEncodingParameters(encoding);\n    }\n    // rtcp is optional. If unset, fill with an empty object.\n    if (params.rtcp && typeof params.rtcp !== 'object') {\n        throw new TypeError('params.rtcp is not an object');\n    }\n    else if (!params.rtcp) {\n        params.rtcp = {};\n    }\n    validateRtcpParameters(params.rtcp);\n}\n/**\n * Validates SctpStreamParameters. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateSctpStreamParameters(params) {\n    if (typeof params !== 'object') {\n        throw new TypeError('params is not an object');\n    }\n    // streamId is mandatory.\n    if (typeof params.streamId !== 'number') {\n        throw new TypeError('missing params.streamId');\n    }\n    // ordered is optional.\n    let orderedGiven = false;\n    if (typeof params.ordered === 'boolean') {\n        orderedGiven = true;\n    }\n    else {\n        params.ordered = true;\n    }\n    // maxPacketLifeTime is optional.\n    if (params.maxPacketLifeTime &&\n        typeof params.maxPacketLifeTime !== 'number') {\n        throw new TypeError('invalid params.maxPacketLifeTime');\n    }\n    // maxRetransmits is optional.\n    if (params.maxRetransmits && typeof params.maxRetransmits !== 'number') {\n        throw new TypeError('invalid params.maxRetransmits');\n    }\n    if (params.maxPacketLifeTime && params.maxRetransmits) {\n        throw new TypeError('cannot provide both maxPacketLifeTime and maxRetransmits');\n    }\n    if (orderedGiven &&\n        params.ordered &&\n        (params.maxPacketLifeTime || params.maxRetransmits)) {\n        throw new TypeError('cannot be ordered with maxPacketLifeTime or maxRetransmits');\n    }\n    else if (!orderedGiven &&\n        (params.maxPacketLifeTime || params.maxRetransmits)) {\n        params.ordered = false;\n    }\n    // label is optional.\n    if (params.label && typeof params.label !== 'string') {\n        throw new TypeError('invalid params.label');\n    }\n    // protocol is optional.\n    if (params.protocol && typeof params.protocol !== 'string') {\n        throw new TypeError('invalid params.protocol');\n    }\n}\n/**\n * Validates SctpCapabilities. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateSctpCapabilities(caps) {\n    if (typeof caps !== 'object') {\n        throw new TypeError('caps is not an object');\n    }\n    // numStreams is mandatory.\n    if (!caps.numStreams || typeof caps.numStreams !== 'object') {\n        throw new TypeError('missing caps.numStreams');\n    }\n    validateNumSctpStreams(caps.numStreams);\n}\n/**\n * Generate extended RTP capabilities for sending and receiving.\n */\nfunction getExtendedRtpCapabilities(localCaps, remoteCaps) {\n    const extendedRtpCapabilities = {\n        codecs: [],\n        headerExtensions: [],\n    };\n    // Match media codecs and keep the order preferred by remoteCaps.\n    for (const remoteCodec of remoteCaps.codecs || []) {\n        if (isRtxCodec(remoteCodec)) {\n            continue;\n        }\n        const matchingLocalCodec = (localCaps.codecs || []).find((localCodec) => matchCodecs(localCodec, remoteCodec, { strict: true, modify: true }));\n        if (!matchingLocalCodec) {\n            continue;\n        }\n        const extendedCodec = {\n            mimeType: matchingLocalCodec.mimeType,\n            kind: matchingLocalCodec.kind,\n            clockRate: matchingLocalCodec.clockRate,\n            channels: matchingLocalCodec.channels,\n            localPayloadType: matchingLocalCodec.preferredPayloadType,\n            localRtxPayloadType: undefined,\n            remotePayloadType: remoteCodec.preferredPayloadType,\n            remoteRtxPayloadType: undefined,\n            localParameters: matchingLocalCodec.parameters,\n            remoteParameters: remoteCodec.parameters,\n            rtcpFeedback: reduceRtcpFeedback(matchingLocalCodec, remoteCodec),\n        };\n        extendedRtpCapabilities.codecs.push(extendedCodec);\n    }\n    // Match RTX codecs.\n    for (const extendedCodec of extendedRtpCapabilities.codecs) {\n        const matchingLocalRtxCodec = localCaps.codecs.find((localCodec) => isRtxCodec(localCodec) &&\n            localCodec.parameters.apt === extendedCodec.localPayloadType);\n        const matchingRemoteRtxCodec = remoteCaps.codecs.find((remoteCodec) => isRtxCodec(remoteCodec) &&\n            remoteCodec.parameters.apt === extendedCodec.remotePayloadType);\n        if (matchingLocalRtxCodec && matchingRemoteRtxCodec) {\n            extendedCodec.localRtxPayloadType =\n                matchingLocalRtxCodec.preferredPayloadType;\n            extendedCodec.remoteRtxPayloadType =\n                matchingRemoteRtxCodec.preferredPayloadType;\n        }\n    }\n    // Match header extensions.\n    for (const remoteExt of remoteCaps.headerExtensions) {\n        const matchingLocalExt = localCaps.headerExtensions.find((localExt) => matchHeaderExtensions(localExt, remoteExt));\n        if (!matchingLocalExt) {\n            continue;\n        }\n        const extendedExt = {\n            kind: remoteExt.kind,\n            uri: remoteExt.uri,\n            sendId: matchingLocalExt.preferredId,\n            recvId: remoteExt.preferredId,\n            encrypt: matchingLocalExt.preferredEncrypt,\n            direction: 'sendrecv',\n        };\n        switch (remoteExt.direction) {\n            case 'sendrecv': {\n                extendedExt.direction = 'sendrecv';\n                break;\n            }\n            case 'recvonly': {\n                extendedExt.direction = 'sendonly';\n                break;\n            }\n            case 'sendonly': {\n                extendedExt.direction = 'recvonly';\n                break;\n            }\n            case 'inactive': {\n                extendedExt.direction = 'inactive';\n                break;\n            }\n        }\n        extendedRtpCapabilities.headerExtensions.push(extendedExt);\n    }\n    return extendedRtpCapabilities;\n}\n/**\n * Generate RTP capabilities for receiving media based on the given extended\n * RTP capabilities.\n */\nfunction getRecvRtpCapabilities(extendedRtpCapabilities) {\n    const rtpCapabilities = {\n        codecs: [],\n        headerExtensions: [],\n    };\n    for (const extendedCodec of extendedRtpCapabilities.codecs) {\n        const codec = {\n            mimeType: extendedCodec.mimeType,\n            kind: extendedCodec.kind,\n            preferredPayloadType: extendedCodec.remotePayloadType,\n            clockRate: extendedCodec.clockRate,\n            channels: extendedCodec.channels,\n            parameters: extendedCodec.localParameters,\n            rtcpFeedback: extendedCodec.rtcpFeedback,\n        };\n        rtpCapabilities.codecs.push(codec);\n        // Add RTX codec.\n        if (!extendedCodec.remoteRtxPayloadType) {\n            continue;\n        }\n        const rtxCodec = {\n            mimeType: `${extendedCodec.kind}/rtx`,\n            kind: extendedCodec.kind,\n            preferredPayloadType: extendedCodec.remoteRtxPayloadType,\n            clockRate: extendedCodec.clockRate,\n            parameters: {\n                apt: extendedCodec.remotePayloadType,\n            },\n            rtcpFeedback: [],\n        };\n        rtpCapabilities.codecs.push(rtxCodec);\n        // TODO: In the future, we need to add FEC, CN, etc, codecs.\n    }\n    for (const extendedExtension of extendedRtpCapabilities.headerExtensions) {\n        // Ignore RTP extensions not valid for receiving.\n        if (extendedExtension.direction !== 'sendrecv' &&\n            extendedExtension.direction !== 'recvonly') {\n            continue;\n        }\n        const ext = {\n            kind: extendedExtension.kind,\n            uri: extendedExtension.uri,\n            preferredId: extendedExtension.recvId,\n            preferredEncrypt: extendedExtension.encrypt,\n            direction: extendedExtension.direction,\n        };\n        rtpCapabilities.headerExtensions.push(ext);\n    }\n    return rtpCapabilities;\n}\n/**\n * Generate RTP parameters of the given kind for sending media.\n * NOTE: mid, encodings and rtcp fields are left empty.\n */\nfunction getSendingRtpParameters(kind, extendedRtpCapabilities) {\n    const rtpParameters = {\n        mid: undefined,\n        codecs: [],\n        headerExtensions: [],\n        encodings: [],\n        rtcp: {},\n    };\n    for (const extendedCodec of extendedRtpCapabilities.codecs) {\n        if (extendedCodec.kind !== kind) {\n            continue;\n        }\n        const codec = {\n            mimeType: extendedCodec.mimeType,\n            payloadType: extendedCodec.localPayloadType,\n            clockRate: extendedCodec.clockRate,\n            channels: extendedCodec.channels,\n            parameters: extendedCodec.localParameters,\n            rtcpFeedback: extendedCodec.rtcpFeedback,\n        };\n        rtpParameters.codecs.push(codec);\n        // Add RTX codec.\n        if (extendedCodec.localRtxPayloadType) {\n            const rtxCodec = {\n                mimeType: `${extendedCodec.kind}/rtx`,\n                payloadType: extendedCodec.localRtxPayloadType,\n                clockRate: extendedCodec.clockRate,\n                parameters: {\n                    apt: extendedCodec.localPayloadType,\n                },\n                rtcpFeedback: [],\n            };\n            rtpParameters.codecs.push(rtxCodec);\n        }\n    }\n    for (const extendedExtension of extendedRtpCapabilities.headerExtensions) {\n        // Ignore RTP extensions of a different kind and those not valid for sending.\n        if ((extendedExtension.kind && extendedExtension.kind !== kind) ||\n            (extendedExtension.direction !== 'sendrecv' &&\n                extendedExtension.direction !== 'sendonly')) {\n            continue;\n        }\n        const ext = {\n            uri: extendedExtension.uri,\n            id: extendedExtension.sendId,\n            encrypt: extendedExtension.encrypt,\n            parameters: {},\n        };\n        rtpParameters.headerExtensions.push(ext);\n    }\n    return rtpParameters;\n}\n/**\n * Generate RTP parameters of the given kind suitable for the remote SDP answer.\n */\nfunction getSendingRemoteRtpParameters(kind, extendedRtpCapabilities) {\n    const rtpParameters = {\n        mid: undefined,\n        codecs: [],\n        headerExtensions: [],\n        encodings: [],\n        rtcp: {},\n    };\n    for (const extendedCodec of extendedRtpCapabilities.codecs) {\n        if (extendedCodec.kind !== kind) {\n            continue;\n        }\n        const codec = {\n            mimeType: extendedCodec.mimeType,\n            payloadType: extendedCodec.localPayloadType,\n            clockRate: extendedCodec.clockRate,\n            channels: extendedCodec.channels,\n            parameters: extendedCodec.remoteParameters,\n            rtcpFeedback: extendedCodec.rtcpFeedback,\n        };\n        rtpParameters.codecs.push(codec);\n        // Add RTX codec.\n        if (extendedCodec.localRtxPayloadType) {\n            const rtxCodec = {\n                mimeType: `${extendedCodec.kind}/rtx`,\n                payloadType: extendedCodec.localRtxPayloadType,\n                clockRate: extendedCodec.clockRate,\n                parameters: {\n                    apt: extendedCodec.localPayloadType,\n                },\n                rtcpFeedback: [],\n            };\n            rtpParameters.codecs.push(rtxCodec);\n        }\n    }\n    for (const extendedExtension of extendedRtpCapabilities.headerExtensions) {\n        // Ignore RTP extensions of a different kind and those not valid for sending.\n        if ((extendedExtension.kind && extendedExtension.kind !== kind) ||\n            (extendedExtension.direction !== 'sendrecv' &&\n                extendedExtension.direction !== 'sendonly')) {\n            continue;\n        }\n        const ext = {\n            uri: extendedExtension.uri,\n            id: extendedExtension.sendId,\n            encrypt: extendedExtension.encrypt,\n            parameters: {},\n        };\n        rtpParameters.headerExtensions.push(ext);\n    }\n    // Reduce codecs' RTCP feedback. Use Transport-CC if available, REMB otherwise.\n    if (rtpParameters.headerExtensions.some(ext => ext.uri ===\n        'http://www.ietf.org/id/draft-holmer-rmcat-transport-wide-cc-extensions-01')) {\n        for (const codec of rtpParameters.codecs) {\n            codec.rtcpFeedback = (codec.rtcpFeedback || []).filter((fb) => fb.type !== 'goog-remb');\n        }\n    }\n    else if (rtpParameters.headerExtensions.some(ext => ext.uri === 'http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time')) {\n        for (const codec of rtpParameters.codecs) {\n            codec.rtcpFeedback = (codec.rtcpFeedback || []).filter(fb => fb.type !== 'transport-cc');\n        }\n    }\n    else {\n        for (const codec of rtpParameters.codecs) {\n            codec.rtcpFeedback = (codec.rtcpFeedback || []).filter((fb) => fb.type !== 'transport-cc' && fb.type !== 'goog-remb');\n        }\n    }\n    return rtpParameters;\n}\n/**\n * Reduce given codecs by returning an array of codecs \"compatible\" with the\n * given capability codec. If no capability codec is given, take the first\n * one(s).\n *\n * Given codecs must be generated by ortc.getSendingRtpParameters() or\n * ortc.getSendingRemoteRtpParameters().\n *\n * The returned array of codecs also include a RTX codec if available.\n */\nfunction reduceCodecs(codecs, capCodec) {\n    const filteredCodecs = [];\n    // If no capability codec is given, take the first one (and RTX).\n    if (!capCodec) {\n        filteredCodecs.push(codecs[0]);\n        if (isRtxCodec(codecs[1])) {\n            filteredCodecs.push(codecs[1]);\n        }\n    }\n    // Otherwise look for a compatible set of codecs.\n    else {\n        for (let idx = 0; idx < codecs.length; ++idx) {\n            if (matchCodecs(codecs[idx], capCodec, { strict: true })) {\n                filteredCodecs.push(codecs[idx]);\n                if (isRtxCodec(codecs[idx + 1])) {\n                    filteredCodecs.push(codecs[idx + 1]);\n                }\n                break;\n            }\n        }\n        if (filteredCodecs.length === 0) {\n            throw new TypeError('no matching codec found');\n        }\n    }\n    return filteredCodecs;\n}\n/**\n * Create RTP parameters for a Consumer for the RTP probator.\n */\nfunction generateProbatorRtpParameters(videoRtpParameters) {\n    // Clone given reference video RTP parameters.\n    videoRtpParameters = utils.clone(videoRtpParameters);\n    // This may throw.\n    validateRtpParameters(videoRtpParameters);\n    const rtpParameters = {\n        mid: RTP_PROBATOR_MID,\n        codecs: [],\n        headerExtensions: [],\n        encodings: [{ ssrc: RTP_PROBATOR_SSRC }],\n        rtcp: { cname: 'probator' },\n    };\n    rtpParameters.codecs.push(videoRtpParameters.codecs[0]);\n    rtpParameters.codecs[0].payloadType = RTP_PROBATOR_CODEC_PAYLOAD_TYPE;\n    rtpParameters.headerExtensions = videoRtpParameters.headerExtensions;\n    return rtpParameters;\n}\n/**\n * Whether media can be sent based on the given RTP capabilities.\n */\nfunction canSend(kind, extendedRtpCapabilities) {\n    return extendedRtpCapabilities.codecs.some((codec) => codec.kind === kind);\n}\n/**\n * Whether the given RTP parameters can be received with the given RTP\n * capabilities.\n */\nfunction canReceive(rtpParameters, extendedRtpCapabilities) {\n    // This may throw.\n    validateRtpParameters(rtpParameters);\n    if (rtpParameters.codecs.length === 0) {\n        return false;\n    }\n    const firstMediaCodec = rtpParameters.codecs[0];\n    return extendedRtpCapabilities.codecs.some((codec) => codec.remotePayloadType === firstMediaCodec.payloadType);\n}\n/**\n * Validates RtpCodecCapability. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpCodecCapability(codec) {\n    const MimeTypeRegex = new RegExp('^(audio|video)/(.+)', 'i');\n    if (typeof codec !== 'object') {\n        throw new TypeError('codec is not an object');\n    }\n    // mimeType is mandatory.\n    if (!codec.mimeType || typeof codec.mimeType !== 'string') {\n        throw new TypeError('missing codec.mimeType');\n    }\n    const mimeTypeMatch = MimeTypeRegex.exec(codec.mimeType);\n    if (!mimeTypeMatch) {\n        throw new TypeError('invalid codec.mimeType');\n    }\n    // Just override kind with media component of mimeType.\n    codec.kind = mimeTypeMatch[1].toLowerCase();\n    // preferredPayloadType is optional.\n    if (codec.preferredPayloadType &&\n        typeof codec.preferredPayloadType !== 'number') {\n        throw new TypeError('invalid codec.preferredPayloadType');\n    }\n    // clockRate is mandatory.\n    if (typeof codec.clockRate !== 'number') {\n        throw new TypeError('missing codec.clockRate');\n    }\n    // channels is optional. If unset, set it to 1 (just if audio).\n    if (codec.kind === 'audio') {\n        if (typeof codec.channels !== 'number') {\n            codec.channels = 1;\n        }\n    }\n    else {\n        delete codec.channels;\n    }\n    // parameters is optional. If unset, set it to an empty object.\n    if (!codec.parameters || typeof codec.parameters !== 'object') {\n        codec.parameters = {};\n    }\n    for (const key of Object.keys(codec.parameters)) {\n        let value = codec.parameters[key];\n        if (value === undefined) {\n            codec.parameters[key] = '';\n            value = '';\n        }\n        if (typeof value !== 'string' && typeof value !== 'number') {\n            throw new TypeError(`invalid codec parameter [key:${key}s, value:${value}]`);\n        }\n        // Specific parameters validation.\n        if (key === 'apt') {\n            if (typeof value !== 'number') {\n                throw new TypeError('invalid codec apt parameter');\n            }\n        }\n    }\n    // rtcpFeedback is optional. If unset, set it to an empty array.\n    if (!codec.rtcpFeedback || !Array.isArray(codec.rtcpFeedback)) {\n        codec.rtcpFeedback = [];\n    }\n    for (const fb of codec.rtcpFeedback) {\n        validateRtcpFeedback(fb);\n    }\n}\n/**\n * Validates RtcpFeedback. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtcpFeedback(fb) {\n    if (typeof fb !== 'object') {\n        throw new TypeError('fb is not an object');\n    }\n    // type is mandatory.\n    if (!fb.type || typeof fb.type !== 'string') {\n        throw new TypeError('missing fb.type');\n    }\n    // parameter is optional. If unset set it to an empty string.\n    if (!fb.parameter || typeof fb.parameter !== 'string') {\n        fb.parameter = '';\n    }\n}\n/**\n * Validates RtpHeaderExtension. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpHeaderExtension(ext) {\n    if (typeof ext !== 'object') {\n        throw new TypeError('ext is not an object');\n    }\n    // kind is mandatory.\n    if (ext.kind !== 'audio' && ext.kind !== 'video') {\n        throw new TypeError('invalid ext.kind');\n    }\n    // uri is mandatory.\n    if (!ext.uri || typeof ext.uri !== 'string') {\n        throw new TypeError('missing ext.uri');\n    }\n    // preferredId is mandatory.\n    if (typeof ext.preferredId !== 'number') {\n        throw new TypeError('missing ext.preferredId');\n    }\n    // preferredEncrypt is optional. If unset set it to false.\n    if (ext.preferredEncrypt && typeof ext.preferredEncrypt !== 'boolean') {\n        throw new TypeError('invalid ext.preferredEncrypt');\n    }\n    else if (!ext.preferredEncrypt) {\n        ext.preferredEncrypt = false;\n    }\n    // direction is optional. If unset set it to sendrecv.\n    if (ext.direction && typeof ext.direction !== 'string') {\n        throw new TypeError('invalid ext.direction');\n    }\n    else if (!ext.direction) {\n        ext.direction = 'sendrecv';\n    }\n}\n/**\n * Validates RtpCodecParameters. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpCodecParameters(codec) {\n    const MimeTypeRegex = new RegExp('^(audio|video)/(.+)', 'i');\n    if (typeof codec !== 'object') {\n        throw new TypeError('codec is not an object');\n    }\n    // mimeType is mandatory.\n    if (!codec.mimeType || typeof codec.mimeType !== 'string') {\n        throw new TypeError('missing codec.mimeType');\n    }\n    const mimeTypeMatch = MimeTypeRegex.exec(codec.mimeType);\n    if (!mimeTypeMatch) {\n        throw new TypeError('invalid codec.mimeType');\n    }\n    // payloadType is mandatory.\n    if (typeof codec.payloadType !== 'number') {\n        throw new TypeError('missing codec.payloadType');\n    }\n    // clockRate is mandatory.\n    if (typeof codec.clockRate !== 'number') {\n        throw new TypeError('missing codec.clockRate');\n    }\n    const kind = mimeTypeMatch[1].toLowerCase();\n    // channels is optional. If unset, set it to 1 (just if audio).\n    if (kind === 'audio') {\n        if (typeof codec.channels !== 'number') {\n            codec.channels = 1;\n        }\n    }\n    else {\n        delete codec.channels;\n    }\n    // parameters is optional. If unset, set it to an empty object.\n    if (!codec.parameters || typeof codec.parameters !== 'object') {\n        codec.parameters = {};\n    }\n    for (const key of Object.keys(codec.parameters)) {\n        let value = codec.parameters[key];\n        if (value === undefined) {\n            codec.parameters[key] = '';\n            value = '';\n        }\n        if (typeof value !== 'string' && typeof value !== 'number') {\n            throw new TypeError(`invalid codec parameter [key:${key}s, value:${value}]`);\n        }\n        // Specific parameters validation.\n        if (key === 'apt') {\n            if (typeof value !== 'number') {\n                throw new TypeError('invalid codec apt parameter');\n            }\n        }\n    }\n    // rtcpFeedback is optional. If unset, set it to an empty array.\n    if (!codec.rtcpFeedback || !Array.isArray(codec.rtcpFeedback)) {\n        codec.rtcpFeedback = [];\n    }\n    for (const fb of codec.rtcpFeedback) {\n        validateRtcpFeedback(fb);\n    }\n}\n/**\n * Validates RtpHeaderExtensionParameteters. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpHeaderExtensionParameters(ext) {\n    if (typeof ext !== 'object') {\n        throw new TypeError('ext is not an object');\n    }\n    // uri is mandatory.\n    if (!ext.uri || typeof ext.uri !== 'string') {\n        throw new TypeError('missing ext.uri');\n    }\n    // id is mandatory.\n    if (typeof ext.id !== 'number') {\n        throw new TypeError('missing ext.id');\n    }\n    // encrypt is optional. If unset set it to false.\n    if (ext.encrypt && typeof ext.encrypt !== 'boolean') {\n        throw new TypeError('invalid ext.encrypt');\n    }\n    else if (!ext.encrypt) {\n        ext.encrypt = false;\n    }\n    // parameters is optional. If unset, set it to an empty object.\n    if (!ext.parameters || typeof ext.parameters !== 'object') {\n        ext.parameters = {};\n    }\n    for (const key of Object.keys(ext.parameters)) {\n        let value = ext.parameters[key];\n        if (value === undefined) {\n            ext.parameters[key] = '';\n            value = '';\n        }\n        if (typeof value !== 'string' && typeof value !== 'number') {\n            throw new TypeError('invalid header extension parameter');\n        }\n    }\n}\n/**\n * Validates RtpEncodingParameters. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtpEncodingParameters(encoding) {\n    if (typeof encoding !== 'object') {\n        throw new TypeError('encoding is not an object');\n    }\n    // ssrc is optional.\n    if (encoding.ssrc && typeof encoding.ssrc !== 'number') {\n        throw new TypeError('invalid encoding.ssrc');\n    }\n    // rid is optional.\n    if (encoding.rid && typeof encoding.rid !== 'string') {\n        throw new TypeError('invalid encoding.rid');\n    }\n    // rtx is optional.\n    if (encoding.rtx && typeof encoding.rtx !== 'object') {\n        throw new TypeError('invalid encoding.rtx');\n    }\n    else if (encoding.rtx) {\n        // RTX ssrc is mandatory if rtx is present.\n        if (typeof encoding.rtx.ssrc !== 'number') {\n            throw new TypeError('missing encoding.rtx.ssrc');\n        }\n    }\n    // dtx is optional. If unset set it to false.\n    if (!encoding.dtx || typeof encoding.dtx !== 'boolean') {\n        encoding.dtx = false;\n    }\n    // scalabilityMode is optional.\n    if (encoding.scalabilityMode &&\n        typeof encoding.scalabilityMode !== 'string') {\n        throw new TypeError('invalid encoding.scalabilityMode');\n    }\n}\n/**\n * Validates RtcpParameters. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateRtcpParameters(rtcp) {\n    if (typeof rtcp !== 'object') {\n        throw new TypeError('rtcp is not an object');\n    }\n    // cname is optional.\n    if (rtcp.cname && typeof rtcp.cname !== 'string') {\n        throw new TypeError('invalid rtcp.cname');\n    }\n    // reducedSize is optional. If unset set it to true.\n    if (!rtcp.reducedSize || typeof rtcp.reducedSize !== 'boolean') {\n        rtcp.reducedSize = true;\n    }\n}\n/**\n * Validates NumSctpStreams. It may modify given data by adding missing\n * fields with default values.\n * It throws if invalid.\n */\nfunction validateNumSctpStreams(numStreams) {\n    if (typeof numStreams !== 'object') {\n        throw new TypeError('numStreams is not an object');\n    }\n    // OS is mandatory.\n    if (typeof numStreams.OS !== 'number') {\n        throw new TypeError('missing numStreams.OS');\n    }\n    // MIS is mandatory.\n    if (typeof numStreams.MIS !== 'number') {\n        throw new TypeError('missing numStreams.MIS');\n    }\n}\nfunction isRtxCodec(codec) {\n    if (!codec) {\n        return false;\n    }\n    return /.+\\/rtx$/i.test(codec.mimeType);\n}\nfunction matchCodecs(aCodec, bCodec, { strict = false, modify = false } = {}) {\n    const aMimeType = aCodec.mimeType.toLowerCase();\n    const bMimeType = bCodec.mimeType.toLowerCase();\n    if (aMimeType !== bMimeType) {\n        return false;\n    }\n    if (aCodec.clockRate !== bCodec.clockRate) {\n        return false;\n    }\n    if (aCodec.channels !== bCodec.channels) {\n        return false;\n    }\n    // Per codec special checks.\n    switch (aMimeType) {\n        case 'video/h264': {\n            if (strict) {\n                const aPacketizationMode = aCodec.parameters['packetization-mode'] || 0;\n                const bPacketizationMode = bCodec.parameters['packetization-mode'] || 0;\n                if (aPacketizationMode !== bPacketizationMode) {\n                    return false;\n                }\n                if (!h264.isSameProfile(aCodec.parameters, bCodec.parameters)) {\n                    return false;\n                }\n                let selectedProfileLevelId;\n                try {\n                    selectedProfileLevelId = h264.generateProfileLevelIdStringForAnswer(aCodec.parameters, bCodec.parameters);\n                }\n                catch (error) {\n                    return false;\n                }\n                if (modify) {\n                    if (selectedProfileLevelId) {\n                        aCodec.parameters['profile-level-id'] = selectedProfileLevelId;\n                        bCodec.parameters['profile-level-id'] = selectedProfileLevelId;\n                    }\n                    else {\n                        delete aCodec.parameters['profile-level-id'];\n                        delete bCodec.parameters['profile-level-id'];\n                    }\n                }\n            }\n            break;\n        }\n        case 'video/vp9': {\n            if (strict) {\n                const aProfileId = aCodec.parameters['profile-id'] || 0;\n                const bProfileId = bCodec.parameters['profile-id'] || 0;\n                if (aProfileId !== bProfileId) {\n                    return false;\n                }\n            }\n            break;\n        }\n    }\n    return true;\n}\nfunction matchHeaderExtensions(aExt, bExt) {\n    if (aExt.kind && bExt.kind && aExt.kind !== bExt.kind) {\n        return false;\n    }\n    if (aExt.uri !== bExt.uri) {\n        return false;\n    }\n    return true;\n}\nfunction reduceRtcpFeedback(codecA, codecB) {\n    const reducedRtcpFeedback = [];\n    for (const aFb of codecA.rtcpFeedback || []) {\n        const matchingBFb = (codecB.rtcpFeedback || []).find((bFb) => bFb.type === aFb.type &&\n            (bFb.parameter === aFb.parameter || (!bFb.parameter && !aFb.parameter)));\n        if (matchingBFb) {\n            reducedRtcpFeedback.push(matchingBFb);\n        }\n    }\n    return reducedRtcpFeedback;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/ortc.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/scalabilityModes.js":
/*!***************************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/scalabilityModes.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.parse = parse;\nconst ScalabilityModeRegex = new RegExp('^[LS]([1-9]\\\\d{0,1})T([1-9]\\\\d{0,1})');\nfunction parse(scalabilityMode) {\n    const match = ScalabilityModeRegex.exec(scalabilityMode || '');\n    if (match) {\n        return {\n            spatialLayers: Number(match[1]),\n            temporalLayers: Number(match[2]),\n        };\n    }\n    else {\n        return {\n            spatialLayers: 1,\n            temporalLayers: 1,\n        };\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/scalabilityModes.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/types.js":
/*!****************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/types.js ***!
  \****************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n__exportStar(__webpack_require__(/*! ./Device */ \"./node_modules/mediasoup-client/lib/Device.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Transport */ \"./node_modules/mediasoup-client/lib/Transport.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Producer */ \"./node_modules/mediasoup-client/lib/Producer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./Consumer */ \"./node_modules/mediasoup-client/lib/Consumer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DataProducer */ \"./node_modules/mediasoup-client/lib/DataProducer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./DataConsumer */ \"./node_modules/mediasoup-client/lib/DataConsumer.js\"), exports);\n__exportStar(__webpack_require__(/*! ./RtpParameters */ \"./node_modules/mediasoup-client/lib/RtpParameters.js\"), exports);\n__exportStar(__webpack_require__(/*! ./SctpParameters */ \"./node_modules/mediasoup-client/lib/SctpParameters.js\"), exports);\n__exportStar(__webpack_require__(/*! ./handlers/HandlerInterface */ \"./node_modules/mediasoup-client/lib/handlers/HandlerInterface.js\"), exports);\n__exportStar(__webpack_require__(/*! ./errors */ \"./node_modules/mediasoup-client/lib/errors.js\"), exports);\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/types.js?");

/***/ }),

/***/ "./node_modules/mediasoup-client/lib/utils.js":
/*!****************************************************!*\
  !*** ./node_modules/mediasoup-client/lib/utils.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.clone = clone;\nexports.generateRandomNumber = generateRandomNumber;\nexports.deepFreeze = deepFreeze;\n/**\n * Clones the given value.\n */\nfunction clone(value) {\n    if (value === undefined) {\n        return undefined;\n    }\n    else if (Number.isNaN(value)) {\n        return NaN;\n    }\n    else if (typeof structuredClone === 'function') {\n        // Available in Node >= 18.\n        return structuredClone(value);\n    }\n    else {\n        return JSON.parse(JSON.stringify(value));\n    }\n}\n/**\n * Generates a random positive integer.\n */\nfunction generateRandomNumber() {\n    return Math.round(Math.random() * 10000000);\n}\n/**\n * Make an object or array recursively immutable.\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze.\n */\nfunction deepFreeze(object) {\n    // Retrieve the property names defined on object.\n    const propNames = Reflect.ownKeys(object);\n    // Freeze properties before freezing self.\n    for (const name of propNames) {\n        const value = object[name];\n        if ((value && typeof value === 'object') || typeof value === 'function') {\n            deepFreeze(value);\n        }\n    }\n    return Object.freeze(object);\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/mediasoup-client/lib/utils.js?");

/***/ }),

/***/ "./node_modules/ms/index.js":
/*!**********************************!*\
  !*** ./node_modules/ms/index.js ***!
  \**********************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/ms/index.js?");

/***/ }),

/***/ "./node_modules/npm-events-package/events.js":
/*!***************************************************!*\
  !*** ./node_modules/npm-events-package/events.js ***!
  \***************************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/npm-events-package/events.js?");

/***/ }),

/***/ "./node_modules/queue-microtask/index.js":
/*!***********************************************!*\
  !*** ./node_modules/queue-microtask/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("/*! queue-microtask. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\nlet promise\n\nmodule.exports = typeof queueMicrotask === 'function'\n  ? queueMicrotask.bind(typeof window !== 'undefined' ? window : __webpack_require__.g)\n  // reuse resolved promise, and allocate it lazily\n  : cb => (promise || (promise = Promise.resolve()))\n    .then(cb)\n    .catch(err => setTimeout(() => { throw err }, 0))\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/queue-microtask/index.js?");

/***/ }),

/***/ "./node_modules/sdp-transform/lib/grammar.js":
/*!***************************************************!*\
  !*** ./node_modules/sdp-transform/lib/grammar.js ***!
  \***************************************************/
/***/ ((module) => {

eval("var grammar = module.exports = {\n  v: [{\n    name: 'version',\n    reg: /^(\\d*)$/\n  }],\n  o: [{\n    // o=- 20518 0 IN IP4 203.0.113.1\n    // NB: sessionId will be a String in most cases because it is huge\n    name: 'origin',\n    reg: /^(\\S*) (\\d*) (\\d*) (\\S*) IP(\\d) (\\S*)/,\n    names: ['username', 'sessionId', 'sessionVersion', 'netType', 'ipVer', 'address'],\n    format: '%s %s %d %s IP%d %s'\n  }],\n  // default parsing of these only (though some of these feel outdated)\n  s: [{ name: 'name' }],\n  i: [{ name: 'description' }],\n  u: [{ name: 'uri' }],\n  e: [{ name: 'email' }],\n  p: [{ name: 'phone' }],\n  z: [{ name: 'timezones' }], // TODO: this one can actually be parsed properly...\n  r: [{ name: 'repeats' }],   // TODO: this one can also be parsed properly\n  // k: [{}], // outdated thing ignored\n  t: [{\n    // t=0 0\n    name: 'timing',\n    reg: /^(\\d*) (\\d*)/,\n    names: ['start', 'stop'],\n    format: '%d %d'\n  }],\n  c: [{\n    // c=IN IP4 10.47.197.26\n    name: 'connection',\n    reg: /^IN IP(\\d) (\\S*)/,\n    names: ['version', 'ip'],\n    format: 'IN IP%d %s'\n  }],\n  b: [{\n    // b=AS:4000\n    push: 'bandwidth',\n    reg: /^(TIAS|AS|CT|RR|RS):(\\d*)/,\n    names: ['type', 'limit'],\n    format: '%s:%s'\n  }],\n  m: [{\n    // m=video 51744 RTP/AVP 126 97 98 34 31\n    // NB: special - pushes to session\n    // TODO: rtp/fmtp should be filtered by the payloads found here?\n    reg: /^(\\w*) (\\d*) ([\\w/]*)(?: (.*))?/,\n    names: ['type', 'port', 'protocol', 'payloads'],\n    format: '%s %d %s %s'\n  }],\n  a: [\n    {\n      // a=rtpmap:110 opus/48000/2\n      push: 'rtp',\n      reg: /^rtpmap:(\\d*) ([\\w\\-.]*)(?:\\s*\\/(\\d*)(?:\\s*\\/(\\S*))?)?/,\n      names: ['payload', 'codec', 'rate', 'encoding'],\n      format: function (o) {\n        return (o.encoding)\n          ? 'rtpmap:%d %s/%s/%s'\n          : o.rate\n            ? 'rtpmap:%d %s/%s'\n            : 'rtpmap:%d %s';\n      }\n    },\n    {\n      // a=fmtp:108 profile-level-id=24;object=23;bitrate=64000\n      // a=fmtp:111 minptime=10; useinbandfec=1\n      push: 'fmtp',\n      reg: /^fmtp:(\\d*) ([\\S| ]*)/,\n      names: ['payload', 'config'],\n      format: 'fmtp:%d %s'\n    },\n    {\n      // a=control:streamid=0\n      name: 'control',\n      reg: /^control:(.*)/,\n      format: 'control:%s'\n    },\n    {\n      // a=rtcp:65179 IN IP4 193.84.77.194\n      name: 'rtcp',\n      reg: /^rtcp:(\\d*)(?: (\\S*) IP(\\d) (\\S*))?/,\n      names: ['port', 'netType', 'ipVer', 'address'],\n      format: function (o) {\n        return (o.address != null)\n          ? 'rtcp:%d %s IP%d %s'\n          : 'rtcp:%d';\n      }\n    },\n    {\n      // a=rtcp-fb:98 trr-int 100\n      push: 'rtcpFbTrrInt',\n      reg: /^rtcp-fb:(\\*|\\d*) trr-int (\\d*)/,\n      names: ['payload', 'value'],\n      format: 'rtcp-fb:%s trr-int %d'\n    },\n    {\n      // a=rtcp-fb:98 nack rpsi\n      push: 'rtcpFb',\n      reg: /^rtcp-fb:(\\*|\\d*) ([\\w-_]*)(?: ([\\w-_]*))?/,\n      names: ['payload', 'type', 'subtype'],\n      format: function (o) {\n        return (o.subtype != null)\n          ? 'rtcp-fb:%s %s %s'\n          : 'rtcp-fb:%s %s';\n      }\n    },\n    {\n      // a=extmap:2 urn:ietf:params:rtp-hdrext:toffset\n      // a=extmap:1/recvonly URI-gps-string\n      // a=extmap:3 urn:ietf:params:rtp-hdrext:encrypt urn:ietf:params:rtp-hdrext:smpte-tc 25@600/24\n      push: 'ext',\n      reg: /^extmap:(\\d+)(?:\\/(\\w+))?(?: (urn:ietf:params:rtp-hdrext:encrypt))? (\\S*)(?: (\\S*))?/,\n      names: ['value', 'direction', 'encrypt-uri', 'uri', 'config'],\n      format: function (o) {\n        return (\n          'extmap:%d' +\n          (o.direction ? '/%s' : '%v') +\n          (o['encrypt-uri'] ? ' %s' : '%v') +\n          ' %s' +\n          (o.config ? ' %s' : '')\n        );\n      }\n    },\n    {\n      // a=extmap-allow-mixed\n      name: 'extmapAllowMixed',\n      reg: /^(extmap-allow-mixed)/\n    },\n    {\n      // a=crypto:1 AES_CM_128_HMAC_SHA1_80 inline:PS1uQCVeeCFCanVmcjkpPywjNWhcYD0mXXtxaVBR|2^20|1:32\n      push: 'crypto',\n      reg: /^crypto:(\\d*) ([\\w_]*) (\\S*)(?: (\\S*))?/,\n      names: ['id', 'suite', 'config', 'sessionConfig'],\n      format: function (o) {\n        return (o.sessionConfig != null)\n          ? 'crypto:%d %s %s %s'\n          : 'crypto:%d %s %s';\n      }\n    },\n    {\n      // a=setup:actpass\n      name: 'setup',\n      reg: /^setup:(\\w*)/,\n      format: 'setup:%s'\n    },\n    {\n      // a=connection:new\n      name: 'connectionType',\n      reg: /^connection:(new|existing)/,\n      format: 'connection:%s'\n    },\n    {\n      // a=mid:1\n      name: 'mid',\n      reg: /^mid:([^\\s]*)/,\n      format: 'mid:%s'\n    },\n    {\n      // a=msid:0c8b064d-d807-43b4-b434-f92a889d8587 98178685-d409-46e0-8e16-7ef0db0db64a\n      name: 'msid',\n      reg: /^msid:(.*)/,\n      format: 'msid:%s'\n    },\n    {\n      // a=ptime:20\n      name: 'ptime',\n      reg: /^ptime:(\\d*(?:\\.\\d*)*)/,\n      format: 'ptime:%d'\n    },\n    {\n      // a=maxptime:60\n      name: 'maxptime',\n      reg: /^maxptime:(\\d*(?:\\.\\d*)*)/,\n      format: 'maxptime:%d'\n    },\n    {\n      // a=sendrecv\n      name: 'direction',\n      reg: /^(sendrecv|recvonly|sendonly|inactive)/\n    },\n    {\n      // a=ice-lite\n      name: 'icelite',\n      reg: /^(ice-lite)/\n    },\n    {\n      // a=ice-ufrag:F7gI\n      name: 'iceUfrag',\n      reg: /^ice-ufrag:(\\S*)/,\n      format: 'ice-ufrag:%s'\n    },\n    {\n      // a=ice-pwd:x9cml/YzichV2+XlhiMu8g\n      name: 'icePwd',\n      reg: /^ice-pwd:(\\S*)/,\n      format: 'ice-pwd:%s'\n    },\n    {\n      // a=fingerprint:SHA-1 00:11:22:33:44:55:66:77:88:99:AA:BB:CC:DD:EE:FF:00:11:22:33\n      name: 'fingerprint',\n      reg: /^fingerprint:(\\S*) (\\S*)/,\n      names: ['type', 'hash'],\n      format: 'fingerprint:%s %s'\n    },\n    {\n      // a=candidate:0 1 UDP 2113667327 203.0.113.1 54400 typ host\n      // a=candidate:1162875081 1 udp 2113937151 192.168.34.75 60017 typ host generation 0 network-id 3 network-cost 10\n      // a=candidate:3289912957 2 udp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 generation 0 network-id 3 network-cost 10\n      // a=candidate:229815620 1 tcp 1518280447 192.168.150.19 60017 typ host tcptype active generation 0 network-id 3 network-cost 10\n      // a=candidate:3289912957 2 tcp 1845501695 193.84.77.194 60017 typ srflx raddr 192.168.34.75 rport 60017 tcptype passive generation 0 network-id 3 network-cost 10\n      push:'candidates',\n      reg: /^candidate:(\\S*) (\\d*) (\\S*) (\\d*) (\\S*) (\\d*) typ (\\S*)(?: raddr (\\S*) rport (\\d*))?(?: tcptype (\\S*))?(?: generation (\\d*))?(?: network-id (\\d*))?(?: network-cost (\\d*))?/,\n      names: ['foundation', 'component', 'transport', 'priority', 'ip', 'port', 'type', 'raddr', 'rport', 'tcptype', 'generation', 'network-id', 'network-cost'],\n      format: function (o) {\n        var str = 'candidate:%s %d %s %d %s %d typ %s';\n\n        str += (o.raddr != null) ? ' raddr %s rport %d' : '%v%v';\n\n        // NB: candidate has three optional chunks, so %void middles one if it's missing\n        str += (o.tcptype != null) ? ' tcptype %s' : '%v';\n\n        if (o.generation != null) {\n          str += ' generation %d';\n        }\n\n        str += (o['network-id'] != null) ? ' network-id %d' : '%v';\n        str += (o['network-cost'] != null) ? ' network-cost %d' : '%v';\n        return str;\n      }\n    },\n    {\n      // a=end-of-candidates (keep after the candidates line for readability)\n      name: 'endOfCandidates',\n      reg: /^(end-of-candidates)/\n    },\n    {\n      // a=remote-candidates:1 203.0.113.1 54400 2 203.0.113.1 54401 ...\n      name: 'remoteCandidates',\n      reg: /^remote-candidates:(.*)/,\n      format: 'remote-candidates:%s'\n    },\n    {\n      // a=ice-options:google-ice\n      name: 'iceOptions',\n      reg: /^ice-options:(\\S*)/,\n      format: 'ice-options:%s'\n    },\n    {\n      // a=ssrc:2566107569 cname:t9YU8M1UxTF8Y1A1\n      push: 'ssrcs',\n      reg: /^ssrc:(\\d*) ([\\w_-]*)(?::(.*))?/,\n      names: ['id', 'attribute', 'value'],\n      format: function (o) {\n        var str = 'ssrc:%d';\n        if (o.attribute != null) {\n          str += ' %s';\n          if (o.value != null) {\n            str += ':%s';\n          }\n        }\n        return str;\n      }\n    },\n    {\n      // a=ssrc-group:FEC 1 2\n      // a=ssrc-group:FEC-FR 3004364195 1080772241\n      push: 'ssrcGroups',\n      // token-char = %x21 / %x23-27 / %x2A-2B / %x2D-2E / %x30-39 / %x41-5A / %x5E-7E\n      reg: /^ssrc-group:([\\x21\\x23\\x24\\x25\\x26\\x27\\x2A\\x2B\\x2D\\x2E\\w]*) (.*)/,\n      names: ['semantics', 'ssrcs'],\n      format: 'ssrc-group:%s %s'\n    },\n    {\n      // a=msid-semantic: WMS Jvlam5X3SX1OP6pn20zWogvaKJz5Hjf9OnlV\n      name: 'msidSemantic',\n      reg: /^msid-semantic:\\s?(\\w*) (\\S*)/,\n      names: ['semantic', 'token'],\n      format: 'msid-semantic: %s %s' // space after ':' is not accidental\n    },\n    {\n      // a=group:BUNDLE audio video\n      push: 'groups',\n      reg: /^group:(\\w*) (.*)/,\n      names: ['type', 'mids'],\n      format: 'group:%s %s'\n    },\n    {\n      // a=rtcp-mux\n      name: 'rtcpMux',\n      reg: /^(rtcp-mux)/\n    },\n    {\n      // a=rtcp-rsize\n      name: 'rtcpRsize',\n      reg: /^(rtcp-rsize)/\n    },\n    {\n      // a=sctpmap:5000 webrtc-datachannel 1024\n      name: 'sctpmap',\n      reg: /^sctpmap:([\\w_/]*) (\\S*)(?: (\\S*))?/,\n      names: ['sctpmapNumber', 'app', 'maxMessageSize'],\n      format: function (o) {\n        return (o.maxMessageSize != null)\n          ? 'sctpmap:%s %s %s'\n          : 'sctpmap:%s %s';\n      }\n    },\n    {\n      // a=x-google-flag:conference\n      name: 'xGoogleFlag',\n      reg: /^x-google-flag:([^\\s]*)/,\n      format: 'x-google-flag:%s'\n    },\n    {\n      // a=rid:1 send max-width=1280;max-height=720;max-fps=30;depend=0\n      push: 'rids',\n      reg: /^rid:([\\d\\w]+) (\\w+)(?: ([\\S| ]*))?/,\n      names: ['id', 'direction', 'params'],\n      format: function (o) {\n        return (o.params) ? 'rid:%s %s %s' : 'rid:%s %s';\n      }\n    },\n    {\n      // a=imageattr:97 send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320] recv [x=330,y=250]\n      // a=imageattr:* send [x=800,y=640] recv *\n      // a=imageattr:100 recv [x=320,y=240]\n      push: 'imageattrs',\n      reg: new RegExp(\n        // a=imageattr:97\n        '^imageattr:(\\\\d+|\\\\*)' +\n        // send [x=800,y=640,sar=1.1,q=0.6] [x=480,y=320]\n        '[\\\\s\\\\t]+(send|recv)[\\\\s\\\\t]+(\\\\*|\\\\[\\\\S+\\\\](?:[\\\\s\\\\t]+\\\\[\\\\S+\\\\])*)' +\n        // recv [x=330,y=250]\n        '(?:[\\\\s\\\\t]+(recv|send)[\\\\s\\\\t]+(\\\\*|\\\\[\\\\S+\\\\](?:[\\\\s\\\\t]+\\\\[\\\\S+\\\\])*))?'\n      ),\n      names: ['pt', 'dir1', 'attrs1', 'dir2', 'attrs2'],\n      format: function (o) {\n        return 'imageattr:%s %s %s' + (o.dir2 ? ' %s %s' : '');\n      }\n    },\n    {\n      // a=simulcast:send 1,2,3;~4,~5 recv 6;~7,~8\n      // a=simulcast:recv 1;4,5 send 6;7\n      name: 'simulcast',\n      reg: new RegExp(\n        // a=simulcast:\n        '^simulcast:' +\n        // send 1,2,3;~4,~5\n        '(send|recv) ([a-zA-Z0-9\\\\-_~;,]+)' +\n        // space + recv 6;~7,~8\n        '(?:\\\\s?(send|recv) ([a-zA-Z0-9\\\\-_~;,]+))?' +\n        // end\n        '$'\n      ),\n      names: ['dir1', 'list1', 'dir2', 'list2'],\n      format: function (o) {\n        return 'simulcast:%s %s' + (o.dir2 ? ' %s %s' : '');\n      }\n    },\n    {\n      // old simulcast draft 03 (implemented by Firefox)\n      //   https://tools.ietf.org/html/draft-ietf-mmusic-sdp-simulcast-03\n      // a=simulcast: recv pt=97;98 send pt=97\n      // a=simulcast: send rid=5;6;7 paused=6,7\n      name: 'simulcast_03',\n      reg: /^simulcast:[\\s\\t]+([\\S+\\s\\t]+)$/,\n      names: ['value'],\n      format: 'simulcast: %s'\n    },\n    {\n      // a=framerate:25\n      // a=framerate:29.97\n      name: 'framerate',\n      reg: /^framerate:(\\d+(?:$|\\.\\d+))/,\n      format: 'framerate:%s'\n    },\n    {\n      // RFC4570\n      // a=source-filter: incl IN IP4 239.5.2.31 10.1.15.5\n      name: 'sourceFilter',\n      reg: /^source-filter: *(excl|incl) (\\S*) (IP4|IP6|\\*) (\\S*) (.*)/,\n      names: ['filterMode', 'netType', 'addressTypes', 'destAddress', 'srcList'],\n      format: 'source-filter: %s %s %s %s %s'\n    },\n    {\n      // a=bundle-only\n      name: 'bundleOnly',\n      reg: /^(bundle-only)/\n    },\n    {\n      // a=label:1\n      name: 'label',\n      reg: /^label:(.+)/,\n      format: 'label:%s'\n    },\n    {\n      // RFC version 26 for SCTP over DTLS\n      // https://tools.ietf.org/html/draft-ietf-mmusic-sctp-sdp-26#section-5\n      name: 'sctpPort',\n      reg: /^sctp-port:(\\d+)$/,\n      format: 'sctp-port:%s'\n    },\n    {\n      // RFC version 26 for SCTP over DTLS\n      // https://tools.ietf.org/html/draft-ietf-mmusic-sctp-sdp-26#section-6\n      name: 'maxMessageSize',\n      reg: /^max-message-size:(\\d+)$/,\n      format: 'max-message-size:%s'\n    },\n    {\n      // RFC7273\n      // a=ts-refclk:ptp=IEEE1588-2008:39-A7-94-FF-FE-07-CB-D0:37\n      push:'tsRefClocks',\n      reg: /^ts-refclk:([^\\s=]*)(?:=(\\S*))?/,\n      names: ['clksrc', 'clksrcExt'],\n      format: function (o) {\n        return 'ts-refclk:%s' + (o.clksrcExt != null ? '=%s' : '');\n      }\n    },\n    {\n      // RFC7273\n      // a=mediaclk:direct=963214424\n      name:'mediaClk',\n      reg: /^mediaclk:(?:id=(\\S*))? *([^\\s=]*)(?:=(\\S*))?(?: *rate=(\\d+)\\/(\\d+))?/,\n      names: ['id', 'mediaClockName', 'mediaClockValue', 'rateNumerator', 'rateDenominator'],\n      format: function (o) {\n        var str = 'mediaclk:';\n        str += (o.id != null ? 'id=%s %s' : '%v%s');\n        str += (o.mediaClockValue != null ? '=%s' : '');\n        str += (o.rateNumerator != null ? ' rate=%s' : '');\n        str += (o.rateDenominator != null ? '/%s' : '');\n        return str;\n      }\n    },\n    {\n      // a=keywds:keywords\n      name: 'keywords',\n      reg: /^keywds:(.+)$/,\n      format: 'keywds:%s'\n    },\n    {\n      // a=content:main\n      name: 'content',\n      reg: /^content:(.+)/,\n      format: 'content:%s'\n    },\n    // BFCP https://tools.ietf.org/html/rfc4583\n    {\n      // a=floorctrl:c-s\n      name: 'bfcpFloorCtrl',\n      reg: /^floorctrl:(c-only|s-only|c-s)/,\n      format: 'floorctrl:%s'\n    },\n    {\n      // a=confid:1\n      name: 'bfcpConfId',\n      reg: /^confid:(\\d+)/,\n      format: 'confid:%s'\n    },\n    {\n      // a=userid:1\n      name: 'bfcpUserId',\n      reg: /^userid:(\\d+)/,\n      format: 'userid:%s'\n    },\n    {\n      // a=floorid:1\n      name: 'bfcpFloorId',\n      reg: /^floorid:(.+) (?:m-stream|mstrm):(.+)/,\n      names: ['id', 'mStream'],\n      format: 'floorid:%s mstrm:%s'\n    },\n    {\n      // any a= that we don't understand is kept verbatim on media.invalid\n      push: 'invalid',\n      names: ['value']\n    }\n  ]\n};\n\n// set sensible defaults to avoid polluting the grammar with boring details\nObject.keys(grammar).forEach(function (key) {\n  var objs = grammar[key];\n  objs.forEach(function (obj) {\n    if (!obj.reg) {\n      obj.reg = /(.*)/;\n    }\n    if (!obj.format) {\n      obj.format = '%s';\n    }\n  });\n});\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/sdp-transform/lib/grammar.js?");

/***/ }),

/***/ "./node_modules/sdp-transform/lib/index.js":
/*!*************************************************!*\
  !*** ./node_modules/sdp-transform/lib/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var parser = __webpack_require__(/*! ./parser */ \"./node_modules/sdp-transform/lib/parser.js\");\nvar writer = __webpack_require__(/*! ./writer */ \"./node_modules/sdp-transform/lib/writer.js\");\n\nexports.write = writer;\nexports.parse = parser.parse;\nexports.parseParams = parser.parseParams;\nexports.parseFmtpConfig = parser.parseFmtpConfig; // Alias of parseParams().\nexports.parsePayloads = parser.parsePayloads;\nexports.parseRemoteCandidates = parser.parseRemoteCandidates;\nexports.parseImageAttributes = parser.parseImageAttributes;\nexports.parseSimulcastStreamList = parser.parseSimulcastStreamList;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/sdp-transform/lib/index.js?");

/***/ }),

/***/ "./node_modules/sdp-transform/lib/parser.js":
/*!**************************************************!*\
  !*** ./node_modules/sdp-transform/lib/parser.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("var toIntIfInt = function (v) {\n  return String(Number(v)) === v ? Number(v) : v;\n};\n\nvar attachProperties = function (match, location, names, rawName) {\n  if (rawName && !names) {\n    location[rawName] = toIntIfInt(match[1]);\n  }\n  else {\n    for (var i = 0; i < names.length; i += 1) {\n      if (match[i+1] != null) {\n        location[names[i]] = toIntIfInt(match[i+1]);\n      }\n    }\n  }\n};\n\nvar parseReg = function (obj, location, content) {\n  var needsBlank = obj.name && obj.names;\n  if (obj.push && !location[obj.push]) {\n    location[obj.push] = [];\n  }\n  else if (needsBlank && !location[obj.name]) {\n    location[obj.name] = {};\n  }\n  var keyLocation = obj.push ?\n    {} :  // blank object that will be pushed\n    needsBlank ? location[obj.name] : location; // otherwise, named location or root\n\n  attachProperties(content.match(obj.reg), keyLocation, obj.names, obj.name);\n\n  if (obj.push) {\n    location[obj.push].push(keyLocation);\n  }\n};\n\nvar grammar = __webpack_require__(/*! ./grammar */ \"./node_modules/sdp-transform/lib/grammar.js\");\nvar validLine = RegExp.prototype.test.bind(/^([a-z])=(.*)/);\n\nexports.parse = function (sdp) {\n  var session = {}\n    , media = []\n    , location = session; // points at where properties go under (one of the above)\n\n  // parse lines we understand\n  sdp.split(/(\\r\\n|\\r|\\n)/).filter(validLine).forEach(function (l) {\n    var type = l[0];\n    var content = l.slice(2);\n    if (type === 'm') {\n      media.push({rtp: [], fmtp: []});\n      location = media[media.length-1]; // point at latest media line\n    }\n\n    for (var j = 0; j < (grammar[type] || []).length; j += 1) {\n      var obj = grammar[type][j];\n      if (obj.reg.test(content)) {\n        return parseReg(obj, location, content);\n      }\n    }\n  });\n\n  session.media = media; // link it up\n  return session;\n};\n\nvar paramReducer = function (acc, expr) {\n  var s = expr.split(/=(.+)/, 2);\n  if (s.length === 2) {\n    acc[s[0]] = toIntIfInt(s[1]);\n  } else if (s.length === 1 && expr.length > 1) {\n    acc[s[0]] = undefined;\n  }\n  return acc;\n};\n\nexports.parseParams = function (str) {\n  return str.split(/;\\s?/).reduce(paramReducer, {});\n};\n\n// For backward compatibility - alias will be removed in 3.0.0\nexports.parseFmtpConfig = exports.parseParams;\n\nexports.parsePayloads = function (str) {\n  return str.toString().split(' ').map(Number);\n};\n\nexports.parseRemoteCandidates = function (str) {\n  var candidates = [];\n  var parts = str.split(' ').map(toIntIfInt);\n  for (var i = 0; i < parts.length; i += 3) {\n    candidates.push({\n      component: parts[i],\n      ip: parts[i + 1],\n      port: parts[i + 2]\n    });\n  }\n  return candidates;\n};\n\nexports.parseImageAttributes = function (str) {\n  return str.split(' ').map(function (item) {\n    return item.substring(1, item.length-1).split(',').reduce(paramReducer, {});\n  });\n};\n\nexports.parseSimulcastStreamList = function (str) {\n  return str.split(';').map(function (stream) {\n    return stream.split(',').map(function (format) {\n      var scid, paused = false;\n\n      if (format[0] !== '~') {\n        scid = toIntIfInt(format);\n      } else {\n        scid = toIntIfInt(format.substring(1, format.length));\n        paused = true;\n      }\n\n      return {\n        scid: scid,\n        paused: paused\n      };\n    });\n  });\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/sdp-transform/lib/parser.js?");

/***/ }),

/***/ "./node_modules/sdp-transform/lib/writer.js":
/*!**************************************************!*\
  !*** ./node_modules/sdp-transform/lib/writer.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var grammar = __webpack_require__(/*! ./grammar */ \"./node_modules/sdp-transform/lib/grammar.js\");\n\n// customized util.format - discards excess arguments and can void middle ones\nvar formatRegExp = /%[sdv%]/g;\nvar format = function (formatStr) {\n  var i = 1;\n  var args = arguments;\n  var len = args.length;\n  return formatStr.replace(formatRegExp, function (x) {\n    if (i >= len) {\n      return x; // missing argument\n    }\n    var arg = args[i];\n    i += 1;\n    switch (x) {\n    case '%%':\n      return '%';\n    case '%s':\n      return String(arg);\n    case '%d':\n      return Number(arg);\n    case '%v':\n      return '';\n    }\n  });\n  // NB: we discard excess arguments - they are typically undefined from makeLine\n};\n\nvar makeLine = function (type, obj, location) {\n  var str = obj.format instanceof Function ?\n    (obj.format(obj.push ? location : location[obj.name])) :\n    obj.format;\n\n  var args = [type + '=' + str];\n  if (obj.names) {\n    for (var i = 0; i < obj.names.length; i += 1) {\n      var n = obj.names[i];\n      if (obj.name) {\n        args.push(location[obj.name][n]);\n      }\n      else { // for mLine and push attributes\n        args.push(location[obj.names[i]]);\n      }\n    }\n  }\n  else {\n    args.push(location[obj.name]);\n  }\n  return format.apply(null, args);\n};\n\n// RFC specified order\n// TODO: extend this with all the rest\nvar defaultOuterOrder = [\n  'v', 'o', 's', 'i',\n  'u', 'e', 'p', 'c',\n  'b', 't', 'r', 'z', 'a'\n];\nvar defaultInnerOrder = ['i', 'c', 'b', 'a'];\n\n\nmodule.exports = function (session, opts) {\n  opts = opts || {};\n  // ensure certain properties exist\n  if (session.version == null) {\n    session.version = 0; // 'v=0' must be there (only defined version atm)\n  }\n  if (session.name == null) {\n    session.name = ' '; // 's= ' must be there if no meaningful name set\n  }\n  session.media.forEach(function (mLine) {\n    if (mLine.payloads == null) {\n      mLine.payloads = '';\n    }\n  });\n\n  var outerOrder = opts.outerOrder || defaultOuterOrder;\n  var innerOrder = opts.innerOrder || defaultInnerOrder;\n  var sdp = [];\n\n  // loop through outerOrder for matching properties on session\n  outerOrder.forEach(function (type) {\n    grammar[type].forEach(function (obj) {\n      if (obj.name in session && session[obj.name] != null) {\n        sdp.push(makeLine(type, obj, session));\n      }\n      else if (obj.push in session && session[obj.push] != null) {\n        session[obj.push].forEach(function (el) {\n          sdp.push(makeLine(type, obj, el));\n        });\n      }\n    });\n  });\n\n  // then for each media line, follow the innerOrder\n  session.media.forEach(function (mLine) {\n    sdp.push(makeLine('m', grammar.m[0], mLine));\n\n    innerOrder.forEach(function (type) {\n      grammar[type].forEach(function (obj) {\n        if (obj.name in mLine && mLine[obj.name] != null) {\n          sdp.push(makeLine(type, obj, mLine));\n        }\n        else if (obj.push in mLine && mLine[obj.push] != null) {\n          mLine[obj.push].forEach(function (el) {\n            sdp.push(makeLine(type, obj, el));\n          });\n        }\n      });\n    });\n  });\n\n  return sdp.join('\\r\\n') + '\\r\\n';\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/sdp-transform/lib/writer.js?");

/***/ }),

/***/ "./node_modules/ua-parser-js/src/ua-parser.js":
/*!****************************************************!*\
  !*** ./node_modules/ua-parser-js/src/ua-parser.js ***!
  \****************************************************/
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_RESULT__;/////////////////////////////////////////////////////////////////////////////////\n/* UAParser.js v1.0.38\n   Copyright  2012-2021 Faisal Salman <f@faisalman.com>\n   MIT License *//*\n   Detect Browser, Engine, OS, CPU, and Device type/model from User-Agent data.\n   Supports browser & node.js environment. \n   Demo   : https://faisalman.github.io/ua-parser-js\n   Source : https://github.com/faisalman/ua-parser-js */\n/////////////////////////////////////////////////////////////////////////////////\n\n(function (window, undefined) {\n\n    'use strict';\n\n    //////////////\n    // Constants\n    /////////////\n\n\n    var LIBVERSION  = '1.0.38',\n        EMPTY       = '',\n        UNKNOWN     = '?',\n        FUNC_TYPE   = 'function',\n        UNDEF_TYPE  = 'undefined',\n        OBJ_TYPE    = 'object',\n        STR_TYPE    = 'string',\n        MAJOR       = 'major',\n        MODEL       = 'model',\n        NAME        = 'name',\n        TYPE        = 'type',\n        VENDOR      = 'vendor',\n        VERSION     = 'version',\n        ARCHITECTURE= 'architecture',\n        CONSOLE     = 'console',\n        MOBILE      = 'mobile',\n        TABLET      = 'tablet',\n        SMARTTV     = 'smarttv',\n        WEARABLE    = 'wearable',\n        EMBEDDED    = 'embedded',\n        UA_MAX_LENGTH = 500;\n\n    var AMAZON  = 'Amazon',\n        APPLE   = 'Apple',\n        ASUS    = 'ASUS',\n        BLACKBERRY = 'BlackBerry',\n        BROWSER = 'Browser',\n        CHROME  = 'Chrome',\n        EDGE    = 'Edge',\n        FIREFOX = 'Firefox',\n        GOOGLE  = 'Google',\n        HUAWEI  = 'Huawei',\n        LG      = 'LG',\n        MICROSOFT = 'Microsoft',\n        MOTOROLA  = 'Motorola',\n        OPERA   = 'Opera',\n        SAMSUNG = 'Samsung',\n        SHARP   = 'Sharp',\n        SONY    = 'Sony',\n        XIAOMI  = 'Xiaomi',\n        ZEBRA   = 'Zebra',\n        FACEBOOK    = 'Facebook',\n        CHROMIUM_OS = 'Chromium OS',\n        MAC_OS  = 'Mac OS';\n\n    ///////////\n    // Helper\n    //////////\n\n    var extend = function (regexes, extensions) {\n            var mergedRegexes = {};\n            for (var i in regexes) {\n                if (extensions[i] && extensions[i].length % 2 === 0) {\n                    mergedRegexes[i] = extensions[i].concat(regexes[i]);\n                } else {\n                    mergedRegexes[i] = regexes[i];\n                }\n            }\n            return mergedRegexes;\n        },\n        enumerize = function (arr) {\n            var enums = {};\n            for (var i=0; i<arr.length; i++) {\n                enums[arr[i].toUpperCase()] = arr[i];\n            }\n            return enums;\n        },\n        has = function (str1, str2) {\n            return typeof str1 === STR_TYPE ? lowerize(str2).indexOf(lowerize(str1)) !== -1 : false;\n        },\n        lowerize = function (str) {\n            return str.toLowerCase();\n        },\n        majorize = function (version) {\n            return typeof(version) === STR_TYPE ? version.replace(/[^\\d\\.]/g, EMPTY).split('.')[0] : undefined;\n        },\n        trim = function (str, len) {\n            if (typeof(str) === STR_TYPE) {\n                str = str.replace(/^\\s\\s*/, EMPTY);\n                return typeof(len) === UNDEF_TYPE ? str : str.substring(0, UA_MAX_LENGTH);\n            }\n    };\n\n    ///////////////\n    // Map helper\n    //////////////\n\n    var rgxMapper = function (ua, arrays) {\n\n            var i = 0, j, k, p, q, matches, match;\n\n            // loop through all regexes maps\n            while (i < arrays.length && !matches) {\n\n                var regex = arrays[i],       // even sequence (0,2,4,..)\n                    props = arrays[i + 1];   // odd sequence (1,3,5,..)\n                j = k = 0;\n\n                // try matching uastring with regexes\n                while (j < regex.length && !matches) {\n\n                    if (!regex[j]) { break; }\n                    matches = regex[j++].exec(ua);\n\n                    if (!!matches) {\n                        for (p = 0; p < props.length; p++) {\n                            match = matches[++k];\n                            q = props[p];\n                            // check if given property is actually array\n                            if (typeof q === OBJ_TYPE && q.length > 0) {\n                                if (q.length === 2) {\n                                    if (typeof q[1] == FUNC_TYPE) {\n                                        // assign modified match\n                                        this[q[0]] = q[1].call(this, match);\n                                    } else {\n                                        // assign given value, ignore regex match\n                                        this[q[0]] = q[1];\n                                    }\n                                } else if (q.length === 3) {\n                                    // check whether function or regex\n                                    if (typeof q[1] === FUNC_TYPE && !(q[1].exec && q[1].test)) {\n                                        // call function (usually string mapper)\n                                        this[q[0]] = match ? q[1].call(this, match, q[2]) : undefined;\n                                    } else {\n                                        // sanitize match using given regex\n                                        this[q[0]] = match ? match.replace(q[1], q[2]) : undefined;\n                                    }\n                                } else if (q.length === 4) {\n                                        this[q[0]] = match ? q[3].call(this, match.replace(q[1], q[2])) : undefined;\n                                }\n                            } else {\n                                this[q] = match ? match : undefined;\n                            }\n                        }\n                    }\n                }\n                i += 2;\n            }\n        },\n\n        strMapper = function (str, map) {\n\n            for (var i in map) {\n                // check if current value is array\n                if (typeof map[i] === OBJ_TYPE && map[i].length > 0) {\n                    for (var j = 0; j < map[i].length; j++) {\n                        if (has(map[i][j], str)) {\n                            return (i === UNKNOWN) ? undefined : i;\n                        }\n                    }\n                } else if (has(map[i], str)) {\n                    return (i === UNKNOWN) ? undefined : i;\n                }\n            }\n            return str;\n    };\n\n    ///////////////\n    // String map\n    //////////////\n\n    // Safari < 3.0\n    var oldSafariMap = {\n            '1.0'   : '/8',\n            '1.2'   : '/1',\n            '1.3'   : '/3',\n            '2.0'   : '/412',\n            '2.0.2' : '/416',\n            '2.0.3' : '/417',\n            '2.0.4' : '/419',\n            '?'     : '/'\n        },\n        windowsVersionMap = {\n            'ME'        : '4.90',\n            'NT 3.11'   : 'NT3.51',\n            'NT 4.0'    : 'NT4.0',\n            '2000'      : 'NT 5.0',\n            'XP'        : ['NT 5.1', 'NT 5.2'],\n            'Vista'     : 'NT 6.0',\n            '7'         : 'NT 6.1',\n            '8'         : 'NT 6.2',\n            '8.1'       : 'NT 6.3',\n            '10'        : ['NT 6.4', 'NT 10.0'],\n            'RT'        : 'ARM'\n    };\n\n    //////////////\n    // Regex map\n    /////////////\n\n    var regexes = {\n\n        browser : [[\n\n            /\\b(?:crmo|crios)\\/([\\w\\.]+)/i                                      // Chrome for Android/iOS\n            ], [VERSION, [NAME, 'Chrome']], [\n            /edg(?:e|ios|a)?\\/([\\w\\.]+)/i                                       // Microsoft Edge\n            ], [VERSION, [NAME, 'Edge']], [\n\n            // Presto based\n            /(opera mini)\\/([-\\w\\.]+)/i,                                        // Opera Mini\n            /(opera [mobiletab]{3,6})\\b.+version\\/([-\\w\\.]+)/i,                 // Opera Mobi/Tablet\n            /(opera)(?:.+version\\/|[\\/ ]+)([\\w\\.]+)/i                           // Opera\n            ], [NAME, VERSION], [\n            /opios[\\/ ]+([\\w\\.]+)/i                                             // Opera mini on iphone >= 8.0\n            ], [VERSION, [NAME, OPERA+' Mini']], [\n            /\\bop(?:rg)?x\\/([\\w\\.]+)/i                                          // Opera GX\n            ], [VERSION, [NAME, OPERA+' GX']], [\n            /\\bopr\\/([\\w\\.]+)/i                                                 // Opera Webkit\n            ], [VERSION, [NAME, OPERA]], [\n\n            // Mixed\n            /\\bb[ai]*d(?:uhd|[ub]*[aekoprswx]{5,6})[\\/ ]?([\\w\\.]+)/i            // Baidu\n            ], [VERSION, [NAME, 'Baidu']], [\n            /(kindle)\\/([\\w\\.]+)/i,                                             // Kindle\n            /(lunascape|maxthon|netfront|jasmine|blazer)[\\/ ]?([\\w\\.]*)/i,      // Lunascape/Maxthon/Netfront/Jasmine/Blazer\n            // Trident based\n            /(avant|iemobile|slim)\\s?(?:browser)?[\\/ ]?([\\w\\.]*)/i,             // Avant/IEMobile/SlimBrowser\n            /(?:ms|\\()(ie) ([\\w\\.]+)/i,                                         // Internet Explorer\n\n            // Webkit/KHTML based                                               // Flock/RockMelt/Midori/Epiphany/Silk/Skyfire/Bolt/Iron/Iridium/PhantomJS/Bowser/QupZilla/Falkon\n            /(flock|rockmelt|midori|epiphany|silk|skyfire|bolt|iron|vivaldi|iridium|phantomjs|bowser|quark|qupzilla|falkon|rekonq|puffin|brave|whale(?!.+naver)|qqbrowserlite|qq|duckduckgo)\\/([-\\w\\.]+)/i,\n                                                                                // Rekonq/Puffin/Brave/Whale/QQBrowserLite/QQ, aka ShouQ\n            /(heytap|ovi)browser\\/([\\d\\.]+)/i,                                  // Heytap/Ovi\n            /(weibo)__([\\d\\.]+)/i                                               // Weibo\n            ], [NAME, VERSION], [\n            /\\bddg\\/([\\w\\.]+)/i                                                 // DuckDuckGo\n            ], [VERSION, [NAME, 'DuckDuckGo']], [\n            /(?:\\buc? ?browser|(?:juc.+)ucweb)[\\/ ]?([\\w\\.]+)/i                 // UCBrowser\n            ], [VERSION, [NAME, 'UC'+BROWSER]], [\n            /microm.+\\bqbcore\\/([\\w\\.]+)/i,                                     // WeChat Desktop for Windows Built-in Browser\n            /\\bqbcore\\/([\\w\\.]+).+microm/i,\n            /micromessenger\\/([\\w\\.]+)/i                                        // WeChat\n            ], [VERSION, [NAME, 'WeChat']], [\n            /konqueror\\/([\\w\\.]+)/i                                             // Konqueror\n            ], [VERSION, [NAME, 'Konqueror']], [\n            /trident.+rv[: ]([\\w\\.]{1,9})\\b.+like gecko/i                       // IE11\n            ], [VERSION, [NAME, 'IE']], [\n            /ya(?:search)?browser\\/([\\w\\.]+)/i                                  // Yandex\n            ], [VERSION, [NAME, 'Yandex']], [\n            /slbrowser\\/([\\w\\.]+)/i                                             // Smart Lenovo Browser\n            ], [VERSION, [NAME, 'Smart Lenovo '+BROWSER]], [\n            /(avast|avg)\\/([\\w\\.]+)/i                                           // Avast/AVG Secure Browser\n            ], [[NAME, /(.+)/, '$1 Secure '+BROWSER], VERSION], [\n            /\\bfocus\\/([\\w\\.]+)/i                                               // Firefox Focus\n            ], [VERSION, [NAME, FIREFOX+' Focus']], [\n            /\\bopt\\/([\\w\\.]+)/i                                                 // Opera Touch\n            ], [VERSION, [NAME, OPERA+' Touch']], [\n            /coc_coc\\w+\\/([\\w\\.]+)/i                                            // Coc Coc Browser\n            ], [VERSION, [NAME, 'Coc Coc']], [\n            /dolfin\\/([\\w\\.]+)/i                                                // Dolphin\n            ], [VERSION, [NAME, 'Dolphin']], [\n            /coast\\/([\\w\\.]+)/i                                                 // Opera Coast\n            ], [VERSION, [NAME, OPERA+' Coast']], [\n            /miuibrowser\\/([\\w\\.]+)/i                                           // MIUI Browser\n            ], [VERSION, [NAME, 'MIUI '+BROWSER]], [\n            /fxios\\/([-\\w\\.]+)/i                                                // Firefox for iOS\n            ], [VERSION, [NAME, FIREFOX]], [\n            /\\bqihu|(qi?ho?o?|360)browser/i                                     // 360\n            ], [[NAME, '360 ' + BROWSER]], [\n            /(oculus|sailfish|huawei|vivo)browser\\/([\\w\\.]+)/i\n            ], [[NAME, /(.+)/, '$1 ' + BROWSER], VERSION], [                    // Oculus/Sailfish/HuaweiBrowser/VivoBrowser\n            /samsungbrowser\\/([\\w\\.]+)/i                                        // Samsung Internet\n            ], [VERSION, [NAME, SAMSUNG + ' Internet']], [\n            /(comodo_dragon)\\/([\\w\\.]+)/i                                       // Comodo Dragon\n            ], [[NAME, /_/g, ' '], VERSION], [\n            /metasr[\\/ ]?([\\d\\.]+)/i                                            // Sogou Explorer\n            ], [VERSION, [NAME, 'Sogou Explorer']], [\n            /(sogou)mo\\w+\\/([\\d\\.]+)/i                                          // Sogou Mobile\n            ], [[NAME, 'Sogou Mobile'], VERSION], [\n            /(electron)\\/([\\w\\.]+) safari/i,                                    // Electron-based App\n            /(tesla)(?: qtcarbrowser|\\/(20\\d\\d\\.[-\\w\\.]+))/i,                   // Tesla\n            /m?(qqbrowser|2345Explorer)[\\/ ]?([\\w\\.]+)/i                        // QQBrowser/2345 Browser\n            ], [NAME, VERSION], [\n            /(lbbrowser)/i,                                                     // LieBao Browser\n            /\\[(linkedin)app\\]/i                                                // LinkedIn App for iOS & Android\n            ], [NAME], [\n\n            // WebView\n            /((?:fban\\/fbios|fb_iab\\/fb4a)(?!.+fbav)|;fbav\\/([\\w\\.]+);)/i       // Facebook App for iOS & Android\n            ], [[NAME, FACEBOOK], VERSION], [\n            /(Klarna)\\/([\\w\\.]+)/i,                                             // Klarna Shopping Browser for iOS & Android\n            /(kakao(?:talk|story))[\\/ ]([\\w\\.]+)/i,                             // Kakao App\n            /(naver)\\(.*?(\\d+\\.[\\w\\.]+).*\\)/i,                                  // Naver InApp\n            /safari (line)\\/([\\w\\.]+)/i,                                        // Line App for iOS\n            /\\b(line)\\/([\\w\\.]+)\\/iab/i,                                        // Line App for Android\n            /(alipay)client\\/([\\w\\.]+)/i,                                       // Alipay\n            /(twitter)(?:and| f.+e\\/([\\w\\.]+))/i,                               // Twitter\n            /(chromium|instagram|snapchat)[\\/ ]([-\\w\\.]+)/i                     // Chromium/Instagram/Snapchat\n            ], [NAME, VERSION], [\n            /\\bgsa\\/([\\w\\.]+) .*safari\\//i                                      // Google Search Appliance on iOS\n            ], [VERSION, [NAME, 'GSA']], [\n            /musical_ly(?:.+app_?version\\/|_)([\\w\\.]+)/i                        // TikTok\n            ], [VERSION, [NAME, 'TikTok']], [\n\n            /headlesschrome(?:\\/([\\w\\.]+)| )/i                                  // Chrome Headless\n            ], [VERSION, [NAME, CHROME+' Headless']], [\n\n            / wv\\).+(chrome)\\/([\\w\\.]+)/i                                       // Chrome WebView\n            ], [[NAME, CHROME+' WebView'], VERSION], [\n\n            /droid.+ version\\/([\\w\\.]+)\\b.+(?:mobile safari|safari)/i           // Android Browser\n            ], [VERSION, [NAME, 'Android '+BROWSER]], [\n\n            /(chrome|omniweb|arora|[tizenoka]{5} ?browser)\\/v?([\\w\\.]+)/i       // Chrome/OmniWeb/Arora/Tizen/Nokia\n            ], [NAME, VERSION], [\n\n            /version\\/([\\w\\.\\,]+) .*mobile\\/\\w+ (safari)/i                      // Mobile Safari\n            ], [VERSION, [NAME, 'Mobile Safari']], [\n            /version\\/([\\w(\\.|\\,)]+) .*(mobile ?safari|safari)/i                // Safari & Safari Mobile\n            ], [VERSION, NAME], [\n            /webkit.+?(mobile ?safari|safari)(\\/[\\w\\.]+)/i                      // Safari < 3.0\n            ], [NAME, [VERSION, strMapper, oldSafariMap]], [\n\n            /(webkit|khtml)\\/([\\w\\.]+)/i\n            ], [NAME, VERSION], [\n\n            // Gecko based\n            /(navigator|netscape\\d?)\\/([-\\w\\.]+)/i                              // Netscape\n            ], [[NAME, 'Netscape'], VERSION], [\n            /mobile vr; rv:([\\w\\.]+)\\).+firefox/i                               // Firefox Reality\n            ], [VERSION, [NAME, FIREFOX+' Reality']], [\n            /ekiohf.+(flow)\\/([\\w\\.]+)/i,                                       // Flow\n            /(swiftfox)/i,                                                      // Swiftfox\n            /(icedragon|iceweasel|camino|chimera|fennec|maemo browser|minimo|conkeror|klar)[\\/ ]?([\\w\\.\\+]+)/i,\n                                                                                // IceDragon/Iceweasel/Camino/Chimera/Fennec/Maemo/Minimo/Conkeror/Klar\n            /(seamonkey|k-meleon|icecat|iceape|firebird|phoenix|palemoon|basilisk|waterfox)\\/([-\\w\\.]+)$/i,\n                                                                                // Firefox/SeaMonkey/K-Meleon/IceCat/IceApe/Firebird/Phoenix\n            /(firefox)\\/([\\w\\.]+)/i,                                            // Other Firefox-based\n            /(mozilla)\\/([\\w\\.]+) .+rv\\:.+gecko\\/\\d+/i,                         // Mozilla\n\n            // Other\n            /(polaris|lynx|dillo|icab|doris|amaya|w3m|netsurf|sleipnir|obigo|mosaic|(?:go|ice|up)[\\. ]?browser)[-\\/ ]?v?([\\w\\.]+)/i,\n                                                                                // Polaris/Lynx/Dillo/iCab/Doris/Amaya/w3m/NetSurf/Sleipnir/Obigo/Mosaic/Go/ICE/UP.Browser\n            /(links) \\(([\\w\\.]+)/i,                                             // Links\n            /panasonic;(viera)/i                                                // Panasonic Viera\n            ], [NAME, VERSION], [\n            \n            /(cobalt)\\/([\\w\\.]+)/i                                              // Cobalt\n            ], [NAME, [VERSION, /master.|lts./, \"\"]]\n        ],\n\n        cpu : [[\n\n            /(?:(amd|x(?:(?:86|64)[-_])?|wow|win)64)[;\\)]/i                     // AMD64 (x64)\n            ], [[ARCHITECTURE, 'amd64']], [\n\n            /(ia32(?=;))/i                                                      // IA32 (quicktime)\n            ], [[ARCHITECTURE, lowerize]], [\n\n            /((?:i[346]|x)86)[;\\)]/i                                            // IA32 (x86)\n            ], [[ARCHITECTURE, 'ia32']], [\n\n            /\\b(aarch64|arm(v?8e?l?|_?64))\\b/i                                 // ARM64\n            ], [[ARCHITECTURE, 'arm64']], [\n\n            /\\b(arm(?:v[67])?ht?n?[fl]p?)\\b/i                                   // ARMHF\n            ], [[ARCHITECTURE, 'armhf']], [\n\n            // PocketPC mistakenly identified as PowerPC\n            /windows (ce|mobile); ppc;/i\n            ], [[ARCHITECTURE, 'arm']], [\n\n            /((?:ppc|powerpc)(?:64)?)(?: mac|;|\\))/i                            // PowerPC\n            ], [[ARCHITECTURE, /ower/, EMPTY, lowerize]], [\n\n            /(sun4\\w)[;\\)]/i                                                    // SPARC\n            ], [[ARCHITECTURE, 'sparc']], [\n\n            /((?:avr32|ia64(?=;))|68k(?=\\))|\\barm(?=v(?:[1-7]|[5-7]1)l?|;|eabi)|(?=atmel )avr|(?:irix|mips|sparc)(?:64)?\\b|pa-risc)/i\n                                                                                // IA64, 68K, ARM/64, AVR/32, IRIX/64, MIPS/64, SPARC/64, PA-RISC\n            ], [[ARCHITECTURE, lowerize]]\n        ],\n\n        device : [[\n\n            //////////////////////////\n            // MOBILES & TABLETS\n            /////////////////////////\n\n            // Samsung\n            /\\b(sch-i[89]0\\d|shw-m380s|sm-[ptx]\\w{2,4}|gt-[pn]\\d{2,4}|sgh-t8[56]9|nexus 10)/i\n            ], [MODEL, [VENDOR, SAMSUNG], [TYPE, TABLET]], [\n            /\\b((?:s[cgp]h|gt|sm)-\\w+|sc[g-]?[\\d]+a?|galaxy nexus)/i,\n            /samsung[- ]([-\\w]+)/i,\n            /sec-(sgh\\w+)/i\n            ], [MODEL, [VENDOR, SAMSUNG], [TYPE, MOBILE]], [\n\n            // Apple\n            /(?:\\/|\\()(ip(?:hone|od)[\\w, ]*)(?:\\/|;)/i                          // iPod/iPhone\n            ], [MODEL, [VENDOR, APPLE], [TYPE, MOBILE]], [\n            /\\((ipad);[-\\w\\),; ]+apple/i,                                       // iPad\n            /applecoremedia\\/[\\w\\.]+ \\((ipad)/i,\n            /\\b(ipad)\\d\\d?,\\d\\d?[;\\]].+ios/i\n            ], [MODEL, [VENDOR, APPLE], [TYPE, TABLET]], [\n            /(macintosh);/i\n            ], [MODEL, [VENDOR, APPLE]], [\n\n            // Sharp\n            /\\b(sh-?[altvz]?\\d\\d[a-ekm]?)/i\n            ], [MODEL, [VENDOR, SHARP], [TYPE, MOBILE]], [\n\n            // Huawei\n            /\\b((?:ag[rs][23]?|bah2?|sht?|btv)-a?[lw]\\d{2})\\b(?!.+d\\/s)/i\n            ], [MODEL, [VENDOR, HUAWEI], [TYPE, TABLET]], [\n            /(?:huawei|honor)([-\\w ]+)[;\\)]/i,\n            /\\b(nexus 6p|\\w{2,4}e?-[atu]?[ln][\\dx][012359c][adn]?)\\b(?!.+d\\/s)/i\n            ], [MODEL, [VENDOR, HUAWEI], [TYPE, MOBILE]], [\n\n            // Xiaomi\n            /\\b(poco[\\w ]+|m2\\d{3}j\\d\\d[a-z]{2})(?: bui|\\))/i,                  // Xiaomi POCO\n            /\\b; (\\w+) build\\/hm\\1/i,                                           // Xiaomi Hongmi 'numeric' models\n            /\\b(hm[-_ ]?note?[_ ]?(?:\\d\\w)?) bui/i,                             // Xiaomi Hongmi\n            /\\b(redmi[\\-_ ]?(?:note|k)?[\\w_ ]+)(?: bui|\\))/i,                   // Xiaomi Redmi\n            /oid[^\\)]+; (m?[12][0-389][01]\\w{3,6}[c-y])( bui|; wv|\\))/i,        // Xiaomi Redmi 'numeric' models\n            /\\b(mi[-_ ]?(?:a\\d|one|one[_ ]plus|note lte|max|cc)?[_ ]?(?:\\d?\\w?)[_ ]?(?:plus|se|lite)?)(?: bui|\\))/i // Xiaomi Mi\n            ], [[MODEL, /_/g, ' '], [VENDOR, XIAOMI], [TYPE, MOBILE]], [\n            /oid[^\\)]+; (2\\d{4}(283|rpbf)[cgl])( bui|\\))/i,                     // Redmi Pad\n            /\\b(mi[-_ ]?(?:pad)(?:[\\w_ ]+))(?: bui|\\))/i                        // Mi Pad tablets\n            ],[[MODEL, /_/g, ' '], [VENDOR, XIAOMI], [TYPE, TABLET]], [\n\n            // OPPO\n            /; (\\w+) bui.+ oppo/i,\n            /\\b(cph[12]\\d{3}|p(?:af|c[al]|d\\w|e[ar])[mt]\\d0|x9007|a101op)\\b/i\n            ], [MODEL, [VENDOR, 'OPPO'], [TYPE, MOBILE]], [\n            /\\b(opd2\\d{3}a?) bui/i\n            ], [MODEL, [VENDOR, 'OPPO'], [TYPE, TABLET]], [\n\n            // Vivo\n            /vivo (\\w+)(?: bui|\\))/i,\n            /\\b(v[12]\\d{3}\\w?[at])(?: bui|;)/i\n            ], [MODEL, [VENDOR, 'Vivo'], [TYPE, MOBILE]], [\n\n            // Realme\n            /\\b(rmx[1-3]\\d{3})(?: bui|;|\\))/i\n            ], [MODEL, [VENDOR, 'Realme'], [TYPE, MOBILE]], [\n\n            // Motorola\n            /\\b(milestone|droid(?:[2-4x]| (?:bionic|x2|pro|razr))?:?( 4g)?)\\b[\\w ]+build\\//i,\n            /\\bmot(?:orola)?[- ](\\w*)/i,\n            /((?:moto[\\w\\(\\) ]+|xt\\d{3,4}|nexus 6)(?= bui|\\)))/i\n            ], [MODEL, [VENDOR, MOTOROLA], [TYPE, MOBILE]], [\n            /\\b(mz60\\d|xoom[2 ]{0,2}) build\\//i\n            ], [MODEL, [VENDOR, MOTOROLA], [TYPE, TABLET]], [\n\n            // LG\n            /((?=lg)?[vl]k\\-?\\d{3}) bui| 3\\.[-\\w; ]{10}lg?-([06cv9]{3,4})/i\n            ], [MODEL, [VENDOR, LG], [TYPE, TABLET]], [\n            /(lm(?:-?f100[nv]?|-[\\w\\.]+)(?= bui|\\))|nexus [45])/i,\n            /\\blg[-e;\\/ ]+((?!browser|netcast|android tv)\\w+)/i,\n            /\\blg-?([\\d\\w]+) bui/i\n            ], [MODEL, [VENDOR, LG], [TYPE, MOBILE]], [\n\n            // Lenovo\n            /(ideatab[-\\w ]+)/i,\n            /lenovo ?(s[56]000[-\\w]+|tab(?:[\\w ]+)|yt[-\\d\\w]{6}|tb[-\\d\\w]{6})/i\n            ], [MODEL, [VENDOR, 'Lenovo'], [TYPE, TABLET]], [\n\n            // Nokia\n            /(?:maemo|nokia).*(n900|lumia \\d+)/i,\n            /nokia[-_ ]?([-\\w\\.]*)/i\n            ], [[MODEL, /_/g, ' '], [VENDOR, 'Nokia'], [TYPE, MOBILE]], [\n\n            // Google\n            /(pixel c)\\b/i                                                      // Google Pixel C\n            ], [MODEL, [VENDOR, GOOGLE], [TYPE, TABLET]], [\n            /droid.+; (pixel[\\daxl ]{0,6})(?: bui|\\))/i                         // Google Pixel\n            ], [MODEL, [VENDOR, GOOGLE], [TYPE, MOBILE]], [\n\n            // Sony\n            /droid.+ (a?\\d[0-2]{2}so|[c-g]\\d{4}|so[-gl]\\w+|xq-a\\w[4-7][12])(?= bui|\\).+chrome\\/(?![1-6]{0,1}\\d\\.))/i\n            ], [MODEL, [VENDOR, SONY], [TYPE, MOBILE]], [\n            /sony tablet [ps]/i,\n            /\\b(?:sony)?sgp\\w+(?: bui|\\))/i\n            ], [[MODEL, 'Xperia Tablet'], [VENDOR, SONY], [TYPE, TABLET]], [\n\n            // OnePlus\n            / (kb2005|in20[12]5|be20[12][59])\\b/i,\n            /(?:one)?(?:plus)? (a\\d0\\d\\d)(?: b|\\))/i\n            ], [MODEL, [VENDOR, 'OnePlus'], [TYPE, MOBILE]], [\n\n            // Amazon\n            /(alexa)webm/i,\n            /(kf[a-z]{2}wi|aeo[c-r]{2})( bui|\\))/i,                             // Kindle Fire without Silk / Echo Show\n            /(kf[a-z]+)( bui|\\)).+silk\\//i                                      // Kindle Fire HD\n            ], [MODEL, [VENDOR, AMAZON], [TYPE, TABLET]], [\n            /((?:sd|kf)[0349hijorstuw]+)( bui|\\)).+silk\\//i                     // Fire Phone\n            ], [[MODEL, /(.+)/g, 'Fire Phone $1'], [VENDOR, AMAZON], [TYPE, MOBILE]], [\n\n            // BlackBerry\n            /(playbook);[-\\w\\),; ]+(rim)/i                                      // BlackBerry PlayBook\n            ], [MODEL, VENDOR, [TYPE, TABLET]], [\n            /\\b((?:bb[a-f]|st[hv])100-\\d)/i,\n            /\\(bb10; (\\w+)/i                                                    // BlackBerry 10\n            ], [MODEL, [VENDOR, BLACKBERRY], [TYPE, MOBILE]], [\n\n            // Asus\n            /(?:\\b|asus_)(transfo[prime ]{4,10} \\w+|eeepc|slider \\w+|nexus 7|padfone|p00[cj])/i\n            ], [MODEL, [VENDOR, ASUS], [TYPE, TABLET]], [\n            / (z[bes]6[027][012][km][ls]|zenfone \\d\\w?)\\b/i\n            ], [MODEL, [VENDOR, ASUS], [TYPE, MOBILE]], [\n\n            // HTC\n            /(nexus 9)/i                                                        // HTC Nexus 9\n            ], [MODEL, [VENDOR, 'HTC'], [TYPE, TABLET]], [\n            /(htc)[-;_ ]{1,2}([\\w ]+(?=\\)| bui)|\\w+)/i,                         // HTC\n\n            // ZTE\n            /(zte)[- ]([\\w ]+?)(?: bui|\\/|\\))/i,\n            /(alcatel|geeksphone|nexian|panasonic(?!(?:;|\\.))|sony(?!-bra))[-_ ]?([-\\w]*)/i         // Alcatel/GeeksPhone/Nexian/Panasonic/Sony\n            ], [VENDOR, [MODEL, /_/g, ' '], [TYPE, MOBILE]], [\n\n            // Acer\n            /droid.+; ([ab][1-7]-?[0178a]\\d\\d?)/i\n            ], [MODEL, [VENDOR, 'Acer'], [TYPE, TABLET]], [\n\n            // Meizu\n            /droid.+; (m[1-5] note) bui/i,\n            /\\bmz-([-\\w]{2,})/i\n            ], [MODEL, [VENDOR, 'Meizu'], [TYPE, MOBILE]], [\n                \n            // Ulefone\n            /; ((?:power )?armor(?:[\\w ]{0,8}))(?: bui|\\))/i\n            ], [MODEL, [VENDOR, 'Ulefone'], [TYPE, MOBILE]], [\n\n            // MIXED\n            /(blackberry|benq|palm(?=\\-)|sonyericsson|acer|asus|dell|meizu|motorola|polytron|infinix|tecno)[-_ ]?([-\\w]*)/i,\n                                                                                // BlackBerry/BenQ/Palm/Sony-Ericsson/Acer/Asus/Dell/Meizu/Motorola/Polytron\n            /(hp) ([\\w ]+\\w)/i,                                                 // HP iPAQ\n            /(asus)-?(\\w+)/i,                                                   // Asus\n            /(microsoft); (lumia[\\w ]+)/i,                                      // Microsoft Lumia\n            /(lenovo)[-_ ]?([-\\w]+)/i,                                          // Lenovo\n            /(jolla)/i,                                                         // Jolla\n            /(oppo) ?([\\w ]+) bui/i                                             // OPPO\n            ], [VENDOR, MODEL, [TYPE, MOBILE]], [\n\n            /(kobo)\\s(ereader|touch)/i,                                         // Kobo\n            /(archos) (gamepad2?)/i,                                            // Archos\n            /(hp).+(touchpad(?!.+tablet)|tablet)/i,                             // HP TouchPad\n            /(kindle)\\/([\\w\\.]+)/i,                                             // Kindle\n            /(nook)[\\w ]+build\\/(\\w+)/i,                                        // Nook\n            /(dell) (strea[kpr\\d ]*[\\dko])/i,                                   // Dell Streak\n            /(le[- ]+pan)[- ]+(\\w{1,9}) bui/i,                                  // Le Pan Tablets\n            /(trinity)[- ]*(t\\d{3}) bui/i,                                      // Trinity Tablets\n            /(gigaset)[- ]+(q\\w{1,9}) bui/i,                                    // Gigaset Tablets\n            /(vodafone) ([\\w ]+)(?:\\)| bui)/i                                   // Vodafone\n            ], [VENDOR, MODEL, [TYPE, TABLET]], [\n\n            /(surface duo)/i                                                    // Surface Duo\n            ], [MODEL, [VENDOR, MICROSOFT], [TYPE, TABLET]], [\n            /droid [\\d\\.]+; (fp\\du?)(?: b|\\))/i                                 // Fairphone\n            ], [MODEL, [VENDOR, 'Fairphone'], [TYPE, MOBILE]], [\n            /(u304aa)/i                                                         // AT&T\n            ], [MODEL, [VENDOR, 'AT&T'], [TYPE, MOBILE]], [\n            /\\bsie-(\\w*)/i                                                      // Siemens\n            ], [MODEL, [VENDOR, 'Siemens'], [TYPE, MOBILE]], [\n            /\\b(rct\\w+) b/i                                                     // RCA Tablets\n            ], [MODEL, [VENDOR, 'RCA'], [TYPE, TABLET]], [\n            /\\b(venue[\\d ]{2,7}) b/i                                            // Dell Venue Tablets\n            ], [MODEL, [VENDOR, 'Dell'], [TYPE, TABLET]], [\n            /\\b(q(?:mv|ta)\\w+) b/i                                              // Verizon Tablet\n            ], [MODEL, [VENDOR, 'Verizon'], [TYPE, TABLET]], [\n            /\\b(?:barnes[& ]+noble |bn[rt])([\\w\\+ ]*) b/i                       // Barnes & Noble Tablet\n            ], [MODEL, [VENDOR, 'Barnes & Noble'], [TYPE, TABLET]], [\n            /\\b(tm\\d{3}\\w+) b/i\n            ], [MODEL, [VENDOR, 'NuVision'], [TYPE, TABLET]], [\n            /\\b(k88) b/i                                                        // ZTE K Series Tablet\n            ], [MODEL, [VENDOR, 'ZTE'], [TYPE, TABLET]], [\n            /\\b(nx\\d{3}j) b/i                                                   // ZTE Nubia\n            ], [MODEL, [VENDOR, 'ZTE'], [TYPE, MOBILE]], [\n            /\\b(gen\\d{3}) b.+49h/i                                              // Swiss GEN Mobile\n            ], [MODEL, [VENDOR, 'Swiss'], [TYPE, MOBILE]], [\n            /\\b(zur\\d{3}) b/i                                                   // Swiss ZUR Tablet\n            ], [MODEL, [VENDOR, 'Swiss'], [TYPE, TABLET]], [\n            /\\b((zeki)?tb.*\\b) b/i                                              // Zeki Tablets\n            ], [MODEL, [VENDOR, 'Zeki'], [TYPE, TABLET]], [\n            /\\b([yr]\\d{2}) b/i,\n            /\\b(dragon[- ]+touch |dt)(\\w{5}) b/i                                // Dragon Touch Tablet\n            ], [[VENDOR, 'Dragon Touch'], MODEL, [TYPE, TABLET]], [\n            /\\b(ns-?\\w{0,9}) b/i                                                // Insignia Tablets\n            ], [MODEL, [VENDOR, 'Insignia'], [TYPE, TABLET]], [\n            /\\b((nxa|next)-?\\w{0,9}) b/i                                        // NextBook Tablets\n            ], [MODEL, [VENDOR, 'NextBook'], [TYPE, TABLET]], [\n            /\\b(xtreme\\_)?(v(1[045]|2[015]|[3469]0|7[05])) b/i                  // Voice Xtreme Phones\n            ], [[VENDOR, 'Voice'], MODEL, [TYPE, MOBILE]], [\n            /\\b(lvtel\\-)?(v1[12]) b/i                                           // LvTel Phones\n            ], [[VENDOR, 'LvTel'], MODEL, [TYPE, MOBILE]], [\n            /\\b(ph-1) /i                                                        // Essential PH-1\n            ], [MODEL, [VENDOR, 'Essential'], [TYPE, MOBILE]], [\n            /\\b(v(100md|700na|7011|917g).*\\b) b/i                               // Envizen Tablets\n            ], [MODEL, [VENDOR, 'Envizen'], [TYPE, TABLET]], [\n            /\\b(trio[-\\w\\. ]+) b/i                                              // MachSpeed Tablets\n            ], [MODEL, [VENDOR, 'MachSpeed'], [TYPE, TABLET]], [\n            /\\btu_(1491) b/i                                                    // Rotor Tablets\n            ], [MODEL, [VENDOR, 'Rotor'], [TYPE, TABLET]], [\n            /(shield[\\w ]+) b/i                                                 // Nvidia Shield Tablets\n            ], [MODEL, [VENDOR, 'Nvidia'], [TYPE, TABLET]], [\n            /(sprint) (\\w+)/i                                                   // Sprint Phones\n            ], [VENDOR, MODEL, [TYPE, MOBILE]], [\n            /(kin\\.[onetw]{3})/i                                                // Microsoft Kin\n            ], [[MODEL, /\\./g, ' '], [VENDOR, MICROSOFT], [TYPE, MOBILE]], [\n            /droid.+; (cc6666?|et5[16]|mc[239][23]x?|vc8[03]x?)\\)/i             // Zebra\n            ], [MODEL, [VENDOR, ZEBRA], [TYPE, TABLET]], [\n            /droid.+; (ec30|ps20|tc[2-8]\\d[kx])\\)/i\n            ], [MODEL, [VENDOR, ZEBRA], [TYPE, MOBILE]], [\n\n            ///////////////////\n            // SMARTTVS\n            ///////////////////\n\n            /smart-tv.+(samsung)/i                                              // Samsung\n            ], [VENDOR, [TYPE, SMARTTV]], [\n            /hbbtv.+maple;(\\d+)/i\n            ], [[MODEL, /^/, 'SmartTV'], [VENDOR, SAMSUNG], [TYPE, SMARTTV]], [\n            /(nux; netcast.+smarttv|lg (netcast\\.tv-201\\d|android tv))/i        // LG SmartTV\n            ], [[VENDOR, LG], [TYPE, SMARTTV]], [\n            /(apple) ?tv/i                                                      // Apple TV\n            ], [VENDOR, [MODEL, APPLE+' TV'], [TYPE, SMARTTV]], [\n            /crkey/i                                                            // Google Chromecast\n            ], [[MODEL, CHROME+'cast'], [VENDOR, GOOGLE], [TYPE, SMARTTV]], [\n            /droid.+aft(\\w+)( bui|\\))/i                                         // Fire TV\n            ], [MODEL, [VENDOR, AMAZON], [TYPE, SMARTTV]], [\n            /\\(dtv[\\);].+(aquos)/i,\n            /(aquos-tv[\\w ]+)\\)/i                                               // Sharp\n            ], [MODEL, [VENDOR, SHARP], [TYPE, SMARTTV]],[\n            /(bravia[\\w ]+)( bui|\\))/i                                              // Sony\n            ], [MODEL, [VENDOR, SONY], [TYPE, SMARTTV]], [\n            /(mitv-\\w{5}) bui/i                                                 // Xiaomi\n            ], [MODEL, [VENDOR, XIAOMI], [TYPE, SMARTTV]], [\n            /Hbbtv.*(technisat) (.*);/i                                         // TechniSAT\n            ], [VENDOR, MODEL, [TYPE, SMARTTV]], [\n            /\\b(roku)[\\dx]*[\\)\\/]((?:dvp-)?[\\d\\.]*)/i,                          // Roku\n            /hbbtv\\/\\d+\\.\\d+\\.\\d+ +\\([\\w\\+ ]*; *([\\w\\d][^;]*);([^;]*)/i         // HbbTV devices\n            ], [[VENDOR, trim], [MODEL, trim], [TYPE, SMARTTV]], [\n            /\\b(android tv|smart[- ]?tv|opera tv|tv; rv:)\\b/i                   // SmartTV from Unidentified Vendors\n            ], [[TYPE, SMARTTV]], [\n\n            ///////////////////\n            // CONSOLES\n            ///////////////////\n\n            /(ouya)/i,                                                          // Ouya\n            /(nintendo) ([wids3utch]+)/i                                        // Nintendo\n            ], [VENDOR, MODEL, [TYPE, CONSOLE]], [\n            /droid.+; (shield) bui/i                                            // Nvidia\n            ], [MODEL, [VENDOR, 'Nvidia'], [TYPE, CONSOLE]], [\n            /(playstation [345portablevi]+)/i                                   // Playstation\n            ], [MODEL, [VENDOR, SONY], [TYPE, CONSOLE]], [\n            /\\b(xbox(?: one)?(?!; xbox))[\\); ]/i                                // Microsoft Xbox\n            ], [MODEL, [VENDOR, MICROSOFT], [TYPE, CONSOLE]], [\n\n            ///////////////////\n            // WEARABLES\n            ///////////////////\n\n            /((pebble))app/i                                                    // Pebble\n            ], [VENDOR, MODEL, [TYPE, WEARABLE]], [\n            /(watch)(?: ?os[,\\/]|\\d,\\d\\/)[\\d\\.]+/i                              // Apple Watch\n            ], [MODEL, [VENDOR, APPLE], [TYPE, WEARABLE]], [\n            /droid.+; (glass) \\d/i                                              // Google Glass\n            ], [MODEL, [VENDOR, GOOGLE], [TYPE, WEARABLE]], [\n            /droid.+; (wt63?0{2,3})\\)/i\n            ], [MODEL, [VENDOR, ZEBRA], [TYPE, WEARABLE]], [\n            /(quest( \\d| pro)?)/i                                               // Oculus Quest\n            ], [MODEL, [VENDOR, FACEBOOK], [TYPE, WEARABLE]], [\n\n            ///////////////////\n            // EMBEDDED\n            ///////////////////\n\n            /(tesla)(?: qtcarbrowser|\\/[-\\w\\.]+)/i                              // Tesla\n            ], [VENDOR, [TYPE, EMBEDDED]], [\n            /(aeobc)\\b/i                                                        // Echo Dot\n            ], [MODEL, [VENDOR, AMAZON], [TYPE, EMBEDDED]], [\n\n            ////////////////////\n            // MIXED (GENERIC)\n            ///////////////////\n\n            /droid .+?; ([^;]+?)(?: bui|; wv\\)|\\) applew).+? mobile safari/i    // Android Phones from Unidentified Vendors\n            ], [MODEL, [TYPE, MOBILE]], [\n            /droid .+?; ([^;]+?)(?: bui|\\) applew).+?(?! mobile) safari/i       // Android Tablets from Unidentified Vendors\n            ], [MODEL, [TYPE, TABLET]], [\n            /\\b((tablet|tab)[;\\/]|focus\\/\\d(?!.+mobile))/i                      // Unidentifiable Tablet\n            ], [[TYPE, TABLET]], [\n            /(phone|mobile(?:[;\\/]| [ \\w\\/\\.]*safari)|pda(?=.+windows ce))/i    // Unidentifiable Mobile\n            ], [[TYPE, MOBILE]], [\n            /(android[-\\w\\. ]{0,9});.+buil/i                                    // Generic Android Device\n            ], [MODEL, [VENDOR, 'Generic']]\n        ],\n\n        engine : [[\n\n            /windows.+ edge\\/([\\w\\.]+)/i                                       // EdgeHTML\n            ], [VERSION, [NAME, EDGE+'HTML']], [\n\n            /webkit\\/537\\.36.+chrome\\/(?!27)([\\w\\.]+)/i                         // Blink\n            ], [VERSION, [NAME, 'Blink']], [\n\n            /(presto)\\/([\\w\\.]+)/i,                                             // Presto\n            /(webkit|trident|netfront|netsurf|amaya|lynx|w3m|goanna)\\/([\\w\\.]+)/i, // WebKit/Trident/NetFront/NetSurf/Amaya/Lynx/w3m/Goanna\n            /ekioh(flow)\\/([\\w\\.]+)/i,                                          // Flow\n            /(khtml|tasman|links)[\\/ ]\\(?([\\w\\.]+)/i,                           // KHTML/Tasman/Links\n            /(icab)[\\/ ]([23]\\.[\\d\\.]+)/i,                                      // iCab\n            /\\b(libweb)/i\n            ], [NAME, VERSION], [\n\n            /rv\\:([\\w\\.]{1,9})\\b.+(gecko)/i                                     // Gecko\n            ], [VERSION, NAME]\n        ],\n\n        os : [[\n\n            // Windows\n            /microsoft (windows) (vista|xp)/i                                   // Windows (iTunes)\n            ], [NAME, VERSION], [\n            /(windows (?:phone(?: os)?|mobile))[\\/ ]?([\\d\\.\\w ]*)/i             // Windows Phone\n            ], [NAME, [VERSION, strMapper, windowsVersionMap]], [\n            /windows nt 6\\.2; (arm)/i,                                        // Windows RT\n            /windows[\\/ ]?([ntce\\d\\. ]+\\w)(?!.+xbox)/i,\n            /(?:win(?=3|9|n)|win 9x )([nt\\d\\.]+)/i\n            ], [[VERSION, strMapper, windowsVersionMap], [NAME, 'Windows']], [\n\n            // iOS/macOS\n            /ip[honead]{2,4}\\b(?:.*os ([\\w]+) like mac|; opera)/i,              // iOS\n            /(?:ios;fbsv\\/|iphone.+ios[\\/ ])([\\d\\.]+)/i,\n            /cfnetwork\\/.+darwin/i\n            ], [[VERSION, /_/g, '.'], [NAME, 'iOS']], [\n            /(mac os x) ?([\\w\\. ]*)/i,\n            /(macintosh|mac_powerpc\\b)(?!.+haiku)/i                             // Mac OS\n            ], [[NAME, MAC_OS], [VERSION, /_/g, '.']], [\n\n            // Mobile OSes\n            /droid ([\\w\\.]+)\\b.+(android[- ]x86|harmonyos)/i                    // Android-x86/HarmonyOS\n            ], [VERSION, NAME], [                                               // Android/WebOS/QNX/Bada/RIM/Maemo/MeeGo/Sailfish OS\n            /(android|webos|qnx|bada|rim tablet os|maemo|meego|sailfish)[-\\/ ]?([\\w\\.]*)/i,\n            /(blackberry)\\w*\\/([\\w\\.]*)/i,                                      // Blackberry\n            /(tizen|kaios)[\\/ ]([\\w\\.]+)/i,                                     // Tizen/KaiOS\n            /\\((series40);/i                                                    // Series 40\n            ], [NAME, VERSION], [\n            /\\(bb(10);/i                                                        // BlackBerry 10\n            ], [VERSION, [NAME, BLACKBERRY]], [\n            /(?:symbian ?os|symbos|s60(?=;)|series60)[-\\/ ]?([\\w\\.]*)/i         // Symbian\n            ], [VERSION, [NAME, 'Symbian']], [\n            /mozilla\\/[\\d\\.]+ \\((?:mobile|tablet|tv|mobile; [\\w ]+); rv:.+ gecko\\/([\\w\\.]+)/i // Firefox OS\n            ], [VERSION, [NAME, FIREFOX+' OS']], [\n            /web0s;.+rt(tv)/i,\n            /\\b(?:hp)?wos(?:browser)?\\/([\\w\\.]+)/i                              // WebOS\n            ], [VERSION, [NAME, 'webOS']], [\n            /watch(?: ?os[,\\/]|\\d,\\d\\/)([\\d\\.]+)/i                              // watchOS\n            ], [VERSION, [NAME, 'watchOS']], [\n\n            // Google Chromecast\n            /crkey\\/([\\d\\.]+)/i                                                 // Google Chromecast\n            ], [VERSION, [NAME, CHROME+'cast']], [\n            /(cros) [\\w]+(?:\\)| ([\\w\\.]+)\\b)/i                                  // Chromium OS\n            ], [[NAME, CHROMIUM_OS], VERSION],[\n\n            // Smart TVs\n            /panasonic;(viera)/i,                                               // Panasonic Viera\n            /(netrange)mmh/i,                                                   // Netrange\n            /(nettv)\\/(\\d+\\.[\\w\\.]+)/i,                                         // NetTV\n\n            // Console\n            /(nintendo|playstation) ([wids345portablevuch]+)/i,                 // Nintendo/Playstation\n            /(xbox); +xbox ([^\\);]+)/i,                                         // Microsoft Xbox (360, One, X, S, Series X, Series S)\n\n            // Other\n            /\\b(joli|palm)\\b ?(?:os)?\\/?([\\w\\.]*)/i,                            // Joli/Palm\n            /(mint)[\\/\\(\\) ]?(\\w*)/i,                                           // Mint\n            /(mageia|vectorlinux)[; ]/i,                                        // Mageia/VectorLinux\n            /([kxln]?ubuntu|debian|suse|opensuse|gentoo|arch(?= linux)|slackware|fedora|mandriva|centos|pclinuxos|red ?hat|zenwalk|linpus|raspbian|plan 9|minix|risc os|contiki|deepin|manjaro|elementary os|sabayon|linspire)(?: gnu\\/linux)?(?: enterprise)?(?:[- ]linux)?(?:-gnu)?[-\\/ ]?(?!chrom|package)([-\\w\\.]*)/i,\n                                                                                // Ubuntu/Debian/SUSE/Gentoo/Arch/Slackware/Fedora/Mandriva/CentOS/PCLinuxOS/RedHat/Zenwalk/Linpus/Raspbian/Plan9/Minix/RISCOS/Contiki/Deepin/Manjaro/elementary/Sabayon/Linspire\n            /(hurd|linux) ?([\\w\\.]*)/i,                                         // Hurd/Linux\n            /(gnu) ?([\\w\\.]*)/i,                                                // GNU\n            /\\b([-frentopcghs]{0,5}bsd|dragonfly)[\\/ ]?(?!amd|[ix346]{1,2}86)([\\w\\.]*)/i, // FreeBSD/NetBSD/OpenBSD/PC-BSD/GhostBSD/DragonFly\n            /(haiku) (\\w+)/i                                                    // Haiku\n            ], [NAME, VERSION], [\n            /(sunos) ?([\\w\\.\\d]*)/i                                             // Solaris\n            ], [[NAME, 'Solaris'], VERSION], [\n            /((?:open)?solaris)[-\\/ ]?([\\w\\.]*)/i,                              // Solaris\n            /(aix) ((\\d)(?=\\.|\\)| )[\\w\\.])*/i,                                  // AIX\n            /\\b(beos|os\\/2|amigaos|morphos|openvms|fuchsia|hp-ux|serenityos)/i, // BeOS/OS2/AmigaOS/MorphOS/OpenVMS/Fuchsia/HP-UX/SerenityOS\n            /(unix) ?([\\w\\.]*)/i                                                // UNIX\n            ], [NAME, VERSION]\n        ]\n    };\n\n    /////////////////\n    // Constructor\n    ////////////////\n\n    var UAParser = function (ua, extensions) {\n\n        if (typeof ua === OBJ_TYPE) {\n            extensions = ua;\n            ua = undefined;\n        }\n\n        if (!(this instanceof UAParser)) {\n            return new UAParser(ua, extensions).getResult();\n        }\n\n        var _navigator = (typeof window !== UNDEF_TYPE && window.navigator) ? window.navigator : undefined;\n        var _ua = ua || ((_navigator && _navigator.userAgent) ? _navigator.userAgent : EMPTY);\n        var _uach = (_navigator && _navigator.userAgentData) ? _navigator.userAgentData : undefined;\n        var _rgxmap = extensions ? extend(regexes, extensions) : regexes;\n        var _isSelfNav = _navigator && _navigator.userAgent == _ua;\n\n        this.getBrowser = function () {\n            var _browser = {};\n            _browser[NAME] = undefined;\n            _browser[VERSION] = undefined;\n            rgxMapper.call(_browser, _ua, _rgxmap.browser);\n            _browser[MAJOR] = majorize(_browser[VERSION]);\n            // Brave-specific detection\n            if (_isSelfNav && _navigator && _navigator.brave && typeof _navigator.brave.isBrave == FUNC_TYPE) {\n                _browser[NAME] = 'Brave';\n            }\n            return _browser;\n        };\n        this.getCPU = function () {\n            var _cpu = {};\n            _cpu[ARCHITECTURE] = undefined;\n            rgxMapper.call(_cpu, _ua, _rgxmap.cpu);\n            return _cpu;\n        };\n        this.getDevice = function () {\n            var _device = {};\n            _device[VENDOR] = undefined;\n            _device[MODEL] = undefined;\n            _device[TYPE] = undefined;\n            rgxMapper.call(_device, _ua, _rgxmap.device);\n            if (_isSelfNav && !_device[TYPE] && _uach && _uach.mobile) {\n                _device[TYPE] = MOBILE;\n            }\n            // iPadOS-specific detection: identified as Mac, but has some iOS-only properties\n            if (_isSelfNav && _device[MODEL] == 'Macintosh' && _navigator && typeof _navigator.standalone !== UNDEF_TYPE && _navigator.maxTouchPoints && _navigator.maxTouchPoints > 2) {\n                _device[MODEL] = 'iPad';\n                _device[TYPE] = TABLET;\n            }\n            return _device;\n        };\n        this.getEngine = function () {\n            var _engine = {};\n            _engine[NAME] = undefined;\n            _engine[VERSION] = undefined;\n            rgxMapper.call(_engine, _ua, _rgxmap.engine);\n            return _engine;\n        };\n        this.getOS = function () {\n            var _os = {};\n            _os[NAME] = undefined;\n            _os[VERSION] = undefined;\n            rgxMapper.call(_os, _ua, _rgxmap.os);\n            if (_isSelfNav && !_os[NAME] && _uach && _uach.platform && _uach.platform != 'Unknown') {\n                _os[NAME] = _uach.platform  \n                                    .replace(/chrome os/i, CHROMIUM_OS)\n                                    .replace(/macos/i, MAC_OS);           // backward compatibility\n            }\n            return _os;\n        };\n        this.getResult = function () {\n            return {\n                ua      : this.getUA(),\n                browser : this.getBrowser(),\n                engine  : this.getEngine(),\n                os      : this.getOS(),\n                device  : this.getDevice(),\n                cpu     : this.getCPU()\n            };\n        };\n        this.getUA = function () {\n            return _ua;\n        };\n        this.setUA = function (ua) {\n            _ua = (typeof ua === STR_TYPE && ua.length > UA_MAX_LENGTH) ? trim(ua, UA_MAX_LENGTH) : ua;\n            return this;\n        };\n        this.setUA(_ua);\n        return this;\n    };\n\n    UAParser.VERSION = LIBVERSION;\n    UAParser.BROWSER =  enumerize([NAME, VERSION, MAJOR]);\n    UAParser.CPU = enumerize([ARCHITECTURE]);\n    UAParser.DEVICE = enumerize([MODEL, VENDOR, TYPE, CONSOLE, MOBILE, SMARTTV, TABLET, WEARABLE, EMBEDDED]);\n    UAParser.ENGINE = UAParser.OS = enumerize([NAME, VERSION]);\n\n    ///////////\n    // Export\n    //////////\n\n    // check js environment\n    if (typeof(exports) !== UNDEF_TYPE) {\n        // nodejs env\n        if (\"object\" !== UNDEF_TYPE && module.exports) {\n            exports = module.exports = UAParser;\n        }\n        exports.UAParser = UAParser;\n    } else {\n        // requirejs env (optional)\n        if (\"function\" === FUNC_TYPE && __webpack_require__.amdO) {\n            !(__WEBPACK_AMD_DEFINE_RESULT__ = (function () {\n                return UAParser;\n            }).call(exports, __webpack_require__, exports, module),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n        } else if (typeof window !== UNDEF_TYPE) {\n            // browser env\n            window.UAParser = UAParser;\n        }\n    }\n\n    // jQuery/Zepto specific (optional)\n    // Note:\n    //   In AMD env the global scope should be kept clean, but jQuery is an exception.\n    //   jQuery always exports to global scope, unless jQuery.noConflict(true) is used,\n    //   and we should catch that.\n    var $ = typeof window !== UNDEF_TYPE && (window.jQuery || window.Zepto);\n    if ($ && !$.ua) {\n        var parser = new UAParser();\n        $.ua = parser.getResult();\n        $.ua.get = function () {\n            return parser.getUA();\n        };\n        $.ua.set = function (ua) {\n            parser.setUA(ua);\n            var result = parser.getResult();\n            for (var prop in result) {\n                $.ua[prop] = result[prop];\n            }\n        };\n    }\n\n})(typeof window === 'object' ? window : this);\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/ua-parser-js/src/ua-parser.js?");

/***/ }),

/***/ "./node_modules/@socket.io/component-emitter/lib/esm/index.js":
/*!********************************************************************!*\
  !*** ./node_modules/@socket.io/component-emitter/lib/esm/index.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Emitter: () => (/* binding */ Emitter)\n/* harmony export */ });\n/**\n * Initialize a new `Emitter`.\n *\n * @api public\n */\n\nfunction Emitter(obj) {\n  if (obj) return mixin(obj);\n}\n\n/**\n * Mixin the emitter properties.\n *\n * @param {Object} obj\n * @return {Object}\n * @api private\n */\n\nfunction mixin(obj) {\n  for (var key in Emitter.prototype) {\n    obj[key] = Emitter.prototype[key];\n  }\n  return obj;\n}\n\n/**\n * Listen on the given `event` with `fn`.\n *\n * @param {String} event\n * @param {Function} fn\n * @return {Emitter}\n * @api public\n */\n\nEmitter.prototype.on =\nEmitter.prototype.addEventListener = function(event, fn){\n  this._callbacks = this._callbacks || {};\n  (this._callbacks['$' + event] = this._callbacks['$' + event] || [])\n    .push(fn);\n  return this;\n};\n\n/**\n * Adds an `event` listener that will be invoked a single\n * time then automatically removed.\n *\n * @param {String} event\n * @param {Function} fn\n * @return {Emitter}\n * @api public\n */\n\nEmitter.prototype.once = function(event, fn){\n  function on() {\n    this.off(event, on);\n    fn.apply(this, arguments);\n  }\n\n  on.fn = fn;\n  this.on(event, on);\n  return this;\n};\n\n/**\n * Remove the given callback for `event` or all\n * registered callbacks.\n *\n * @param {String} event\n * @param {Function} fn\n * @return {Emitter}\n * @api public\n */\n\nEmitter.prototype.off =\nEmitter.prototype.removeListener =\nEmitter.prototype.removeAllListeners =\nEmitter.prototype.removeEventListener = function(event, fn){\n  this._callbacks = this._callbacks || {};\n\n  // all\n  if (0 == arguments.length) {\n    this._callbacks = {};\n    return this;\n  }\n\n  // specific event\n  var callbacks = this._callbacks['$' + event];\n  if (!callbacks) return this;\n\n  // remove all handlers\n  if (1 == arguments.length) {\n    delete this._callbacks['$' + event];\n    return this;\n  }\n\n  // remove specific handler\n  var cb;\n  for (var i = 0; i < callbacks.length; i++) {\n    cb = callbacks[i];\n    if (cb === fn || cb.fn === fn) {\n      callbacks.splice(i, 1);\n      break;\n    }\n  }\n\n  // Remove event specific arrays for event types that no\n  // one is subscribed for to avoid memory leak.\n  if (callbacks.length === 0) {\n    delete this._callbacks['$' + event];\n  }\n\n  return this;\n};\n\n/**\n * Emit `event` with the given args.\n *\n * @param {String} event\n * @param {Mixed} ...\n * @return {Emitter}\n */\n\nEmitter.prototype.emit = function(event){\n  this._callbacks = this._callbacks || {};\n\n  var args = new Array(arguments.length - 1)\n    , callbacks = this._callbacks['$' + event];\n\n  for (var i = 1; i < arguments.length; i++) {\n    args[i - 1] = arguments[i];\n  }\n\n  if (callbacks) {\n    callbacks = callbacks.slice(0);\n    for (var i = 0, len = callbacks.length; i < len; ++i) {\n      callbacks[i].apply(this, args);\n    }\n  }\n\n  return this;\n};\n\n// alias used for reserved events (protected method)\nEmitter.prototype.emitReserved = Emitter.prototype.emit;\n\n/**\n * Return array of callbacks for `event`.\n *\n * @param {String} event\n * @return {Array}\n * @api public\n */\n\nEmitter.prototype.listeners = function(event){\n  this._callbacks = this._callbacks || {};\n  return this._callbacks['$' + event] || [];\n};\n\n/**\n * Check if this emitter has `event` handlers.\n *\n * @param {String} event\n * @return {Boolean}\n * @api public\n */\n\nEmitter.prototype.hasListeners = function(event){\n  return !! this.listeners(event).length;\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/@socket.io/component-emitter/lib/esm/index.js?");

/***/ }),

/***/ "./public/index.js":
/*!*************************!*\
  !*** ./public/index.js ***!
  \*************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var socket_io_client__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! socket.io-client */ \"./node_modules/socket.io-client/build/esm/index.js\");\n/* harmony import */ var mediasoup_client__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! mediasoup-client */ \"./node_modules/mediasoup-client/lib/index.js\");\n/* harmony import */ var hls_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! hls.js */ \"./node_modules/hls.js/dist/hls.mjs\");\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _regeneratorRuntime() { \"use strict\"; /*! regenerator-runtime -- Copyright (c) 2014-present, Facebook, Inc. -- license (MIT): https://github.com/facebook/regenerator/blob/main/LICENSE */ _regeneratorRuntime = function _regeneratorRuntime() { return e; }; var t, e = {}, r = Object.prototype, n = r.hasOwnProperty, o = Object.defineProperty || function (t, e, r) { t[e] = r.value; }, i = \"function\" == typeof Symbol ? Symbol : {}, a = i.iterator || \"@@iterator\", c = i.asyncIterator || \"@@asyncIterator\", u = i.toStringTag || \"@@toStringTag\"; function define(t, e, r) { return Object.defineProperty(t, e, { value: r, enumerable: !0, configurable: !0, writable: !0 }), t[e]; } try { define({}, \"\"); } catch (t) { define = function define(t, e, r) { return t[e] = r; }; } function wrap(t, e, r, n) { var i = e && e.prototype instanceof Generator ? e : Generator, a = Object.create(i.prototype), c = new Context(n || []); return o(a, \"_invoke\", { value: makeInvokeMethod(t, r, c) }), a; } function tryCatch(t, e, r) { try { return { type: \"normal\", arg: t.call(e, r) }; } catch (t) { return { type: \"throw\", arg: t }; } } e.wrap = wrap; var h = \"suspendedStart\", l = \"suspendedYield\", f = \"executing\", s = \"completed\", y = {}; function Generator() {} function GeneratorFunction() {} function GeneratorFunctionPrototype() {} var p = {}; define(p, a, function () { return this; }); var d = Object.getPrototypeOf, v = d && d(d(values([]))); v && v !== r && n.call(v, a) && (p = v); var g = GeneratorFunctionPrototype.prototype = Generator.prototype = Object.create(p); function defineIteratorMethods(t) { [\"next\", \"throw\", \"return\"].forEach(function (e) { define(t, e, function (t) { return this._invoke(e, t); }); }); } function AsyncIterator(t, e) { function invoke(r, o, i, a) { var c = tryCatch(t[r], t, o); if (\"throw\" !== c.type) { var u = c.arg, h = u.value; return h && \"object\" == _typeof(h) && n.call(h, \"__await\") ? e.resolve(h.__await).then(function (t) { invoke(\"next\", t, i, a); }, function (t) { invoke(\"throw\", t, i, a); }) : e.resolve(h).then(function (t) { u.value = t, i(u); }, function (t) { return invoke(\"throw\", t, i, a); }); } a(c.arg); } var r; o(this, \"_invoke\", { value: function value(t, n) { function callInvokeWithMethodAndArg() { return new e(function (e, r) { invoke(t, n, e, r); }); } return r = r ? r.then(callInvokeWithMethodAndArg, callInvokeWithMethodAndArg) : callInvokeWithMethodAndArg(); } }); } function makeInvokeMethod(e, r, n) { var o = h; return function (i, a) { if (o === f) throw Error(\"Generator is already running\"); if (o === s) { if (\"throw\" === i) throw a; return { value: t, done: !0 }; } for (n.method = i, n.arg = a;;) { var c = n.delegate; if (c) { var u = maybeInvokeDelegate(c, n); if (u) { if (u === y) continue; return u; } } if (\"next\" === n.method) n.sent = n._sent = n.arg;else if (\"throw\" === n.method) { if (o === h) throw o = s, n.arg; n.dispatchException(n.arg); } else \"return\" === n.method && n.abrupt(\"return\", n.arg); o = f; var p = tryCatch(e, r, n); if (\"normal\" === p.type) { if (o = n.done ? s : l, p.arg === y) continue; return { value: p.arg, done: n.done }; } \"throw\" === p.type && (o = s, n.method = \"throw\", n.arg = p.arg); } }; } function maybeInvokeDelegate(e, r) { var n = r.method, o = e.iterator[n]; if (o === t) return r.delegate = null, \"throw\" === n && e.iterator[\"return\"] && (r.method = \"return\", r.arg = t, maybeInvokeDelegate(e, r), \"throw\" === r.method) || \"return\" !== n && (r.method = \"throw\", r.arg = new TypeError(\"The iterator does not provide a '\" + n + \"' method\")), y; var i = tryCatch(o, e.iterator, r.arg); if (\"throw\" === i.type) return r.method = \"throw\", r.arg = i.arg, r.delegate = null, y; var a = i.arg; return a ? a.done ? (r[e.resultName] = a.value, r.next = e.nextLoc, \"return\" !== r.method && (r.method = \"next\", r.arg = t), r.delegate = null, y) : a : (r.method = \"throw\", r.arg = new TypeError(\"iterator result is not an object\"), r.delegate = null, y); } function pushTryEntry(t) { var e = { tryLoc: t[0] }; 1 in t && (e.catchLoc = t[1]), 2 in t && (e.finallyLoc = t[2], e.afterLoc = t[3]), this.tryEntries.push(e); } function resetTryEntry(t) { var e = t.completion || {}; e.type = \"normal\", delete e.arg, t.completion = e; } function Context(t) { this.tryEntries = [{ tryLoc: \"root\" }], t.forEach(pushTryEntry, this), this.reset(!0); } function values(e) { if (e || \"\" === e) { var r = e[a]; if (r) return r.call(e); if (\"function\" == typeof e.next) return e; if (!isNaN(e.length)) { var o = -1, i = function next() { for (; ++o < e.length;) if (n.call(e, o)) return next.value = e[o], next.done = !1, next; return next.value = t, next.done = !0, next; }; return i.next = i; } } throw new TypeError(_typeof(e) + \" is not iterable\"); } return GeneratorFunction.prototype = GeneratorFunctionPrototype, o(g, \"constructor\", { value: GeneratorFunctionPrototype, configurable: !0 }), o(GeneratorFunctionPrototype, \"constructor\", { value: GeneratorFunction, configurable: !0 }), GeneratorFunction.displayName = define(GeneratorFunctionPrototype, u, \"GeneratorFunction\"), e.isGeneratorFunction = function (t) { var e = \"function\" == typeof t && t.constructor; return !!e && (e === GeneratorFunction || \"GeneratorFunction\" === (e.displayName || e.name)); }, e.mark = function (t) { return Object.setPrototypeOf ? Object.setPrototypeOf(t, GeneratorFunctionPrototype) : (t.__proto__ = GeneratorFunctionPrototype, define(t, u, \"GeneratorFunction\")), t.prototype = Object.create(g), t; }, e.awrap = function (t) { return { __await: t }; }, defineIteratorMethods(AsyncIterator.prototype), define(AsyncIterator.prototype, c, function () { return this; }), e.AsyncIterator = AsyncIterator, e.async = function (t, r, n, o, i) { void 0 === i && (i = Promise); var a = new AsyncIterator(wrap(t, r, n, o), i); return e.isGeneratorFunction(r) ? a : a.next().then(function (t) { return t.done ? t.value : a.next(); }); }, defineIteratorMethods(g), define(g, u, \"Generator\"), define(g, a, function () { return this; }), define(g, \"toString\", function () { return \"[object Generator]\"; }), e.keys = function (t) { var e = Object(t), r = []; for (var n in e) r.push(n); return r.reverse(), function next() { for (; r.length;) { var t = r.pop(); if (t in e) return next.value = t, next.done = !1, next; } return next.done = !0, next; }; }, e.values = values, Context.prototype = { constructor: Context, reset: function reset(e) { if (this.prev = 0, this.next = 0, this.sent = this._sent = t, this.done = !1, this.delegate = null, this.method = \"next\", this.arg = t, this.tryEntries.forEach(resetTryEntry), !e) for (var r in this) \"t\" === r.charAt(0) && n.call(this, r) && !isNaN(+r.slice(1)) && (this[r] = t); }, stop: function stop() { this.done = !0; var t = this.tryEntries[0].completion; if (\"throw\" === t.type) throw t.arg; return this.rval; }, dispatchException: function dispatchException(e) { if (this.done) throw e; var r = this; function handle(n, o) { return a.type = \"throw\", a.arg = e, r.next = n, o && (r.method = \"next\", r.arg = t), !!o; } for (var o = this.tryEntries.length - 1; o >= 0; --o) { var i = this.tryEntries[o], a = i.completion; if (\"root\" === i.tryLoc) return handle(\"end\"); if (i.tryLoc <= this.prev) { var c = n.call(i, \"catchLoc\"), u = n.call(i, \"finallyLoc\"); if (c && u) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } else if (c) { if (this.prev < i.catchLoc) return handle(i.catchLoc, !0); } else { if (!u) throw Error(\"try statement without catch or finally\"); if (this.prev < i.finallyLoc) return handle(i.finallyLoc); } } } }, abrupt: function abrupt(t, e) { for (var r = this.tryEntries.length - 1; r >= 0; --r) { var o = this.tryEntries[r]; if (o.tryLoc <= this.prev && n.call(o, \"finallyLoc\") && this.prev < o.finallyLoc) { var i = o; break; } } i && (\"break\" === t || \"continue\" === t) && i.tryLoc <= e && e <= i.finallyLoc && (i = null); var a = i ? i.completion : {}; return a.type = t, a.arg = e, i ? (this.method = \"next\", this.next = i.finallyLoc, y) : this.complete(a); }, complete: function complete(t, e) { if (\"throw\" === t.type) throw t.arg; return \"break\" === t.type || \"continue\" === t.type ? this.next = t.arg : \"return\" === t.type ? (this.rval = this.arg = t.arg, this.method = \"return\", this.next = \"end\") : \"normal\" === t.type && e && (this.next = e), y; }, finish: function finish(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.finallyLoc === t) return this.complete(r.completion, r.afterLoc), resetTryEntry(r), y; } }, \"catch\": function _catch(t) { for (var e = this.tryEntries.length - 1; e >= 0; --e) { var r = this.tryEntries[e]; if (r.tryLoc === t) { var n = r.completion; if (\"throw\" === n.type) { var o = n.arg; resetTryEntry(r); } return o; } } throw Error(\"illegal catch attempt\"); }, delegateYield: function delegateYield(e, r, n) { return this.delegate = { iterator: values(e), resultName: r, nextLoc: n }, \"next\" === this.method && (this.arg = t), y; } }, e; }\nfunction ownKeys(e, r) { var t = Object.keys(e); if (Object.getOwnPropertySymbols) { var o = Object.getOwnPropertySymbols(e); r && (o = o.filter(function (r) { return Object.getOwnPropertyDescriptor(e, r).enumerable; })), t.push.apply(t, o); } return t; }\nfunction _objectSpread(e) { for (var r = 1; r < arguments.length; r++) { var t = null != arguments[r] ? arguments[r] : {}; r % 2 ? ownKeys(Object(t), !0).forEach(function (r) { _defineProperty(e, r, t[r]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) { Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r)); }); } return e; }\nfunction _defineProperty(e, r, t) { return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, { value: t, enumerable: !0, configurable: !0, writable: !0 }) : e[r] = t, e; }\nfunction _toPropertyKey(t) { var i = _toPrimitive(t, \"string\"); return \"symbol\" == _typeof(i) ? i : i + \"\"; }\nfunction _toPrimitive(t, r) { if (\"object\" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || \"default\"); if (\"object\" != _typeof(i)) return i; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (\"string\" === r ? String : Number)(t); }\nfunction asyncGeneratorStep(n, t, e, r, o, a, c) { try { var i = n[a](c), u = i.value; } catch (n) { return void e(n); } i.done ? t(u) : Promise.resolve(u).then(r, o); }\nfunction _asyncToGenerator(n) { return function () { var t = this, e = arguments; return new Promise(function (r, o) { var a = n.apply(t, e); function _next(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"next\", n); } function _throw(n) { asyncGeneratorStep(a, r, o, _next, _throw, \"throw\", n); } _next(void 0); }); }; }\n\n\n\nvar roomName = window.location.pathname.split('/')[2];\nvar socket = (0,socket_io_client__WEBPACK_IMPORTED_MODULE_0__[\"default\"])('/mediasoup');\nvar device;\nvar rtpCapabilities;\nvar producerTransport;\nvar consumerTransports = [];\nvar audioProducer;\nvar videoProducer;\nvar consumingTransports = [];\nvar hlsPlayer;\nvar isMobile = function isMobile() {\n  return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);\n};\nvar params = {\n  encodings: isMobile() ? [{\n    rid: 'r0',\n    maxBitrate: 50000,\n    scalabilityMode: 'L1T1'\n  }, {\n    rid: 'r1',\n    maxBitrate: 150000,\n    scalabilityMode: 'L1T1'\n  }] : [{\n    rid: 'r0',\n    maxBitrate: 100000,\n    scalabilityMode: 'S1T3'\n  }, {\n    rid: 'r1',\n    maxBitrate: 300000,\n    scalabilityMode: 'S1T3'\n  }, {\n    rid: 'r2',\n    maxBitrate: 900000,\n    scalabilityMode: 'S1T3'\n  }],\n  codecOptions: {\n    videoGoogleStartBitrate: isMobile() ? 500 : 1000\n  }\n};\nvar videoParams = {\n  params: params\n};\nvar audioParams;\nsocket.on('connections-success', function (_ref) {\n  var socketId = _ref.socketId;\n  console.log(\"SocketId: \".concat(socketId));\n});\nvar streamSuccess = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(stream) {\n    return _regeneratorRuntime().wrap(function _callee$(_context) {\n      while (1) switch (_context.prev = _context.next) {\n        case 0:\n          localVideo.srcObject = stream;\n          audioParams = _objectSpread({\n            track: stream.getAudioTracks()[0]\n          }, audioParams);\n          videoParams = _objectSpread({\n            track: stream.getVideoTracks()[0]\n          }, videoParams);\n          console.log(audioParams, videoParams);\n          joinRoom();\n        case 5:\n        case \"end\":\n          return _context.stop();\n      }\n    }, _callee);\n  }));\n  return function streamSuccess(_x) {\n    return _ref2.apply(this, arguments);\n  };\n}();\nvar loadFile = /*#__PURE__*/function () {\n  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2() {\n    var file, url, fileStream;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) switch (_context2.prev = _context2.next) {\n        case 0:\n          file = fileInput.files[0];\n          if (file) {\n            _context2.next = 4;\n            break;\n          }\n          console.error('No File selected');\n          return _context2.abrupt(\"return\");\n        case 4:\n          url = URL.createObjectURL(file);\n          localVideo.src = url;\n          _context2.next = 8;\n          return localVideo.play();\n        case 8:\n          fileStream = localVideo.captureStream();\n          console.log(fileStream);\n          if (fileStream) {\n            audioParams = _objectSpread({\n              track: fileStream.getAudioTracks()[0]\n            }, audioParams);\n            videoParams = _objectSpread({\n              track: fileStream.getVideoTracks()[0]\n            }, videoParams);\n            console.log(audioParams, videoParams);\n            joinRoom();\n          } else {\n            console.error('No File selected');\n          }\n        case 11:\n        case \"end\":\n          return _context2.stop();\n      }\n    }, _callee2);\n  }));\n  return function loadFile() {\n    return _ref3.apply(this, arguments);\n  };\n}();\n\n// RTSP URL  \nvar extractStreamName = function extractStreamName(rtspUrl) {\n  var match = rtspUrl.match(/\\/(\\w+)\\.stream$/);\n  if (match && match.length > 1) {\n    return match[1];\n  }\n  return null;\n};\nvar loadRTSP = /*#__PURE__*/function () {\n  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3() {\n    var rtspUrl, streamName;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) switch (_context3.prev = _context3.next) {\n        case 0:\n          rtspUrl = document.getElementById('rtspUrlInput').value;\n          if (rtspUrl) {\n            _context3.next = 4;\n            break;\n          }\n          console.error('RTSP URL not found');\n          return _context3.abrupt(\"return\");\n        case 4:\n          console.log(rtspUrl);\n          streamName = extractStreamName(rtspUrl);\n          console.log(\"Stream Name: \".concat(streamName));\n          if (streamName) {\n            _context3.next = 10;\n            break;\n          }\n          console.error('Failed to extract stream name from RTSP URL');\n          return _context3.abrupt(\"return\");\n        case 10:\n          socket.emit('loadRTSP', {\n            rtspUrl: rtspUrl,\n            streamName: streamName\n          }, function (response) {\n            console.log('RTSP load callback received', response);\n            setupHls(streamName);\n          });\n        case 11:\n        case \"end\":\n          return _context3.stop();\n      }\n    }, _callee3);\n  }));\n  return function loadRTSP() {\n    return _ref4.apply(this, arguments);\n  };\n}();\nvar setupHls = function setupHls(streamName) {\n  var videoElement = document.getElementById('localVideo');\n  if (hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].isSupported()) {\n    if (hlsPlayer) {\n      hlsPlayer.destroy();\n      hlsPlayer = null;\n    }\n    hlsPlayer = new hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"]({\n      liveSyncDuration: 10,\n      //   \n      maxBufferLength: 30,\n      //  \n      maxMaxBufferLength: 60,\n      //    \n      lowLatencyMode: true\n    });\n\n    // hlsPlayer.loadSource(`https://192.168.0.9:3100/broadcast/${roomName}/files/${streamName}/playlist.m3u8`);\n    hlsPlayer.loadSource(\"https://127.0.0.1:3000/broadcast/\".concat(roomName, \"/files/\").concat(streamName, \"/playlist.m3u8\"));\n    hlsPlayer.attachMedia(videoElement);\n    hlsPlayer.on(hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].Events.MANIFEST_PARSED, function () {\n      videoElement.play()[\"catch\"](function (error) {\n        return console.log('Failed to play video: ', error);\n      });\n    });\n    hlsPlayer.on(hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].Events.FRAG_LOADING, function (event, data) {\n      var fileStream = videoElement.captureStream();\n      console.log('HLS stream:', fileStream);\n      var audioTrack = fileStream.getAudioTracks()[0];\n      var videoTrack = fileStream.getVideoTracks()[0];\n      audioParams = audioTrack ? _objectSpread({\n        track: audioTrack\n      }, audioParams) : null;\n      videoParams = videoTrack ? _objectSpread({\n        track: videoTrack\n      }, videoParams) : null;\n      console.log(\"HLS Video Params: \", videoParams);\n      console.log(\"HLS Audio Params: \", audioParams);\n    });\n    hlsPlayer.on(hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].Events.ERROR, function (event, data) {\n      if (data.fatal) {\n        switch (data.type) {\n          case hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].ErrorTypes.NETWORK_ERROR:\n            console.error('Network error encountered:', data);\n            hlsPlayer.startLoad();\n            break;\n          case hls_js__WEBPACK_IMPORTED_MODULE_2__[\"default\"].ErrorTypes.MEDIA_ERROR:\n            console.error('Media error encountered:', data);\n            hlsPlayer.recoverMediaError();\n            break;\n          default:\n            console.error('An unrecoverable error occurred:', data);\n            hlsPlayer.destroy();\n            break;\n        }\n      }\n    });\n  } else if (videoElement.canPlayType('application/vnd.apple.mpegurl')) {\n    // videoElement.src =`https://192.168.0.9:3100/broadcast/${roomName}/files/${streamName}/playlist.m3u8`;\n    videoElement.src = \"https://127.0.0.1:3000/broadcast/\".concat(roomName, \"/files/\").concat(streamName, \"/playlist.m3u8\");\n    videoElement.addEventListener('canplay', /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee4() {\n      return _regeneratorRuntime().wrap(function _callee4$(_context4) {\n        while (1) switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return videoElement.play()[\"catch\"](function (error) {\n              return console.error('Error attempting to play:', error);\n            });\n          case 2:\n          case \"end\":\n            return _context4.stop();\n        }\n      }, _callee4);\n    })));\n  }\n};\nvar publishRTSP = function publishRTSP() {\n  joinRoom();\n};\nvar joinRoom = /*#__PURE__*/function () {\n  var _ref6 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee5() {\n    return _regeneratorRuntime().wrap(function _callee5$(_context5) {\n      while (1) switch (_context5.prev = _context5.next) {\n        case 0:\n          socket.emit('joinRoom', {\n            roomName: roomName\n          }, function (data) {\n            console.log(\"Router RTP Capabilities: \".concat(data.rtpCapabilities));\n            rtpCapabilities = data.rtpCapabilities;\n            createDevice();\n          });\n        case 1:\n        case \"end\":\n          return _context5.stop();\n      }\n    }, _callee5);\n  }));\n  return function joinRoom() {\n    return _ref6.apply(this, arguments);\n  };\n}();\nvar getLocalStream = function getLocalStream() {\n  navigator.mediaDevices.getUserMedia({\n    audio: true,\n    video: {\n      width: {\n        min: 640,\n        ideal: 1280,\n        max: 1920\n      },\n      height: {\n        min: 400,\n        ideal: 720,\n        max: 1090\n      }\n    }\n  }).then(streamSuccess)[\"catch\"](function (error) {\n    return console.error('Error getting user media:', error);\n  });\n};\nvar createDevice = /*#__PURE__*/function () {\n  var _ref7 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee6() {\n    return _regeneratorRuntime().wrap(function _callee6$(_context6) {\n      while (1) switch (_context6.prev = _context6.next) {\n        case 0:\n          _context6.prev = 0;\n          device = new mediasoup_client__WEBPACK_IMPORTED_MODULE_1__.Device();\n          _context6.next = 4;\n          return device.load({\n            routerRtpCapabilities: rtpCapabilities\n          });\n        case 4:\n          console.log('Device RTP Capabilities', device.rtpCapabilities);\n          createSendTransport();\n          _context6.next = 12;\n          break;\n        case 8:\n          _context6.prev = 8;\n          _context6.t0 = _context6[\"catch\"](0);\n          console.log(_context6.t0);\n          if (_context6.t0.name === 'UnsuppportedError') {\n            console.warn('browser not supported');\n          }\n        case 12:\n        case \"end\":\n          return _context6.stop();\n      }\n    }, _callee6, null, [[0, 8]]);\n  }));\n  return function createDevice() {\n    return _ref7.apply(this, arguments);\n  };\n}();\nvar createSendTransport = function createSendTransport() {\n  socket.emit('createWebRtcTransport', {\n    consumer: false\n  }, function (_ref8) {\n    var params = _ref8.params;\n    if (params.error) {\n      console.log(params.error);\n      return;\n    }\n    console.log('createWebRTCTransport:', params);\n    producerTransport = device.createSendTransport(_objectSpread(_objectSpread({}, params), {}, {\n      iceServers: isMobile() ? iceServers : [],\n      enableUdp: true,\n      enableTcp: true,\n      preferUdp: isMobile()\n    }));\n    producerTransport.on('connect', /*#__PURE__*/function () {\n      var _ref10 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee7(_ref9, callback, errback) {\n        var dtlsParameters;\n        return _regeneratorRuntime().wrap(function _callee7$(_context7) {\n          while (1) switch (_context7.prev = _context7.next) {\n            case 0:\n              dtlsParameters = _ref9.dtlsParameters;\n              _context7.prev = 1;\n              _context7.next = 4;\n              return socket.emit('transport-connect', {\n                dtlsParameters: dtlsParameters\n              });\n            case 4:\n              callback();\n              _context7.next = 10;\n              break;\n            case 7:\n              _context7.prev = 7;\n              _context7.t0 = _context7[\"catch\"](1);\n              errback(_context7.t0);\n            case 10:\n            case \"end\":\n              return _context7.stop();\n          }\n        }, _callee7, null, [[1, 7]]);\n      }));\n      return function (_x2, _x3, _x4) {\n        return _ref10.apply(this, arguments);\n      };\n    }());\n    producerTransport.on('icecandidate', function (event) {\n      if (event.candidate) {\n        console.log('New ICE candidate', event.candidate);\n      } else {\n        console.log('All ICE candidate have been gathered');\n      }\n    });\n    producerTransport.on('produce', /*#__PURE__*/function () {\n      var _ref11 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee8(parameters, callback, errback) {\n        return _regeneratorRuntime().wrap(function _callee8$(_context8) {\n          while (1) switch (_context8.prev = _context8.next) {\n            case 0:\n              _context8.prev = 0;\n              _context8.next = 3;\n              return socket.emit('transport-produce', {\n                kind: parameters.kind,\n                rtpParameters: parameters.rtpParameters,\n                appData: parameters.appData\n              }, function (_ref12) {\n                var id = _ref12.id,\n                  producersExist = _ref12.producersExist;\n                callback({\n                  id: id\n                });\n                if (producersExist) getProducers();\n              });\n            case 3:\n              _context8.next = 8;\n              break;\n            case 5:\n              _context8.prev = 5;\n              _context8.t0 = _context8[\"catch\"](0);\n              errback(_context8.t0);\n            case 8:\n            case \"end\":\n              return _context8.stop();\n          }\n        }, _callee8, null, [[0, 5]]);\n      }));\n      return function (_x5, _x6, _x7) {\n        return _ref11.apply(this, arguments);\n      };\n    }());\n    connectSendTransport();\n  });\n};\nvar connectSendTransport = /*#__PURE__*/function () {\n  var _ref13 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee9() {\n    return _regeneratorRuntime().wrap(function _callee9$(_context9) {\n      while (1) switch (_context9.prev = _context9.next) {\n        case 0:\n          if (!audioParams) {\n            _context9.next = 6;\n            break;\n          }\n          _context9.next = 3;\n          return producerTransport.produce(audioParams);\n        case 3:\n          _context9.t0 = _context9.sent;\n          _context9.next = 7;\n          break;\n        case 6:\n          _context9.t0 = null;\n        case 7:\n          audioProducer = _context9.t0;\n          _context9.next = 10;\n          return producerTransport.produce(videoParams);\n        case 10:\n          videoProducer = _context9.sent;\n          console.log('audioProducer', audioProducer);\n          console.log('videoProducer', videoProducer);\n          if (audioProducer) {\n            audioProducer.on('trackended', function () {\n              return console.log('audio track ended');\n            });\n            audioProducer.on('transportclose', function () {\n              return console.log('audio producer closed');\n            });\n          }\n          videoProducer.on('trackended', function () {\n            return console.log('video track ended');\n          });\n          videoProducer.on('transportclose', function () {\n            return console.log('video producer closed');\n          });\n        case 16:\n        case \"end\":\n          return _context9.stop();\n      }\n    }, _callee9);\n  }));\n  return function connectSendTransport() {\n    return _ref13.apply(this, arguments);\n  };\n}();\nvar signalNewConsumerTransport = /*#__PURE__*/function () {\n  var _ref14 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee11(remoteProducerId) {\n    return _regeneratorRuntime().wrap(function _callee11$(_context11) {\n      while (1) switch (_context11.prev = _context11.next) {\n        case 0:\n          if (!consumingTransports.includes(remoteProducerId)) {\n            _context11.next = 2;\n            break;\n          }\n          return _context11.abrupt(\"return\");\n        case 2:\n          consumingTransports.push(remoteProducerId);\n          _context11.next = 5;\n          return socket.emit('createWebRtcTransport', {\n            consumer: true\n          }, function (_ref15) {\n            var params = _ref15.params;\n            if (params.error) {\n              console.log(params.error);\n              return;\n            }\n            console.log(\"PARAMS: \".concat(params));\n            var consumerTransport;\n            try {\n              consumerTransport = device.createRecvTransport(_objectSpread(_objectSpread({}, params), {}, {\n                iceServers: isMobile() ? iceServers : [],\n                enableUdp: true,\n                enableTcp: true,\n                preferUdp: isMobile()\n              }));\n            } catch (error) {\n              console.log(error);\n              return;\n            }\n            consumerTransport.on('connect', /*#__PURE__*/function () {\n              var _ref17 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee10(_ref16, callback, errback) {\n                var dtlsParameters;\n                return _regeneratorRuntime().wrap(function _callee10$(_context10) {\n                  while (1) switch (_context10.prev = _context10.next) {\n                    case 0:\n                      dtlsParameters = _ref16.dtlsParameters;\n                      _context10.prev = 1;\n                      _context10.next = 4;\n                      return socket.emit('transport-recv-connect', {\n                        dtlsParameters: dtlsParameters,\n                        serverConsumerTransportId: params.id\n                      });\n                    case 4:\n                      callback();\n                      _context10.next = 10;\n                      break;\n                    case 7:\n                      _context10.prev = 7;\n                      _context10.t0 = _context10[\"catch\"](1);\n                      errback(_context10.t0);\n                    case 10:\n                    case \"end\":\n                      return _context10.stop();\n                  }\n                }, _callee10, null, [[1, 7]]);\n              }));\n              return function (_x9, _x10, _x11) {\n                return _ref17.apply(this, arguments);\n              };\n            }());\n            connectRecvTransport(consumerTransport, remoteProducerId, params.id);\n          });\n        case 5:\n        case \"end\":\n          return _context11.stop();\n      }\n    }, _callee11);\n  }));\n  return function signalNewConsumerTransport(_x8) {\n    return _ref14.apply(this, arguments);\n  };\n}();\nvar connectRecvTransport = /*#__PURE__*/function () {\n  var _ref18 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee13(consumerTransport, remoteProducerId, serverConsumerTransportId) {\n    return _regeneratorRuntime().wrap(function _callee13$(_context13) {\n      while (1) switch (_context13.prev = _context13.next) {\n        case 0:\n          _context13.next = 2;\n          return socket.emit('consume', {\n            rtpCapabilities: device.rtpCapabilities,\n            remoteProducerId: remoteProducerId,\n            serverConsumerTransportId: serverConsumerTransportId\n          }, /*#__PURE__*/function () {\n            var _ref20 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee12(_ref19) {\n              var params, consumer, newElem;\n              return _regeneratorRuntime().wrap(function _callee12$(_context12) {\n                while (1) switch (_context12.prev = _context12.next) {\n                  case 0:\n                    params = _ref19.params;\n                    if (!params.error) {\n                      _context12.next = 5;\n                      break;\n                    }\n                    console.log(params.error);\n                    console.log('Cannot Consume');\n                    return _context12.abrupt(\"return\");\n                  case 5:\n                    console.log(\"consumerParams: \".concat(params));\n                    _context12.next = 8;\n                    return consumerTransport.consume({\n                      id: params.id,\n                      producerId: params.producerId,\n                      kind: params.kind,\n                      rtpParameters: params.rtpParameters\n                    });\n                  case 8:\n                    consumer = _context12.sent;\n                    consumerTransports.push({\n                      consumerTransport: consumerTransport,\n                      serverConsumerTransportId: params.id,\n                      producerId: remoteProducerId,\n                      consumer: consumer\n                    });\n                    newElem = document.createElement('div');\n                    newElem.setAttribute('id', \"td-\".concat(remoteProducerId));\n                    if (params.kind === 'audio') {\n                      newElem.innerHTML = \"<audio id=\\\"\".concat(remoteProducerId, \"\\\" autoplay></audio>\");\n                    } else {\n                      newElem.setAttribute('class', 'remoteVideo');\n                      newElem.innerHTML = \"<video id=\\\"\".concat(remoteProducerId, \"\\\" autoplay class=\\\"video\\\"></video>\");\n                    }\n                    videoContainer.appendChild(newElem);\n                    document.getElementById(remoteProducerId).srcObject = new MediaStream([consumer.track]);\n                    socket.emit('consumer-resume', {\n                      serverConsumerId: params.serverConsumerId\n                    });\n                  case 16:\n                  case \"end\":\n                    return _context12.stop();\n                }\n              }, _callee12);\n            }));\n            return function (_x15) {\n              return _ref20.apply(this, arguments);\n            };\n          }());\n        case 2:\n        case \"end\":\n          return _context13.stop();\n      }\n    }, _callee13);\n  }));\n  return function connectRecvTransport(_x12, _x13, _x14) {\n    return _ref18.apply(this, arguments);\n  };\n}();\nvar getProducers = function getProducers() {\n  socket.emit('getProducers', function (producerIds) {\n    producerIds.forEach(signalNewConsumerTransport);\n  });\n};\nsocket.on('new-producer', function (_ref21) {\n  var producerId = _ref21.producerId;\n  return signalNewConsumerTransport(producerId);\n});\nsocket.on('producer-closed', function (_ref22) {\n  var remoteProducerId = _ref22.remoteProducerId;\n  var producerToClose = consumerTransports.find(function (transportData) {\n    return transportData.producerId === remoteProducerId;\n  });\n  producerToClose.consumerTransport.close();\n  producerToClose.consumer.close();\n  consumerTransports = consumerTransports.filter(function (transportData) {\n    return transportData.producerId !== remoteProducerId;\n  });\n  videoContainer.removeChild(document.getElementById(\"td-\".concat(remoteProducerId)));\n});\nvar addEventListeners = function addEventListeners() {\n  btnLocalVideo.addEventListener('click', getLocalStream);\n  btnLoadFile.addEventListener('click', loadFile);\n  btnPublishRTSP.addEventListener('click', publishRTSP);\n  btnLoadRTSP.addEventListener('click', loadRTSP);\n};\ndocument.addEventListener('DOMContentLoaded', addEventListeners);\n\n//# sourceURL=webpack://mediasoup-nodejs/./public/index.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/contrib/has-cors.js":
/*!*********************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/contrib/has-cors.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   hasCORS: () => (/* binding */ hasCORS)\n/* harmony export */ });\n// imported from https://github.com/component/has-cors\nlet value = false;\ntry {\n    value = typeof XMLHttpRequest !== 'undefined' &&\n        'withCredentials' in new XMLHttpRequest();\n}\ncatch (err) {\n    // if XMLHttp support is disabled in IE then it will throw\n    // when trying to create\n}\nconst hasCORS = value;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/contrib/has-cors.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/contrib/parseqs.js":
/*!********************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/contrib/parseqs.js ***!
  \********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   encode: () => (/* binding */ encode)\n/* harmony export */ });\n// imported from https://github.com/galkn/querystring\n/**\n * Compiles a querystring\n * Returns string representation of the object\n *\n * @param {Object}\n * @api private\n */\nfunction encode(obj) {\n    let str = '';\n    for (let i in obj) {\n        if (obj.hasOwnProperty(i)) {\n            if (str.length)\n                str += '&';\n            str += encodeURIComponent(i) + '=' + encodeURIComponent(obj[i]);\n        }\n    }\n    return str;\n}\n/**\n * Parses a simple querystring into an object\n *\n * @param {String} qs\n * @api private\n */\nfunction decode(qs) {\n    let qry = {};\n    let pairs = qs.split('&');\n    for (let i = 0, l = pairs.length; i < l; i++) {\n        let pair = pairs[i].split('=');\n        qry[decodeURIComponent(pair[0])] = decodeURIComponent(pair[1]);\n    }\n    return qry;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/contrib/parseqs.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/contrib/parseuri.js":
/*!*********************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/contrib/parseuri.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   parse: () => (/* binding */ parse)\n/* harmony export */ });\n// imported from https://github.com/galkn/parseuri\n/**\n * Parses a URI\n *\n * Note: we could also have used the built-in URL object, but it isn't supported on all platforms.\n *\n * See:\n * - https://developer.mozilla.org/en-US/docs/Web/API/URL\n * - https://caniuse.com/url\n * - https://www.rfc-editor.org/rfc/rfc3986#appendix-B\n *\n * History of the parse() method:\n * - first commit: https://github.com/socketio/socket.io-client/commit/4ee1d5d94b3906a9c052b459f1a818b15f38f91c\n * - export into its own module: https://github.com/socketio/engine.io-client/commit/de2c561e4564efeb78f1bdb1ba39ef81b2822cb3\n * - reimport: https://github.com/socketio/engine.io-client/commit/df32277c3f6d622eec5ed09f493cae3f3391d242\n *\n * @author Steven Levithan <stevenlevithan.com> (MIT license)\n * @api private\n */\nconst re = /^(?:(?![^:@\\/?#]+:[^:@\\/]*@)(http|https|ws|wss):\\/\\/)?((?:(([^:@\\/?#]*)(?::([^:@\\/?#]*))?)?@)?((?:[a-f0-9]{0,4}:){2,7}[a-f0-9]{0,4}|[^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\nconst parts = [\n    'source', 'protocol', 'authority', 'userInfo', 'user', 'password', 'host', 'port', 'relative', 'path', 'directory', 'file', 'query', 'anchor'\n];\nfunction parse(str) {\n    if (str.length > 2000) {\n        throw \"URI too long\";\n    }\n    const src = str, b = str.indexOf('['), e = str.indexOf(']');\n    if (b != -1 && e != -1) {\n        str = str.substring(0, b) + str.substring(b, e).replace(/:/g, ';') + str.substring(e, str.length);\n    }\n    let m = re.exec(str || ''), uri = {}, i = 14;\n    while (i--) {\n        uri[parts[i]] = m[i] || '';\n    }\n    if (b != -1 && e != -1) {\n        uri.source = src;\n        uri.host = uri.host.substring(1, uri.host.length - 1).replace(/;/g, ':');\n        uri.authority = uri.authority.replace('[', '').replace(']', '').replace(/;/g, ':');\n        uri.ipv6uri = true;\n    }\n    uri.pathNames = pathNames(uri, uri['path']);\n    uri.queryKey = queryKey(uri, uri['query']);\n    return uri;\n}\nfunction pathNames(obj, path) {\n    const regx = /\\/{2,9}/g, names = path.replace(regx, \"/\").split(\"/\");\n    if (path.slice(0, 1) == '/' || path.length === 0) {\n        names.splice(0, 1);\n    }\n    if (path.slice(-1) == '/') {\n        names.splice(names.length - 1, 1);\n    }\n    return names;\n}\nfunction queryKey(uri, query) {\n    const data = {};\n    query.replace(/(?:^|&)([^&=]*)=?([^&]*)/g, function ($0, $1, $2) {\n        if ($1) {\n            data[$1] = $2;\n        }\n    });\n    return data;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/contrib/parseuri.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/contrib/yeast.js":
/*!******************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/contrib/yeast.js ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   yeast: () => (/* binding */ yeast)\n/* harmony export */ });\n// imported from https://github.com/unshiftio/yeast\n\nconst alphabet = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-_'.split(''), length = 64, map = {};\nlet seed = 0, i = 0, prev;\n/**\n * Return a string representing the specified number.\n *\n * @param {Number} num The number to convert.\n * @returns {String} The string representation of the number.\n * @api public\n */\nfunction encode(num) {\n    let encoded = '';\n    do {\n        encoded = alphabet[num % length] + encoded;\n        num = Math.floor(num / length);\n    } while (num > 0);\n    return encoded;\n}\n/**\n * Return the integer value specified by the given string.\n *\n * @param {String} str The string to convert.\n * @returns {Number} The integer value represented by the string.\n * @api public\n */\nfunction decode(str) {\n    let decoded = 0;\n    for (i = 0; i < str.length; i++) {\n        decoded = decoded * length + map[str.charAt(i)];\n    }\n    return decoded;\n}\n/**\n * Yeast: A tiny growing id generator.\n *\n * @returns {String} A unique id.\n * @api public\n */\nfunction yeast() {\n    const now = encode(+new Date());\n    if (now !== prev)\n        return seed = 0, prev = now;\n    return now + '.' + encode(seed++);\n}\n//\n// Map each character to its index.\n//\nfor (; i < length; i++)\n    map[alphabet[i]] = i;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/contrib/yeast.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/globalThis.browser.js":
/*!***********************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/globalThis.browser.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   globalThisShim: () => (/* binding */ globalThisShim)\n/* harmony export */ });\nconst globalThisShim = (() => {\n    if (typeof self !== \"undefined\") {\n        return self;\n    }\n    else if (typeof window !== \"undefined\") {\n        return window;\n    }\n    else {\n        return Function(\"return this\")();\n    }\n})();\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/globalThis.browser.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Socket: () => (/* reexport safe */ _socket_js__WEBPACK_IMPORTED_MODULE_0__.Socket),\n/* harmony export */   Transport: () => (/* reexport safe */ _transport_js__WEBPACK_IMPORTED_MODULE_1__.Transport),\n/* harmony export */   TransportError: () => (/* reexport safe */ _transport_js__WEBPACK_IMPORTED_MODULE_1__.TransportError),\n/* harmony export */   installTimerFunctions: () => (/* reexport safe */ _util_js__WEBPACK_IMPORTED_MODULE_3__.installTimerFunctions),\n/* harmony export */   nextTick: () => (/* reexport safe */ _transports_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_5__.nextTick),\n/* harmony export */   parse: () => (/* reexport safe */ _contrib_parseuri_js__WEBPACK_IMPORTED_MODULE_4__.parse),\n/* harmony export */   protocol: () => (/* binding */ protocol),\n/* harmony export */   transports: () => (/* reexport safe */ _transports_index_js__WEBPACK_IMPORTED_MODULE_2__.transports)\n/* harmony export */ });\n/* harmony import */ var _socket_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./socket.js */ \"./node_modules/engine.io-client/build/esm/socket.js\");\n/* harmony import */ var _transport_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./transport.js */ \"./node_modules/engine.io-client/build/esm/transport.js\");\n/* harmony import */ var _transports_index_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./transports/index.js */ \"./node_modules/engine.io-client/build/esm/transports/index.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./util.js */ \"./node_modules/engine.io-client/build/esm/util.js\");\n/* harmony import */ var _contrib_parseuri_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./contrib/parseuri.js */ \"./node_modules/engine.io-client/build/esm/contrib/parseuri.js\");\n/* harmony import */ var _transports_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./transports/websocket-constructor.js */ \"./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js\");\n\n\nconst protocol = _socket_js__WEBPACK_IMPORTED_MODULE_0__.Socket.protocol;\n\n\n\n\n\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/index.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/socket.js":
/*!***********************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/socket.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Socket: () => (/* binding */ Socket)\n/* harmony export */ });\n/* harmony import */ var _transports_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./transports/index.js */ \"./node_modules/engine.io-client/build/esm/transports/index.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./util.js */ \"./node_modules/engine.io-client/build/esm/util.js\");\n/* harmony import */ var _contrib_parseqs_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./contrib/parseqs.js */ \"./node_modules/engine.io-client/build/esm/contrib/parseqs.js\");\n/* harmony import */ var _contrib_parseuri_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./contrib/parseuri.js */ \"./node_modules/engine.io-client/build/esm/contrib/parseuri.js\");\n/* harmony import */ var _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @socket.io/component-emitter */ \"./node_modules/@socket.io/component-emitter/lib/esm/index.js\");\n/* harmony import */ var engine_io_parser__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! engine.io-parser */ \"./node_modules/engine.io-parser/build/esm/index.js\");\n/* harmony import */ var _transports_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./transports/websocket-constructor.js */ \"./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js\");\n\n\n\n\n\n\n\nclass Socket extends _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_4__.Emitter {\n    /**\n     * Socket constructor.\n     *\n     * @param {String|Object} uri - uri or options\n     * @param {Object} opts - options\n     */\n    constructor(uri, opts = {}) {\n        super();\n        this.binaryType = _transports_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_6__.defaultBinaryType;\n        this.writeBuffer = [];\n        if (uri && \"object\" === typeof uri) {\n            opts = uri;\n            uri = null;\n        }\n        if (uri) {\n            uri = (0,_contrib_parseuri_js__WEBPACK_IMPORTED_MODULE_3__.parse)(uri);\n            opts.hostname = uri.host;\n            opts.secure = uri.protocol === \"https\" || uri.protocol === \"wss\";\n            opts.port = uri.port;\n            if (uri.query)\n                opts.query = uri.query;\n        }\n        else if (opts.host) {\n            opts.hostname = (0,_contrib_parseuri_js__WEBPACK_IMPORTED_MODULE_3__.parse)(opts.host).host;\n        }\n        (0,_util_js__WEBPACK_IMPORTED_MODULE_1__.installTimerFunctions)(this, opts);\n        this.secure =\n            null != opts.secure\n                ? opts.secure\n                : typeof location !== \"undefined\" && \"https:\" === location.protocol;\n        if (opts.hostname && !opts.port) {\n            // if no port is specified manually, use the protocol default\n            opts.port = this.secure ? \"443\" : \"80\";\n        }\n        this.hostname =\n            opts.hostname ||\n                (typeof location !== \"undefined\" ? location.hostname : \"localhost\");\n        this.port =\n            opts.port ||\n                (typeof location !== \"undefined\" && location.port\n                    ? location.port\n                    : this.secure\n                        ? \"443\"\n                        : \"80\");\n        this.transports = opts.transports || [\n            \"polling\",\n            \"websocket\",\n            \"webtransport\",\n        ];\n        this.writeBuffer = [];\n        this.prevBufferLen = 0;\n        this.opts = Object.assign({\n            path: \"/engine.io\",\n            agent: false,\n            withCredentials: false,\n            upgrade: true,\n            timestampParam: \"t\",\n            rememberUpgrade: false,\n            addTrailingSlash: true,\n            rejectUnauthorized: true,\n            perMessageDeflate: {\n                threshold: 1024,\n            },\n            transportOptions: {},\n            closeOnBeforeunload: false,\n        }, opts);\n        this.opts.path =\n            this.opts.path.replace(/\\/$/, \"\") +\n                (this.opts.addTrailingSlash ? \"/\" : \"\");\n        if (typeof this.opts.query === \"string\") {\n            this.opts.query = (0,_contrib_parseqs_js__WEBPACK_IMPORTED_MODULE_2__.decode)(this.opts.query);\n        }\n        // set on handshake\n        this.id = null;\n        this.upgrades = null;\n        this.pingInterval = null;\n        this.pingTimeout = null;\n        // set on heartbeat\n        this.pingTimeoutTimer = null;\n        if (typeof addEventListener === \"function\") {\n            if (this.opts.closeOnBeforeunload) {\n                // Firefox closes the connection when the \"beforeunload\" event is emitted but not Chrome. This event listener\n                // ensures every browser behaves the same (no \"disconnect\" event at the Socket.IO level when the page is\n                // closed/reloaded)\n                this.beforeunloadEventListener = () => {\n                    if (this.transport) {\n                        // silently close the transport\n                        this.transport.removeAllListeners();\n                        this.transport.close();\n                    }\n                };\n                addEventListener(\"beforeunload\", this.beforeunloadEventListener, false);\n            }\n            if (this.hostname !== \"localhost\") {\n                this.offlineEventListener = () => {\n                    this.onClose(\"transport close\", {\n                        description: \"network connection lost\",\n                    });\n                };\n                addEventListener(\"offline\", this.offlineEventListener, false);\n            }\n        }\n        this.open();\n    }\n    /**\n     * Creates transport of the given type.\n     *\n     * @param {String} name - transport name\n     * @return {Transport}\n     * @private\n     */\n    createTransport(name) {\n        const query = Object.assign({}, this.opts.query);\n        // append engine.io protocol identifier\n        query.EIO = engine_io_parser__WEBPACK_IMPORTED_MODULE_5__.protocol;\n        // transport name\n        query.transport = name;\n        // session id if we already have one\n        if (this.id)\n            query.sid = this.id;\n        const opts = Object.assign({}, this.opts, {\n            query,\n            socket: this,\n            hostname: this.hostname,\n            secure: this.secure,\n            port: this.port,\n        }, this.opts.transportOptions[name]);\n        return new _transports_index_js__WEBPACK_IMPORTED_MODULE_0__.transports[name](opts);\n    }\n    /**\n     * Initializes transport to use and starts probe.\n     *\n     * @private\n     */\n    open() {\n        let transport;\n        if (this.opts.rememberUpgrade &&\n            Socket.priorWebsocketSuccess &&\n            this.transports.indexOf(\"websocket\") !== -1) {\n            transport = \"websocket\";\n        }\n        else if (0 === this.transports.length) {\n            // Emit error on next tick so it can be listened to\n            this.setTimeoutFn(() => {\n                this.emitReserved(\"error\", \"No transports available\");\n            }, 0);\n            return;\n        }\n        else {\n            transport = this.transports[0];\n        }\n        this.readyState = \"opening\";\n        // Retry with the next transport if the transport is disabled (jsonp: false)\n        try {\n            transport = this.createTransport(transport);\n        }\n        catch (e) {\n            this.transports.shift();\n            this.open();\n            return;\n        }\n        transport.open();\n        this.setTransport(transport);\n    }\n    /**\n     * Sets the current transport. Disables the existing one (if any).\n     *\n     * @private\n     */\n    setTransport(transport) {\n        if (this.transport) {\n            this.transport.removeAllListeners();\n        }\n        // set up transport\n        this.transport = transport;\n        // set up transport listeners\n        transport\n            .on(\"drain\", this.onDrain.bind(this))\n            .on(\"packet\", this.onPacket.bind(this))\n            .on(\"error\", this.onError.bind(this))\n            .on(\"close\", (reason) => this.onClose(\"transport close\", reason));\n    }\n    /**\n     * Probes a transport.\n     *\n     * @param {String} name - transport name\n     * @private\n     */\n    probe(name) {\n        let transport = this.createTransport(name);\n        let failed = false;\n        Socket.priorWebsocketSuccess = false;\n        const onTransportOpen = () => {\n            if (failed)\n                return;\n            transport.send([{ type: \"ping\", data: \"probe\" }]);\n            transport.once(\"packet\", (msg) => {\n                if (failed)\n                    return;\n                if (\"pong\" === msg.type && \"probe\" === msg.data) {\n                    this.upgrading = true;\n                    this.emitReserved(\"upgrading\", transport);\n                    if (!transport)\n                        return;\n                    Socket.priorWebsocketSuccess = \"websocket\" === transport.name;\n                    this.transport.pause(() => {\n                        if (failed)\n                            return;\n                        if (\"closed\" === this.readyState)\n                            return;\n                        cleanup();\n                        this.setTransport(transport);\n                        transport.send([{ type: \"upgrade\" }]);\n                        this.emitReserved(\"upgrade\", transport);\n                        transport = null;\n                        this.upgrading = false;\n                        this.flush();\n                    });\n                }\n                else {\n                    const err = new Error(\"probe error\");\n                    // @ts-ignore\n                    err.transport = transport.name;\n                    this.emitReserved(\"upgradeError\", err);\n                }\n            });\n        };\n        function freezeTransport() {\n            if (failed)\n                return;\n            // Any callback called by transport should be ignored since now\n            failed = true;\n            cleanup();\n            transport.close();\n            transport = null;\n        }\n        // Handle any error that happens while probing\n        const onerror = (err) => {\n            const error = new Error(\"probe error: \" + err);\n            // @ts-ignore\n            error.transport = transport.name;\n            freezeTransport();\n            this.emitReserved(\"upgradeError\", error);\n        };\n        function onTransportClose() {\n            onerror(\"transport closed\");\n        }\n        // When the socket is closed while we're probing\n        function onclose() {\n            onerror(\"socket closed\");\n        }\n        // When the socket is upgraded while we're probing\n        function onupgrade(to) {\n            if (transport && to.name !== transport.name) {\n                freezeTransport();\n            }\n        }\n        // Remove all listeners on the transport and on self\n        const cleanup = () => {\n            transport.removeListener(\"open\", onTransportOpen);\n            transport.removeListener(\"error\", onerror);\n            transport.removeListener(\"close\", onTransportClose);\n            this.off(\"close\", onclose);\n            this.off(\"upgrading\", onupgrade);\n        };\n        transport.once(\"open\", onTransportOpen);\n        transport.once(\"error\", onerror);\n        transport.once(\"close\", onTransportClose);\n        this.once(\"close\", onclose);\n        this.once(\"upgrading\", onupgrade);\n        if (this.upgrades.indexOf(\"webtransport\") !== -1 &&\n            name !== \"webtransport\") {\n            // favor WebTransport\n            this.setTimeoutFn(() => {\n                if (!failed) {\n                    transport.open();\n                }\n            }, 200);\n        }\n        else {\n            transport.open();\n        }\n    }\n    /**\n     * Called when connection is deemed open.\n     *\n     * @private\n     */\n    onOpen() {\n        this.readyState = \"open\";\n        Socket.priorWebsocketSuccess = \"websocket\" === this.transport.name;\n        this.emitReserved(\"open\");\n        this.flush();\n        // we check for `readyState` in case an `open`\n        // listener already closed the socket\n        if (\"open\" === this.readyState && this.opts.upgrade) {\n            let i = 0;\n            const l = this.upgrades.length;\n            for (; i < l; i++) {\n                this.probe(this.upgrades[i]);\n            }\n        }\n    }\n    /**\n     * Handles a packet.\n     *\n     * @private\n     */\n    onPacket(packet) {\n        if (\"opening\" === this.readyState ||\n            \"open\" === this.readyState ||\n            \"closing\" === this.readyState) {\n            this.emitReserved(\"packet\", packet);\n            // Socket is live - any packet counts\n            this.emitReserved(\"heartbeat\");\n            this.resetPingTimeout();\n            switch (packet.type) {\n                case \"open\":\n                    this.onHandshake(JSON.parse(packet.data));\n                    break;\n                case \"ping\":\n                    this.sendPacket(\"pong\");\n                    this.emitReserved(\"ping\");\n                    this.emitReserved(\"pong\");\n                    break;\n                case \"error\":\n                    const err = new Error(\"server error\");\n                    // @ts-ignore\n                    err.code = packet.data;\n                    this.onError(err);\n                    break;\n                case \"message\":\n                    this.emitReserved(\"data\", packet.data);\n                    this.emitReserved(\"message\", packet.data);\n                    break;\n            }\n        }\n        else {\n        }\n    }\n    /**\n     * Called upon handshake completion.\n     *\n     * @param {Object} data - handshake obj\n     * @private\n     */\n    onHandshake(data) {\n        this.emitReserved(\"handshake\", data);\n        this.id = data.sid;\n        this.transport.query.sid = data.sid;\n        this.upgrades = this.filterUpgrades(data.upgrades);\n        this.pingInterval = data.pingInterval;\n        this.pingTimeout = data.pingTimeout;\n        this.maxPayload = data.maxPayload;\n        this.onOpen();\n        // In case open handler closes socket\n        if (\"closed\" === this.readyState)\n            return;\n        this.resetPingTimeout();\n    }\n    /**\n     * Sets and resets ping timeout timer based on server pings.\n     *\n     * @private\n     */\n    resetPingTimeout() {\n        this.clearTimeoutFn(this.pingTimeoutTimer);\n        this.pingTimeoutTimer = this.setTimeoutFn(() => {\n            this.onClose(\"ping timeout\");\n        }, this.pingInterval + this.pingTimeout);\n        if (this.opts.autoUnref) {\n            this.pingTimeoutTimer.unref();\n        }\n    }\n    /**\n     * Called on `drain` event\n     *\n     * @private\n     */\n    onDrain() {\n        this.writeBuffer.splice(0, this.prevBufferLen);\n        // setting prevBufferLen = 0 is very important\n        // for example, when upgrading, upgrade packet is sent over,\n        // and a nonzero prevBufferLen could cause problems on `drain`\n        this.prevBufferLen = 0;\n        if (0 === this.writeBuffer.length) {\n            this.emitReserved(\"drain\");\n        }\n        else {\n            this.flush();\n        }\n    }\n    /**\n     * Flush write buffers.\n     *\n     * @private\n     */\n    flush() {\n        if (\"closed\" !== this.readyState &&\n            this.transport.writable &&\n            !this.upgrading &&\n            this.writeBuffer.length) {\n            const packets = this.getWritablePackets();\n            this.transport.send(packets);\n            // keep track of current length of writeBuffer\n            // splice writeBuffer and callbackBuffer on `drain`\n            this.prevBufferLen = packets.length;\n            this.emitReserved(\"flush\");\n        }\n    }\n    /**\n     * Ensure the encoded size of the writeBuffer is below the maxPayload value sent by the server (only for HTTP\n     * long-polling)\n     *\n     * @private\n     */\n    getWritablePackets() {\n        const shouldCheckPayloadSize = this.maxPayload &&\n            this.transport.name === \"polling\" &&\n            this.writeBuffer.length > 1;\n        if (!shouldCheckPayloadSize) {\n            return this.writeBuffer;\n        }\n        let payloadSize = 1; // first packet type\n        for (let i = 0; i < this.writeBuffer.length; i++) {\n            const data = this.writeBuffer[i].data;\n            if (data) {\n                payloadSize += (0,_util_js__WEBPACK_IMPORTED_MODULE_1__.byteLength)(data);\n            }\n            if (i > 0 && payloadSize > this.maxPayload) {\n                return this.writeBuffer.slice(0, i);\n            }\n            payloadSize += 2; // separator + packet type\n        }\n        return this.writeBuffer;\n    }\n    /**\n     * Sends a message.\n     *\n     * @param {String} msg - message.\n     * @param {Object} options.\n     * @param {Function} callback function.\n     * @return {Socket} for chaining.\n     */\n    write(msg, options, fn) {\n        this.sendPacket(\"message\", msg, options, fn);\n        return this;\n    }\n    send(msg, options, fn) {\n        this.sendPacket(\"message\", msg, options, fn);\n        return this;\n    }\n    /**\n     * Sends a packet.\n     *\n     * @param {String} type: packet type.\n     * @param {String} data.\n     * @param {Object} options.\n     * @param {Function} fn - callback function.\n     * @private\n     */\n    sendPacket(type, data, options, fn) {\n        if (\"function\" === typeof data) {\n            fn = data;\n            data = undefined;\n        }\n        if (\"function\" === typeof options) {\n            fn = options;\n            options = null;\n        }\n        if (\"closing\" === this.readyState || \"closed\" === this.readyState) {\n            return;\n        }\n        options = options || {};\n        options.compress = false !== options.compress;\n        const packet = {\n            type: type,\n            data: data,\n            options: options,\n        };\n        this.emitReserved(\"packetCreate\", packet);\n        this.writeBuffer.push(packet);\n        if (fn)\n            this.once(\"flush\", fn);\n        this.flush();\n    }\n    /**\n     * Closes the connection.\n     */\n    close() {\n        const close = () => {\n            this.onClose(\"forced close\");\n            this.transport.close();\n        };\n        const cleanupAndClose = () => {\n            this.off(\"upgrade\", cleanupAndClose);\n            this.off(\"upgradeError\", cleanupAndClose);\n            close();\n        };\n        const waitForUpgrade = () => {\n            // wait for upgrade to finish since we can't send packets while pausing a transport\n            this.once(\"upgrade\", cleanupAndClose);\n            this.once(\"upgradeError\", cleanupAndClose);\n        };\n        if (\"opening\" === this.readyState || \"open\" === this.readyState) {\n            this.readyState = \"closing\";\n            if (this.writeBuffer.length) {\n                this.once(\"drain\", () => {\n                    if (this.upgrading) {\n                        waitForUpgrade();\n                    }\n                    else {\n                        close();\n                    }\n                });\n            }\n            else if (this.upgrading) {\n                waitForUpgrade();\n            }\n            else {\n                close();\n            }\n        }\n        return this;\n    }\n    /**\n     * Called upon transport error\n     *\n     * @private\n     */\n    onError(err) {\n        Socket.priorWebsocketSuccess = false;\n        this.emitReserved(\"error\", err);\n        this.onClose(\"transport error\", err);\n    }\n    /**\n     * Called upon transport close.\n     *\n     * @private\n     */\n    onClose(reason, description) {\n        if (\"opening\" === this.readyState ||\n            \"open\" === this.readyState ||\n            \"closing\" === this.readyState) {\n            // clear timers\n            this.clearTimeoutFn(this.pingTimeoutTimer);\n            // stop event from firing again for transport\n            this.transport.removeAllListeners(\"close\");\n            // ensure transport won't stay open\n            this.transport.close();\n            // ignore further transport communication\n            this.transport.removeAllListeners();\n            if (typeof removeEventListener === \"function\") {\n                removeEventListener(\"beforeunload\", this.beforeunloadEventListener, false);\n                removeEventListener(\"offline\", this.offlineEventListener, false);\n            }\n            // set ready state\n            this.readyState = \"closed\";\n            // clear session id\n            this.id = null;\n            // emit close event\n            this.emitReserved(\"close\", reason, description);\n            // clean buffers after, so users can still\n            // grab the buffers on `close` event\n            this.writeBuffer = [];\n            this.prevBufferLen = 0;\n        }\n    }\n    /**\n     * Filters upgrades, returning only those matching client transports.\n     *\n     * @param {Array} upgrades - server upgrades\n     * @private\n     */\n    filterUpgrades(upgrades) {\n        const filteredUpgrades = [];\n        let i = 0;\n        const j = upgrades.length;\n        for (; i < j; i++) {\n            if (~this.transports.indexOf(upgrades[i]))\n                filteredUpgrades.push(upgrades[i]);\n        }\n        return filteredUpgrades;\n    }\n}\nSocket.protocol = engine_io_parser__WEBPACK_IMPORTED_MODULE_5__.protocol;\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/socket.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transport.js":
/*!**************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transport.js ***!
  \**************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Transport: () => (/* binding */ Transport),\n/* harmony export */   TransportError: () => (/* binding */ TransportError)\n/* harmony export */ });\n/* harmony import */ var engine_io_parser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! engine.io-parser */ \"./node_modules/engine.io-parser/build/esm/index.js\");\n/* harmony import */ var _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @socket.io/component-emitter */ \"./node_modules/@socket.io/component-emitter/lib/esm/index.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./util.js */ \"./node_modules/engine.io-client/build/esm/util.js\");\n/* harmony import */ var _contrib_parseqs_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./contrib/parseqs.js */ \"./node_modules/engine.io-client/build/esm/contrib/parseqs.js\");\n\n\n\n\nclass TransportError extends Error {\n    constructor(reason, description, context) {\n        super(reason);\n        this.description = description;\n        this.context = context;\n        this.type = \"TransportError\";\n    }\n}\nclass Transport extends _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_1__.Emitter {\n    /**\n     * Transport abstract constructor.\n     *\n     * @param {Object} opts - options\n     * @protected\n     */\n    constructor(opts) {\n        super();\n        this.writable = false;\n        (0,_util_js__WEBPACK_IMPORTED_MODULE_2__.installTimerFunctions)(this, opts);\n        this.opts = opts;\n        this.query = opts.query;\n        this.socket = opts.socket;\n    }\n    /**\n     * Emits an error.\n     *\n     * @param {String} reason\n     * @param description\n     * @param context - the error context\n     * @return {Transport} for chaining\n     * @protected\n     */\n    onError(reason, description, context) {\n        super.emitReserved(\"error\", new TransportError(reason, description, context));\n        return this;\n    }\n    /**\n     * Opens the transport.\n     */\n    open() {\n        this.readyState = \"opening\";\n        this.doOpen();\n        return this;\n    }\n    /**\n     * Closes the transport.\n     */\n    close() {\n        if (this.readyState === \"opening\" || this.readyState === \"open\") {\n            this.doClose();\n            this.onClose();\n        }\n        return this;\n    }\n    /**\n     * Sends multiple packets.\n     *\n     * @param {Array} packets\n     */\n    send(packets) {\n        if (this.readyState === \"open\") {\n            this.write(packets);\n        }\n        else {\n            // this might happen if the transport was silently closed in the beforeunload event handler\n        }\n    }\n    /**\n     * Called upon open\n     *\n     * @protected\n     */\n    onOpen() {\n        this.readyState = \"open\";\n        this.writable = true;\n        super.emitReserved(\"open\");\n    }\n    /**\n     * Called with data.\n     *\n     * @param {String} data\n     * @protected\n     */\n    onData(data) {\n        const packet = (0,engine_io_parser__WEBPACK_IMPORTED_MODULE_0__.decodePacket)(data, this.socket.binaryType);\n        this.onPacket(packet);\n    }\n    /**\n     * Called with a decoded packet.\n     *\n     * @protected\n     */\n    onPacket(packet) {\n        super.emitReserved(\"packet\", packet);\n    }\n    /**\n     * Called upon close.\n     *\n     * @protected\n     */\n    onClose(details) {\n        this.readyState = \"closed\";\n        super.emitReserved(\"close\", details);\n    }\n    /**\n     * Pauses the transport, in order not to lose packets during an upgrade.\n     *\n     * @param onPause\n     */\n    pause(onPause) { }\n    createUri(schema, query = {}) {\n        return (schema +\n            \"://\" +\n            this._hostname() +\n            this._port() +\n            this.opts.path +\n            this._query(query));\n    }\n    _hostname() {\n        const hostname = this.opts.hostname;\n        return hostname.indexOf(\":\") === -1 ? hostname : \"[\" + hostname + \"]\";\n    }\n    _port() {\n        if (this.opts.port &&\n            ((this.opts.secure && Number(this.opts.port !== 443)) ||\n                (!this.opts.secure && Number(this.opts.port) !== 80))) {\n            return \":\" + this.opts.port;\n        }\n        else {\n            return \"\";\n        }\n    }\n    _query(query) {\n        const encodedQuery = (0,_contrib_parseqs_js__WEBPACK_IMPORTED_MODULE_3__.encode)(query);\n        return encodedQuery.length ? \"?\" + encodedQuery : \"\";\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transport.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transports/index.js":
/*!*********************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transports/index.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   transports: () => (/* binding */ transports)\n/* harmony export */ });\n/* harmony import */ var _polling_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./polling.js */ \"./node_modules/engine.io-client/build/esm/transports/polling.js\");\n/* harmony import */ var _websocket_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./websocket.js */ \"./node_modules/engine.io-client/build/esm/transports/websocket.js\");\n/* harmony import */ var _webtransport_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./webtransport.js */ \"./node_modules/engine.io-client/build/esm/transports/webtransport.js\");\n\n\n\nconst transports = {\n    websocket: _websocket_js__WEBPACK_IMPORTED_MODULE_1__.WS,\n    webtransport: _webtransport_js__WEBPACK_IMPORTED_MODULE_2__.WT,\n    polling: _polling_js__WEBPACK_IMPORTED_MODULE_0__.Polling,\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transports/index.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transports/polling.js":
/*!***********************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transports/polling.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Polling: () => (/* binding */ Polling),\n/* harmony export */   Request: () => (/* binding */ Request)\n/* harmony export */ });\n/* harmony import */ var _transport_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../transport.js */ \"./node_modules/engine.io-client/build/esm/transport.js\");\n/* harmony import */ var _contrib_yeast_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../contrib/yeast.js */ \"./node_modules/engine.io-client/build/esm/contrib/yeast.js\");\n/* harmony import */ var engine_io_parser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! engine.io-parser */ \"./node_modules/engine.io-parser/build/esm/index.js\");\n/* harmony import */ var _xmlhttprequest_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./xmlhttprequest.js */ \"./node_modules/engine.io-client/build/esm/transports/xmlhttprequest.browser.js\");\n/* harmony import */ var _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! @socket.io/component-emitter */ \"./node_modules/@socket.io/component-emitter/lib/esm/index.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util.js */ \"./node_modules/engine.io-client/build/esm/util.js\");\n/* harmony import */ var _globalThis_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../globalThis.js */ \"./node_modules/engine.io-client/build/esm/globalThis.browser.js\");\n\n\n\n\n\n\n\nfunction empty() { }\nconst hasXHR2 = (function () {\n    const xhr = new _xmlhttprequest_js__WEBPACK_IMPORTED_MODULE_3__.XHR({\n        xdomain: false,\n    });\n    return null != xhr.responseType;\n})();\nclass Polling extends _transport_js__WEBPACK_IMPORTED_MODULE_0__.Transport {\n    /**\n     * XHR Polling constructor.\n     *\n     * @param {Object} opts\n     * @package\n     */\n    constructor(opts) {\n        super(opts);\n        this.polling = false;\n        if (typeof location !== \"undefined\") {\n            const isSSL = \"https:\" === location.protocol;\n            let port = location.port;\n            // some user agents have empty `location.port`\n            if (!port) {\n                port = isSSL ? \"443\" : \"80\";\n            }\n            this.xd =\n                (typeof location !== \"undefined\" &&\n                    opts.hostname !== location.hostname) ||\n                    port !== opts.port;\n        }\n        /**\n         * XHR supports binary\n         */\n        const forceBase64 = opts && opts.forceBase64;\n        this.supportsBinary = hasXHR2 && !forceBase64;\n        if (this.opts.withCredentials) {\n            this.cookieJar = (0,_xmlhttprequest_js__WEBPACK_IMPORTED_MODULE_3__.createCookieJar)();\n        }\n    }\n    get name() {\n        return \"polling\";\n    }\n    /**\n     * Opens the socket (triggers polling). We write a PING message to determine\n     * when the transport is open.\n     *\n     * @protected\n     */\n    doOpen() {\n        this.poll();\n    }\n    /**\n     * Pauses polling.\n     *\n     * @param {Function} onPause - callback upon buffers are flushed and transport is paused\n     * @package\n     */\n    pause(onPause) {\n        this.readyState = \"pausing\";\n        const pause = () => {\n            this.readyState = \"paused\";\n            onPause();\n        };\n        if (this.polling || !this.writable) {\n            let total = 0;\n            if (this.polling) {\n                total++;\n                this.once(\"pollComplete\", function () {\n                    --total || pause();\n                });\n            }\n            if (!this.writable) {\n                total++;\n                this.once(\"drain\", function () {\n                    --total || pause();\n                });\n            }\n        }\n        else {\n            pause();\n        }\n    }\n    /**\n     * Starts polling cycle.\n     *\n     * @private\n     */\n    poll() {\n        this.polling = true;\n        this.doPoll();\n        this.emitReserved(\"poll\");\n    }\n    /**\n     * Overloads onData to detect payloads.\n     *\n     * @protected\n     */\n    onData(data) {\n        const callback = (packet) => {\n            // if its the first message we consider the transport open\n            if (\"opening\" === this.readyState && packet.type === \"open\") {\n                this.onOpen();\n            }\n            // if its a close packet, we close the ongoing requests\n            if (\"close\" === packet.type) {\n                this.onClose({ description: \"transport closed by the server\" });\n                return false;\n            }\n            // otherwise bypass onData and handle the message\n            this.onPacket(packet);\n        };\n        // decode payload\n        (0,engine_io_parser__WEBPACK_IMPORTED_MODULE_2__.decodePayload)(data, this.socket.binaryType).forEach(callback);\n        // if an event did not trigger closing\n        if (\"closed\" !== this.readyState) {\n            // if we got data we're not polling\n            this.polling = false;\n            this.emitReserved(\"pollComplete\");\n            if (\"open\" === this.readyState) {\n                this.poll();\n            }\n            else {\n            }\n        }\n    }\n    /**\n     * For polling, send a close packet.\n     *\n     * @protected\n     */\n    doClose() {\n        const close = () => {\n            this.write([{ type: \"close\" }]);\n        };\n        if (\"open\" === this.readyState) {\n            close();\n        }\n        else {\n            // in case we're trying to close while\n            // handshaking is in progress (GH-164)\n            this.once(\"open\", close);\n        }\n    }\n    /**\n     * Writes a packets payload.\n     *\n     * @param {Array} packets - data packets\n     * @protected\n     */\n    write(packets) {\n        this.writable = false;\n        (0,engine_io_parser__WEBPACK_IMPORTED_MODULE_2__.encodePayload)(packets, (data) => {\n            this.doWrite(data, () => {\n                this.writable = true;\n                this.emitReserved(\"drain\");\n            });\n        });\n    }\n    /**\n     * Generates uri for connection.\n     *\n     * @private\n     */\n    uri() {\n        const schema = this.opts.secure ? \"https\" : \"http\";\n        const query = this.query || {};\n        // cache busting is forced\n        if (false !== this.opts.timestampRequests) {\n            query[this.opts.timestampParam] = (0,_contrib_yeast_js__WEBPACK_IMPORTED_MODULE_1__.yeast)();\n        }\n        if (!this.supportsBinary && !query.sid) {\n            query.b64 = 1;\n        }\n        return this.createUri(schema, query);\n    }\n    /**\n     * Creates a request.\n     *\n     * @param {String} method\n     * @private\n     */\n    request(opts = {}) {\n        Object.assign(opts, { xd: this.xd, cookieJar: this.cookieJar }, this.opts);\n        return new Request(this.uri(), opts);\n    }\n    /**\n     * Sends data.\n     *\n     * @param {String} data to send.\n     * @param {Function} called upon flush.\n     * @private\n     */\n    doWrite(data, fn) {\n        const req = this.request({\n            method: \"POST\",\n            data: data,\n        });\n        req.on(\"success\", fn);\n        req.on(\"error\", (xhrStatus, context) => {\n            this.onError(\"xhr post error\", xhrStatus, context);\n        });\n    }\n    /**\n     * Starts a poll cycle.\n     *\n     * @private\n     */\n    doPoll() {\n        const req = this.request();\n        req.on(\"data\", this.onData.bind(this));\n        req.on(\"error\", (xhrStatus, context) => {\n            this.onError(\"xhr poll error\", xhrStatus, context);\n        });\n        this.pollXhr = req;\n    }\n}\nclass Request extends _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_4__.Emitter {\n    /**\n     * Request constructor\n     *\n     * @param {Object} options\n     * @package\n     */\n    constructor(uri, opts) {\n        super();\n        (0,_util_js__WEBPACK_IMPORTED_MODULE_5__.installTimerFunctions)(this, opts);\n        this.opts = opts;\n        this.method = opts.method || \"GET\";\n        this.uri = uri;\n        this.data = undefined !== opts.data ? opts.data : null;\n        this.create();\n    }\n    /**\n     * Creates the XHR object and sends the request.\n     *\n     * @private\n     */\n    create() {\n        var _a;\n        const opts = (0,_util_js__WEBPACK_IMPORTED_MODULE_5__.pick)(this.opts, \"agent\", \"pfx\", \"key\", \"passphrase\", \"cert\", \"ca\", \"ciphers\", \"rejectUnauthorized\", \"autoUnref\");\n        opts.xdomain = !!this.opts.xd;\n        const xhr = (this.xhr = new _xmlhttprequest_js__WEBPACK_IMPORTED_MODULE_3__.XHR(opts));\n        try {\n            xhr.open(this.method, this.uri, true);\n            try {\n                if (this.opts.extraHeaders) {\n                    xhr.setDisableHeaderCheck && xhr.setDisableHeaderCheck(true);\n                    for (let i in this.opts.extraHeaders) {\n                        if (this.opts.extraHeaders.hasOwnProperty(i)) {\n                            xhr.setRequestHeader(i, this.opts.extraHeaders[i]);\n                        }\n                    }\n                }\n            }\n            catch (e) { }\n            if (\"POST\" === this.method) {\n                try {\n                    xhr.setRequestHeader(\"Content-type\", \"text/plain;charset=UTF-8\");\n                }\n                catch (e) { }\n            }\n            try {\n                xhr.setRequestHeader(\"Accept\", \"*/*\");\n            }\n            catch (e) { }\n            (_a = this.opts.cookieJar) === null || _a === void 0 ? void 0 : _a.addCookies(xhr);\n            // ie6 check\n            if (\"withCredentials\" in xhr) {\n                xhr.withCredentials = this.opts.withCredentials;\n            }\n            if (this.opts.requestTimeout) {\n                xhr.timeout = this.opts.requestTimeout;\n            }\n            xhr.onreadystatechange = () => {\n                var _a;\n                if (xhr.readyState === 3) {\n                    (_a = this.opts.cookieJar) === null || _a === void 0 ? void 0 : _a.parseCookies(xhr);\n                }\n                if (4 !== xhr.readyState)\n                    return;\n                if (200 === xhr.status || 1223 === xhr.status) {\n                    this.onLoad();\n                }\n                else {\n                    // make sure the `error` event handler that's user-set\n                    // does not throw in the same tick and gets caught here\n                    this.setTimeoutFn(() => {\n                        this.onError(typeof xhr.status === \"number\" ? xhr.status : 0);\n                    }, 0);\n                }\n            };\n            xhr.send(this.data);\n        }\n        catch (e) {\n            // Need to defer since .create() is called directly from the constructor\n            // and thus the 'error' event can only be only bound *after* this exception\n            // occurs.  Therefore, also, we cannot throw here at all.\n            this.setTimeoutFn(() => {\n                this.onError(e);\n            }, 0);\n            return;\n        }\n        if (typeof document !== \"undefined\") {\n            this.index = Request.requestsCount++;\n            Request.requests[this.index] = this;\n        }\n    }\n    /**\n     * Called upon error.\n     *\n     * @private\n     */\n    onError(err) {\n        this.emitReserved(\"error\", err, this.xhr);\n        this.cleanup(true);\n    }\n    /**\n     * Cleans up house.\n     *\n     * @private\n     */\n    cleanup(fromError) {\n        if (\"undefined\" === typeof this.xhr || null === this.xhr) {\n            return;\n        }\n        this.xhr.onreadystatechange = empty;\n        if (fromError) {\n            try {\n                this.xhr.abort();\n            }\n            catch (e) { }\n        }\n        if (typeof document !== \"undefined\") {\n            delete Request.requests[this.index];\n        }\n        this.xhr = null;\n    }\n    /**\n     * Called upon load.\n     *\n     * @private\n     */\n    onLoad() {\n        const data = this.xhr.responseText;\n        if (data !== null) {\n            this.emitReserved(\"data\", data);\n            this.emitReserved(\"success\");\n            this.cleanup();\n        }\n    }\n    /**\n     * Aborts the request.\n     *\n     * @package\n     */\n    abort() {\n        this.cleanup();\n    }\n}\nRequest.requestsCount = 0;\nRequest.requests = {};\n/**\n * Aborts pending requests when unloading the window. This is needed to prevent\n * memory leaks (e.g. when using IE) and to ensure that no spurious error is\n * emitted.\n */\nif (typeof document !== \"undefined\") {\n    // @ts-ignore\n    if (typeof attachEvent === \"function\") {\n        // @ts-ignore\n        attachEvent(\"onunload\", unloadHandler);\n    }\n    else if (typeof addEventListener === \"function\") {\n        const terminationEvent = \"onpagehide\" in _globalThis_js__WEBPACK_IMPORTED_MODULE_6__.globalThisShim ? \"pagehide\" : \"unload\";\n        addEventListener(terminationEvent, unloadHandler, false);\n    }\n}\nfunction unloadHandler() {\n    for (let i in Request.requests) {\n        if (Request.requests.hasOwnProperty(i)) {\n            Request.requests[i].abort();\n        }\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transports/polling.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WebSocket: () => (/* binding */ WebSocket),\n/* harmony export */   defaultBinaryType: () => (/* binding */ defaultBinaryType),\n/* harmony export */   nextTick: () => (/* binding */ nextTick),\n/* harmony export */   usingBrowserWebSocket: () => (/* binding */ usingBrowserWebSocket)\n/* harmony export */ });\n/* harmony import */ var _globalThis_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globalThis.js */ \"./node_modules/engine.io-client/build/esm/globalThis.browser.js\");\n\nconst nextTick = (() => {\n    const isPromiseAvailable = typeof Promise === \"function\" && typeof Promise.resolve === \"function\";\n    if (isPromiseAvailable) {\n        return (cb) => Promise.resolve().then(cb);\n    }\n    else {\n        return (cb, setTimeoutFn) => setTimeoutFn(cb, 0);\n    }\n})();\nconst WebSocket = _globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim.WebSocket || _globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim.MozWebSocket;\nconst usingBrowserWebSocket = true;\nconst defaultBinaryType = \"arraybuffer\";\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transports/websocket.js":
/*!*************************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transports/websocket.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WS: () => (/* binding */ WS)\n/* harmony export */ });\n/* harmony import */ var _transport_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../transport.js */ \"./node_modules/engine.io-client/build/esm/transport.js\");\n/* harmony import */ var _contrib_yeast_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../contrib/yeast.js */ \"./node_modules/engine.io-client/build/esm/contrib/yeast.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util.js */ \"./node_modules/engine.io-client/build/esm/util.js\");\n/* harmony import */ var _websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./websocket-constructor.js */ \"./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js\");\n/* harmony import */ var engine_io_parser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! engine.io-parser */ \"./node_modules/engine.io-parser/build/esm/index.js\");\n\n\n\n\n\n// detect ReactNative environment\nconst isReactNative = typeof navigator !== \"undefined\" &&\n    typeof navigator.product === \"string\" &&\n    navigator.product.toLowerCase() === \"reactnative\";\nclass WS extends _transport_js__WEBPACK_IMPORTED_MODULE_0__.Transport {\n    /**\n     * WebSocket transport constructor.\n     *\n     * @param {Object} opts - connection options\n     * @protected\n     */\n    constructor(opts) {\n        super(opts);\n        this.supportsBinary = !opts.forceBase64;\n    }\n    get name() {\n        return \"websocket\";\n    }\n    doOpen() {\n        if (!this.check()) {\n            // let probe timeout\n            return;\n        }\n        const uri = this.uri();\n        const protocols = this.opts.protocols;\n        // React Native only supports the 'headers' option, and will print a warning if anything else is passed\n        const opts = isReactNative\n            ? {}\n            : (0,_util_js__WEBPACK_IMPORTED_MODULE_2__.pick)(this.opts, \"agent\", \"perMessageDeflate\", \"pfx\", \"key\", \"passphrase\", \"cert\", \"ca\", \"ciphers\", \"rejectUnauthorized\", \"localAddress\", \"protocolVersion\", \"origin\", \"maxPayload\", \"family\", \"checkServerIdentity\");\n        if (this.opts.extraHeaders) {\n            opts.headers = this.opts.extraHeaders;\n        }\n        try {\n            this.ws =\n                _websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.usingBrowserWebSocket && !isReactNative\n                    ? protocols\n                        ? new _websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.WebSocket(uri, protocols)\n                        : new _websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.WebSocket(uri)\n                    : new _websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.WebSocket(uri, protocols, opts);\n        }\n        catch (err) {\n            return this.emitReserved(\"error\", err);\n        }\n        this.ws.binaryType = this.socket.binaryType;\n        this.addEventListeners();\n    }\n    /**\n     * Adds event listeners to the socket\n     *\n     * @private\n     */\n    addEventListeners() {\n        this.ws.onopen = () => {\n            if (this.opts.autoUnref) {\n                this.ws._socket.unref();\n            }\n            this.onOpen();\n        };\n        this.ws.onclose = (closeEvent) => this.onClose({\n            description: \"websocket connection closed\",\n            context: closeEvent,\n        });\n        this.ws.onmessage = (ev) => this.onData(ev.data);\n        this.ws.onerror = (e) => this.onError(\"websocket error\", e);\n    }\n    write(packets) {\n        this.writable = false;\n        // encodePacket efficient as it uses WS framing\n        // no need for encodePayload\n        for (let i = 0; i < packets.length; i++) {\n            const packet = packets[i];\n            const lastPacket = i === packets.length - 1;\n            (0,engine_io_parser__WEBPACK_IMPORTED_MODULE_4__.encodePacket)(packet, this.supportsBinary, (data) => {\n                // always create a new object (GH-437)\n                const opts = {};\n                if (!_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.usingBrowserWebSocket) {\n                    if (packet.options) {\n                        opts.compress = packet.options.compress;\n                    }\n                    if (this.opts.perMessageDeflate) {\n                        const len = \n                        // @ts-ignore\n                        \"string\" === typeof data ? Buffer.byteLength(data) : data.length;\n                        if (len < this.opts.perMessageDeflate.threshold) {\n                            opts.compress = false;\n                        }\n                    }\n                }\n                // Sometimes the websocket has already been closed but the browser didn't\n                // have a chance of informing us about it yet, in that case send will\n                // throw an error\n                try {\n                    if (_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.usingBrowserWebSocket) {\n                        // TypeError is thrown when passing the second argument on Safari\n                        this.ws.send(data);\n                    }\n                    else {\n                        this.ws.send(data, opts);\n                    }\n                }\n                catch (e) {\n                }\n                if (lastPacket) {\n                    // fake drain\n                    // defer to next tick to allow Socket to clear writeBuffer\n                    (0,_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.nextTick)(() => {\n                        this.writable = true;\n                        this.emitReserved(\"drain\");\n                    }, this.setTimeoutFn);\n                }\n            });\n        }\n    }\n    doClose() {\n        if (typeof this.ws !== \"undefined\") {\n            this.ws.close();\n            this.ws = null;\n        }\n    }\n    /**\n     * Generates uri for connection.\n     *\n     * @private\n     */\n    uri() {\n        const schema = this.opts.secure ? \"wss\" : \"ws\";\n        const query = this.query || {};\n        // append timestamp to URI\n        if (this.opts.timestampRequests) {\n            query[this.opts.timestampParam] = (0,_contrib_yeast_js__WEBPACK_IMPORTED_MODULE_1__.yeast)();\n        }\n        // communicate binary support capabilities\n        if (!this.supportsBinary) {\n            query.b64 = 1;\n        }\n        return this.createUri(schema, query);\n    }\n    /**\n     * Feature detection for WebSocket.\n     *\n     * @return {Boolean} whether this transport is available.\n     * @private\n     */\n    check() {\n        return !!_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_3__.WebSocket;\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transports/websocket.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transports/webtransport.js":
/*!****************************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transports/webtransport.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WT: () => (/* binding */ WT)\n/* harmony export */ });\n/* harmony import */ var _transport_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../transport.js */ \"./node_modules/engine.io-client/build/esm/transport.js\");\n/* harmony import */ var _websocket_constructor_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./websocket-constructor.js */ \"./node_modules/engine.io-client/build/esm/transports/websocket-constructor.browser.js\");\n/* harmony import */ var engine_io_parser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! engine.io-parser */ \"./node_modules/engine.io-parser/build/esm/index.js\");\n\n\n\nclass WT extends _transport_js__WEBPACK_IMPORTED_MODULE_0__.Transport {\n    get name() {\n        return \"webtransport\";\n    }\n    doOpen() {\n        // @ts-ignore\n        if (typeof WebTransport !== \"function\") {\n            return;\n        }\n        // @ts-ignore\n        this.transport = new WebTransport(this.createUri(\"https\"), this.opts.transportOptions[this.name]);\n        this.transport.closed\n            .then(() => {\n            this.onClose();\n        })\n            .catch((err) => {\n            this.onError(\"webtransport error\", err);\n        });\n        // note: we could have used async/await, but that would require some additional polyfills\n        this.transport.ready.then(() => {\n            this.transport.createBidirectionalStream().then((stream) => {\n                const decoderStream = (0,engine_io_parser__WEBPACK_IMPORTED_MODULE_2__.createPacketDecoderStream)(Number.MAX_SAFE_INTEGER, this.socket.binaryType);\n                const reader = stream.readable.pipeThrough(decoderStream).getReader();\n                const encoderStream = (0,engine_io_parser__WEBPACK_IMPORTED_MODULE_2__.createPacketEncoderStream)();\n                encoderStream.readable.pipeTo(stream.writable);\n                this.writer = encoderStream.writable.getWriter();\n                const read = () => {\n                    reader\n                        .read()\n                        .then(({ done, value }) => {\n                        if (done) {\n                            return;\n                        }\n                        this.onPacket(value);\n                        read();\n                    })\n                        .catch((err) => {\n                    });\n                };\n                read();\n                const packet = { type: \"open\" };\n                if (this.query.sid) {\n                    packet.data = `{\"sid\":\"${this.query.sid}\"}`;\n                }\n                this.writer.write(packet).then(() => this.onOpen());\n            });\n        });\n    }\n    write(packets) {\n        this.writable = false;\n        for (let i = 0; i < packets.length; i++) {\n            const packet = packets[i];\n            const lastPacket = i === packets.length - 1;\n            this.writer.write(packet).then(() => {\n                if (lastPacket) {\n                    (0,_websocket_constructor_js__WEBPACK_IMPORTED_MODULE_1__.nextTick)(() => {\n                        this.writable = true;\n                        this.emitReserved(\"drain\");\n                    }, this.setTimeoutFn);\n                }\n            });\n        }\n    }\n    doClose() {\n        var _a;\n        (_a = this.transport) === null || _a === void 0 ? void 0 : _a.close();\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transports/webtransport.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/transports/xmlhttprequest.browser.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/transports/xmlhttprequest.browser.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   XHR: () => (/* binding */ XHR),\n/* harmony export */   createCookieJar: () => (/* binding */ createCookieJar)\n/* harmony export */ });\n/* harmony import */ var _contrib_has_cors_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../contrib/has-cors.js */ \"./node_modules/engine.io-client/build/esm/contrib/has-cors.js\");\n/* harmony import */ var _globalThis_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../globalThis.js */ \"./node_modules/engine.io-client/build/esm/globalThis.browser.js\");\n// browser shim for xmlhttprequest module\n\n\nfunction XHR(opts) {\n    const xdomain = opts.xdomain;\n    // XMLHttpRequest can be disabled on IE\n    try {\n        if (\"undefined\" !== typeof XMLHttpRequest && (!xdomain || _contrib_has_cors_js__WEBPACK_IMPORTED_MODULE_0__.hasCORS)) {\n            return new XMLHttpRequest();\n        }\n    }\n    catch (e) { }\n    if (!xdomain) {\n        try {\n            return new _globalThis_js__WEBPACK_IMPORTED_MODULE_1__.globalThisShim[[\"Active\"].concat(\"Object\").join(\"X\")](\"Microsoft.XMLHTTP\");\n        }\n        catch (e) { }\n    }\n}\nfunction createCookieJar() { }\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/transports/xmlhttprequest.browser.js?");

/***/ }),

/***/ "./node_modules/engine.io-client/build/esm/util.js":
/*!*********************************************************!*\
  !*** ./node_modules/engine.io-client/build/esm/util.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   byteLength: () => (/* binding */ byteLength),\n/* harmony export */   installTimerFunctions: () => (/* binding */ installTimerFunctions),\n/* harmony export */   pick: () => (/* binding */ pick)\n/* harmony export */ });\n/* harmony import */ var _globalThis_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./globalThis.js */ \"./node_modules/engine.io-client/build/esm/globalThis.browser.js\");\n\nfunction pick(obj, ...attr) {\n    return attr.reduce((acc, k) => {\n        if (obj.hasOwnProperty(k)) {\n            acc[k] = obj[k];\n        }\n        return acc;\n    }, {});\n}\n// Keep a reference to the real timeout functions so they can be used when overridden\nconst NATIVE_SET_TIMEOUT = _globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim.setTimeout;\nconst NATIVE_CLEAR_TIMEOUT = _globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim.clearTimeout;\nfunction installTimerFunctions(obj, opts) {\n    if (opts.useNativeTimers) {\n        obj.setTimeoutFn = NATIVE_SET_TIMEOUT.bind(_globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim);\n        obj.clearTimeoutFn = NATIVE_CLEAR_TIMEOUT.bind(_globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim);\n    }\n    else {\n        obj.setTimeoutFn = _globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim.setTimeout.bind(_globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim);\n        obj.clearTimeoutFn = _globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim.clearTimeout.bind(_globalThis_js__WEBPACK_IMPORTED_MODULE_0__.globalThisShim);\n    }\n}\n// base64 encoded buffers are about 33% bigger (https://en.wikipedia.org/wiki/Base64)\nconst BASE64_OVERHEAD = 1.33;\n// we could also have used `new Blob([obj]).size`, but it isn't supported in IE9\nfunction byteLength(obj) {\n    if (typeof obj === \"string\") {\n        return utf8Length(obj);\n    }\n    // arraybuffer or blob\n    return Math.ceil((obj.byteLength || obj.size) * BASE64_OVERHEAD);\n}\nfunction utf8Length(str) {\n    let c = 0, length = 0;\n    for (let i = 0, l = str.length; i < l; i++) {\n        c = str.charCodeAt(i);\n        if (c < 0x80) {\n            length += 1;\n        }\n        else if (c < 0x800) {\n            length += 2;\n        }\n        else if (c < 0xd800 || c >= 0xe000) {\n            length += 3;\n        }\n        else {\n            i++;\n            length += 4;\n        }\n    }\n    return length;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-client/build/esm/util.js?");

/***/ }),

/***/ "./node_modules/engine.io-parser/build/esm/commons.js":
/*!************************************************************!*\
  !*** ./node_modules/engine.io-parser/build/esm/commons.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ERROR_PACKET: () => (/* binding */ ERROR_PACKET),\n/* harmony export */   PACKET_TYPES: () => (/* binding */ PACKET_TYPES),\n/* harmony export */   PACKET_TYPES_REVERSE: () => (/* binding */ PACKET_TYPES_REVERSE)\n/* harmony export */ });\nconst PACKET_TYPES = Object.create(null); // no Map = no polyfill\nPACKET_TYPES[\"open\"] = \"0\";\nPACKET_TYPES[\"close\"] = \"1\";\nPACKET_TYPES[\"ping\"] = \"2\";\nPACKET_TYPES[\"pong\"] = \"3\";\nPACKET_TYPES[\"message\"] = \"4\";\nPACKET_TYPES[\"upgrade\"] = \"5\";\nPACKET_TYPES[\"noop\"] = \"6\";\nconst PACKET_TYPES_REVERSE = Object.create(null);\nObject.keys(PACKET_TYPES).forEach((key) => {\n    PACKET_TYPES_REVERSE[PACKET_TYPES[key]] = key;\n});\nconst ERROR_PACKET = { type: \"error\", data: \"parser error\" };\n\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-parser/build/esm/commons.js?");

/***/ }),

/***/ "./node_modules/engine.io-parser/build/esm/contrib/base64-arraybuffer.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/engine.io-parser/build/esm/contrib/base64-arraybuffer.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   encode: () => (/* binding */ encode)\n/* harmony export */ });\n// imported from https://github.com/socketio/base64-arraybuffer\nconst chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';\n// Use a lookup table to find the index.\nconst lookup = typeof Uint8Array === 'undefined' ? [] : new Uint8Array(256);\nfor (let i = 0; i < chars.length; i++) {\n    lookup[chars.charCodeAt(i)] = i;\n}\nconst encode = (arraybuffer) => {\n    let bytes = new Uint8Array(arraybuffer), i, len = bytes.length, base64 = '';\n    for (i = 0; i < len; i += 3) {\n        base64 += chars[bytes[i] >> 2];\n        base64 += chars[((bytes[i] & 3) << 4) | (bytes[i + 1] >> 4)];\n        base64 += chars[((bytes[i + 1] & 15) << 2) | (bytes[i + 2] >> 6)];\n        base64 += chars[bytes[i + 2] & 63];\n    }\n    if (len % 3 === 2) {\n        base64 = base64.substring(0, base64.length - 1) + '=';\n    }\n    else if (len % 3 === 1) {\n        base64 = base64.substring(0, base64.length - 2) + '==';\n    }\n    return base64;\n};\nconst decode = (base64) => {\n    let bufferLength = base64.length * 0.75, len = base64.length, i, p = 0, encoded1, encoded2, encoded3, encoded4;\n    if (base64[base64.length - 1] === '=') {\n        bufferLength--;\n        if (base64[base64.length - 2] === '=') {\n            bufferLength--;\n        }\n    }\n    const arraybuffer = new ArrayBuffer(bufferLength), bytes = new Uint8Array(arraybuffer);\n    for (i = 0; i < len; i += 4) {\n        encoded1 = lookup[base64.charCodeAt(i)];\n        encoded2 = lookup[base64.charCodeAt(i + 1)];\n        encoded3 = lookup[base64.charCodeAt(i + 2)];\n        encoded4 = lookup[base64.charCodeAt(i + 3)];\n        bytes[p++] = (encoded1 << 2) | (encoded2 >> 4);\n        bytes[p++] = ((encoded2 & 15) << 4) | (encoded3 >> 2);\n        bytes[p++] = ((encoded3 & 3) << 6) | (encoded4 & 63);\n    }\n    return arraybuffer;\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-parser/build/esm/contrib/base64-arraybuffer.js?");

/***/ }),

/***/ "./node_modules/engine.io-parser/build/esm/decodePacket.browser.js":
/*!*************************************************************************!*\
  !*** ./node_modules/engine.io-parser/build/esm/decodePacket.browser.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decodePacket: () => (/* binding */ decodePacket)\n/* harmony export */ });\n/* harmony import */ var _commons_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./commons.js */ \"./node_modules/engine.io-parser/build/esm/commons.js\");\n/* harmony import */ var _contrib_base64_arraybuffer_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./contrib/base64-arraybuffer.js */ \"./node_modules/engine.io-parser/build/esm/contrib/base64-arraybuffer.js\");\n\n\nconst withNativeArrayBuffer = typeof ArrayBuffer === \"function\";\nconst decodePacket = (encodedPacket, binaryType) => {\n    if (typeof encodedPacket !== \"string\") {\n        return {\n            type: \"message\",\n            data: mapBinary(encodedPacket, binaryType),\n        };\n    }\n    const type = encodedPacket.charAt(0);\n    if (type === \"b\") {\n        return {\n            type: \"message\",\n            data: decodeBase64Packet(encodedPacket.substring(1), binaryType),\n        };\n    }\n    const packetType = _commons_js__WEBPACK_IMPORTED_MODULE_0__.PACKET_TYPES_REVERSE[type];\n    if (!packetType) {\n        return _commons_js__WEBPACK_IMPORTED_MODULE_0__.ERROR_PACKET;\n    }\n    return encodedPacket.length > 1\n        ? {\n            type: _commons_js__WEBPACK_IMPORTED_MODULE_0__.PACKET_TYPES_REVERSE[type],\n            data: encodedPacket.substring(1),\n        }\n        : {\n            type: _commons_js__WEBPACK_IMPORTED_MODULE_0__.PACKET_TYPES_REVERSE[type],\n        };\n};\nconst decodeBase64Packet = (data, binaryType) => {\n    if (withNativeArrayBuffer) {\n        const decoded = (0,_contrib_base64_arraybuffer_js__WEBPACK_IMPORTED_MODULE_1__.decode)(data);\n        return mapBinary(decoded, binaryType);\n    }\n    else {\n        return { base64: true, data }; // fallback for old browsers\n    }\n};\nconst mapBinary = (data, binaryType) => {\n    switch (binaryType) {\n        case \"blob\":\n            if (data instanceof Blob) {\n                // from WebSocket + binaryType \"blob\"\n                return data;\n            }\n            else {\n                // from HTTP long-polling or WebTransport\n                return new Blob([data]);\n            }\n        case \"arraybuffer\":\n        default:\n            if (data instanceof ArrayBuffer) {\n                // from HTTP long-polling (base64) or WebSocket + binaryType \"arraybuffer\"\n                return data;\n            }\n            else {\n                // from WebTransport (Uint8Array)\n                return data.buffer;\n            }\n    }\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-parser/build/esm/decodePacket.browser.js?");

/***/ }),

/***/ "./node_modules/engine.io-parser/build/esm/encodePacket.browser.js":
/*!*************************************************************************!*\
  !*** ./node_modules/engine.io-parser/build/esm/encodePacket.browser.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   encodePacket: () => (/* binding */ encodePacket),\n/* harmony export */   encodePacketToBinary: () => (/* binding */ encodePacketToBinary)\n/* harmony export */ });\n/* harmony import */ var _commons_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./commons.js */ \"./node_modules/engine.io-parser/build/esm/commons.js\");\n\nconst withNativeBlob = typeof Blob === \"function\" ||\n    (typeof Blob !== \"undefined\" &&\n        Object.prototype.toString.call(Blob) === \"[object BlobConstructor]\");\nconst withNativeArrayBuffer = typeof ArrayBuffer === \"function\";\n// ArrayBuffer.isView method is not defined in IE10\nconst isView = (obj) => {\n    return typeof ArrayBuffer.isView === \"function\"\n        ? ArrayBuffer.isView(obj)\n        : obj && obj.buffer instanceof ArrayBuffer;\n};\nconst encodePacket = ({ type, data }, supportsBinary, callback) => {\n    if (withNativeBlob && data instanceof Blob) {\n        if (supportsBinary) {\n            return callback(data);\n        }\n        else {\n            return encodeBlobAsBase64(data, callback);\n        }\n    }\n    else if (withNativeArrayBuffer &&\n        (data instanceof ArrayBuffer || isView(data))) {\n        if (supportsBinary) {\n            return callback(data);\n        }\n        else {\n            return encodeBlobAsBase64(new Blob([data]), callback);\n        }\n    }\n    // plain string\n    return callback(_commons_js__WEBPACK_IMPORTED_MODULE_0__.PACKET_TYPES[type] + (data || \"\"));\n};\nconst encodeBlobAsBase64 = (data, callback) => {\n    const fileReader = new FileReader();\n    fileReader.onload = function () {\n        const content = fileReader.result.split(\",\")[1];\n        callback(\"b\" + (content || \"\"));\n    };\n    return fileReader.readAsDataURL(data);\n};\nfunction toArray(data) {\n    if (data instanceof Uint8Array) {\n        return data;\n    }\n    else if (data instanceof ArrayBuffer) {\n        return new Uint8Array(data);\n    }\n    else {\n        return new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n    }\n}\nlet TEXT_ENCODER;\nfunction encodePacketToBinary(packet, callback) {\n    if (withNativeBlob && packet.data instanceof Blob) {\n        return packet.data.arrayBuffer().then(toArray).then(callback);\n    }\n    else if (withNativeArrayBuffer &&\n        (packet.data instanceof ArrayBuffer || isView(packet.data))) {\n        return callback(toArray(packet.data));\n    }\n    encodePacket(packet, false, (encoded) => {\n        if (!TEXT_ENCODER) {\n            TEXT_ENCODER = new TextEncoder();\n        }\n        callback(TEXT_ENCODER.encode(encoded));\n    });\n}\n\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-parser/build/esm/encodePacket.browser.js?");

/***/ }),

/***/ "./node_modules/engine.io-parser/build/esm/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/engine.io-parser/build/esm/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   createPacketDecoderStream: () => (/* binding */ createPacketDecoderStream),\n/* harmony export */   createPacketEncoderStream: () => (/* binding */ createPacketEncoderStream),\n/* harmony export */   decodePacket: () => (/* reexport safe */ _decodePacket_js__WEBPACK_IMPORTED_MODULE_1__.decodePacket),\n/* harmony export */   decodePayload: () => (/* binding */ decodePayload),\n/* harmony export */   encodePacket: () => (/* reexport safe */ _encodePacket_js__WEBPACK_IMPORTED_MODULE_0__.encodePacket),\n/* harmony export */   encodePayload: () => (/* binding */ encodePayload),\n/* harmony export */   protocol: () => (/* binding */ protocol)\n/* harmony export */ });\n/* harmony import */ var _encodePacket_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./encodePacket.js */ \"./node_modules/engine.io-parser/build/esm/encodePacket.browser.js\");\n/* harmony import */ var _decodePacket_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./decodePacket.js */ \"./node_modules/engine.io-parser/build/esm/decodePacket.browser.js\");\n/* harmony import */ var _commons_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./commons.js */ \"./node_modules/engine.io-parser/build/esm/commons.js\");\n\n\n\nconst SEPARATOR = String.fromCharCode(30); // see https://en.wikipedia.org/wiki/Delimiter#ASCII_delimited_text\nconst encodePayload = (packets, callback) => {\n    // some packets may be added to the array while encoding, so the initial length must be saved\n    const length = packets.length;\n    const encodedPackets = new Array(length);\n    let count = 0;\n    packets.forEach((packet, i) => {\n        // force base64 encoding for binary packets\n        (0,_encodePacket_js__WEBPACK_IMPORTED_MODULE_0__.encodePacket)(packet, false, (encodedPacket) => {\n            encodedPackets[i] = encodedPacket;\n            if (++count === length) {\n                callback(encodedPackets.join(SEPARATOR));\n            }\n        });\n    });\n};\nconst decodePayload = (encodedPayload, binaryType) => {\n    const encodedPackets = encodedPayload.split(SEPARATOR);\n    const packets = [];\n    for (let i = 0; i < encodedPackets.length; i++) {\n        const decodedPacket = (0,_decodePacket_js__WEBPACK_IMPORTED_MODULE_1__.decodePacket)(encodedPackets[i], binaryType);\n        packets.push(decodedPacket);\n        if (decodedPacket.type === \"error\") {\n            break;\n        }\n    }\n    return packets;\n};\nfunction createPacketEncoderStream() {\n    return new TransformStream({\n        transform(packet, controller) {\n            (0,_encodePacket_js__WEBPACK_IMPORTED_MODULE_0__.encodePacketToBinary)(packet, (encodedPacket) => {\n                const payloadLength = encodedPacket.length;\n                let header;\n                // inspired by the WebSocket format: https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers#decoding_payload_length\n                if (payloadLength < 126) {\n                    header = new Uint8Array(1);\n                    new DataView(header.buffer).setUint8(0, payloadLength);\n                }\n                else if (payloadLength < 65536) {\n                    header = new Uint8Array(3);\n                    const view = new DataView(header.buffer);\n                    view.setUint8(0, 126);\n                    view.setUint16(1, payloadLength);\n                }\n                else {\n                    header = new Uint8Array(9);\n                    const view = new DataView(header.buffer);\n                    view.setUint8(0, 127);\n                    view.setBigUint64(1, BigInt(payloadLength));\n                }\n                // first bit indicates whether the payload is plain text (0) or binary (1)\n                if (packet.data && typeof packet.data !== \"string\") {\n                    header[0] |= 0x80;\n                }\n                controller.enqueue(header);\n                controller.enqueue(encodedPacket);\n            });\n        },\n    });\n}\nlet TEXT_DECODER;\nfunction totalLength(chunks) {\n    return chunks.reduce((acc, chunk) => acc + chunk.length, 0);\n}\nfunction concatChunks(chunks, size) {\n    if (chunks[0].length === size) {\n        return chunks.shift();\n    }\n    const buffer = new Uint8Array(size);\n    let j = 0;\n    for (let i = 0; i < size; i++) {\n        buffer[i] = chunks[0][j++];\n        if (j === chunks[0].length) {\n            chunks.shift();\n            j = 0;\n        }\n    }\n    if (chunks.length && j < chunks[0].length) {\n        chunks[0] = chunks[0].slice(j);\n    }\n    return buffer;\n}\nfunction createPacketDecoderStream(maxPayload, binaryType) {\n    if (!TEXT_DECODER) {\n        TEXT_DECODER = new TextDecoder();\n    }\n    const chunks = [];\n    let state = 0 /* State.READ_HEADER */;\n    let expectedLength = -1;\n    let isBinary = false;\n    return new TransformStream({\n        transform(chunk, controller) {\n            chunks.push(chunk);\n            while (true) {\n                if (state === 0 /* State.READ_HEADER */) {\n                    if (totalLength(chunks) < 1) {\n                        break;\n                    }\n                    const header = concatChunks(chunks, 1);\n                    isBinary = (header[0] & 0x80) === 0x80;\n                    expectedLength = header[0] & 0x7f;\n                    if (expectedLength < 126) {\n                        state = 3 /* State.READ_PAYLOAD */;\n                    }\n                    else if (expectedLength === 126) {\n                        state = 1 /* State.READ_EXTENDED_LENGTH_16 */;\n                    }\n                    else {\n                        state = 2 /* State.READ_EXTENDED_LENGTH_64 */;\n                    }\n                }\n                else if (state === 1 /* State.READ_EXTENDED_LENGTH_16 */) {\n                    if (totalLength(chunks) < 2) {\n                        break;\n                    }\n                    const headerArray = concatChunks(chunks, 2);\n                    expectedLength = new DataView(headerArray.buffer, headerArray.byteOffset, headerArray.length).getUint16(0);\n                    state = 3 /* State.READ_PAYLOAD */;\n                }\n                else if (state === 2 /* State.READ_EXTENDED_LENGTH_64 */) {\n                    if (totalLength(chunks) < 8) {\n                        break;\n                    }\n                    const headerArray = concatChunks(chunks, 8);\n                    const view = new DataView(headerArray.buffer, headerArray.byteOffset, headerArray.length);\n                    const n = view.getUint32(0);\n                    if (n > Math.pow(2, 53 - 32) - 1) {\n                        // the maximum safe integer in JavaScript is 2^53 - 1\n                        controller.enqueue(_commons_js__WEBPACK_IMPORTED_MODULE_2__.ERROR_PACKET);\n                        break;\n                    }\n                    expectedLength = n * Math.pow(2, 32) + view.getUint32(4);\n                    state = 3 /* State.READ_PAYLOAD */;\n                }\n                else {\n                    if (totalLength(chunks) < expectedLength) {\n                        break;\n                    }\n                    const data = concatChunks(chunks, expectedLength);\n                    controller.enqueue((0,_decodePacket_js__WEBPACK_IMPORTED_MODULE_1__.decodePacket)(isBinary ? data : TEXT_DECODER.decode(data), binaryType));\n                    state = 0 /* State.READ_HEADER */;\n                }\n                if (expectedLength === 0 || expectedLength > maxPayload) {\n                    controller.enqueue(_commons_js__WEBPACK_IMPORTED_MODULE_2__.ERROR_PACKET);\n                    break;\n                }\n            }\n        },\n    });\n}\nconst protocol = 4;\n\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/engine.io-parser/build/esm/index.js?");

/***/ }),

/***/ "./node_modules/hls.js/dist/hls.mjs":
/*!******************************************!*\
  !*** ./node_modules/hls.js/dist/hls.mjs ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AbrController: () => (/* binding */ AbrController),\n/* harmony export */   AttrList: () => (/* binding */ AttrList),\n/* harmony export */   AudioStreamController: () => (/* binding */ AudioStreamController),\n/* harmony export */   AudioTrackController: () => (/* binding */ AudioTrackController),\n/* harmony export */   BasePlaylistController: () => (/* binding */ BasePlaylistController),\n/* harmony export */   BaseSegment: () => (/* binding */ BaseSegment),\n/* harmony export */   BaseStreamController: () => (/* binding */ BaseStreamController),\n/* harmony export */   BufferController: () => (/* binding */ BufferController),\n/* harmony export */   CMCDController: () => (/* binding */ CMCDController),\n/* harmony export */   CapLevelController: () => (/* binding */ CapLevelController),\n/* harmony export */   ChunkMetadata: () => (/* binding */ ChunkMetadata),\n/* harmony export */   ContentSteeringController: () => (/* binding */ ContentSteeringController),\n/* harmony export */   DateRange: () => (/* binding */ DateRange),\n/* harmony export */   EMEController: () => (/* binding */ EMEController),\n/* harmony export */   ErrorActionFlags: () => (/* binding */ ErrorActionFlags),\n/* harmony export */   ErrorController: () => (/* binding */ ErrorController),\n/* harmony export */   ErrorDetails: () => (/* binding */ ErrorDetails),\n/* harmony export */   ErrorTypes: () => (/* binding */ ErrorTypes),\n/* harmony export */   Events: () => (/* binding */ Events),\n/* harmony export */   FPSController: () => (/* binding */ FPSController),\n/* harmony export */   Fragment: () => (/* binding */ Fragment),\n/* harmony export */   Hls: () => (/* binding */ Hls),\n/* harmony export */   HlsSkip: () => (/* binding */ HlsSkip),\n/* harmony export */   HlsUrlParameters: () => (/* binding */ HlsUrlParameters),\n/* harmony export */   KeySystemFormats: () => (/* binding */ KeySystemFormats),\n/* harmony export */   KeySystems: () => (/* binding */ KeySystems),\n/* harmony export */   Level: () => (/* binding */ Level),\n/* harmony export */   LevelDetails: () => (/* binding */ LevelDetails),\n/* harmony export */   LevelKey: () => (/* binding */ LevelKey),\n/* harmony export */   LoadStats: () => (/* binding */ LoadStats),\n/* harmony export */   MetadataSchema: () => (/* binding */ MetadataSchema),\n/* harmony export */   NetworkErrorAction: () => (/* binding */ NetworkErrorAction),\n/* harmony export */   Part: () => (/* binding */ Part),\n/* harmony export */   PlaylistLevelType: () => (/* binding */ PlaylistLevelType),\n/* harmony export */   SubtitleStreamController: () => (/* binding */ SubtitleStreamController),\n/* harmony export */   SubtitleTrackController: () => (/* binding */ SubtitleTrackController),\n/* harmony export */   TimelineController: () => (/* binding */ TimelineController),\n/* harmony export */   \"default\": () => (/* binding */ Hls),\n/* harmony export */   getMediaSource: () => (/* binding */ getMediaSource),\n/* harmony export */   isMSESupported: () => (/* binding */ isMSESupported),\n/* harmony export */   isSupported: () => (/* binding */ isSupported)\n/* harmony export */ });\nfunction getDefaultExportFromCjs (x) {\n\treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n}\n\nvar urlToolkit = {exports: {}};\n\n(function (module, exports) {\n\t// see https://tools.ietf.org/html/rfc1808\n\n\t(function (root) {\n\t  var URL_REGEX =\n\t    /^(?=((?:[a-zA-Z0-9+\\-.]+:)?))\\1(?=((?:\\/\\/[^\\/?#]*)?))\\2(?=((?:(?:[^?#\\/]*\\/)*[^;?#\\/]*)?))\\3((?:;[^?#]*)?)(\\?[^#]*)?(#[^]*)?$/;\n\t  var FIRST_SEGMENT_REGEX = /^(?=([^\\/?#]*))\\1([^]*)$/;\n\t  var SLASH_DOT_REGEX = /(?:\\/|^)\\.(?=\\/)/g;\n\t  var SLASH_DOT_DOT_REGEX = /(?:\\/|^)\\.\\.\\/(?!\\.\\.\\/)[^\\/]*(?=\\/)/g;\n\n\t  var URLToolkit = {\n\t    // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //\n\t    // E.g\n\t    // With opts.alwaysNormalize = false (default, spec compliant)\n\t    // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g\n\t    // With opts.alwaysNormalize = true (not spec compliant)\n\t    // http://a.com/b/cd + /e/f/../g => http://a.com/e/g\n\t    buildAbsoluteURL: function (baseURL, relativeURL, opts) {\n\t      opts = opts || {};\n\t      // remove any remaining space and CRLF\n\t      baseURL = baseURL.trim();\n\t      relativeURL = relativeURL.trim();\n\t      if (!relativeURL) {\n\t        // 2a) If the embedded URL is entirely empty, it inherits the\n\t        // entire base URL (i.e., is set equal to the base URL)\n\t        // and we are done.\n\t        if (!opts.alwaysNormalize) {\n\t          return baseURL;\n\t        }\n\t        var basePartsForNormalise = URLToolkit.parseURL(baseURL);\n\t        if (!basePartsForNormalise) {\n\t          throw new Error('Error trying to parse base URL.');\n\t        }\n\t        basePartsForNormalise.path = URLToolkit.normalizePath(\n\t          basePartsForNormalise.path\n\t        );\n\t        return URLToolkit.buildURLFromParts(basePartsForNormalise);\n\t      }\n\t      var relativeParts = URLToolkit.parseURL(relativeURL);\n\t      if (!relativeParts) {\n\t        throw new Error('Error trying to parse relative URL.');\n\t      }\n\t      if (relativeParts.scheme) {\n\t        // 2b) If the embedded URL starts with a scheme name, it is\n\t        // interpreted as an absolute URL and we are done.\n\t        if (!opts.alwaysNormalize) {\n\t          return relativeURL;\n\t        }\n\t        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);\n\t        return URLToolkit.buildURLFromParts(relativeParts);\n\t      }\n\t      var baseParts = URLToolkit.parseURL(baseURL);\n\t      if (!baseParts) {\n\t        throw new Error('Error trying to parse base URL.');\n\t      }\n\t      if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {\n\t        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc\n\t        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'\n\t        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);\n\t        baseParts.netLoc = pathParts[1];\n\t        baseParts.path = pathParts[2];\n\t      }\n\t      if (baseParts.netLoc && !baseParts.path) {\n\t        baseParts.path = '/';\n\t      }\n\t      var builtParts = {\n\t        // 2c) Otherwise, the embedded URL inherits the scheme of\n\t        // the base URL.\n\t        scheme: baseParts.scheme,\n\t        netLoc: relativeParts.netLoc,\n\t        path: null,\n\t        params: relativeParts.params,\n\t        query: relativeParts.query,\n\t        fragment: relativeParts.fragment,\n\t      };\n\t      if (!relativeParts.netLoc) {\n\t        // 3) If the embedded URL's <net_loc> is non-empty, we skip to\n\t        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>\n\t        // (if any) of the base URL.\n\t        builtParts.netLoc = baseParts.netLoc;\n\t        // 4) If the embedded URL path is preceded by a slash \"/\", the\n\t        // path is not relative and we skip to Step 7.\n\t        if (relativeParts.path[0] !== '/') {\n\t          if (!relativeParts.path) {\n\t            // 5) If the embedded URL path is empty (and not preceded by a\n\t            // slash), then the embedded URL inherits the base URL path\n\t            builtParts.path = baseParts.path;\n\t            // 5a) if the embedded URL's <params> is non-empty, we skip to\n\t            // step 7; otherwise, it inherits the <params> of the base\n\t            // URL (if any) and\n\t            if (!relativeParts.params) {\n\t              builtParts.params = baseParts.params;\n\t              // 5b) if the embedded URL's <query> is non-empty, we skip to\n\t              // step 7; otherwise, it inherits the <query> of the base\n\t              // URL (if any) and we skip to step 7.\n\t              if (!relativeParts.query) {\n\t                builtParts.query = baseParts.query;\n\t              }\n\t            }\n\t          } else {\n\t            // 6) The last segment of the base URL's path (anything\n\t            // following the rightmost slash \"/\", or the entire path if no\n\t            // slash is present) is removed and the embedded URL's path is\n\t            // appended in its place.\n\t            var baseURLPath = baseParts.path;\n\t            var newPath =\n\t              baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +\n\t              relativeParts.path;\n\t            builtParts.path = URLToolkit.normalizePath(newPath);\n\t          }\n\t        }\n\t      }\n\t      if (builtParts.path === null) {\n\t        builtParts.path = opts.alwaysNormalize\n\t          ? URLToolkit.normalizePath(relativeParts.path)\n\t          : relativeParts.path;\n\t      }\n\t      return URLToolkit.buildURLFromParts(builtParts);\n\t    },\n\t    parseURL: function (url) {\n\t      var parts = URL_REGEX.exec(url);\n\t      if (!parts) {\n\t        return null;\n\t      }\n\t      return {\n\t        scheme: parts[1] || '',\n\t        netLoc: parts[2] || '',\n\t        path: parts[3] || '',\n\t        params: parts[4] || '',\n\t        query: parts[5] || '',\n\t        fragment: parts[6] || '',\n\t      };\n\t    },\n\t    normalizePath: function (path) {\n\t      // The following operations are\n\t      // then applied, in order, to the new path:\n\t      // 6a) All occurrences of \"./\", where \".\" is a complete path\n\t      // segment, are removed.\n\t      // 6b) If the path ends with \".\" as a complete path segment,\n\t      // that \".\" is removed.\n\t      path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');\n\t      // 6c) All occurrences of \"<segment>/../\", where <segment> is a\n\t      // complete path segment not equal to \"..\", are removed.\n\t      // Removal of these path segments is performed iteratively,\n\t      // removing the leftmost matching pattern on each iteration,\n\t      // until no matching pattern remains.\n\t      // 6d) If the path ends with \"<segment>/..\", where <segment> is a\n\t      // complete path segment not equal to \"..\", that\n\t      // \"<segment>/..\" is removed.\n\t      while (\n\t        path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length\n\t      ) {}\n\t      return path.split('').reverse().join('');\n\t    },\n\t    buildURLFromParts: function (parts) {\n\t      return (\n\t        parts.scheme +\n\t        parts.netLoc +\n\t        parts.path +\n\t        parts.params +\n\t        parts.query +\n\t        parts.fragment\n\t      );\n\t    },\n\t  };\n\n\t  module.exports = URLToolkit;\n\t})(); \n} (urlToolkit));\n\nvar urlToolkitExports = urlToolkit.exports;\n\nfunction ownKeys(e, r) {\n  var t = Object.keys(e);\n  if (Object.getOwnPropertySymbols) {\n    var o = Object.getOwnPropertySymbols(e);\n    r && (o = o.filter(function (r) {\n      return Object.getOwnPropertyDescriptor(e, r).enumerable;\n    })), t.push.apply(t, o);\n  }\n  return t;\n}\nfunction _objectSpread2(e) {\n  for (var r = 1; r < arguments.length; r++) {\n    var t = null != arguments[r] ? arguments[r] : {};\n    r % 2 ? ownKeys(Object(t), !0).forEach(function (r) {\n      _defineProperty(e, r, t[r]);\n    }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) {\n      Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r));\n    });\n  }\n  return e;\n}\nfunction _toPrimitive(t, r) {\n  if (\"object\" != typeof t || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != typeof i) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\nfunction _toPropertyKey(t) {\n  var i = _toPrimitive(t, \"string\");\n  return \"symbol\" == typeof i ? i : String(i);\n}\nfunction _defineProperty(obj, key, value) {\n  key = _toPropertyKey(key);\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n  return obj;\n}\nfunction _extends() {\n  _extends = Object.assign ? Object.assign.bind() : function (target) {\n    for (var i = 1; i < arguments.length; i++) {\n      var source = arguments[i];\n      for (var key in source) {\n        if (Object.prototype.hasOwnProperty.call(source, key)) {\n          target[key] = source[key];\n        }\n      }\n    }\n    return target;\n  };\n  return _extends.apply(this, arguments);\n}\n\n// https://caniuse.com/mdn-javascript_builtins_number_isfinite\nconst isFiniteNumber = Number.isFinite || function (value) {\n  return typeof value === 'number' && isFinite(value);\n};\n\n// https://caniuse.com/mdn-javascript_builtins_number_issafeinteger\nconst isSafeInteger = Number.isSafeInteger || function (value) {\n  return typeof value === 'number' && Math.abs(value) <= MAX_SAFE_INTEGER;\n};\nconst MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\n\nlet Events = /*#__PURE__*/function (Events) {\n  Events[\"MEDIA_ATTACHING\"] = \"hlsMediaAttaching\";\n  Events[\"MEDIA_ATTACHED\"] = \"hlsMediaAttached\";\n  Events[\"MEDIA_DETACHING\"] = \"hlsMediaDetaching\";\n  Events[\"MEDIA_DETACHED\"] = \"hlsMediaDetached\";\n  Events[\"BUFFER_RESET\"] = \"hlsBufferReset\";\n  Events[\"BUFFER_CODECS\"] = \"hlsBufferCodecs\";\n  Events[\"BUFFER_CREATED\"] = \"hlsBufferCreated\";\n  Events[\"BUFFER_APPENDING\"] = \"hlsBufferAppending\";\n  Events[\"BUFFER_APPENDED\"] = \"hlsBufferAppended\";\n  Events[\"BUFFER_EOS\"] = \"hlsBufferEos\";\n  Events[\"BUFFER_FLUSHING\"] = \"hlsBufferFlushing\";\n  Events[\"BUFFER_FLUSHED\"] = \"hlsBufferFlushed\";\n  Events[\"MANIFEST_LOADING\"] = \"hlsManifestLoading\";\n  Events[\"MANIFEST_LOADED\"] = \"hlsManifestLoaded\";\n  Events[\"MANIFEST_PARSED\"] = \"hlsManifestParsed\";\n  Events[\"LEVEL_SWITCHING\"] = \"hlsLevelSwitching\";\n  Events[\"LEVEL_SWITCHED\"] = \"hlsLevelSwitched\";\n  Events[\"LEVEL_LOADING\"] = \"hlsLevelLoading\";\n  Events[\"LEVEL_LOADED\"] = \"hlsLevelLoaded\";\n  Events[\"LEVEL_UPDATED\"] = \"hlsLevelUpdated\";\n  Events[\"LEVEL_PTS_UPDATED\"] = \"hlsLevelPtsUpdated\";\n  Events[\"LEVELS_UPDATED\"] = \"hlsLevelsUpdated\";\n  Events[\"AUDIO_TRACKS_UPDATED\"] = \"hlsAudioTracksUpdated\";\n  Events[\"AUDIO_TRACK_SWITCHING\"] = \"hlsAudioTrackSwitching\";\n  Events[\"AUDIO_TRACK_SWITCHED\"] = \"hlsAudioTrackSwitched\";\n  Events[\"AUDIO_TRACK_LOADING\"] = \"hlsAudioTrackLoading\";\n  Events[\"AUDIO_TRACK_LOADED\"] = \"hlsAudioTrackLoaded\";\n  Events[\"SUBTITLE_TRACKS_UPDATED\"] = \"hlsSubtitleTracksUpdated\";\n  Events[\"SUBTITLE_TRACKS_CLEARED\"] = \"hlsSubtitleTracksCleared\";\n  Events[\"SUBTITLE_TRACK_SWITCH\"] = \"hlsSubtitleTrackSwitch\";\n  Events[\"SUBTITLE_TRACK_LOADING\"] = \"hlsSubtitleTrackLoading\";\n  Events[\"SUBTITLE_TRACK_LOADED\"] = \"hlsSubtitleTrackLoaded\";\n  Events[\"SUBTITLE_FRAG_PROCESSED\"] = \"hlsSubtitleFragProcessed\";\n  Events[\"CUES_PARSED\"] = \"hlsCuesParsed\";\n  Events[\"NON_NATIVE_TEXT_TRACKS_FOUND\"] = \"hlsNonNativeTextTracksFound\";\n  Events[\"INIT_PTS_FOUND\"] = \"hlsInitPtsFound\";\n  Events[\"FRAG_LOADING\"] = \"hlsFragLoading\";\n  Events[\"FRAG_LOAD_EMERGENCY_ABORTED\"] = \"hlsFragLoadEmergencyAborted\";\n  Events[\"FRAG_LOADED\"] = \"hlsFragLoaded\";\n  Events[\"FRAG_DECRYPTED\"] = \"hlsFragDecrypted\";\n  Events[\"FRAG_PARSING_INIT_SEGMENT\"] = \"hlsFragParsingInitSegment\";\n  Events[\"FRAG_PARSING_USERDATA\"] = \"hlsFragParsingUserdata\";\n  Events[\"FRAG_PARSING_METADATA\"] = \"hlsFragParsingMetadata\";\n  Events[\"FRAG_PARSED\"] = \"hlsFragParsed\";\n  Events[\"FRAG_BUFFERED\"] = \"hlsFragBuffered\";\n  Events[\"FRAG_CHANGED\"] = \"hlsFragChanged\";\n  Events[\"FPS_DROP\"] = \"hlsFpsDrop\";\n  Events[\"FPS_DROP_LEVEL_CAPPING\"] = \"hlsFpsDropLevelCapping\";\n  Events[\"MAX_AUTO_LEVEL_UPDATED\"] = \"hlsMaxAutoLevelUpdated\";\n  Events[\"ERROR\"] = \"hlsError\";\n  Events[\"DESTROYING\"] = \"hlsDestroying\";\n  Events[\"KEY_LOADING\"] = \"hlsKeyLoading\";\n  Events[\"KEY_LOADED\"] = \"hlsKeyLoaded\";\n  Events[\"LIVE_BACK_BUFFER_REACHED\"] = \"hlsLiveBackBufferReached\";\n  Events[\"BACK_BUFFER_REACHED\"] = \"hlsBackBufferReached\";\n  Events[\"STEERING_MANIFEST_LOADED\"] = \"hlsSteeringManifestLoaded\";\n  return Events;\n}({});\n\n/**\n * Defines each Event type and payload by Event name. Used in {@link hls.js#HlsEventEmitter} to strongly type the event listener API.\n */\n\nlet ErrorTypes = /*#__PURE__*/function (ErrorTypes) {\n  ErrorTypes[\"NETWORK_ERROR\"] = \"networkError\";\n  ErrorTypes[\"MEDIA_ERROR\"] = \"mediaError\";\n  ErrorTypes[\"KEY_SYSTEM_ERROR\"] = \"keySystemError\";\n  ErrorTypes[\"MUX_ERROR\"] = \"muxError\";\n  ErrorTypes[\"OTHER_ERROR\"] = \"otherError\";\n  return ErrorTypes;\n}({});\nlet ErrorDetails = /*#__PURE__*/function (ErrorDetails) {\n  ErrorDetails[\"KEY_SYSTEM_NO_KEYS\"] = \"keySystemNoKeys\";\n  ErrorDetails[\"KEY_SYSTEM_NO_ACCESS\"] = \"keySystemNoAccess\";\n  ErrorDetails[\"KEY_SYSTEM_NO_SESSION\"] = \"keySystemNoSession\";\n  ErrorDetails[\"KEY_SYSTEM_NO_CONFIGURED_LICENSE\"] = \"keySystemNoConfiguredLicense\";\n  ErrorDetails[\"KEY_SYSTEM_LICENSE_REQUEST_FAILED\"] = \"keySystemLicenseRequestFailed\";\n  ErrorDetails[\"KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED\"] = \"keySystemServerCertificateRequestFailed\";\n  ErrorDetails[\"KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED\"] = \"keySystemServerCertificateUpdateFailed\";\n  ErrorDetails[\"KEY_SYSTEM_SESSION_UPDATE_FAILED\"] = \"keySystemSessionUpdateFailed\";\n  ErrorDetails[\"KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED\"] = \"keySystemStatusOutputRestricted\";\n  ErrorDetails[\"KEY_SYSTEM_STATUS_INTERNAL_ERROR\"] = \"keySystemStatusInternalError\";\n  ErrorDetails[\"MANIFEST_LOAD_ERROR\"] = \"manifestLoadError\";\n  ErrorDetails[\"MANIFEST_LOAD_TIMEOUT\"] = \"manifestLoadTimeOut\";\n  ErrorDetails[\"MANIFEST_PARSING_ERROR\"] = \"manifestParsingError\";\n  ErrorDetails[\"MANIFEST_INCOMPATIBLE_CODECS_ERROR\"] = \"manifestIncompatibleCodecsError\";\n  ErrorDetails[\"LEVEL_EMPTY_ERROR\"] = \"levelEmptyError\";\n  ErrorDetails[\"LEVEL_LOAD_ERROR\"] = \"levelLoadError\";\n  ErrorDetails[\"LEVEL_LOAD_TIMEOUT\"] = \"levelLoadTimeOut\";\n  ErrorDetails[\"LEVEL_PARSING_ERROR\"] = \"levelParsingError\";\n  ErrorDetails[\"LEVEL_SWITCH_ERROR\"] = \"levelSwitchError\";\n  ErrorDetails[\"AUDIO_TRACK_LOAD_ERROR\"] = \"audioTrackLoadError\";\n  ErrorDetails[\"AUDIO_TRACK_LOAD_TIMEOUT\"] = \"audioTrackLoadTimeOut\";\n  ErrorDetails[\"SUBTITLE_LOAD_ERROR\"] = \"subtitleTrackLoadError\";\n  ErrorDetails[\"SUBTITLE_TRACK_LOAD_TIMEOUT\"] = \"subtitleTrackLoadTimeOut\";\n  ErrorDetails[\"FRAG_LOAD_ERROR\"] = \"fragLoadError\";\n  ErrorDetails[\"FRAG_LOAD_TIMEOUT\"] = \"fragLoadTimeOut\";\n  ErrorDetails[\"FRAG_DECRYPT_ERROR\"] = \"fragDecryptError\";\n  ErrorDetails[\"FRAG_PARSING_ERROR\"] = \"fragParsingError\";\n  ErrorDetails[\"FRAG_GAP\"] = \"fragGap\";\n  ErrorDetails[\"REMUX_ALLOC_ERROR\"] = \"remuxAllocError\";\n  ErrorDetails[\"KEY_LOAD_ERROR\"] = \"keyLoadError\";\n  ErrorDetails[\"KEY_LOAD_TIMEOUT\"] = \"keyLoadTimeOut\";\n  ErrorDetails[\"BUFFER_ADD_CODEC_ERROR\"] = \"bufferAddCodecError\";\n  ErrorDetails[\"BUFFER_INCOMPATIBLE_CODECS_ERROR\"] = \"bufferIncompatibleCodecsError\";\n  ErrorDetails[\"BUFFER_APPEND_ERROR\"] = \"bufferAppendError\";\n  ErrorDetails[\"BUFFER_APPENDING_ERROR\"] = \"bufferAppendingError\";\n  ErrorDetails[\"BUFFER_STALLED_ERROR\"] = \"bufferStalledError\";\n  ErrorDetails[\"BUFFER_FULL_ERROR\"] = \"bufferFullError\";\n  ErrorDetails[\"BUFFER_SEEK_OVER_HOLE\"] = \"bufferSeekOverHole\";\n  ErrorDetails[\"BUFFER_NUDGE_ON_STALL\"] = \"bufferNudgeOnStall\";\n  ErrorDetails[\"INTERNAL_EXCEPTION\"] = \"internalException\";\n  ErrorDetails[\"INTERNAL_ABORTED\"] = \"aborted\";\n  ErrorDetails[\"UNKNOWN\"] = \"unknown\";\n  return ErrorDetails;\n}({});\n\nconst noop = function noop() {};\nconst fakeLogger = {\n  trace: noop,\n  debug: noop,\n  log: noop,\n  warn: noop,\n  info: noop,\n  error: noop\n};\nlet exportedLogger = fakeLogger;\n\n// let lastCallTime;\n// function formatMsgWithTimeInfo(type, msg) {\n//   const now = Date.now();\n//   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';\n//   lastCallTime = now;\n//   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';\n//   return msg;\n// }\n\nfunction consolePrintFn(type) {\n  const func = self.console[type];\n  if (func) {\n    return func.bind(self.console, `[${type}] >`);\n  }\n  return noop;\n}\nfunction exportLoggerFunctions(debugConfig, ...functions) {\n  functions.forEach(function (type) {\n    exportedLogger[type] = debugConfig[type] ? debugConfig[type].bind(debugConfig) : consolePrintFn(type);\n  });\n}\nfunction enableLogs(debugConfig, id) {\n  // check that console is available\n  if (typeof console === 'object' && debugConfig === true || typeof debugConfig === 'object') {\n    exportLoggerFunctions(debugConfig,\n    // Remove out from list here to hard-disable a log-level\n    // 'trace',\n    'debug', 'log', 'info', 'warn', 'error');\n    // Some browsers don't allow to use bind on console object anyway\n    // fallback to default if needed\n    try {\n      exportedLogger.log(`Debug logs enabled for \"${id}\" in hls.js version ${\"1.5.13\"}`);\n    } catch (e) {\n      exportedLogger = fakeLogger;\n    }\n  } else {\n    exportedLogger = fakeLogger;\n  }\n}\nconst logger = exportedLogger;\n\nconst DECIMAL_RESOLUTION_REGEX = /^(\\d+)x(\\d+)$/;\nconst ATTR_LIST_REGEX = /(.+?)=(\".*?\"|.*?)(?:,|$)/g;\n\n// adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js\nclass AttrList {\n  constructor(attrs) {\n    if (typeof attrs === 'string') {\n      attrs = AttrList.parseAttrList(attrs);\n    }\n    _extends(this, attrs);\n  }\n  get clientAttrs() {\n    return Object.keys(this).filter(attr => attr.substring(0, 2) === 'X-');\n  }\n  decimalInteger(attrName) {\n    const intValue = parseInt(this[attrName], 10);\n    if (intValue > Number.MAX_SAFE_INTEGER) {\n      return Infinity;\n    }\n    return intValue;\n  }\n  hexadecimalInteger(attrName) {\n    if (this[attrName]) {\n      let stringValue = (this[attrName] || '0x').slice(2);\n      stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;\n      const value = new Uint8Array(stringValue.length / 2);\n      for (let i = 0; i < stringValue.length / 2; i++) {\n        value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);\n      }\n      return value;\n    } else {\n      return null;\n    }\n  }\n  hexadecimalIntegerAsNumber(attrName) {\n    const intValue = parseInt(this[attrName], 16);\n    if (intValue > Number.MAX_SAFE_INTEGER) {\n      return Infinity;\n    }\n    return intValue;\n  }\n  decimalFloatingPoint(attrName) {\n    return parseFloat(this[attrName]);\n  }\n  optionalFloat(attrName, defaultValue) {\n    const value = this[attrName];\n    return value ? parseFloat(value) : defaultValue;\n  }\n  enumeratedString(attrName) {\n    return this[attrName];\n  }\n  bool(attrName) {\n    return this[attrName] === 'YES';\n  }\n  decimalResolution(attrName) {\n    const res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);\n    if (res === null) {\n      return undefined;\n    }\n    return {\n      width: parseInt(res[1], 10),\n      height: parseInt(res[2], 10)\n    };\n  }\n  static parseAttrList(input) {\n    let match;\n    const attrs = {};\n    const quote = '\"';\n    ATTR_LIST_REGEX.lastIndex = 0;\n    while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {\n      let value = match[2];\n      if (value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1) {\n        value = value.slice(1, -1);\n      }\n      const name = match[1].trim();\n      attrs[name] = value;\n    }\n    return attrs;\n  }\n}\n\n// Avoid exporting const enum so that these values can be inlined\n\nfunction isDateRangeCueAttribute(attrName) {\n  return attrName !== \"ID\" && attrName !== \"CLASS\" && attrName !== \"START-DATE\" && attrName !== \"DURATION\" && attrName !== \"END-DATE\" && attrName !== \"END-ON-NEXT\";\n}\nfunction isSCTE35Attribute(attrName) {\n  return attrName === \"SCTE35-OUT\" || attrName === \"SCTE35-IN\";\n}\nclass DateRange {\n  constructor(dateRangeAttr, dateRangeWithSameId) {\n    this.attr = void 0;\n    this._startDate = void 0;\n    this._endDate = void 0;\n    this._badValueForSameId = void 0;\n    if (dateRangeWithSameId) {\n      const previousAttr = dateRangeWithSameId.attr;\n      for (const key in previousAttr) {\n        if (Object.prototype.hasOwnProperty.call(dateRangeAttr, key) && dateRangeAttr[key] !== previousAttr[key]) {\n          logger.warn(`DATERANGE tag attribute: \"${key}\" does not match for tags with ID: \"${dateRangeAttr.ID}\"`);\n          this._badValueForSameId = key;\n          break;\n        }\n      }\n      // Merge DateRange tags with the same ID\n      dateRangeAttr = _extends(new AttrList({}), previousAttr, dateRangeAttr);\n    }\n    this.attr = dateRangeAttr;\n    this._startDate = new Date(dateRangeAttr[\"START-DATE\"]);\n    if (\"END-DATE\" in this.attr) {\n      const endDate = new Date(this.attr[\"END-DATE\"]);\n      if (isFiniteNumber(endDate.getTime())) {\n        this._endDate = endDate;\n      }\n    }\n  }\n  get id() {\n    return this.attr.ID;\n  }\n  get class() {\n    return this.attr.CLASS;\n  }\n  get startDate() {\n    return this._startDate;\n  }\n  get endDate() {\n    if (this._endDate) {\n      return this._endDate;\n    }\n    const duration = this.duration;\n    if (duration !== null) {\n      return new Date(this._startDate.getTime() + duration * 1000);\n    }\n    return null;\n  }\n  get duration() {\n    if (\"DURATION\" in this.attr) {\n      const duration = this.attr.decimalFloatingPoint(\"DURATION\");\n      if (isFiniteNumber(duration)) {\n        return duration;\n      }\n    } else if (this._endDate) {\n      return (this._endDate.getTime() - this._startDate.getTime()) / 1000;\n    }\n    return null;\n  }\n  get plannedDuration() {\n    if (\"PLANNED-DURATION\" in this.attr) {\n      return this.attr.decimalFloatingPoint(\"PLANNED-DURATION\");\n    }\n    return null;\n  }\n  get endOnNext() {\n    return this.attr.bool(\"END-ON-NEXT\");\n  }\n  get isValid() {\n    return !!this.id && !this._badValueForSameId && isFiniteNumber(this.startDate.getTime()) && (this.duration === null || this.duration >= 0) && (!this.endOnNext || !!this.class);\n  }\n}\n\nclass LoadStats {\n  constructor() {\n    this.aborted = false;\n    this.loaded = 0;\n    this.retry = 0;\n    this.total = 0;\n    this.chunkCount = 0;\n    this.bwEstimate = 0;\n    this.loading = {\n      start: 0,\n      first: 0,\n      end: 0\n    };\n    this.parsing = {\n      start: 0,\n      end: 0\n    };\n    this.buffering = {\n      start: 0,\n      first: 0,\n      end: 0\n    };\n  }\n}\n\nvar ElementaryStreamTypes = {\n  AUDIO: \"audio\",\n  VIDEO: \"video\",\n  AUDIOVIDEO: \"audiovideo\"\n};\nclass BaseSegment {\n  constructor(baseurl) {\n    this._byteRange = null;\n    this._url = null;\n    // baseurl is the URL to the playlist\n    this.baseurl = void 0;\n    // relurl is the portion of the URL that comes from inside the playlist.\n    this.relurl = void 0;\n    // Holds the types of data this fragment supports\n    this.elementaryStreams = {\n      [ElementaryStreamTypes.AUDIO]: null,\n      [ElementaryStreamTypes.VIDEO]: null,\n      [ElementaryStreamTypes.AUDIOVIDEO]: null\n    };\n    this.baseurl = baseurl;\n  }\n\n  // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array\n  setByteRange(value, previous) {\n    const params = value.split('@', 2);\n    let start;\n    if (params.length === 1) {\n      start = (previous == null ? void 0 : previous.byteRangeEndOffset) || 0;\n    } else {\n      start = parseInt(params[1]);\n    }\n    this._byteRange = [start, parseInt(params[0]) + start];\n  }\n  get byteRange() {\n    if (!this._byteRange) {\n      return [];\n    }\n    return this._byteRange;\n  }\n  get byteRangeStartOffset() {\n    return this.byteRange[0];\n  }\n  get byteRangeEndOffset() {\n    return this.byteRange[1];\n  }\n  get url() {\n    if (!this._url && this.baseurl && this.relurl) {\n      this._url = urlToolkitExports.buildAbsoluteURL(this.baseurl, this.relurl, {\n        alwaysNormalize: true\n      });\n    }\n    return this._url || '';\n  }\n  set url(value) {\n    this._url = value;\n  }\n}\n\n/**\n * Object representing parsed data from an HLS Segment. Found in {@link hls.js#LevelDetails.fragments}.\n */\nclass Fragment extends BaseSegment {\n  constructor(type, baseurl) {\n    super(baseurl);\n    this._decryptdata = null;\n    this.rawProgramDateTime = null;\n    this.programDateTime = null;\n    this.tagList = [];\n    // EXTINF has to be present for a m3u8 to be considered valid\n    this.duration = 0;\n    // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'\n    this.sn = 0;\n    // levelkeys are the EXT-X-KEY tags that apply to this segment for decryption\n    // core difference from the private field _decryptdata is the lack of the initialized IV\n    // _decryptdata will set the IV for this segment based on the segment number in the fragment\n    this.levelkeys = void 0;\n    // A string representing the fragment type\n    this.type = void 0;\n    // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading\n    this.loader = null;\n    // A reference to the key loader. Set while the key is loading, and removed afterwards. Used to abort key loading\n    this.keyLoader = null;\n    // The level/track index to which the fragment belongs\n    this.level = -1;\n    // The continuity counter of the fragment\n    this.cc = 0;\n    // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n    this.startPTS = void 0;\n    // The ending Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n    this.endPTS = void 0;\n    // The starting Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n    this.startDTS = void 0;\n    // The ending Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n    this.endDTS = void 0;\n    // The start time of the fragment, as listed in the manifest. Updated after transmux complete.\n    this.start = 0;\n    // Set by `updateFragPTSDTS` in level-helper\n    this.deltaPTS = void 0;\n    // The maximum starting Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n    this.maxStartPTS = void 0;\n    // The minimum ending Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n    this.minEndPTS = void 0;\n    // Load/parse timing information\n    this.stats = new LoadStats();\n    // Init Segment bytes (unset for media segments)\n    this.data = void 0;\n    // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered\n    this.bitrateTest = false;\n    // #EXTINF  segment title\n    this.title = null;\n    // The Media Initialization Section for this segment\n    this.initSegment = null;\n    // Fragment is the last fragment in the media playlist\n    this.endList = void 0;\n    // Fragment is marked by an EXT-X-GAP tag indicating that it does not contain media data and should not be loaded\n    this.gap = void 0;\n    // Deprecated\n    this.urlId = 0;\n    this.type = type;\n  }\n  get decryptdata() {\n    const {\n      levelkeys\n    } = this;\n    if (!levelkeys && !this._decryptdata) {\n      return null;\n    }\n    if (!this._decryptdata && this.levelkeys && !this.levelkeys.NONE) {\n      const key = this.levelkeys.identity;\n      if (key) {\n        this._decryptdata = key.getDecryptData(this.sn);\n      } else {\n        const keyFormats = Object.keys(this.levelkeys);\n        if (keyFormats.length === 1) {\n          return this._decryptdata = this.levelkeys[keyFormats[0]].getDecryptData(this.sn);\n        }\n      }\n    }\n    return this._decryptdata;\n  }\n  get end() {\n    return this.start + this.duration;\n  }\n  get endProgramDateTime() {\n    if (this.programDateTime === null) {\n      return null;\n    }\n    if (!isFiniteNumber(this.programDateTime)) {\n      return null;\n    }\n    const duration = !isFiniteNumber(this.duration) ? 0 : this.duration;\n    return this.programDateTime + duration * 1000;\n  }\n  get encrypted() {\n    var _this$_decryptdata;\n    // At the m3u8-parser level we need to add support for manifest signalled keyformats\n    // when we want the fragment to start reporting that it is encrypted.\n    // Currently, keyFormat will only be set for identity keys\n    if ((_this$_decryptdata = this._decryptdata) != null && _this$_decryptdata.encrypted) {\n      return true;\n    } else if (this.levelkeys) {\n      const keyFormats = Object.keys(this.levelkeys);\n      const len = keyFormats.length;\n      if (len > 1 || len === 1 && this.levelkeys[keyFormats[0]].encrypted) {\n        return true;\n      }\n    }\n    return false;\n  }\n  setKeyFormat(keyFormat) {\n    if (this.levelkeys) {\n      const key = this.levelkeys[keyFormat];\n      if (key && !this._decryptdata) {\n        this._decryptdata = key.getDecryptData(this.sn);\n      }\n    }\n  }\n  abortRequests() {\n    var _this$loader, _this$keyLoader;\n    (_this$loader = this.loader) == null ? void 0 : _this$loader.abort();\n    (_this$keyLoader = this.keyLoader) == null ? void 0 : _this$keyLoader.abort();\n  }\n  setElementaryStreamInfo(type, startPTS, endPTS, startDTS, endDTS, partial = false) {\n    const {\n      elementaryStreams\n    } = this;\n    const info = elementaryStreams[type];\n    if (!info) {\n      elementaryStreams[type] = {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS,\n        partial\n      };\n      return;\n    }\n    info.startPTS = Math.min(info.startPTS, startPTS);\n    info.endPTS = Math.max(info.endPTS, endPTS);\n    info.startDTS = Math.min(info.startDTS, startDTS);\n    info.endDTS = Math.max(info.endDTS, endDTS);\n  }\n  clearElementaryStreamInfo() {\n    const {\n      elementaryStreams\n    } = this;\n    elementaryStreams[ElementaryStreamTypes.AUDIO] = null;\n    elementaryStreams[ElementaryStreamTypes.VIDEO] = null;\n    elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;\n  }\n}\n\n/**\n * Object representing parsed data from an HLS Partial Segment. Found in {@link hls.js#LevelDetails.partList}.\n */\nclass Part extends BaseSegment {\n  constructor(partAttrs, frag, baseurl, index, previous) {\n    super(baseurl);\n    this.fragOffset = 0;\n    this.duration = 0;\n    this.gap = false;\n    this.independent = false;\n    this.relurl = void 0;\n    this.fragment = void 0;\n    this.index = void 0;\n    this.stats = new LoadStats();\n    this.duration = partAttrs.decimalFloatingPoint('DURATION');\n    this.gap = partAttrs.bool('GAP');\n    this.independent = partAttrs.bool('INDEPENDENT');\n    this.relurl = partAttrs.enumeratedString('URI');\n    this.fragment = frag;\n    this.index = index;\n    const byteRange = partAttrs.enumeratedString('BYTERANGE');\n    if (byteRange) {\n      this.setByteRange(byteRange, previous);\n    }\n    if (previous) {\n      this.fragOffset = previous.fragOffset + previous.duration;\n    }\n  }\n  get start() {\n    return this.fragment.start + this.fragOffset;\n  }\n  get end() {\n    return this.start + this.duration;\n  }\n  get loaded() {\n    const {\n      elementaryStreams\n    } = this;\n    return !!(elementaryStreams.audio || elementaryStreams.video || elementaryStreams.audiovideo);\n  }\n}\n\nconst DEFAULT_TARGET_DURATION = 10;\n\n/**\n * Object representing parsed data from an HLS Media Playlist. Found in {@link hls.js#Level.details}.\n */\nclass LevelDetails {\n  constructor(baseUrl) {\n    this.PTSKnown = false;\n    this.alignedSliding = false;\n    this.averagetargetduration = void 0;\n    this.endCC = 0;\n    this.endSN = 0;\n    this.fragments = void 0;\n    this.fragmentHint = void 0;\n    this.partList = null;\n    this.dateRanges = void 0;\n    this.live = true;\n    this.ageHeader = 0;\n    this.advancedDateTime = void 0;\n    this.updated = true;\n    this.advanced = true;\n    this.availabilityDelay = void 0;\n    // Manifest reload synchronization\n    this.misses = 0;\n    this.startCC = 0;\n    this.startSN = 0;\n    this.startTimeOffset = null;\n    this.targetduration = 0;\n    this.totalduration = 0;\n    this.type = null;\n    this.url = void 0;\n    this.m3u8 = '';\n    this.version = null;\n    this.canBlockReload = false;\n    this.canSkipUntil = 0;\n    this.canSkipDateRanges = false;\n    this.skippedSegments = 0;\n    this.recentlyRemovedDateranges = void 0;\n    this.partHoldBack = 0;\n    this.holdBack = 0;\n    this.partTarget = 0;\n    this.preloadHint = void 0;\n    this.renditionReports = void 0;\n    this.tuneInGoal = 0;\n    this.deltaUpdateFailed = void 0;\n    this.driftStartTime = 0;\n    this.driftEndTime = 0;\n    this.driftStart = 0;\n    this.driftEnd = 0;\n    this.encryptedFragments = void 0;\n    this.playlistParsingError = null;\n    this.variableList = null;\n    this.hasVariableRefs = false;\n    this.fragments = [];\n    this.encryptedFragments = [];\n    this.dateRanges = {};\n    this.url = baseUrl;\n  }\n  reloaded(previous) {\n    if (!previous) {\n      this.advanced = true;\n      this.updated = true;\n      return;\n    }\n    const partSnDiff = this.lastPartSn - previous.lastPartSn;\n    const partIndexDiff = this.lastPartIndex - previous.lastPartIndex;\n    this.updated = this.endSN !== previous.endSN || !!partIndexDiff || !!partSnDiff || !this.live;\n    this.advanced = this.endSN > previous.endSN || partSnDiff > 0 || partSnDiff === 0 && partIndexDiff > 0;\n    if (this.updated || this.advanced) {\n      this.misses = Math.floor(previous.misses * 0.6);\n    } else {\n      this.misses = previous.misses + 1;\n    }\n    this.availabilityDelay = previous.availabilityDelay;\n  }\n  get hasProgramDateTime() {\n    if (this.fragments.length) {\n      return isFiniteNumber(this.fragments[this.fragments.length - 1].programDateTime);\n    }\n    return false;\n  }\n  get levelTargetDuration() {\n    return this.averagetargetduration || this.targetduration || DEFAULT_TARGET_DURATION;\n  }\n  get drift() {\n    const runTime = this.driftEndTime - this.driftStartTime;\n    if (runTime > 0) {\n      const runDuration = this.driftEnd - this.driftStart;\n      return runDuration * 1000 / runTime;\n    }\n    return 1;\n  }\n  get edge() {\n    return this.partEnd || this.fragmentEnd;\n  }\n  get partEnd() {\n    var _this$partList;\n    if ((_this$partList = this.partList) != null && _this$partList.length) {\n      return this.partList[this.partList.length - 1].end;\n    }\n    return this.fragmentEnd;\n  }\n  get fragmentEnd() {\n    var _this$fragments;\n    if ((_this$fragments = this.fragments) != null && _this$fragments.length) {\n      return this.fragments[this.fragments.length - 1].end;\n    }\n    return 0;\n  }\n  get age() {\n    if (this.advancedDateTime) {\n      return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;\n    }\n    return 0;\n  }\n  get lastPartIndex() {\n    var _this$partList2;\n    if ((_this$partList2 = this.partList) != null && _this$partList2.length) {\n      return this.partList[this.partList.length - 1].index;\n    }\n    return -1;\n  }\n  get lastPartSn() {\n    var _this$partList3;\n    if ((_this$partList3 = this.partList) != null && _this$partList3.length) {\n      return this.partList[this.partList.length - 1].fragment.sn;\n    }\n    return this.endSN;\n  }\n}\n\nfunction base64Decode(base64encodedStr) {\n  return Uint8Array.from(atob(base64encodedStr), c => c.charCodeAt(0));\n}\n\nfunction getKeyIdBytes(str) {\n  const keyIdbytes = strToUtf8array(str).subarray(0, 16);\n  const paddedkeyIdbytes = new Uint8Array(16);\n  paddedkeyIdbytes.set(keyIdbytes, 16 - keyIdbytes.length);\n  return paddedkeyIdbytes;\n}\nfunction changeEndianness(keyId) {\n  const swap = function swap(array, from, to) {\n    const cur = array[from];\n    array[from] = array[to];\n    array[to] = cur;\n  };\n  swap(keyId, 0, 3);\n  swap(keyId, 1, 2);\n  swap(keyId, 4, 5);\n  swap(keyId, 6, 7);\n}\nfunction convertDataUriToArrayBytes(uri) {\n  // data:[<media type][;attribute=value][;base64],<data>\n  const colonsplit = uri.split(':');\n  let keydata = null;\n  if (colonsplit[0] === 'data' && colonsplit.length === 2) {\n    const semicolonsplit = colonsplit[1].split(';');\n    const commasplit = semicolonsplit[semicolonsplit.length - 1].split(',');\n    if (commasplit.length === 2) {\n      const isbase64 = commasplit[0] === 'base64';\n      const data = commasplit[1];\n      if (isbase64) {\n        semicolonsplit.splice(-1, 1); // remove from processing\n        keydata = base64Decode(data);\n      } else {\n        keydata = getKeyIdBytes(data);\n      }\n    }\n  }\n  return keydata;\n}\nfunction strToUtf8array(str) {\n  return Uint8Array.from(unescape(encodeURIComponent(str)), c => c.charCodeAt(0));\n}\n\n/** returns `undefined` is `self` is missing, e.g. in node */\nconst optionalSelf = typeof self !== 'undefined' ? self : undefined;\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess\n */\nvar KeySystems = {\n  CLEARKEY: \"org.w3.clearkey\",\n  FAIRPLAY: \"com.apple.fps\",\n  PLAYREADY: \"com.microsoft.playready\",\n  WIDEVINE: \"com.widevine.alpha\"\n};\n\n// Playlist #EXT-X-KEY KEYFORMAT values\nvar KeySystemFormats = {\n  CLEARKEY: \"org.w3.clearkey\",\n  FAIRPLAY: \"com.apple.streamingkeydelivery\",\n  PLAYREADY: \"com.microsoft.playready\",\n  WIDEVINE: \"urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed\"\n};\nfunction keySystemFormatToKeySystemDomain(format) {\n  switch (format) {\n    case KeySystemFormats.FAIRPLAY:\n      return KeySystems.FAIRPLAY;\n    case KeySystemFormats.PLAYREADY:\n      return KeySystems.PLAYREADY;\n    case KeySystemFormats.WIDEVINE:\n      return KeySystems.WIDEVINE;\n    case KeySystemFormats.CLEARKEY:\n      return KeySystems.CLEARKEY;\n  }\n}\n\n// System IDs for which we can extract a key ID from \"encrypted\" event PSSH\nvar KeySystemIds = {\n  WIDEVINE: \"edef8ba979d64acea3c827dcd51d21ed\"\n};\nfunction keySystemIdToKeySystemDomain(systemId) {\n  if (systemId === KeySystemIds.WIDEVINE) {\n    return KeySystems.WIDEVINE;\n    // } else if (systemId === KeySystemIds.PLAYREADY) {\n    //   return KeySystems.PLAYREADY;\n    // } else if (systemId === KeySystemIds.CENC || systemId === KeySystemIds.CLEARKEY) {\n    //   return KeySystems.CLEARKEY;\n  }\n}\nfunction keySystemDomainToKeySystemFormat(keySystem) {\n  switch (keySystem) {\n    case KeySystems.FAIRPLAY:\n      return KeySystemFormats.FAIRPLAY;\n    case KeySystems.PLAYREADY:\n      return KeySystemFormats.PLAYREADY;\n    case KeySystems.WIDEVINE:\n      return KeySystemFormats.WIDEVINE;\n    case KeySystems.CLEARKEY:\n      return KeySystemFormats.CLEARKEY;\n  }\n}\nfunction getKeySystemsForConfig(config) {\n  const {\n    drmSystems,\n    widevineLicenseUrl\n  } = config;\n  const keySystemsToAttempt = drmSystems ? [KeySystems.FAIRPLAY, KeySystems.WIDEVINE, KeySystems.PLAYREADY, KeySystems.CLEARKEY].filter(keySystem => !!drmSystems[keySystem]) : [];\n  if (!keySystemsToAttempt[KeySystems.WIDEVINE] && widevineLicenseUrl) {\n    keySystemsToAttempt.push(KeySystems.WIDEVINE);\n  }\n  return keySystemsToAttempt;\n}\nconst requestMediaKeySystemAccess = function (_optionalSelf$navigat) {\n  if (optionalSelf != null && (_optionalSelf$navigat = optionalSelf.navigator) != null && _optionalSelf$navigat.requestMediaKeySystemAccess) {\n    return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);\n  } else {\n    return null;\n  }\n}();\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration\n */\nfunction getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {\n  let initDataTypes;\n  switch (keySystem) {\n    case KeySystems.FAIRPLAY:\n      initDataTypes = ['cenc', 'sinf'];\n      break;\n    case KeySystems.WIDEVINE:\n    case KeySystems.PLAYREADY:\n      initDataTypes = ['cenc'];\n      break;\n    case KeySystems.CLEARKEY:\n      initDataTypes = ['cenc', 'keyids'];\n      break;\n    default:\n      throw new Error(`Unknown key-system: ${keySystem}`);\n  }\n  return createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions);\n}\nfunction createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions) {\n  const baseConfig = {\n    initDataTypes: initDataTypes,\n    persistentState: drmSystemOptions.persistentState || 'optional',\n    distinctiveIdentifier: drmSystemOptions.distinctiveIdentifier || 'optional',\n    sessionTypes: drmSystemOptions.sessionTypes || [drmSystemOptions.sessionType || 'temporary'],\n    audioCapabilities: audioCodecs.map(codec => ({\n      contentType: `audio/mp4; codecs=\"${codec}\"`,\n      robustness: drmSystemOptions.audioRobustness || '',\n      encryptionScheme: drmSystemOptions.audioEncryptionScheme || null\n    })),\n    videoCapabilities: videoCodecs.map(codec => ({\n      contentType: `video/mp4; codecs=\"${codec}\"`,\n      robustness: drmSystemOptions.videoRobustness || '',\n      encryptionScheme: drmSystemOptions.videoEncryptionScheme || null\n    }))\n  };\n  return [baseConfig];\n}\n\nfunction sliceUint8(array, start, end) {\n  // @ts-expect-error This polyfills IE11 usage of Uint8Array slice.\n  // It always exists in the TypeScript definition so fails, but it fails at runtime on IE11.\n  return Uint8Array.prototype.slice ? array.slice(start, end) : new Uint8Array(Array.prototype.slice.call(array, start, end));\n}\n\n// breaking up those two types in order to clarify what is happening in the decoding path.\n\n/**\n * Returns true if an ID3 header can be found at offset in data\n * @param data - The data to search\n * @param offset - The offset at which to start searching\n */\nconst isHeader$2 = (data, offset) => {\n  /*\n   * http://id3.org/id3v2.3.0\n   * [0]     = 'I'\n   * [1]     = 'D'\n   * [2]     = '3'\n   * [3,4]   = {Version}\n   * [5]     = {Flags}\n   * [6-9]   = {ID3 Size}\n   *\n   * An ID3v2 tag can be detected with the following pattern:\n   *  $49 44 33 yy yy xx zz zz zz zz\n   * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80\n   */\n  if (offset + 10 <= data.length) {\n    // look for 'ID3' identifier\n    if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {\n      // check version is within range\n      if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n        // check size is within range\n        if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\n          return true;\n        }\n      }\n    }\n  }\n  return false;\n};\n\n/**\n * Returns true if an ID3 footer can be found at offset in data\n * @param data - The data to search\n * @param offset - The offset at which to start searching\n */\nconst isFooter = (data, offset) => {\n  /*\n   * The footer is a copy of the header, but with a different identifier\n   */\n  if (offset + 10 <= data.length) {\n    // look for '3DI' identifier\n    if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {\n      // check version is within range\n      if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n        // check size is within range\n        if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\n          return true;\n        }\n      }\n    }\n  }\n  return false;\n};\n\n/**\n * Returns any adjacent ID3 tags found in data starting at offset, as one block of data\n * @param data - The data to search in\n * @param offset - The offset at which to start searching\n * @returns the block of data containing any ID3 tags found\n * or *undefined* if no header is found at the starting offset\n */\nconst getID3Data = (data, offset) => {\n  const front = offset;\n  let length = 0;\n  while (isHeader$2(data, offset)) {\n    // ID3 header is 10 bytes\n    length += 10;\n    const size = readSize(data, offset + 6);\n    length += size;\n    if (isFooter(data, offset + 10)) {\n      // ID3 footer is 10 bytes\n      length += 10;\n    }\n    offset += length;\n  }\n  if (length > 0) {\n    return data.subarray(front, front + length);\n  }\n  return undefined;\n};\nconst readSize = (data, offset) => {\n  let size = 0;\n  size = (data[offset] & 0x7f) << 21;\n  size |= (data[offset + 1] & 0x7f) << 14;\n  size |= (data[offset + 2] & 0x7f) << 7;\n  size |= data[offset + 3] & 0x7f;\n  return size;\n};\nconst canParse$2 = (data, offset) => {\n  return isHeader$2(data, offset) && readSize(data, offset + 6) + 10 <= data.length - offset;\n};\n\n/**\n * Searches for the Elementary Stream timestamp found in the ID3 data chunk\n * @param data - Block of data containing one or more ID3 tags\n */\nconst getTimeStamp = data => {\n  const frames = getID3Frames(data);\n  for (let i = 0; i < frames.length; i++) {\n    const frame = frames[i];\n    if (isTimeStampFrame(frame)) {\n      return readTimeStamp(frame);\n    }\n  }\n  return undefined;\n};\n\n/**\n * Returns true if the ID3 frame is an Elementary Stream timestamp frame\n */\nconst isTimeStampFrame = frame => {\n  return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';\n};\nconst getFrameData = data => {\n  /*\n  Frame ID       $xx xx xx xx (four characters)\n  Size           $xx xx xx xx\n  Flags          $xx xx\n  */\n  const type = String.fromCharCode(data[0], data[1], data[2], data[3]);\n  const size = readSize(data, 4);\n\n  // skip frame id, size, and flags\n  const offset = 10;\n  return {\n    type,\n    size,\n    data: data.subarray(offset, offset + size)\n  };\n};\n\n/**\n * Returns an array of ID3 frames found in all the ID3 tags in the id3Data\n * @param id3Data - The ID3 data containing one or more ID3 tags\n */\nconst getID3Frames = id3Data => {\n  let offset = 0;\n  const frames = [];\n  while (isHeader$2(id3Data, offset)) {\n    const size = readSize(id3Data, offset + 6);\n    // skip past ID3 header\n    offset += 10;\n    const end = offset + size;\n    // loop through frames in the ID3 tag\n    while (offset + 8 < end) {\n      const frameData = getFrameData(id3Data.subarray(offset));\n      const frame = decodeFrame(frameData);\n      if (frame) {\n        frames.push(frame);\n      }\n\n      // skip frame header and frame data\n      offset += frameData.size + 10;\n    }\n    if (isFooter(id3Data, offset)) {\n      offset += 10;\n    }\n  }\n  return frames;\n};\nconst decodeFrame = frame => {\n  if (frame.type === 'PRIV') {\n    return decodePrivFrame(frame);\n  } else if (frame.type[0] === 'W') {\n    return decodeURLFrame(frame);\n  }\n  return decodeTextFrame(frame);\n};\nconst decodePrivFrame = frame => {\n  /*\n  Format: <text string>\\0<binary data>\n  */\n  if (frame.size < 2) {\n    return undefined;\n  }\n  const owner = utf8ArrayToStr(frame.data, true);\n  const privateData = new Uint8Array(frame.data.subarray(owner.length + 1));\n  return {\n    key: frame.type,\n    info: owner,\n    data: privateData.buffer\n  };\n};\nconst decodeTextFrame = frame => {\n  if (frame.size < 2) {\n    return undefined;\n  }\n  if (frame.type === 'TXXX') {\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Description}\\0{Value}\n    */\n    let index = 1;\n    const description = utf8ArrayToStr(frame.data.subarray(index), true);\n    index += description.length + 1;\n    const value = utf8ArrayToStr(frame.data.subarray(index));\n    return {\n      key: frame.type,\n      info: description,\n      data: value\n    };\n  }\n  /*\n  Format:\n  [0]   = {Text Encoding}\n  [1-?] = {Value}\n  */\n  const text = utf8ArrayToStr(frame.data.subarray(1));\n  return {\n    key: frame.type,\n    data: text\n  };\n};\nconst decodeURLFrame = frame => {\n  if (frame.type === 'WXXX') {\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Description}\\0{URL}\n    */\n    if (frame.size < 2) {\n      return undefined;\n    }\n    let index = 1;\n    const description = utf8ArrayToStr(frame.data.subarray(index), true);\n    index += description.length + 1;\n    const value = utf8ArrayToStr(frame.data.subarray(index));\n    return {\n      key: frame.type,\n      info: description,\n      data: value\n    };\n  }\n  /*\n  Format:\n  [0-?] = {URL}\n  */\n  const url = utf8ArrayToStr(frame.data);\n  return {\n    key: frame.type,\n    data: url\n  };\n};\nconst readTimeStamp = timeStampFrame => {\n  if (timeStampFrame.data.byteLength === 8) {\n    const data = new Uint8Array(timeStampFrame.data);\n    // timestamp is 33 bit expressed as a big-endian eight-octet number,\n    // with the upper 31 bits set to zero.\n    const pts33Bit = data[3] & 0x1;\n    let timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];\n    timestamp /= 45;\n    if (pts33Bit) {\n      timestamp += 47721858.84;\n    } // 2^32 / 90\n\n    return Math.round(timestamp);\n  }\n  return undefined;\n};\n\n// http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\n// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n/* utf.js - UTF-8 <=> UTF-16 convertion\n *\n * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0\n * LastModified: Dec 25 1999\n * This library is free.  You can redistribute it and/or modify it.\n */\nconst utf8ArrayToStr = (array, exitOnNull = false) => {\n  const decoder = getTextDecoder();\n  if (decoder) {\n    const decoded = decoder.decode(array);\n    if (exitOnNull) {\n      // grab up to the first null\n      const idx = decoded.indexOf('\\0');\n      return idx !== -1 ? decoded.substring(0, idx) : decoded;\n    }\n\n    // remove any null characters\n    return decoded.replace(/\\0/g, '');\n  }\n  const len = array.length;\n  let c;\n  let char2;\n  let char3;\n  let out = '';\n  let i = 0;\n  while (i < len) {\n    c = array[i++];\n    if (c === 0x00 && exitOnNull) {\n      return out;\n    } else if (c === 0x00 || c === 0x03) {\n      // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it\n      continue;\n    }\n    switch (c >> 4) {\n      case 0:\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n      case 5:\n      case 6:\n      case 7:\n        // 0xxxxxxx\n        out += String.fromCharCode(c);\n        break;\n      case 12:\n      case 13:\n        // 110x xxxx   10xx xxxx\n        char2 = array[i++];\n        out += String.fromCharCode((c & 0x1f) << 6 | char2 & 0x3f);\n        break;\n      case 14:\n        // 1110 xxxx  10xx xxxx  10xx xxxx\n        char2 = array[i++];\n        char3 = array[i++];\n        out += String.fromCharCode((c & 0x0f) << 12 | (char2 & 0x3f) << 6 | (char3 & 0x3f) << 0);\n        break;\n    }\n  }\n  return out;\n};\nlet decoder;\nfunction getTextDecoder() {\n  // On Play Station 4, TextDecoder is defined but partially implemented.\n  // Manual decoding option is preferable\n  if (navigator.userAgent.includes('PlayStation 4')) {\n    return;\n  }\n  if (!decoder && typeof self.TextDecoder !== 'undefined') {\n    decoder = new self.TextDecoder('utf-8');\n  }\n  return decoder;\n}\n\n/**\n *  hex dump helper class\n */\n\nconst Hex = {\n  hexDump: function (array) {\n    let str = '';\n    for (let i = 0; i < array.length; i++) {\n      let h = array[i].toString(16);\n      if (h.length < 2) {\n        h = '0' + h;\n      }\n      str += h;\n    }\n    return str;\n  }\n};\n\nconst UINT32_MAX$1 = Math.pow(2, 32) - 1;\nconst push = [].push;\n\n// We are using fixed track IDs for driving the MP4 remuxer\n// instead of following the TS PIDs.\n// There is no reason not to do this and some browsers/SourceBuffer-demuxers\n// may not like if there are TrackID \"switches\"\n// See https://github.com/video-dev/hls.js/issues/1331\n// Here we are mapping our internal track types to constant MP4 track IDs\n// With MSE currently one can only have one track of each, and we are muxing\n// whatever video/audio rendition in them.\nconst RemuxerTrackIdConfig = {\n  video: 1,\n  audio: 2,\n  id3: 3,\n  text: 4\n};\nfunction bin2str(data) {\n  return String.fromCharCode.apply(null, data);\n}\nfunction readUint16(buffer, offset) {\n  const val = buffer[offset] << 8 | buffer[offset + 1];\n  return val < 0 ? 65536 + val : val;\n}\nfunction readUint32(buffer, offset) {\n  const val = readSint32(buffer, offset);\n  return val < 0 ? 4294967296 + val : val;\n}\nfunction readUint64(buffer, offset) {\n  let result = readUint32(buffer, offset);\n  result *= Math.pow(2, 32);\n  result += readUint32(buffer, offset + 4);\n  return result;\n}\nfunction readSint32(buffer, offset) {\n  return buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];\n}\nfunction writeUint32(buffer, offset, value) {\n  buffer[offset] = value >> 24;\n  buffer[offset + 1] = value >> 16 & 0xff;\n  buffer[offset + 2] = value >> 8 & 0xff;\n  buffer[offset + 3] = value & 0xff;\n}\n\n// Find \"moof\" box\nfunction hasMoofData(data) {\n  const end = data.byteLength;\n  for (let i = 0; i < end;) {\n    const size = readUint32(data, i);\n    if (size > 8 && data[i + 4] === 0x6d && data[i + 5] === 0x6f && data[i + 6] === 0x6f && data[i + 7] === 0x66) {\n      return true;\n    }\n    i = size > 1 ? i + size : end;\n  }\n  return false;\n}\n\n// Find the data for a box specified by its path\nfunction findBox(data, path) {\n  const results = [];\n  if (!path.length) {\n    // short-circuit the search for empty paths\n    return results;\n  }\n  const end = data.byteLength;\n  for (let i = 0; i < end;) {\n    const size = readUint32(data, i);\n    const type = bin2str(data.subarray(i + 4, i + 8));\n    const endbox = size > 1 ? i + size : end;\n    if (type === path[0]) {\n      if (path.length === 1) {\n        // this is the end of the path and we've found the box we were\n        // looking for\n        results.push(data.subarray(i + 8, endbox));\n      } else {\n        // recursively search for the next box along the path\n        const subresults = findBox(data.subarray(i + 8, endbox), path.slice(1));\n        if (subresults.length) {\n          push.apply(results, subresults);\n        }\n      }\n    }\n    i = endbox;\n  }\n\n  // we've finished searching all of data\n  return results;\n}\nfunction parseSegmentIndex(sidx) {\n  const references = [];\n  const version = sidx[0];\n\n  // set initial offset, we skip the reference ID (not needed)\n  let index = 8;\n  const timescale = readUint32(sidx, index);\n  index += 4;\n  let earliestPresentationTime = 0;\n  let firstOffset = 0;\n  if (version === 0) {\n    earliestPresentationTime = readUint32(sidx, index);\n    firstOffset = readUint32(sidx, index + 4);\n    index += 8;\n  } else {\n    earliestPresentationTime = readUint64(sidx, index);\n    firstOffset = readUint64(sidx, index + 8);\n    index += 16;\n  }\n\n  // skip reserved\n  index += 2;\n  let startByte = sidx.length + firstOffset;\n  const referencesCount = readUint16(sidx, index);\n  index += 2;\n  for (let i = 0; i < referencesCount; i++) {\n    let referenceIndex = index;\n    const referenceInfo = readUint32(sidx, referenceIndex);\n    referenceIndex += 4;\n    const referenceSize = referenceInfo & 0x7fffffff;\n    const referenceType = (referenceInfo & 0x80000000) >>> 31;\n    if (referenceType === 1) {\n      logger.warn('SIDX has hierarchical references (not supported)');\n      return null;\n    }\n    const subsegmentDuration = readUint32(sidx, referenceIndex);\n    referenceIndex += 4;\n    references.push({\n      referenceSize,\n      subsegmentDuration,\n      // unscaled\n      info: {\n        duration: subsegmentDuration / timescale,\n        start: startByte,\n        end: startByte + referenceSize - 1\n      }\n    });\n    startByte += referenceSize;\n\n    // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits\n    // for |sapDelta|.\n    referenceIndex += 4;\n\n    // skip to next ref\n    index = referenceIndex;\n  }\n  return {\n    earliestPresentationTime,\n    timescale,\n    version,\n    referencesCount,\n    references\n  };\n}\n\n/**\n * Parses an MP4 initialization segment and extracts stream type and\n * timescale values for any declared tracks. Timescale values indicate the\n * number of clock ticks per second to assume for time-based values\n * elsewhere in the MP4.\n *\n * To determine the start time of an MP4, you need two pieces of\n * information: the timescale unit and the earliest base media decode\n * time. Multiple timescales can be specified within an MP4 but the\n * base media decode time is always expressed in the timescale from\n * the media header box for the track:\n * ```\n * moov > trak > mdia > mdhd.timescale\n * moov > trak > mdia > hdlr\n * ```\n * @param initSegment the bytes of the init segment\n * @returns a hash of track type to timescale values or null if\n * the init segment is malformed.\n */\n\nfunction parseInitSegment(initSegment) {\n  const result = [];\n  const traks = findBox(initSegment, ['moov', 'trak']);\n  for (let i = 0; i < traks.length; i++) {\n    const trak = traks[i];\n    const tkhd = findBox(trak, ['tkhd'])[0];\n    if (tkhd) {\n      let version = tkhd[0];\n      const trackId = readUint32(tkhd, version === 0 ? 12 : 20);\n      const mdhd = findBox(trak, ['mdia', 'mdhd'])[0];\n      if (mdhd) {\n        version = mdhd[0];\n        const timescale = readUint32(mdhd, version === 0 ? 12 : 20);\n        const hdlr = findBox(trak, ['mdia', 'hdlr'])[0];\n        if (hdlr) {\n          const hdlrType = bin2str(hdlr.subarray(8, 12));\n          const type = {\n            soun: ElementaryStreamTypes.AUDIO,\n            vide: ElementaryStreamTypes.VIDEO\n          }[hdlrType];\n          if (type) {\n            // Parse codec details\n            const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n            const stsdData = parseStsd(stsd);\n            result[trackId] = {\n              timescale,\n              type\n            };\n            result[type] = _objectSpread2({\n              timescale,\n              id: trackId\n            }, stsdData);\n          }\n        }\n      }\n    }\n  }\n  const trex = findBox(initSegment, ['moov', 'mvex', 'trex']);\n  trex.forEach(trex => {\n    const trackId = readUint32(trex, 4);\n    const track = result[trackId];\n    if (track) {\n      track.default = {\n        duration: readUint32(trex, 12),\n        flags: readUint32(trex, 20)\n      };\n    }\n  });\n  return result;\n}\nfunction parseStsd(stsd) {\n  const sampleEntries = stsd.subarray(8);\n  const sampleEntriesEnd = sampleEntries.subarray(8 + 78);\n  const fourCC = bin2str(sampleEntries.subarray(4, 8));\n  let codec = fourCC;\n  const encrypted = fourCC === 'enca' || fourCC === 'encv';\n  if (encrypted) {\n    const encBox = findBox(sampleEntries, [fourCC])[0];\n    const encBoxChildren = encBox.subarray(fourCC === 'enca' ? 28 : 78);\n    const sinfs = findBox(encBoxChildren, ['sinf']);\n    sinfs.forEach(sinf => {\n      const schm = findBox(sinf, ['schm'])[0];\n      if (schm) {\n        const scheme = bin2str(schm.subarray(4, 8));\n        if (scheme === 'cbcs' || scheme === 'cenc') {\n          const frma = findBox(sinf, ['frma'])[0];\n          if (frma) {\n            // for encrypted content codec fourCC will be in frma\n            codec = bin2str(frma);\n          }\n        }\n      }\n    });\n  }\n  switch (codec) {\n    case 'avc1':\n    case 'avc2':\n    case 'avc3':\n    case 'avc4':\n      {\n        // extract profile + compatibility + level out of avcC box\n        const avcCBox = findBox(sampleEntriesEnd, ['avcC'])[0];\n        codec += '.' + toHex(avcCBox[1]) + toHex(avcCBox[2]) + toHex(avcCBox[3]);\n        break;\n      }\n    case 'mp4a':\n      {\n        const codecBox = findBox(sampleEntries, [fourCC])[0];\n        const esdsBox = findBox(codecBox.subarray(28), ['esds'])[0];\n        if (esdsBox && esdsBox.length > 12) {\n          let i = 4;\n          // ES Descriptor tag\n          if (esdsBox[i++] !== 0x03) {\n            break;\n          }\n          i = skipBERInteger(esdsBox, i);\n          i += 2; // skip es_id;\n          const flags = esdsBox[i++];\n          if (flags & 0x80) {\n            i += 2; // skip dependency es_id\n          }\n          if (flags & 0x40) {\n            i += esdsBox[i++]; // skip URL\n          }\n          // Decoder config descriptor\n          if (esdsBox[i++] !== 0x04) {\n            break;\n          }\n          i = skipBERInteger(esdsBox, i);\n          const objectType = esdsBox[i++];\n          if (objectType === 0x40) {\n            codec += '.' + toHex(objectType);\n          } else {\n            break;\n          }\n          i += 12;\n          // Decoder specific info\n          if (esdsBox[i++] !== 0x05) {\n            break;\n          }\n          i = skipBERInteger(esdsBox, i);\n          const firstByte = esdsBox[i++];\n          let audioObjectType = (firstByte & 0xf8) >> 3;\n          if (audioObjectType === 31) {\n            audioObjectType += 1 + ((firstByte & 0x7) << 3) + ((esdsBox[i] & 0xe0) >> 5);\n          }\n          codec += '.' + audioObjectType;\n        }\n        break;\n      }\n    case 'hvc1':\n    case 'hev1':\n      {\n        const hvcCBox = findBox(sampleEntriesEnd, ['hvcC'])[0];\n        const profileByte = hvcCBox[1];\n        const profileSpace = ['', 'A', 'B', 'C'][profileByte >> 6];\n        const generalProfileIdc = profileByte & 0x1f;\n        const profileCompat = readUint32(hvcCBox, 2);\n        const tierFlag = (profileByte & 0x20) >> 5 ? 'H' : 'L';\n        const levelIDC = hvcCBox[12];\n        const constraintIndicator = hvcCBox.subarray(6, 12);\n        codec += '.' + profileSpace + generalProfileIdc;\n        codec += '.' + profileCompat.toString(16).toUpperCase();\n        codec += '.' + tierFlag + levelIDC;\n        let constraintString = '';\n        for (let i = constraintIndicator.length; i--;) {\n          const byte = constraintIndicator[i];\n          if (byte || constraintString) {\n            const encodedByte = byte.toString(16).toUpperCase();\n            constraintString = '.' + encodedByte + constraintString;\n          }\n        }\n        codec += constraintString;\n        break;\n      }\n    case 'dvh1':\n    case 'dvhe':\n      {\n        const dvcCBox = findBox(sampleEntriesEnd, ['dvcC'])[0];\n        const profile = dvcCBox[2] >> 1 & 0x7f;\n        const level = dvcCBox[2] << 5 & 0x20 | dvcCBox[3] >> 3 & 0x1f;\n        codec += '.' + addLeadingZero(profile) + '.' + addLeadingZero(level);\n        break;\n      }\n    case 'vp09':\n      {\n        const vpcCBox = findBox(sampleEntriesEnd, ['vpcC'])[0];\n        const profile = vpcCBox[4];\n        const level = vpcCBox[5];\n        const bitDepth = vpcCBox[6] >> 4 & 0x0f;\n        codec += '.' + addLeadingZero(profile) + '.' + addLeadingZero(level) + '.' + addLeadingZero(bitDepth);\n        break;\n      }\n    case 'av01':\n      {\n        const av1CBox = findBox(sampleEntriesEnd, ['av1C'])[0];\n        const profile = av1CBox[1] >>> 5;\n        const level = av1CBox[1] & 0x1f;\n        const tierFlag = av1CBox[2] >>> 7 ? 'H' : 'M';\n        const highBitDepth = (av1CBox[2] & 0x40) >> 6;\n        const twelveBit = (av1CBox[2] & 0x20) >> 5;\n        const bitDepth = profile === 2 && highBitDepth ? twelveBit ? 12 : 10 : highBitDepth ? 10 : 8;\n        const monochrome = (av1CBox[2] & 0x10) >> 4;\n        const chromaSubsamplingX = (av1CBox[2] & 0x08) >> 3;\n        const chromaSubsamplingY = (av1CBox[2] & 0x04) >> 2;\n        const chromaSamplePosition = av1CBox[2] & 0x03;\n        // TODO: parse color_description_present_flag\n        // default it to BT.709/limited range for now\n        // more info https://aomediacodec.github.io/av1-isobmff/#av1codecconfigurationbox-syntax\n        const colorPrimaries = 1;\n        const transferCharacteristics = 1;\n        const matrixCoefficients = 1;\n        const videoFullRangeFlag = 0;\n        codec += '.' + profile + '.' + addLeadingZero(level) + tierFlag + '.' + addLeadingZero(bitDepth) + '.' + monochrome + '.' + chromaSubsamplingX + chromaSubsamplingY + chromaSamplePosition + '.' + addLeadingZero(colorPrimaries) + '.' + addLeadingZero(transferCharacteristics) + '.' + addLeadingZero(matrixCoefficients) + '.' + videoFullRangeFlag;\n        break;\n      }\n  }\n  return {\n    codec,\n    encrypted\n  };\n}\nfunction skipBERInteger(bytes, i) {\n  const limit = i + 5;\n  while (bytes[i++] & 0x80 && i < limit) {}\n  return i;\n}\nfunction toHex(x) {\n  return ('0' + x.toString(16).toUpperCase()).slice(-2);\n}\nfunction addLeadingZero(num) {\n  return (num < 10 ? '0' : '') + num;\n}\nfunction patchEncyptionData(initSegment, decryptdata) {\n  if (!initSegment || !decryptdata) {\n    return initSegment;\n  }\n  const keyId = decryptdata.keyId;\n  if (keyId && decryptdata.isCommonEncryption) {\n    const traks = findBox(initSegment, ['moov', 'trak']);\n    traks.forEach(trak => {\n      const stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n\n      // skip the sample entry count\n      const sampleEntries = stsd.subarray(8);\n      let encBoxes = findBox(sampleEntries, ['enca']);\n      const isAudio = encBoxes.length > 0;\n      if (!isAudio) {\n        encBoxes = findBox(sampleEntries, ['encv']);\n      }\n      encBoxes.forEach(enc => {\n        const encBoxChildren = isAudio ? enc.subarray(28) : enc.subarray(78);\n        const sinfBoxes = findBox(encBoxChildren, ['sinf']);\n        sinfBoxes.forEach(sinf => {\n          const tenc = parseSinf(sinf);\n          if (tenc) {\n            // Look for default key id (keyID offset is always 8 within the tenc box):\n            const tencKeyId = tenc.subarray(8, 24);\n            if (!tencKeyId.some(b => b !== 0)) {\n              logger.log(`[eme] Patching keyId in 'enc${isAudio ? 'a' : 'v'}>sinf>>tenc' box: ${Hex.hexDump(tencKeyId)} -> ${Hex.hexDump(keyId)}`);\n              tenc.set(keyId, 8);\n            }\n          }\n        });\n      });\n    });\n  }\n  return initSegment;\n}\nfunction parseSinf(sinf) {\n  const schm = findBox(sinf, ['schm'])[0];\n  if (schm) {\n    const scheme = bin2str(schm.subarray(4, 8));\n    if (scheme === 'cbcs' || scheme === 'cenc') {\n      return findBox(sinf, ['schi', 'tenc'])[0];\n    }\n  }\n  logger.error(`[eme] missing 'schm' box`);\n  return null;\n}\n\n/**\n * Determine the base media decode start time, in seconds, for an MP4\n * fragment. If multiple fragments are specified, the earliest time is\n * returned.\n *\n * The base media decode time can be parsed from track fragment\n * metadata:\n * ```\n * moof > traf > tfdt.baseMediaDecodeTime\n * ```\n * It requires the timescale value from the mdhd to interpret.\n *\n * @param initData - a hash of track type to timescale values\n * @param fmp4 - the bytes of the mp4 fragment\n * @returns the earliest base media decode start time for the\n * fragment, in seconds\n */\nfunction getStartDTS(initData, fmp4) {\n  // we need info from two children of each track fragment box\n  return findBox(fmp4, ['moof', 'traf']).reduce((result, traf) => {\n    const tfdt = findBox(traf, ['tfdt'])[0];\n    const version = tfdt[0];\n    const start = findBox(traf, ['tfhd']).reduce((result, tfhd) => {\n      // get the track id from the tfhd\n      const id = readUint32(tfhd, 4);\n      const track = initData[id];\n      if (track) {\n        let baseTime = readUint32(tfdt, 4);\n        if (version === 1) {\n          // If value is too large, assume signed 64-bit. Negative track fragment decode times are invalid, but they exist in the wild.\n          // This prevents large values from being used for initPTS, which can cause playlist sync issues.\n          // https://github.com/video-dev/hls.js/issues/5303\n          if (baseTime === UINT32_MAX$1) {\n            logger.warn(`[mp4-demuxer]: Ignoring assumed invalid signed 64-bit track fragment decode time`);\n            return result;\n          }\n          baseTime *= UINT32_MAX$1 + 1;\n          baseTime += readUint32(tfdt, 8);\n        }\n        // assume a 90kHz clock if no timescale was specified\n        const scale = track.timescale || 90e3;\n        // convert base time to seconds\n        const startTime = baseTime / scale;\n        if (isFiniteNumber(startTime) && (result === null || startTime < result)) {\n          return startTime;\n        }\n      }\n      return result;\n    }, null);\n    if (start !== null && isFiniteNumber(start) && (result === null || start < result)) {\n      return start;\n    }\n    return result;\n  }, null);\n}\n\n/*\n  For Reference:\n  aligned(8) class TrackFragmentHeaderBox\n           extends FullBox(tfhd, 0, tf_flags){\n     unsigned int(32)  track_ID;\n     // all the following are optional fields\n     unsigned int(64)  base_data_offset;\n     unsigned int(32)  sample_description_index;\n     unsigned int(32)  default_sample_duration;\n     unsigned int(32)  default_sample_size;\n     unsigned int(32)  default_sample_flags\n  }\n */\nfunction getDuration(data, initData) {\n  let rawDuration = 0;\n  let videoDuration = 0;\n  let audioDuration = 0;\n  const trafs = findBox(data, ['moof', 'traf']);\n  for (let i = 0; i < trafs.length; i++) {\n    const traf = trafs[i];\n    // There is only one tfhd & trun per traf\n    // This is true for CMAF style content, and we should perhaps check the ftyp\n    // and only look for a single trun then, but for ISOBMFF we should check\n    // for multiple track runs.\n    const tfhd = findBox(traf, ['tfhd'])[0];\n    // get the track id from the tfhd\n    const id = readUint32(tfhd, 4);\n    const track = initData[id];\n    if (!track) {\n      continue;\n    }\n    const trackDefault = track.default;\n    const tfhdFlags = readUint32(tfhd, 0) | (trackDefault == null ? void 0 : trackDefault.flags);\n    let sampleDuration = trackDefault == null ? void 0 : trackDefault.duration;\n    if (tfhdFlags & 0x000008) {\n      // 0x000008 indicates the presence of the default_sample_duration field\n      if (tfhdFlags & 0x000002) {\n        // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration\n        // If present, the default_sample_duration exists at byte offset 12\n        sampleDuration = readUint32(tfhd, 12);\n      } else {\n        // Otherwise, the duration is at byte offset 8\n        sampleDuration = readUint32(tfhd, 8);\n      }\n    }\n    // assume a 90kHz clock if no timescale was specified\n    const timescale = track.timescale || 90e3;\n    const truns = findBox(traf, ['trun']);\n    for (let j = 0; j < truns.length; j++) {\n      rawDuration = computeRawDurationFromSamples(truns[j]);\n      if (!rawDuration && sampleDuration) {\n        const sampleCount = readUint32(truns[j], 4);\n        rawDuration = sampleDuration * sampleCount;\n      }\n      if (track.type === ElementaryStreamTypes.VIDEO) {\n        videoDuration += rawDuration / timescale;\n      } else if (track.type === ElementaryStreamTypes.AUDIO) {\n        audioDuration += rawDuration / timescale;\n      }\n    }\n  }\n  if (videoDuration === 0 && audioDuration === 0) {\n    // If duration samples are not available in the traf use sidx subsegment_duration\n    let sidxMinStart = Infinity;\n    let sidxMaxEnd = 0;\n    let sidxDuration = 0;\n    const sidxs = findBox(data, ['sidx']);\n    for (let i = 0; i < sidxs.length; i++) {\n      const sidx = parseSegmentIndex(sidxs[i]);\n      if (sidx != null && sidx.references) {\n        sidxMinStart = Math.min(sidxMinStart, sidx.earliestPresentationTime / sidx.timescale);\n        const subSegmentDuration = sidx.references.reduce((dur, ref) => dur + ref.info.duration || 0, 0);\n        sidxMaxEnd = Math.max(sidxMaxEnd, subSegmentDuration + sidx.earliestPresentationTime / sidx.timescale);\n        sidxDuration = sidxMaxEnd - sidxMinStart;\n      }\n    }\n    if (sidxDuration && isFiniteNumber(sidxDuration)) {\n      return sidxDuration;\n    }\n  }\n  if (videoDuration) {\n    return videoDuration;\n  }\n  return audioDuration;\n}\n\n/*\n  For Reference:\n  aligned(8) class TrackRunBox\n           extends FullBox(trun, version, tr_flags) {\n     unsigned int(32)  sample_count;\n     // the following are optional fields\n     signed int(32) data_offset;\n     unsigned int(32)  first_sample_flags;\n     // all fields in the following array are optional\n     {\n        unsigned int(32)  sample_duration;\n        unsigned int(32)  sample_size;\n        unsigned int(32)  sample_flags\n        if (version == 0)\n           { unsigned int(32)\n        else\n           { signed int(32)\n     }[ sample_count ]\n  }\n */\nfunction computeRawDurationFromSamples(trun) {\n  const flags = readUint32(trun, 0);\n  // Flags are at offset 0, non-optional sample_count is at offset 4. Therefore we start 8 bytes in.\n  // Each field is an int32, which is 4 bytes\n  let offset = 8;\n  // data-offset-present flag\n  if (flags & 0x000001) {\n    offset += 4;\n  }\n  // first-sample-flags-present flag\n  if (flags & 0x000004) {\n    offset += 4;\n  }\n  let duration = 0;\n  const sampleCount = readUint32(trun, 4);\n  for (let i = 0; i < sampleCount; i++) {\n    // sample-duration-present flag\n    if (flags & 0x000100) {\n      const sampleDuration = readUint32(trun, offset);\n      duration += sampleDuration;\n      offset += 4;\n    }\n    // sample-size-present flag\n    if (flags & 0x000200) {\n      offset += 4;\n    }\n    // sample-flags-present flag\n    if (flags & 0x000400) {\n      offset += 4;\n    }\n    // sample-composition-time-offsets-present flag\n    if (flags & 0x000800) {\n      offset += 4;\n    }\n  }\n  return duration;\n}\nfunction offsetStartDTS(initData, fmp4, timeOffset) {\n  findBox(fmp4, ['moof', 'traf']).forEach(traf => {\n    findBox(traf, ['tfhd']).forEach(tfhd => {\n      // get the track id from the tfhd\n      const id = readUint32(tfhd, 4);\n      const track = initData[id];\n      if (!track) {\n        return;\n      }\n      // assume a 90kHz clock if no timescale was specified\n      const timescale = track.timescale || 90e3;\n      // get the base media decode time from the tfdt\n      findBox(traf, ['tfdt']).forEach(tfdt => {\n        const version = tfdt[0];\n        const offset = timeOffset * timescale;\n        if (offset) {\n          let baseMediaDecodeTime = readUint32(tfdt, 4);\n          if (version === 0) {\n            baseMediaDecodeTime -= offset;\n            baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n            writeUint32(tfdt, 4, baseMediaDecodeTime);\n          } else {\n            baseMediaDecodeTime *= Math.pow(2, 32);\n            baseMediaDecodeTime += readUint32(tfdt, 8);\n            baseMediaDecodeTime -= offset;\n            baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n            const upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX$1 + 1));\n            const lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX$1 + 1));\n            writeUint32(tfdt, 4, upper);\n            writeUint32(tfdt, 8, lower);\n          }\n        }\n      });\n    });\n  });\n}\n\n// TODO: Check if the last moof+mdat pair is part of the valid range\nfunction segmentValidRange(data) {\n  const segmentedRange = {\n    valid: null,\n    remainder: null\n  };\n  const moofs = findBox(data, ['moof']);\n  if (moofs.length < 2) {\n    segmentedRange.remainder = data;\n    return segmentedRange;\n  }\n  const last = moofs[moofs.length - 1];\n  // Offset by 8 bytes; findBox offsets the start by as much\n  segmentedRange.valid = sliceUint8(data, 0, last.byteOffset - 8);\n  segmentedRange.remainder = sliceUint8(data, last.byteOffset - 8);\n  return segmentedRange;\n}\nfunction appendUint8Array(data1, data2) {\n  const temp = new Uint8Array(data1.length + data2.length);\n  temp.set(data1);\n  temp.set(data2, data1.length);\n  return temp;\n}\nfunction parseSamples(timeOffset, track) {\n  const seiSamples = [];\n  const videoData = track.samples;\n  const timescale = track.timescale;\n  const trackId = track.id;\n  let isHEVCFlavor = false;\n  const moofs = findBox(videoData, ['moof']);\n  moofs.map(moof => {\n    const moofOffset = moof.byteOffset - 8;\n    const trafs = findBox(moof, ['traf']);\n    trafs.map(traf => {\n      // get the base media decode time from the tfdt\n      const baseTime = findBox(traf, ['tfdt']).map(tfdt => {\n        const version = tfdt[0];\n        let result = readUint32(tfdt, 4);\n        if (version === 1) {\n          result *= Math.pow(2, 32);\n          result += readUint32(tfdt, 8);\n        }\n        return result / timescale;\n      })[0];\n      if (baseTime !== undefined) {\n        timeOffset = baseTime;\n      }\n      return findBox(traf, ['tfhd']).map(tfhd => {\n        const id = readUint32(tfhd, 4);\n        const tfhdFlags = readUint32(tfhd, 0) & 0xffffff;\n        const baseDataOffsetPresent = (tfhdFlags & 0x000001) !== 0;\n        const sampleDescriptionIndexPresent = (tfhdFlags & 0x000002) !== 0;\n        const defaultSampleDurationPresent = (tfhdFlags & 0x000008) !== 0;\n        let defaultSampleDuration = 0;\n        const defaultSampleSizePresent = (tfhdFlags & 0x000010) !== 0;\n        let defaultSampleSize = 0;\n        const defaultSampleFlagsPresent = (tfhdFlags & 0x000020) !== 0;\n        let tfhdOffset = 8;\n        if (id === trackId) {\n          if (baseDataOffsetPresent) {\n            tfhdOffset += 8;\n          }\n          if (sampleDescriptionIndexPresent) {\n            tfhdOffset += 4;\n          }\n          if (defaultSampleDurationPresent) {\n            defaultSampleDuration = readUint32(tfhd, tfhdOffset);\n            tfhdOffset += 4;\n          }\n          if (defaultSampleSizePresent) {\n            defaultSampleSize = readUint32(tfhd, tfhdOffset);\n            tfhdOffset += 4;\n          }\n          if (defaultSampleFlagsPresent) {\n            tfhdOffset += 4;\n          }\n          if (track.type === 'video') {\n            isHEVCFlavor = isHEVC(track.codec);\n          }\n          findBox(traf, ['trun']).map(trun => {\n            const version = trun[0];\n            const flags = readUint32(trun, 0) & 0xffffff;\n            const dataOffsetPresent = (flags & 0x000001) !== 0;\n            let dataOffset = 0;\n            const firstSampleFlagsPresent = (flags & 0x000004) !== 0;\n            const sampleDurationPresent = (flags & 0x000100) !== 0;\n            let sampleDuration = 0;\n            const sampleSizePresent = (flags & 0x000200) !== 0;\n            let sampleSize = 0;\n            const sampleFlagsPresent = (flags & 0x000400) !== 0;\n            const sampleCompositionOffsetsPresent = (flags & 0x000800) !== 0;\n            let compositionOffset = 0;\n            const sampleCount = readUint32(trun, 4);\n            let trunOffset = 8; // past version, flags, and sample count\n\n            if (dataOffsetPresent) {\n              dataOffset = readUint32(trun, trunOffset);\n              trunOffset += 4;\n            }\n            if (firstSampleFlagsPresent) {\n              trunOffset += 4;\n            }\n            let sampleOffset = dataOffset + moofOffset;\n            for (let ix = 0; ix < sampleCount; ix++) {\n              if (sampleDurationPresent) {\n                sampleDuration = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              } else {\n                sampleDuration = defaultSampleDuration;\n              }\n              if (sampleSizePresent) {\n                sampleSize = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              } else {\n                sampleSize = defaultSampleSize;\n              }\n              if (sampleFlagsPresent) {\n                trunOffset += 4;\n              }\n              if (sampleCompositionOffsetsPresent) {\n                if (version === 0) {\n                  compositionOffset = readUint32(trun, trunOffset);\n                } else {\n                  compositionOffset = readSint32(trun, trunOffset);\n                }\n                trunOffset += 4;\n              }\n              if (track.type === ElementaryStreamTypes.VIDEO) {\n                let naluTotalSize = 0;\n                while (naluTotalSize < sampleSize) {\n                  const naluSize = readUint32(videoData, sampleOffset);\n                  sampleOffset += 4;\n                  if (isSEIMessage(isHEVCFlavor, videoData[sampleOffset])) {\n                    const data = videoData.subarray(sampleOffset, sampleOffset + naluSize);\n                    parseSEIMessageFromNALu(data, isHEVCFlavor ? 2 : 1, timeOffset + compositionOffset / timescale, seiSamples);\n                  }\n                  sampleOffset += naluSize;\n                  naluTotalSize += naluSize + 4;\n                }\n              }\n              timeOffset += sampleDuration / timescale;\n            }\n          });\n        }\n      });\n    });\n  });\n  return seiSamples;\n}\nfunction isHEVC(codec) {\n  if (!codec) {\n    return false;\n  }\n  const delimit = codec.indexOf('.');\n  const baseCodec = delimit < 0 ? codec : codec.substring(0, delimit);\n  return baseCodec === 'hvc1' || baseCodec === 'hev1' ||\n  // Dolby Vision\n  baseCodec === 'dvh1' || baseCodec === 'dvhe';\n}\nfunction isSEIMessage(isHEVCFlavor, naluHeader) {\n  if (isHEVCFlavor) {\n    const naluType = naluHeader >> 1 & 0x3f;\n    return naluType === 39 || naluType === 40;\n  } else {\n    const naluType = naluHeader & 0x1f;\n    return naluType === 6;\n  }\n}\nfunction parseSEIMessageFromNALu(unescapedData, headerSize, pts, samples) {\n  const data = discardEPB(unescapedData);\n  let seiPtr = 0;\n  // skip nal header\n  seiPtr += headerSize;\n  let payloadType = 0;\n  let payloadSize = 0;\n  let b = 0;\n  while (seiPtr < data.length) {\n    payloadType = 0;\n    do {\n      if (seiPtr >= data.length) {\n        break;\n      }\n      b = data[seiPtr++];\n      payloadType += b;\n    } while (b === 0xff);\n\n    // Parse payload size.\n    payloadSize = 0;\n    do {\n      if (seiPtr >= data.length) {\n        break;\n      }\n      b = data[seiPtr++];\n      payloadSize += b;\n    } while (b === 0xff);\n    const leftOver = data.length - seiPtr;\n    // Create a variable to process the payload\n    let payPtr = seiPtr;\n\n    // Increment the seiPtr to the end of the payload\n    if (payloadSize < leftOver) {\n      seiPtr += payloadSize;\n    } else if (payloadSize > leftOver) {\n      // Some type of corruption has happened?\n      logger.error(`Malformed SEI payload. ${payloadSize} is too small, only ${leftOver} bytes left to parse.`);\n      // We might be able to parse some data, but let's be safe and ignore it.\n      break;\n    }\n    if (payloadType === 4) {\n      const countryCode = data[payPtr++];\n      if (countryCode === 181) {\n        const providerCode = readUint16(data, payPtr);\n        payPtr += 2;\n        if (providerCode === 49) {\n          const userStructure = readUint32(data, payPtr);\n          payPtr += 4;\n          if (userStructure === 0x47413934) {\n            const userDataType = data[payPtr++];\n\n            // Raw CEA-608 bytes wrapped in CEA-708 packet\n            if (userDataType === 3) {\n              const firstByte = data[payPtr++];\n              const totalCCs = 0x1f & firstByte;\n              const enabled = 0x40 & firstByte;\n              const totalBytes = enabled ? 2 + totalCCs * 3 : 0;\n              const byteArray = new Uint8Array(totalBytes);\n              if (enabled) {\n                byteArray[0] = firstByte;\n                for (let i = 1; i < totalBytes; i++) {\n                  byteArray[i] = data[payPtr++];\n                }\n              }\n              samples.push({\n                type: userDataType,\n                payloadType,\n                pts,\n                bytes: byteArray\n              });\n            }\n          }\n        }\n      }\n    } else if (payloadType === 5) {\n      if (payloadSize > 16) {\n        const uuidStrArray = [];\n        for (let i = 0; i < 16; i++) {\n          const _b = data[payPtr++].toString(16);\n          uuidStrArray.push(_b.length == 1 ? '0' + _b : _b);\n          if (i === 3 || i === 5 || i === 7 || i === 9) {\n            uuidStrArray.push('-');\n          }\n        }\n        const length = payloadSize - 16;\n        const userDataBytes = new Uint8Array(length);\n        for (let i = 0; i < length; i++) {\n          userDataBytes[i] = data[payPtr++];\n        }\n        samples.push({\n          payloadType,\n          pts,\n          uuid: uuidStrArray.join(''),\n          userData: utf8ArrayToStr(userDataBytes),\n          userDataBytes\n        });\n      }\n    }\n  }\n}\n\n/**\n * remove Emulation Prevention bytes from a RBSP\n */\nfunction discardEPB(data) {\n  const length = data.byteLength;\n  const EPBPositions = [];\n  let i = 1;\n\n  // Find all `Emulation Prevention Bytes`\n  while (i < length - 2) {\n    if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n      EPBPositions.push(i + 2);\n      i += 2;\n    } else {\n      i++;\n    }\n  }\n\n  // If no Emulation Prevention Bytes were found just return the original\n  // array\n  if (EPBPositions.length === 0) {\n    return data;\n  }\n\n  // Create a new array to hold the NAL unit data\n  const newLength = length - EPBPositions.length;\n  const newData = new Uint8Array(newLength);\n  let sourceIndex = 0;\n  for (i = 0; i < newLength; sourceIndex++, i++) {\n    if (sourceIndex === EPBPositions[0]) {\n      // Skip this byte\n      sourceIndex++;\n      // Remove this position index\n      EPBPositions.shift();\n    }\n    newData[i] = data[sourceIndex];\n  }\n  return newData;\n}\nfunction parseEmsg(data) {\n  const version = data[0];\n  let schemeIdUri = '';\n  let value = '';\n  let timeScale = 0;\n  let presentationTimeDelta = 0;\n  let presentationTime = 0;\n  let eventDuration = 0;\n  let id = 0;\n  let offset = 0;\n  if (version === 0) {\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    value += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n    timeScale = readUint32(data, 12);\n    presentationTimeDelta = readUint32(data, 16);\n    eventDuration = readUint32(data, 20);\n    id = readUint32(data, 24);\n    offset = 28;\n  } else if (version === 1) {\n    offset += 4;\n    timeScale = readUint32(data, offset);\n    offset += 4;\n    const leftPresentationTime = readUint32(data, offset);\n    offset += 4;\n    const rightPresentationTime = readUint32(data, offset);\n    offset += 4;\n    presentationTime = 2 ** 32 * leftPresentationTime + rightPresentationTime;\n    if (!isSafeInteger(presentationTime)) {\n      presentationTime = Number.MAX_SAFE_INTEGER;\n      logger.warn('Presentation time exceeds safe integer limit and wrapped to max safe integer in parsing emsg box');\n    }\n    eventDuration = readUint32(data, offset);\n    offset += 4;\n    id = readUint32(data, offset);\n    offset += 4;\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n    while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    value += bin2str(data.subarray(offset, offset + 1));\n    offset += 1;\n  }\n  const payload = data.subarray(offset, data.byteLength);\n  return {\n    schemeIdUri,\n    value,\n    timeScale,\n    presentationTime,\n    presentationTimeDelta,\n    eventDuration,\n    id,\n    payload\n  };\n}\nfunction mp4Box(type, ...payload) {\n  const len = payload.length;\n  let size = 8;\n  let i = len;\n  while (i--) {\n    size += payload[i].byteLength;\n  }\n  const result = new Uint8Array(size);\n  result[0] = size >> 24 & 0xff;\n  result[1] = size >> 16 & 0xff;\n  result[2] = size >> 8 & 0xff;\n  result[3] = size & 0xff;\n  result.set(type, 4);\n  for (i = 0, size = 8; i < len; i++) {\n    result.set(payload[i], size);\n    size += payload[i].byteLength;\n  }\n  return result;\n}\nfunction mp4pssh(systemId, keyids, data) {\n  if (systemId.byteLength !== 16) {\n    throw new RangeError('Invalid system id');\n  }\n  let version;\n  let kids;\n  if (keyids) {\n    version = 1;\n    kids = new Uint8Array(keyids.length * 16);\n    for (let ix = 0; ix < keyids.length; ix++) {\n      const k = keyids[ix]; // uint8array\n      if (k.byteLength !== 16) {\n        throw new RangeError('Invalid key');\n      }\n      kids.set(k, ix * 16);\n    }\n  } else {\n    version = 0;\n    kids = new Uint8Array();\n  }\n  let kidCount;\n  if (version > 0) {\n    kidCount = new Uint8Array(4);\n    if (keyids.length > 0) {\n      new DataView(kidCount.buffer).setUint32(0, keyids.length, false);\n    }\n  } else {\n    kidCount = new Uint8Array();\n  }\n  const dataSize = new Uint8Array(4);\n  if (data && data.byteLength > 0) {\n    new DataView(dataSize.buffer).setUint32(0, data.byteLength, false);\n  }\n  return mp4Box([112, 115, 115, 104], new Uint8Array([version, 0x00, 0x00, 0x00 // Flags\n  ]), systemId,\n  // 16 bytes\n  kidCount, kids, dataSize, data || new Uint8Array());\n}\nfunction parsePssh(initData) {\n  if (!(initData instanceof ArrayBuffer) || initData.byteLength < 32) {\n    return null;\n  }\n  const result = {\n    version: 0,\n    systemId: '',\n    kids: null,\n    data: null\n  };\n  const view = new DataView(initData);\n  const boxSize = view.getUint32(0);\n  if (initData.byteLength !== boxSize && boxSize > 44) {\n    return null;\n  }\n  const type = view.getUint32(4);\n  if (type !== 0x70737368) {\n    return null;\n  }\n  result.version = view.getUint32(8) >>> 24;\n  if (result.version > 1) {\n    return null;\n  }\n  result.systemId = Hex.hexDump(new Uint8Array(initData, 12, 16));\n  const dataSizeOrKidCount = view.getUint32(28);\n  if (result.version === 0) {\n    if (boxSize - 32 < dataSizeOrKidCount) {\n      return null;\n    }\n    result.data = new Uint8Array(initData, 32, dataSizeOrKidCount);\n  } else if (result.version === 1) {\n    result.kids = [];\n    for (let i = 0; i < dataSizeOrKidCount; i++) {\n      result.kids.push(new Uint8Array(initData, 32 + i * 16, 16));\n    }\n  }\n  return result;\n}\n\nlet keyUriToKeyIdMap = {};\nclass LevelKey {\n  static clearKeyUriToKeyIdMap() {\n    keyUriToKeyIdMap = {};\n  }\n  constructor(method, uri, format, formatversions = [1], iv = null) {\n    this.uri = void 0;\n    this.method = void 0;\n    this.keyFormat = void 0;\n    this.keyFormatVersions = void 0;\n    this.encrypted = void 0;\n    this.isCommonEncryption = void 0;\n    this.iv = null;\n    this.key = null;\n    this.keyId = null;\n    this.pssh = null;\n    this.method = method;\n    this.uri = uri;\n    this.keyFormat = format;\n    this.keyFormatVersions = formatversions;\n    this.iv = iv;\n    this.encrypted = method ? method !== 'NONE' : false;\n    this.isCommonEncryption = this.encrypted && method !== 'AES-128';\n  }\n  isSupported() {\n    // If it's Segment encryption or No encryption, just select that key system\n    if (this.method) {\n      if (this.method === 'AES-128' || this.method === 'NONE') {\n        return true;\n      }\n      if (this.keyFormat === 'identity') {\n        // Maintain support for clear SAMPLE-AES with MPEG-3 TS\n        return this.method === 'SAMPLE-AES';\n      } else {\n        switch (this.keyFormat) {\n          case KeySystemFormats.FAIRPLAY:\n          case KeySystemFormats.WIDEVINE:\n          case KeySystemFormats.PLAYREADY:\n          case KeySystemFormats.CLEARKEY:\n            return ['ISO-23001-7', 'SAMPLE-AES', 'SAMPLE-AES-CENC', 'SAMPLE-AES-CTR'].indexOf(this.method) !== -1;\n        }\n      }\n    }\n    return false;\n  }\n  getDecryptData(sn) {\n    if (!this.encrypted || !this.uri) {\n      return null;\n    }\n    if (this.method === 'AES-128' && this.uri && !this.iv) {\n      if (typeof sn !== 'number') {\n        // We are fetching decryption data for a initialization segment\n        // If the segment was encrypted with AES-128\n        // It must have an IV defined. We cannot substitute the Segment Number in.\n        if (this.method === 'AES-128' && !this.iv) {\n          logger.warn(`missing IV for initialization segment with method=\"${this.method}\" - compliance issue`);\n        }\n        // Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.\n        sn = 0;\n      }\n      const iv = createInitializationVector(sn);\n      const decryptdata = new LevelKey(this.method, this.uri, 'identity', this.keyFormatVersions, iv);\n      return decryptdata;\n    }\n\n    // Initialize keyId if possible\n    const keyBytes = convertDataUriToArrayBytes(this.uri);\n    if (keyBytes) {\n      switch (this.keyFormat) {\n        case KeySystemFormats.WIDEVINE:\n          this.pssh = keyBytes;\n          // In case of widevine keyID is embedded in PSSH box. Read Key ID.\n          if (keyBytes.length >= 22) {\n            this.keyId = keyBytes.subarray(keyBytes.length - 22, keyBytes.length - 6);\n          }\n          break;\n        case KeySystemFormats.PLAYREADY:\n          {\n            const PlayReadyKeySystemUUID = new Uint8Array([0x9a, 0x04, 0xf0, 0x79, 0x98, 0x40, 0x42, 0x86, 0xab, 0x92, 0xe6, 0x5b, 0xe0, 0x88, 0x5f, 0x95]);\n            this.pssh = mp4pssh(PlayReadyKeySystemUUID, null, keyBytes);\n            const keyBytesUtf16 = new Uint16Array(keyBytes.buffer, keyBytes.byteOffset, keyBytes.byteLength / 2);\n            const keyByteStr = String.fromCharCode.apply(null, Array.from(keyBytesUtf16));\n\n            // Parse Playready WRMHeader XML\n            const xmlKeyBytes = keyByteStr.substring(keyByteStr.indexOf('<'), keyByteStr.length);\n            const parser = new DOMParser();\n            const xmlDoc = parser.parseFromString(xmlKeyBytes, 'text/xml');\n            const keyData = xmlDoc.getElementsByTagName('KID')[0];\n            if (keyData) {\n              const keyId = keyData.childNodes[0] ? keyData.childNodes[0].nodeValue : keyData.getAttribute('VALUE');\n              if (keyId) {\n                const keyIdArray = base64Decode(keyId).subarray(0, 16);\n                // KID value in PRO is a base64-encoded little endian GUID interpretation of UUID\n                // KID value in tenc is a big endian UUID GUID interpretation of UUID\n                changeEndianness(keyIdArray);\n                this.keyId = keyIdArray;\n              }\n            }\n            break;\n          }\n        default:\n          {\n            let keydata = keyBytes.subarray(0, 16);\n            if (keydata.length !== 16) {\n              const padded = new Uint8Array(16);\n              padded.set(keydata, 16 - keydata.length);\n              keydata = padded;\n            }\n            this.keyId = keydata;\n            break;\n          }\n      }\n    }\n\n    // Default behavior: assign a new keyId for each uri\n    if (!this.keyId || this.keyId.byteLength !== 16) {\n      let keyId = keyUriToKeyIdMap[this.uri];\n      if (!keyId) {\n        const val = Object.keys(keyUriToKeyIdMap).length % Number.MAX_SAFE_INTEGER;\n        keyId = new Uint8Array(16);\n        const dv = new DataView(keyId.buffer, 12, 4); // Just set the last 4 bytes\n        dv.setUint32(0, val);\n        keyUriToKeyIdMap[this.uri] = keyId;\n      }\n      this.keyId = keyId;\n    }\n    return this;\n  }\n}\nfunction createInitializationVector(segmentNumber) {\n  const uint8View = new Uint8Array(16);\n  for (let i = 12; i < 16; i++) {\n    uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;\n  }\n  return uint8View;\n}\n\nconst VARIABLE_REPLACEMENT_REGEX = /\\{\\$([a-zA-Z0-9-_]+)\\}/g;\nfunction hasVariableReferences(str) {\n  return VARIABLE_REPLACEMENT_REGEX.test(str);\n}\nfunction substituteVariablesInAttributes(parsed, attr, attributeNames) {\n  if (parsed.variableList !== null || parsed.hasVariableRefs) {\n    for (let i = attributeNames.length; i--;) {\n      const name = attributeNames[i];\n      const value = attr[name];\n      if (value) {\n        attr[name] = substituteVariables(parsed, value);\n      }\n    }\n  }\n}\nfunction substituteVariables(parsed, value) {\n  if (parsed.variableList !== null || parsed.hasVariableRefs) {\n    const variableList = parsed.variableList;\n    return value.replace(VARIABLE_REPLACEMENT_REGEX, variableReference => {\n      const variableName = variableReference.substring(2, variableReference.length - 1);\n      const variableValue = variableList == null ? void 0 : variableList[variableName];\n      if (variableValue === undefined) {\n        parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`Missing preceding EXT-X-DEFINE tag for Variable Reference: \"${variableName}\"`));\n        return variableReference;\n      }\n      return variableValue;\n    });\n  }\n  return value;\n}\nfunction addVariableDefinition(parsed, attr, parentUrl) {\n  let variableList = parsed.variableList;\n  if (!variableList) {\n    parsed.variableList = variableList = {};\n  }\n  let NAME;\n  let VALUE;\n  if ('QUERYPARAM' in attr) {\n    NAME = attr.QUERYPARAM;\n    try {\n      const searchParams = new self.URL(parentUrl).searchParams;\n      if (searchParams.has(NAME)) {\n        VALUE = searchParams.get(NAME);\n      } else {\n        throw new Error(`\"${NAME}\" does not match any query parameter in URI: \"${parentUrl}\"`);\n      }\n    } catch (error) {\n      parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE QUERYPARAM: ${error.message}`));\n    }\n  } else {\n    NAME = attr.NAME;\n    VALUE = attr.VALUE;\n  }\n  if (NAME in variableList) {\n    parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE duplicate Variable Name declarations: \"${NAME}\"`));\n  } else {\n    variableList[NAME] = VALUE || '';\n  }\n}\nfunction importVariableDefinition(parsed, attr, sourceVariableList) {\n  const IMPORT = attr.IMPORT;\n  if (sourceVariableList && IMPORT in sourceVariableList) {\n    let variableList = parsed.variableList;\n    if (!variableList) {\n      parsed.variableList = variableList = {};\n    }\n    variableList[IMPORT] = sourceVariableList[IMPORT];\n  } else {\n    parsed.playlistParsingError || (parsed.playlistParsingError = new Error(`EXT-X-DEFINE IMPORT attribute not found in Multivariant Playlist: \"${IMPORT}\"`));\n  }\n}\n\n/**\n * MediaSource helper\n */\n\nfunction getMediaSource(preferManagedMediaSource = true) {\n  if (typeof self === 'undefined') return undefined;\n  const mms = (preferManagedMediaSource || !self.MediaSource) && self.ManagedMediaSource;\n  return mms || self.MediaSource || self.WebKitMediaSource;\n}\nfunction isManagedMediaSource(source) {\n  return typeof self !== 'undefined' && source === self.ManagedMediaSource;\n}\n\n// from http://mp4ra.org/codecs.html\n// values indicate codec selection preference (lower is higher priority)\nconst sampleEntryCodesISO = {\n  audio: {\n    a3ds: 1,\n    'ac-3': 0.95,\n    'ac-4': 1,\n    alac: 0.9,\n    alaw: 1,\n    dra1: 1,\n    'dts+': 1,\n    'dts-': 1,\n    dtsc: 1,\n    dtse: 1,\n    dtsh: 1,\n    'ec-3': 0.9,\n    enca: 1,\n    fLaC: 0.9,\n    // MP4-RA listed codec entry for FLAC\n    flac: 0.9,\n    // legacy browser codec name for FLAC\n    FLAC: 0.9,\n    // some manifests may list \"FLAC\" with Apple's tools\n    g719: 1,\n    g726: 1,\n    m4ae: 1,\n    mha1: 1,\n    mha2: 1,\n    mhm1: 1,\n    mhm2: 1,\n    mlpa: 1,\n    mp4a: 1,\n    'raw ': 1,\n    Opus: 1,\n    opus: 1,\n    // browsers expect this to be lowercase despite MP4RA says 'Opus'\n    samr: 1,\n    sawb: 1,\n    sawp: 1,\n    sevc: 1,\n    sqcp: 1,\n    ssmv: 1,\n    twos: 1,\n    ulaw: 1\n  },\n  video: {\n    avc1: 1,\n    avc2: 1,\n    avc3: 1,\n    avc4: 1,\n    avcp: 1,\n    av01: 0.8,\n    drac: 1,\n    dva1: 1,\n    dvav: 1,\n    dvh1: 0.7,\n    dvhe: 0.7,\n    encv: 1,\n    hev1: 0.75,\n    hvc1: 0.75,\n    mjp2: 1,\n    mp4v: 1,\n    mvc1: 1,\n    mvc2: 1,\n    mvc3: 1,\n    mvc4: 1,\n    resv: 1,\n    rv60: 1,\n    s263: 1,\n    svc1: 1,\n    svc2: 1,\n    'vc-1': 1,\n    vp08: 1,\n    vp09: 0.9\n  },\n  text: {\n    stpp: 1,\n    wvtt: 1\n  }\n};\nfunction isCodecType(codec, type) {\n  const typeCodes = sampleEntryCodesISO[type];\n  return !!typeCodes && !!typeCodes[codec.slice(0, 4)];\n}\nfunction areCodecsMediaSourceSupported(codecs, type, preferManagedMediaSource = true) {\n  return !codecs.split(',').some(codec => !isCodecMediaSourceSupported(codec, type, preferManagedMediaSource));\n}\nfunction isCodecMediaSourceSupported(codec, type, preferManagedMediaSource = true) {\n  var _MediaSource$isTypeSu;\n  const MediaSource = getMediaSource(preferManagedMediaSource);\n  return (_MediaSource$isTypeSu = MediaSource == null ? void 0 : MediaSource.isTypeSupported(mimeTypeForCodec(codec, type))) != null ? _MediaSource$isTypeSu : false;\n}\nfunction mimeTypeForCodec(codec, type) {\n  return `${type}/mp4;codecs=\"${codec}\"`;\n}\nfunction videoCodecPreferenceValue(videoCodec) {\n  if (videoCodec) {\n    const fourCC = videoCodec.substring(0, 4);\n    return sampleEntryCodesISO.video[fourCC];\n  }\n  return 2;\n}\nfunction codecsSetSelectionPreferenceValue(codecSet) {\n  return codecSet.split(',').reduce((num, fourCC) => {\n    const preferenceValue = sampleEntryCodesISO.video[fourCC];\n    if (preferenceValue) {\n      return (preferenceValue * 2 + num) / (num ? 3 : 2);\n    }\n    return (sampleEntryCodesISO.audio[fourCC] + num) / (num ? 2 : 1);\n  }, 0);\n}\nconst CODEC_COMPATIBLE_NAMES = {};\nfunction getCodecCompatibleNameLower(lowerCaseCodec, preferManagedMediaSource = true) {\n  if (CODEC_COMPATIBLE_NAMES[lowerCaseCodec]) {\n    return CODEC_COMPATIBLE_NAMES[lowerCaseCodec];\n  }\n\n  // Idealy fLaC and Opus would be first (spec-compliant) but\n  // some browsers will report that fLaC is supported then fail.\n  // see: https://bugs.chromium.org/p/chromium/issues/detail?id=1422728\n  const codecsToCheck = {\n    flac: ['flac', 'fLaC', 'FLAC'],\n    opus: ['opus', 'Opus']\n  }[lowerCaseCodec];\n  for (let i = 0; i < codecsToCheck.length; i++) {\n    if (isCodecMediaSourceSupported(codecsToCheck[i], 'audio', preferManagedMediaSource)) {\n      CODEC_COMPATIBLE_NAMES[lowerCaseCodec] = codecsToCheck[i];\n      return codecsToCheck[i];\n    }\n  }\n  return lowerCaseCodec;\n}\nconst AUDIO_CODEC_REGEXP = /flac|opus/i;\nfunction getCodecCompatibleName(codec, preferManagedMediaSource = true) {\n  return codec.replace(AUDIO_CODEC_REGEXP, m => getCodecCompatibleNameLower(m.toLowerCase(), preferManagedMediaSource));\n}\nfunction pickMostCompleteCodecName(parsedCodec, levelCodec) {\n  // Parsing of mp4a codecs strings in mp4-tools from media is incomplete as of d8c6c7a\n  // so use level codec is parsed codec is unavailable or incomplete\n  if (parsedCodec && parsedCodec !== 'mp4a') {\n    return parsedCodec;\n  }\n  return levelCodec ? levelCodec.split(',')[0] : levelCodec;\n}\nfunction convertAVC1ToAVCOTI(codec) {\n  // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported\n  // Examples: avc1.66.30 to avc1.42001e and avc1.77.30,avc1.66.30 to avc1.4d001e,avc1.42001e.\n  const codecs = codec.split(',');\n  for (let i = 0; i < codecs.length; i++) {\n    const avcdata = codecs[i].split('.');\n    if (avcdata.length > 2) {\n      let result = avcdata.shift() + '.';\n      result += parseInt(avcdata.shift()).toString(16);\n      result += ('000' + parseInt(avcdata.shift()).toString(16)).slice(-4);\n      codecs[i] = result;\n    }\n  }\n  return codecs.join(',');\n}\n\nconst MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\\r\\n]*)(?:[\\r\\n](?:#[^\\r\\n]*)?)*([^\\r\\n]+)|#EXT-X-(SESSION-DATA|SESSION-KEY|DEFINE|CONTENT-STEERING|START):([^\\r\\n]*)[\\r\\n]+/g;\nconst MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;\nconst IS_MEDIA_PLAYLIST = /^#EXT(?:INF|-X-TARGETDURATION):/m; // Handle empty Media Playlist (first EXTINF not signaled, but TARGETDURATION present)\n\nconst LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\\s*(\\d*(?:\\.\\d+)?)(?:,(.*)\\s+)?/.source,\n// duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title\n/(?!#) *(\\S[^\\r\\n]*)/.source,\n// segment URI, group 3 => the URI (note newline is not eaten)\n/#EXT-X-BYTERANGE:*(.+)/.source,\n// next segment's byterange, group 4 => range spec (x@y)\n/#EXT-X-PROGRAM-DATE-TIME:(.+)/.source,\n// next segment's program date/time group 5 => the datetime spec\n/#.*/.source // All other non-segment oriented tags will match with all groups empty\n].join('|'), 'g');\nconst LEVEL_PLAYLIST_REGEX_SLOW = new RegExp([/#(EXTM3U)/.source, /#EXT-X-(DATERANGE|DEFINE|KEY|MAP|PART|PART-INF|PLAYLIST-TYPE|PRELOAD-HINT|RENDITION-REPORT|SERVER-CONTROL|SKIP|START):(.+)/.source, /#EXT-X-(BITRATE|DISCONTINUITY-SEQUENCE|MEDIA-SEQUENCE|TARGETDURATION|VERSION): *(\\d+)/.source, /#EXT-X-(DISCONTINUITY|ENDLIST|GAP|INDEPENDENT-SEGMENTS)/.source, /(#)([^:]*):(.*)/.source, /(#)(.*)(?:.*)\\r?\\n?/.source].join('|'));\nclass M3U8Parser {\n  static findGroup(groups, mediaGroupId) {\n    for (let i = 0; i < groups.length; i++) {\n      const group = groups[i];\n      if (group.id === mediaGroupId) {\n        return group;\n      }\n    }\n  }\n  static resolve(url, baseUrl) {\n    return urlToolkitExports.buildAbsoluteURL(baseUrl, url, {\n      alwaysNormalize: true\n    });\n  }\n  static isMediaPlaylist(str) {\n    return IS_MEDIA_PLAYLIST.test(str);\n  }\n  static parseMasterPlaylist(string, baseurl) {\n    const hasVariableRefs = hasVariableReferences(string) ;\n    const parsed = {\n      contentSteering: null,\n      levels: [],\n      playlistParsingError: null,\n      sessionData: null,\n      sessionKeys: null,\n      startTimeOffset: null,\n      variableList: null,\n      hasVariableRefs\n    };\n    const levelsWithKnownCodecs = [];\n    MASTER_PLAYLIST_REGEX.lastIndex = 0;\n    let result;\n    while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {\n      if (result[1]) {\n        var _level$unknownCodecs;\n        // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1\n        const attrs = new AttrList(result[1]);\n        {\n          substituteVariablesInAttributes(parsed, attrs, ['CODECS', 'SUPPLEMENTAL-CODECS', 'ALLOWED-CPC', 'PATHWAY-ID', 'STABLE-VARIANT-ID', 'AUDIO', 'VIDEO', 'SUBTITLES', 'CLOSED-CAPTIONS', 'NAME']);\n        }\n        const uri = substituteVariables(parsed, result[2]) ;\n        const level = {\n          attrs,\n          bitrate: attrs.decimalInteger('BANDWIDTH') || attrs.decimalInteger('AVERAGE-BANDWIDTH'),\n          name: attrs.NAME,\n          url: M3U8Parser.resolve(uri, baseurl)\n        };\n        const resolution = attrs.decimalResolution('RESOLUTION');\n        if (resolution) {\n          level.width = resolution.width;\n          level.height = resolution.height;\n        }\n        setCodecs(attrs.CODECS, level);\n        if (!((_level$unknownCodecs = level.unknownCodecs) != null && _level$unknownCodecs.length)) {\n          levelsWithKnownCodecs.push(level);\n        }\n        parsed.levels.push(level);\n      } else if (result[3]) {\n        const tag = result[3];\n        const attributes = result[4];\n        switch (tag) {\n          case 'SESSION-DATA':\n            {\n              // #EXT-X-SESSION-DATA\n              const sessionAttrs = new AttrList(attributes);\n              {\n                substituteVariablesInAttributes(parsed, sessionAttrs, ['DATA-ID', 'LANGUAGE', 'VALUE', 'URI']);\n              }\n              const dataId = sessionAttrs['DATA-ID'];\n              if (dataId) {\n                if (parsed.sessionData === null) {\n                  parsed.sessionData = {};\n                }\n                parsed.sessionData[dataId] = sessionAttrs;\n              }\n              break;\n            }\n          case 'SESSION-KEY':\n            {\n              // #EXT-X-SESSION-KEY\n              const sessionKey = parseKey(attributes, baseurl, parsed);\n              if (sessionKey.encrypted && sessionKey.isSupported()) {\n                if (parsed.sessionKeys === null) {\n                  parsed.sessionKeys = [];\n                }\n                parsed.sessionKeys.push(sessionKey);\n              } else {\n                logger.warn(`[Keys] Ignoring invalid EXT-X-SESSION-KEY tag: \"${attributes}\"`);\n              }\n              break;\n            }\n          case 'DEFINE':\n            {\n              // #EXT-X-DEFINE\n              {\n                const variableAttributes = new AttrList(attributes);\n                substituteVariablesInAttributes(parsed, variableAttributes, ['NAME', 'VALUE', 'QUERYPARAM']);\n                addVariableDefinition(parsed, variableAttributes, baseurl);\n              }\n              break;\n            }\n          case 'CONTENT-STEERING':\n            {\n              // #EXT-X-CONTENT-STEERING\n              const contentSteeringAttributes = new AttrList(attributes);\n              {\n                substituteVariablesInAttributes(parsed, contentSteeringAttributes, ['SERVER-URI', 'PATHWAY-ID']);\n              }\n              parsed.contentSteering = {\n                uri: M3U8Parser.resolve(contentSteeringAttributes['SERVER-URI'], baseurl),\n                pathwayId: contentSteeringAttributes['PATHWAY-ID'] || '.'\n              };\n              break;\n            }\n          case 'START':\n            {\n              // #EXT-X-START\n              parsed.startTimeOffset = parseStartTimeOffset(attributes);\n              break;\n            }\n        }\n      }\n    }\n    // Filter out levels with unknown codecs if it does not remove all levels\n    const stripUnknownCodecLevels = levelsWithKnownCodecs.length > 0 && levelsWithKnownCodecs.length < parsed.levels.length;\n    parsed.levels = stripUnknownCodecLevels ? levelsWithKnownCodecs : parsed.levels;\n    if (parsed.levels.length === 0) {\n      parsed.playlistParsingError = new Error('no levels found in manifest');\n    }\n    return parsed;\n  }\n  static parseMasterPlaylistMedia(string, baseurl, parsed) {\n    let result;\n    const results = {};\n    const levels = parsed.levels;\n    const groupsByType = {\n      AUDIO: levels.map(level => ({\n        id: level.attrs.AUDIO,\n        audioCodec: level.audioCodec\n      })),\n      SUBTITLES: levels.map(level => ({\n        id: level.attrs.SUBTITLES,\n        textCodec: level.textCodec\n      })),\n      'CLOSED-CAPTIONS': []\n    };\n    let id = 0;\n    MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;\n    while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {\n      const attrs = new AttrList(result[1]);\n      const type = attrs.TYPE;\n      if (type) {\n        const groups = groupsByType[type];\n        const medias = results[type] || [];\n        results[type] = medias;\n        {\n          substituteVariablesInAttributes(parsed, attrs, ['URI', 'GROUP-ID', 'LANGUAGE', 'ASSOC-LANGUAGE', 'STABLE-RENDITION-ID', 'NAME', 'INSTREAM-ID', 'CHARACTERISTICS', 'CHANNELS']);\n        }\n        const lang = attrs.LANGUAGE;\n        const assocLang = attrs['ASSOC-LANGUAGE'];\n        const channels = attrs.CHANNELS;\n        const characteristics = attrs.CHARACTERISTICS;\n        const instreamId = attrs['INSTREAM-ID'];\n        const media = {\n          attrs,\n          bitrate: 0,\n          id: id++,\n          groupId: attrs['GROUP-ID'] || '',\n          name: attrs.NAME || lang || '',\n          type,\n          default: attrs.bool('DEFAULT'),\n          autoselect: attrs.bool('AUTOSELECT'),\n          forced: attrs.bool('FORCED'),\n          lang,\n          url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : ''\n        };\n        if (assocLang) {\n          media.assocLang = assocLang;\n        }\n        if (channels) {\n          media.channels = channels;\n        }\n        if (characteristics) {\n          media.characteristics = characteristics;\n        }\n        if (instreamId) {\n          media.instreamId = instreamId;\n        }\n        if (groups != null && groups.length) {\n          // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track\n          // If we don't find the track signalled, lets use the first audio groups codec we have\n          // Acting as a best guess\n          const groupCodec = M3U8Parser.findGroup(groups, media.groupId) || groups[0];\n          assignCodec(media, groupCodec, 'audioCodec');\n          assignCodec(media, groupCodec, 'textCodec');\n        }\n        medias.push(media);\n      }\n    }\n    return results;\n  }\n  static parseLevelPlaylist(string, baseurl, id, type, levelUrlId, multivariantVariableList) {\n    const level = new LevelDetails(baseurl);\n    const fragments = level.fragments;\n    // The most recent init segment seen (applies to all subsequent segments)\n    let currentInitSegment = null;\n    let currentSN = 0;\n    let currentPart = 0;\n    let totalduration = 0;\n    let discontinuityCounter = 0;\n    let prevFrag = null;\n    let frag = new Fragment(type, baseurl);\n    let result;\n    let i;\n    let levelkeys;\n    let firstPdtIndex = -1;\n    let createNextFrag = false;\n    let nextByteRange = null;\n    LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;\n    level.m3u8 = string;\n    level.hasVariableRefs = hasVariableReferences(string) ;\n    while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {\n      if (createNextFrag) {\n        createNextFrag = false;\n        frag = new Fragment(type, baseurl);\n        // setup the next fragment for part loading\n        frag.start = totalduration;\n        frag.sn = currentSN;\n        frag.cc = discontinuityCounter;\n        frag.level = id;\n        if (currentInitSegment) {\n          frag.initSegment = currentInitSegment;\n          frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n          currentInitSegment.rawProgramDateTime = null;\n          if (nextByteRange) {\n            frag.setByteRange(nextByteRange);\n            nextByteRange = null;\n          }\n        }\n      }\n      const duration = result[1];\n      if (duration) {\n        // INF\n        frag.duration = parseFloat(duration);\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        const title = (' ' + result[2]).slice(1);\n        frag.title = title || null;\n        frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);\n      } else if (result[3]) {\n        // url\n        if (isFiniteNumber(frag.duration)) {\n          frag.start = totalduration;\n          if (levelkeys) {\n            setFragLevelKeys(frag, levelkeys, level);\n          }\n          frag.sn = currentSN;\n          frag.level = id;\n          frag.cc = discontinuityCounter;\n          fragments.push(frag);\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          const uri = (' ' + result[3]).slice(1);\n          frag.relurl = substituteVariables(level, uri) ;\n          assignProgramDateTime(frag, prevFrag);\n          prevFrag = frag;\n          totalduration += frag.duration;\n          currentSN++;\n          currentPart = 0;\n          createNextFrag = true;\n        }\n      } else if (result[4]) {\n        // X-BYTERANGE\n        const data = (' ' + result[4]).slice(1);\n        if (prevFrag) {\n          frag.setByteRange(data, prevFrag);\n        } else {\n          frag.setByteRange(data);\n        }\n      } else if (result[5]) {\n        // PROGRAM-DATE-TIME\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        frag.rawProgramDateTime = (' ' + result[5]).slice(1);\n        frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);\n        if (firstPdtIndex === -1) {\n          firstPdtIndex = fragments.length;\n        }\n      } else {\n        result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);\n        if (!result) {\n          logger.warn('No matches on slow regex match for level playlist!');\n          continue;\n        }\n        for (i = 1; i < result.length; i++) {\n          if (typeof result[i] !== 'undefined') {\n            break;\n          }\n        }\n\n        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n        const tag = (' ' + result[i]).slice(1);\n        const value1 = (' ' + result[i + 1]).slice(1);\n        const value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : '';\n        switch (tag) {\n          case 'PLAYLIST-TYPE':\n            level.type = value1.toUpperCase();\n            break;\n          case 'MEDIA-SEQUENCE':\n            currentSN = level.startSN = parseInt(value1);\n            break;\n          case 'SKIP':\n            {\n              const skipAttrs = new AttrList(value1);\n              {\n                substituteVariablesInAttributes(level, skipAttrs, ['RECENTLY-REMOVED-DATERANGES']);\n              }\n              const skippedSegments = skipAttrs.decimalInteger('SKIPPED-SEGMENTS');\n              if (isFiniteNumber(skippedSegments)) {\n                level.skippedSegments = skippedSegments;\n                // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`\n                for (let _i = skippedSegments; _i--;) {\n                  fragments.unshift(null);\n                }\n                currentSN += skippedSegments;\n              }\n              const recentlyRemovedDateranges = skipAttrs.enumeratedString('RECENTLY-REMOVED-DATERANGES');\n              if (recentlyRemovedDateranges) {\n                level.recentlyRemovedDateranges = recentlyRemovedDateranges.split('\\t');\n              }\n              break;\n            }\n          case 'TARGETDURATION':\n            level.targetduration = Math.max(parseInt(value1), 1);\n            break;\n          case 'VERSION':\n            level.version = parseInt(value1);\n            break;\n          case 'INDEPENDENT-SEGMENTS':\n          case 'EXTM3U':\n            break;\n          case 'ENDLIST':\n            level.live = false;\n            break;\n          case '#':\n            if (value1 || value2) {\n              frag.tagList.push(value2 ? [value1, value2] : [value1]);\n            }\n            break;\n          case 'DISCONTINUITY':\n            discontinuityCounter++;\n            frag.tagList.push(['DIS']);\n            break;\n          case 'GAP':\n            frag.gap = true;\n            frag.tagList.push([tag]);\n            break;\n          case 'BITRATE':\n            frag.tagList.push([tag, value1]);\n            break;\n          case 'DATERANGE':\n            {\n              const dateRangeAttr = new AttrList(value1);\n              {\n                substituteVariablesInAttributes(level, dateRangeAttr, ['ID', 'CLASS', 'START-DATE', 'END-DATE', 'SCTE35-CMD', 'SCTE35-OUT', 'SCTE35-IN']);\n                substituteVariablesInAttributes(level, dateRangeAttr, dateRangeAttr.clientAttrs);\n              }\n              const dateRange = new DateRange(dateRangeAttr, level.dateRanges[dateRangeAttr.ID]);\n              if (dateRange.isValid || level.skippedSegments) {\n                level.dateRanges[dateRange.id] = dateRange;\n              } else {\n                logger.warn(`Ignoring invalid DATERANGE tag: \"${value1}\"`);\n              }\n              // Add to fragment tag list for backwards compatibility (< v1.2.0)\n              frag.tagList.push(['EXT-X-DATERANGE', value1]);\n              break;\n            }\n          case 'DEFINE':\n            {\n              {\n                const variableAttributes = new AttrList(value1);\n                substituteVariablesInAttributes(level, variableAttributes, ['NAME', 'VALUE', 'IMPORT', 'QUERYPARAM']);\n                if ('IMPORT' in variableAttributes) {\n                  importVariableDefinition(level, variableAttributes, multivariantVariableList);\n                } else {\n                  addVariableDefinition(level, variableAttributes, baseurl);\n                }\n              }\n              break;\n            }\n          case 'DISCONTINUITY-SEQUENCE':\n            discontinuityCounter = parseInt(value1);\n            break;\n          case 'KEY':\n            {\n              const levelKey = parseKey(value1, baseurl, level);\n              if (levelKey.isSupported()) {\n                if (levelKey.method === 'NONE') {\n                  levelkeys = undefined;\n                  break;\n                }\n                if (!levelkeys) {\n                  levelkeys = {};\n                }\n                if (levelkeys[levelKey.keyFormat]) {\n                  levelkeys = _extends({}, levelkeys);\n                }\n                levelkeys[levelKey.keyFormat] = levelKey;\n              } else {\n                logger.warn(`[Keys] Ignoring invalid EXT-X-KEY tag: \"${value1}\"`);\n              }\n              break;\n            }\n          case 'START':\n            level.startTimeOffset = parseStartTimeOffset(value1);\n            break;\n          case 'MAP':\n            {\n              const mapAttrs = new AttrList(value1);\n              {\n                substituteVariablesInAttributes(level, mapAttrs, ['BYTERANGE', 'URI']);\n              }\n              if (frag.duration) {\n                // Initial segment tag is after segment duration tag.\n                //   #EXTINF: 6.0\n                //   #EXT-X-MAP:URI=\"init.mp4\n                const init = new Fragment(type, baseurl);\n                setInitSegment(init, mapAttrs, id, levelkeys);\n                currentInitSegment = init;\n                frag.initSegment = currentInitSegment;\n                if (currentInitSegment.rawProgramDateTime && !frag.rawProgramDateTime) {\n                  frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n                }\n              } else {\n                // Initial segment tag is before segment duration tag\n                // Handle case where EXT-X-MAP is declared after EXT-X-BYTERANGE\n                const end = frag.byteRangeEndOffset;\n                if (end) {\n                  const start = frag.byteRangeStartOffset;\n                  nextByteRange = `${end - start}@${start}`;\n                } else {\n                  nextByteRange = null;\n                }\n                setInitSegment(frag, mapAttrs, id, levelkeys);\n                currentInitSegment = frag;\n                createNextFrag = true;\n              }\n              break;\n            }\n          case 'SERVER-CONTROL':\n            {\n              const serverControlAttrs = new AttrList(value1);\n              level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');\n              level.canSkipUntil = serverControlAttrs.optionalFloat('CAN-SKIP-UNTIL', 0);\n              level.canSkipDateRanges = level.canSkipUntil > 0 && serverControlAttrs.bool('CAN-SKIP-DATERANGES');\n              level.partHoldBack = serverControlAttrs.optionalFloat('PART-HOLD-BACK', 0);\n              level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);\n              break;\n            }\n          case 'PART-INF':\n            {\n              const partInfAttrs = new AttrList(value1);\n              level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');\n              break;\n            }\n          case 'PART':\n            {\n              let partList = level.partList;\n              if (!partList) {\n                partList = level.partList = [];\n              }\n              const previousFragmentPart = currentPart > 0 ? partList[partList.length - 1] : undefined;\n              const index = currentPart++;\n              const partAttrs = new AttrList(value1);\n              {\n                substituteVariablesInAttributes(level, partAttrs, ['BYTERANGE', 'URI']);\n              }\n              const part = new Part(partAttrs, frag, baseurl, index, previousFragmentPart);\n              partList.push(part);\n              frag.duration += part.duration;\n              break;\n            }\n          case 'PRELOAD-HINT':\n            {\n              const preloadHintAttrs = new AttrList(value1);\n              {\n                substituteVariablesInAttributes(level, preloadHintAttrs, ['URI']);\n              }\n              level.preloadHint = preloadHintAttrs;\n              break;\n            }\n          case 'RENDITION-REPORT':\n            {\n              const renditionReportAttrs = new AttrList(value1);\n              {\n                substituteVariablesInAttributes(level, renditionReportAttrs, ['URI']);\n              }\n              level.renditionReports = level.renditionReports || [];\n              level.renditionReports.push(renditionReportAttrs);\n              break;\n            }\n          default:\n            logger.warn(`line parsed but not handled: ${result}`);\n            break;\n        }\n      }\n    }\n    if (prevFrag && !prevFrag.relurl) {\n      fragments.pop();\n      totalduration -= prevFrag.duration;\n      if (level.partList) {\n        level.fragmentHint = prevFrag;\n      }\n    } else if (level.partList) {\n      assignProgramDateTime(frag, prevFrag);\n      frag.cc = discontinuityCounter;\n      level.fragmentHint = frag;\n      if (levelkeys) {\n        setFragLevelKeys(frag, levelkeys, level);\n      }\n    }\n    const fragmentLength = fragments.length;\n    const firstFragment = fragments[0];\n    const lastFragment = fragments[fragmentLength - 1];\n    totalduration += level.skippedSegments * level.targetduration;\n    if (totalduration > 0 && fragmentLength && lastFragment) {\n      level.averagetargetduration = totalduration / fragmentLength;\n      const lastSn = lastFragment.sn;\n      level.endSN = lastSn !== 'initSegment' ? lastSn : 0;\n      if (!level.live) {\n        lastFragment.endList = true;\n      }\n      if (firstFragment) {\n        level.startCC = firstFragment.cc;\n      }\n    } else {\n      level.endSN = 0;\n      level.startCC = 0;\n    }\n    if (level.fragmentHint) {\n      totalduration += level.fragmentHint.duration;\n    }\n    level.totalduration = totalduration;\n    level.endCC = discontinuityCounter;\n\n    /**\n     * Backfill any missing PDT values\n     * \"If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after\n     * one or more Media Segment URIs, the client SHOULD extrapolate\n     * backward from that tag (using EXTINF durations and/or media\n     * timestamps) to associate dates with those segments.\"\n     * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs\n     * computed.\n     */\n    if (firstPdtIndex > 0) {\n      backfillProgramDateTimes(fragments, firstPdtIndex);\n    }\n    return level;\n  }\n}\nfunction parseKey(keyTagAttributes, baseurl, parsed) {\n  var _keyAttrs$METHOD, _keyAttrs$KEYFORMAT;\n  // https://tools.ietf.org/html/rfc8216#section-4.3.2.4\n  const keyAttrs = new AttrList(keyTagAttributes);\n  {\n    substituteVariablesInAttributes(parsed, keyAttrs, ['KEYFORMAT', 'KEYFORMATVERSIONS', 'URI', 'IV', 'URI']);\n  }\n  const decryptmethod = (_keyAttrs$METHOD = keyAttrs.METHOD) != null ? _keyAttrs$METHOD : '';\n  const decrypturi = keyAttrs.URI;\n  const decryptiv = keyAttrs.hexadecimalInteger('IV');\n  const decryptkeyformatversions = keyAttrs.KEYFORMATVERSIONS;\n  // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of \"identity\".\n  const decryptkeyformat = (_keyAttrs$KEYFORMAT = keyAttrs.KEYFORMAT) != null ? _keyAttrs$KEYFORMAT : 'identity';\n  if (decrypturi && keyAttrs.IV && !decryptiv) {\n    logger.error(`Invalid IV: ${keyAttrs.IV}`);\n  }\n  // If decrypturi is a URI with a scheme, then baseurl will be ignored\n  // No uri is allowed when METHOD is NONE\n  const resolvedUri = decrypturi ? M3U8Parser.resolve(decrypturi, baseurl) : '';\n  const keyFormatVersions = (decryptkeyformatversions ? decryptkeyformatversions : '1').split('/').map(Number).filter(Number.isFinite);\n  return new LevelKey(decryptmethod, resolvedUri, decryptkeyformat, keyFormatVersions, decryptiv);\n}\nfunction parseStartTimeOffset(startAttributes) {\n  const startAttrs = new AttrList(startAttributes);\n  const startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');\n  if (isFiniteNumber(startTimeOffset)) {\n    return startTimeOffset;\n  }\n  return null;\n}\nfunction setCodecs(codecsAttributeValue, level) {\n  let codecs = (codecsAttributeValue || '').split(/[ ,]+/).filter(c => c);\n  ['video', 'audio', 'text'].forEach(type => {\n    const filtered = codecs.filter(codec => isCodecType(codec, type));\n    if (filtered.length) {\n      // Comma separated list of all codecs for type\n      level[`${type}Codec`] = filtered.join(',');\n      // Remove known codecs so that only unknownCodecs are left after iterating through each type\n      codecs = codecs.filter(codec => filtered.indexOf(codec) === -1);\n    }\n  });\n  level.unknownCodecs = codecs;\n}\nfunction assignCodec(media, groupItem, codecProperty) {\n  const codecValue = groupItem[codecProperty];\n  if (codecValue) {\n    media[codecProperty] = codecValue;\n  }\n}\nfunction backfillProgramDateTimes(fragments, firstPdtIndex) {\n  let fragPrev = fragments[firstPdtIndex];\n  for (let i = firstPdtIndex; i--;) {\n    const frag = fragments[i];\n    // Exit on delta-playlist skipped segments\n    if (!frag) {\n      return;\n    }\n    frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;\n    fragPrev = frag;\n  }\n}\nfunction assignProgramDateTime(frag, prevFrag) {\n  if (frag.rawProgramDateTime) {\n    frag.programDateTime = Date.parse(frag.rawProgramDateTime);\n  } else if (prevFrag != null && prevFrag.programDateTime) {\n    frag.programDateTime = prevFrag.endProgramDateTime;\n  }\n  if (!isFiniteNumber(frag.programDateTime)) {\n    frag.programDateTime = null;\n    frag.rawProgramDateTime = null;\n  }\n}\nfunction setInitSegment(frag, mapAttrs, id, levelkeys) {\n  frag.relurl = mapAttrs.URI;\n  if (mapAttrs.BYTERANGE) {\n    frag.setByteRange(mapAttrs.BYTERANGE);\n  }\n  frag.level = id;\n  frag.sn = 'initSegment';\n  if (levelkeys) {\n    frag.levelkeys = levelkeys;\n  }\n  frag.initSegment = null;\n}\nfunction setFragLevelKeys(frag, levelkeys, level) {\n  frag.levelkeys = levelkeys;\n  const {\n    encryptedFragments\n  } = level;\n  if ((!encryptedFragments.length || encryptedFragments[encryptedFragments.length - 1].levelkeys !== levelkeys) && Object.keys(levelkeys).some(format => levelkeys[format].isCommonEncryption)) {\n    encryptedFragments.push(frag);\n  }\n}\n\nvar PlaylistContextType = {\n  MANIFEST: \"manifest\",\n  LEVEL: \"level\",\n  AUDIO_TRACK: \"audioTrack\",\n  SUBTITLE_TRACK: \"subtitleTrack\"\n};\nvar PlaylistLevelType = {\n  MAIN: \"main\",\n  AUDIO: \"audio\",\n  SUBTITLE: \"subtitle\"\n};\n\nfunction mapContextToLevelType(context) {\n  const {\n    type\n  } = context;\n  switch (type) {\n    case PlaylistContextType.AUDIO_TRACK:\n      return PlaylistLevelType.AUDIO;\n    case PlaylistContextType.SUBTITLE_TRACK:\n      return PlaylistLevelType.SUBTITLE;\n    default:\n      return PlaylistLevelType.MAIN;\n  }\n}\nfunction getResponseUrl(response, context) {\n  let url = response.url;\n  // responseURL not supported on some browsers (it is used to detect URL redirection)\n  // data-uri mode also not supported (but no need to detect redirection)\n  if (url === undefined || url.indexOf('data:') === 0) {\n    // fallback to initial URL\n    url = context.url;\n  }\n  return url;\n}\nclass PlaylistLoader {\n  constructor(hls) {\n    this.hls = void 0;\n    this.loaders = Object.create(null);\n    this.variableList = null;\n    this.hls = hls;\n    this.registerListeners();\n  }\n  startLoad(startPosition) {}\n  stopLoad() {\n    this.destroyInternalLoaders();\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n  }\n\n  /**\n   * Returns defaults or configured loader-type overloads (pLoader and loader config params)\n   */\n  createInternalLoader(context) {\n    const config = this.hls.config;\n    const PLoader = config.pLoader;\n    const Loader = config.loader;\n    const InternalLoader = PLoader || Loader;\n    const loader = new InternalLoader(config);\n    this.loaders[context.type] = loader;\n    return loader;\n  }\n  getInternalLoader(context) {\n    return this.loaders[context.type];\n  }\n  resetInternalLoader(contextType) {\n    if (this.loaders[contextType]) {\n      delete this.loaders[contextType];\n    }\n  }\n\n  /**\n   * Call `destroy` on all internal loader instances mapped (one per context type)\n   */\n  destroyInternalLoaders() {\n    for (const contextType in this.loaders) {\n      const loader = this.loaders[contextType];\n      if (loader) {\n        loader.destroy();\n      }\n      this.resetInternalLoader(contextType);\n    }\n  }\n  destroy() {\n    this.variableList = null;\n    this.unregisterListeners();\n    this.destroyInternalLoaders();\n  }\n  onManifestLoading(event, data) {\n    const {\n      url\n    } = data;\n    this.variableList = null;\n    this.load({\n      id: null,\n      level: 0,\n      responseType: 'text',\n      type: PlaylistContextType.MANIFEST,\n      url,\n      deliveryDirectives: null\n    });\n  }\n  onLevelLoading(event, data) {\n    const {\n      id,\n      level,\n      pathwayId,\n      url,\n      deliveryDirectives\n    } = data;\n    this.load({\n      id,\n      level,\n      pathwayId,\n      responseType: 'text',\n      type: PlaylistContextType.LEVEL,\n      url,\n      deliveryDirectives\n    });\n  }\n  onAudioTrackLoading(event, data) {\n    const {\n      id,\n      groupId,\n      url,\n      deliveryDirectives\n    } = data;\n    this.load({\n      id,\n      groupId,\n      level: null,\n      responseType: 'text',\n      type: PlaylistContextType.AUDIO_TRACK,\n      url,\n      deliveryDirectives\n    });\n  }\n  onSubtitleTrackLoading(event, data) {\n    const {\n      id,\n      groupId,\n      url,\n      deliveryDirectives\n    } = data;\n    this.load({\n      id,\n      groupId,\n      level: null,\n      responseType: 'text',\n      type: PlaylistContextType.SUBTITLE_TRACK,\n      url,\n      deliveryDirectives\n    });\n  }\n  load(context) {\n    var _context$deliveryDire;\n    const config = this.hls.config;\n\n    // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);\n\n    // Check if a loader for this context already exists\n    let loader = this.getInternalLoader(context);\n    if (loader) {\n      const loaderContext = loader.context;\n      if (loaderContext && loaderContext.url === context.url && loaderContext.level === context.level) {\n        // same URL can't overlap\n        logger.trace('[playlist-loader]: playlist request ongoing');\n        return;\n      }\n      logger.log(`[playlist-loader]: aborting previous loader for type: ${context.type}`);\n      loader.abort();\n    }\n\n    // apply different configs for retries depending on\n    // context (manifest, level, audio/subs playlist)\n    let loadPolicy;\n    if (context.type === PlaylistContextType.MANIFEST) {\n      loadPolicy = config.manifestLoadPolicy.default;\n    } else {\n      loadPolicy = _extends({}, config.playlistLoadPolicy.default, {\n        timeoutRetry: null,\n        errorRetry: null\n      });\n    }\n    loader = this.createInternalLoader(context);\n\n    // Override level/track timeout for LL-HLS requests\n    // (the default of 10000ms is counter productive to blocking playlist reload requests)\n    if (isFiniteNumber((_context$deliveryDire = context.deliveryDirectives) == null ? void 0 : _context$deliveryDire.part)) {\n      let levelDetails;\n      if (context.type === PlaylistContextType.LEVEL && context.level !== null) {\n        levelDetails = this.hls.levels[context.level].details;\n      } else if (context.type === PlaylistContextType.AUDIO_TRACK && context.id !== null) {\n        levelDetails = this.hls.audioTracks[context.id].details;\n      } else if (context.type === PlaylistContextType.SUBTITLE_TRACK && context.id !== null) {\n        levelDetails = this.hls.subtitleTracks[context.id].details;\n      }\n      if (levelDetails) {\n        const partTarget = levelDetails.partTarget;\n        const targetDuration = levelDetails.targetduration;\n        if (partTarget && targetDuration) {\n          const maxLowLatencyPlaylistRefresh = Math.max(partTarget * 3, targetDuration * 0.8) * 1000;\n          loadPolicy = _extends({}, loadPolicy, {\n            maxTimeToFirstByteMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs),\n            maxLoadTimeMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs)\n          });\n        }\n      }\n    }\n    const legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n    const loaderConfig = {\n      loadPolicy,\n      timeout: loadPolicy.maxLoadTimeMs,\n      maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n      retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n      maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0\n    };\n    const loaderCallbacks = {\n      onSuccess: (response, stats, context, networkDetails) => {\n        const loader = this.getInternalLoader(context);\n        this.resetInternalLoader(context.type);\n        const string = response.data;\n\n        // Validate if it is an M3U8 at all\n        if (string.indexOf('#EXTM3U') !== 0) {\n          this.handleManifestParsingError(response, context, new Error('no EXTM3U delimiter'), networkDetails || null, stats);\n          return;\n        }\n        stats.parsing.start = performance.now();\n        if (M3U8Parser.isMediaPlaylist(string)) {\n          this.handleTrackOrLevelPlaylist(response, stats, context, networkDetails || null, loader);\n        } else {\n          this.handleMasterPlaylist(response, stats, context, networkDetails);\n        }\n      },\n      onError: (response, context, networkDetails, stats) => {\n        this.handleNetworkError(context, networkDetails, false, response, stats);\n      },\n      onTimeout: (stats, context, networkDetails) => {\n        this.handleNetworkError(context, networkDetails, true, undefined, stats);\n      }\n    };\n\n    // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);\n\n    loader.load(context, loaderConfig, loaderCallbacks);\n  }\n  handleMasterPlaylist(response, stats, context, networkDetails) {\n    const hls = this.hls;\n    const string = response.data;\n    const url = getResponseUrl(response, context);\n    const parsedResult = M3U8Parser.parseMasterPlaylist(string, url);\n    if (parsedResult.playlistParsingError) {\n      this.handleManifestParsingError(response, context, parsedResult.playlistParsingError, networkDetails, stats);\n      return;\n    }\n    const {\n      contentSteering,\n      levels,\n      sessionData,\n      sessionKeys,\n      startTimeOffset,\n      variableList\n    } = parsedResult;\n    this.variableList = variableList;\n    const {\n      AUDIO: audioTracks = [],\n      SUBTITLES: subtitles,\n      'CLOSED-CAPTIONS': captions\n    } = M3U8Parser.parseMasterPlaylistMedia(string, url, parsedResult);\n    if (audioTracks.length) {\n      // check if we have found an audio track embedded in main playlist (audio track without URI attribute)\n      const embeddedAudioFound = audioTracks.some(audioTrack => !audioTrack.url);\n\n      // if no embedded audio track defined, but audio codec signaled in quality level,\n      // we need to signal this main audio track this could happen with playlists with\n      // alt audio rendition in which quality levels (main)\n      // contains both audio+video. but with mixed audio track not signaled\n      if (!embeddedAudioFound && levels[0].audioCodec && !levels[0].attrs.AUDIO) {\n        logger.log('[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one');\n        audioTracks.unshift({\n          type: 'main',\n          name: 'main',\n          groupId: 'main',\n          default: false,\n          autoselect: false,\n          forced: false,\n          id: -1,\n          attrs: new AttrList({}),\n          bitrate: 0,\n          url: ''\n        });\n      }\n    }\n    hls.trigger(Events.MANIFEST_LOADED, {\n      levels,\n      audioTracks,\n      subtitles,\n      captions,\n      contentSteering,\n      url,\n      stats,\n      networkDetails,\n      sessionData,\n      sessionKeys,\n      startTimeOffset,\n      variableList\n    });\n  }\n  handleTrackOrLevelPlaylist(response, stats, context, networkDetails, loader) {\n    const hls = this.hls;\n    const {\n      id,\n      level,\n      type\n    } = context;\n    const url = getResponseUrl(response, context);\n    const levelUrlId = 0;\n    const levelId = isFiniteNumber(level) ? level : isFiniteNumber(id) ? id : 0;\n    const levelType = mapContextToLevelType(context);\n    const levelDetails = M3U8Parser.parseLevelPlaylist(response.data, url, levelId, levelType, levelUrlId, this.variableList);\n\n    // We have done our first request (Manifest-type) and receive\n    // not a master playlist but a chunk-list (track/level)\n    // We fire the manifest-loaded event anyway with the parsed level-details\n    // by creating a single-level structure for it.\n    if (type === PlaylistContextType.MANIFEST) {\n      const singleLevel = {\n        attrs: new AttrList({}),\n        bitrate: 0,\n        details: levelDetails,\n        name: '',\n        url\n      };\n      hls.trigger(Events.MANIFEST_LOADED, {\n        levels: [singleLevel],\n        audioTracks: [],\n        url,\n        stats,\n        networkDetails,\n        sessionData: null,\n        sessionKeys: null,\n        contentSteering: null,\n        startTimeOffset: null,\n        variableList: null\n      });\n    }\n\n    // save parsing time\n    stats.parsing.end = performance.now();\n\n    // extend the context with the new levelDetails property\n    context.levelDetails = levelDetails;\n    this.handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader);\n  }\n  handleManifestParsingError(response, context, error, networkDetails, stats) {\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.NETWORK_ERROR,\n      details: ErrorDetails.MANIFEST_PARSING_ERROR,\n      fatal: context.type === PlaylistContextType.MANIFEST,\n      url: response.url,\n      err: error,\n      error,\n      reason: error.message,\n      response,\n      context,\n      networkDetails,\n      stats\n    });\n  }\n  handleNetworkError(context, networkDetails, timeout = false, response, stats) {\n    let message = `A network ${timeout ? 'timeout' : 'error' + (response ? ' (status ' + response.code + ')' : '')} occurred while loading ${context.type}`;\n    if (context.type === PlaylistContextType.LEVEL) {\n      message += `: ${context.level} id: ${context.id}`;\n    } else if (context.type === PlaylistContextType.AUDIO_TRACK || context.type === PlaylistContextType.SUBTITLE_TRACK) {\n      message += ` id: ${context.id} group-id: \"${context.groupId}\"`;\n    }\n    const error = new Error(message);\n    logger.warn(`[playlist-loader]: ${message}`);\n    let details = ErrorDetails.UNKNOWN;\n    let fatal = false;\n    const loader = this.getInternalLoader(context);\n    switch (context.type) {\n      case PlaylistContextType.MANIFEST:\n        details = timeout ? ErrorDetails.MANIFEST_LOAD_TIMEOUT : ErrorDetails.MANIFEST_LOAD_ERROR;\n        fatal = true;\n        break;\n      case PlaylistContextType.LEVEL:\n        details = timeout ? ErrorDetails.LEVEL_LOAD_TIMEOUT : ErrorDetails.LEVEL_LOAD_ERROR;\n        fatal = false;\n        break;\n      case PlaylistContextType.AUDIO_TRACK:\n        details = timeout ? ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT : ErrorDetails.AUDIO_TRACK_LOAD_ERROR;\n        fatal = false;\n        break;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        details = timeout ? ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT : ErrorDetails.SUBTITLE_LOAD_ERROR;\n        fatal = false;\n        break;\n    }\n    if (loader) {\n      this.resetInternalLoader(context.type);\n    }\n    const errorData = {\n      type: ErrorTypes.NETWORK_ERROR,\n      details,\n      fatal,\n      url: context.url,\n      loader,\n      context,\n      error,\n      networkDetails,\n      stats\n    };\n    if (response) {\n      const url = (networkDetails == null ? void 0 : networkDetails.url) || context.url;\n      errorData.response = _objectSpread2({\n        url,\n        data: undefined\n      }, response);\n    }\n    this.hls.trigger(Events.ERROR, errorData);\n  }\n  handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader) {\n    const hls = this.hls;\n    const {\n      type,\n      level,\n      id,\n      groupId,\n      deliveryDirectives\n    } = context;\n    const url = getResponseUrl(response, context);\n    const parent = mapContextToLevelType(context);\n    const levelIndex = typeof context.level === 'number' && parent === PlaylistLevelType.MAIN ? level : undefined;\n    if (!levelDetails.fragments.length) {\n      const _error = new Error('No Segments found in Playlist');\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.LEVEL_EMPTY_ERROR,\n        fatal: false,\n        url,\n        error: _error,\n        reason: _error.message,\n        response,\n        context,\n        level: levelIndex,\n        parent,\n        networkDetails,\n        stats\n      });\n      return;\n    }\n    if (!levelDetails.targetduration) {\n      levelDetails.playlistParsingError = new Error('Missing Target Duration');\n    }\n    const error = levelDetails.playlistParsingError;\n    if (error) {\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.LEVEL_PARSING_ERROR,\n        fatal: false,\n        url,\n        error,\n        reason: error.message,\n        response,\n        context,\n        level: levelIndex,\n        parent,\n        networkDetails,\n        stats\n      });\n      return;\n    }\n    if (levelDetails.live && loader) {\n      if (loader.getCacheAge) {\n        levelDetails.ageHeader = loader.getCacheAge() || 0;\n      }\n      if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {\n        levelDetails.ageHeader = 0;\n      }\n    }\n    switch (type) {\n      case PlaylistContextType.MANIFEST:\n      case PlaylistContextType.LEVEL:\n        hls.trigger(Events.LEVEL_LOADED, {\n          details: levelDetails,\n          level: levelIndex || 0,\n          id: id || 0,\n          stats,\n          networkDetails,\n          deliveryDirectives\n        });\n        break;\n      case PlaylistContextType.AUDIO_TRACK:\n        hls.trigger(Events.AUDIO_TRACK_LOADED, {\n          details: levelDetails,\n          id: id || 0,\n          groupId: groupId || '',\n          stats,\n          networkDetails,\n          deliveryDirectives\n        });\n        break;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        hls.trigger(Events.SUBTITLE_TRACK_LOADED, {\n          details: levelDetails,\n          id: id || 0,\n          groupId: groupId || '',\n          stats,\n          networkDetails,\n          deliveryDirectives\n        });\n        break;\n    }\n  }\n}\n\nfunction sendAddTrackEvent(track, videoEl) {\n  let event;\n  try {\n    event = new Event('addtrack');\n  } catch (err) {\n    // for IE11\n    event = document.createEvent('Event');\n    event.initEvent('addtrack', false, false);\n  }\n  event.track = track;\n  videoEl.dispatchEvent(event);\n}\nfunction addCueToTrack(track, cue) {\n  // Sometimes there are cue overlaps on segmented vtts so the same\n  // cue can appear more than once in different vtt files.\n  // This avoid showing duplicated cues with same timecode and text.\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues && !track.cues.getCueById(cue.id)) {\n    try {\n      track.addCue(cue);\n      if (!track.cues.getCueById(cue.id)) {\n        throw new Error(`addCue is failed for: ${cue}`);\n      }\n    } catch (err) {\n      logger.debug(`[texttrack-utils]: ${err}`);\n      try {\n        const textTrackCue = new self.TextTrackCue(cue.startTime, cue.endTime, cue.text);\n        textTrackCue.id = cue.id;\n        track.addCue(textTrackCue);\n      } catch (err2) {\n        logger.debug(`[texttrack-utils]: Legacy TextTrackCue fallback failed: ${err2}`);\n      }\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\nfunction clearCurrentCues(track) {\n  // When track.mode is disabled, track.cues will be null.\n  // To guarantee the removal of cues, we need to temporarily\n  // change the mode to hidden\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues) {\n    for (let i = track.cues.length; i--;) {\n      track.removeCue(track.cues[i]);\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\nfunction removeCuesInRange(track, start, end, predicate) {\n  const mode = track.mode;\n  if (mode === 'disabled') {\n    track.mode = 'hidden';\n  }\n  if (track.cues && track.cues.length > 0) {\n    const cues = getCuesInRange(track.cues, start, end);\n    for (let i = 0; i < cues.length; i++) {\n      if (!predicate || predicate(cues[i])) {\n        track.removeCue(cues[i]);\n      }\n    }\n  }\n  if (mode === 'disabled') {\n    track.mode = mode;\n  }\n}\n\n// Find first cue starting after given time.\n// Modified version of binary search O(log(n)).\nfunction getFirstCueIndexAfterTime(cues, time) {\n  // If first cue starts after time, start there\n  if (time < cues[0].startTime) {\n    return 0;\n  }\n  // If the last cue ends before time there is no overlap\n  const len = cues.length - 1;\n  if (time > cues[len].endTime) {\n    return -1;\n  }\n  let left = 0;\n  let right = len;\n  while (left <= right) {\n    const mid = Math.floor((right + left) / 2);\n    if (time < cues[mid].startTime) {\n      right = mid - 1;\n    } else if (time > cues[mid].startTime && left < len) {\n      left = mid + 1;\n    } else {\n      // If it's not lower or higher, it must be equal.\n      return mid;\n    }\n  }\n  // At this point, left and right have swapped.\n  // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.\n  return cues[left].startTime - time < time - cues[right].startTime ? left : right;\n}\nfunction getCuesInRange(cues, start, end) {\n  const cuesFound = [];\n  const firstCueInRange = getFirstCueIndexAfterTime(cues, start);\n  if (firstCueInRange > -1) {\n    for (let i = firstCueInRange, len = cues.length; i < len; i++) {\n      const cue = cues[i];\n      if (cue.startTime >= start && cue.endTime <= end) {\n        cuesFound.push(cue);\n      } else if (cue.startTime > end) {\n        return cuesFound;\n      }\n    }\n  }\n  return cuesFound;\n}\nfunction filterSubtitleTracks(textTrackList) {\n  const tracks = [];\n  for (let i = 0; i < textTrackList.length; i++) {\n    const track = textTrackList[i];\n    // Edge adds a track without a label; we don't want to use it\n    if ((track.kind === 'subtitles' || track.kind === 'captions') && track.label) {\n      tracks.push(textTrackList[i]);\n    }\n  }\n  return tracks;\n}\n\nvar MetadataSchema = {\n  audioId3: \"org.id3\",\n  dateRange: \"com.apple.quicktime.HLS\",\n  emsg: \"https://aomedia.org/emsg/ID3\"\n};\n\nconst MIN_CUE_DURATION = 0.25;\nfunction getCueClass() {\n  if (typeof self === 'undefined') return undefined;\n  return self.VTTCue || self.TextTrackCue;\n}\nfunction createCueWithDataFields(Cue, startTime, endTime, data, type) {\n  let cue = new Cue(startTime, endTime, '');\n  try {\n    cue.value = data;\n    if (type) {\n      cue.type = type;\n    }\n  } catch (e) {\n    cue = new Cue(startTime, endTime, JSON.stringify(type ? _objectSpread2({\n      type\n    }, data) : data));\n  }\n  return cue;\n}\n\n// VTTCue latest draft allows an infinite duration, fallback\n// to MAX_VALUE if necessary\nconst MAX_CUE_ENDTIME = (() => {\n  const Cue = getCueClass();\n  try {\n    Cue && new Cue(0, Number.POSITIVE_INFINITY, '');\n  } catch (e) {\n    return Number.MAX_VALUE;\n  }\n  return Number.POSITIVE_INFINITY;\n})();\nfunction dateRangeDateToTimelineSeconds(date, offset) {\n  return date.getTime() / 1000 - offset;\n}\nfunction hexToArrayBuffer(str) {\n  return Uint8Array.from(str.replace(/^0x/, '').replace(/([\\da-fA-F]{2}) ?/g, '0x$1 ').replace(/ +$/, '').split(' ')).buffer;\n}\nclass ID3TrackController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n    this.hls = hls;\n    this._registerListeners();\n  }\n  destroy() {\n    this._unregisterListeners();\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n    // @ts-ignore\n    this.hls = null;\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n\n  // Add ID3 metatadata text track.\n  onMediaAttached(event, data) {\n    this.media = data.media;\n  }\n  onMediaDetaching() {\n    if (!this.id3Track) {\n      return;\n    }\n    clearCurrentCues(this.id3Track);\n    this.id3Track = null;\n    this.media = null;\n    this.dateRangeCuesAppended = {};\n  }\n  onManifestLoading() {\n    this.dateRangeCuesAppended = {};\n  }\n  createTrack(media) {\n    const track = this.getID3Track(media.textTracks);\n    track.mode = 'hidden';\n    return track;\n  }\n  getID3Track(textTracks) {\n    if (!this.media) {\n      return;\n    }\n    for (let i = 0; i < textTracks.length; i++) {\n      const textTrack = textTracks[i];\n      if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {\n        // send 'addtrack' when reusing the textTrack for metadata,\n        // same as what we do for captions\n        sendAddTrackEvent(textTrack, this.media);\n        return textTrack;\n      }\n    }\n    return this.media.addTextTrack('metadata', 'id3');\n  }\n  onFragParsingMetadata(event, data) {\n    if (!this.media) {\n      return;\n    }\n    const {\n      hls: {\n        config: {\n          enableEmsgMetadataCues,\n          enableID3MetadataCues\n        }\n      }\n    } = this;\n    if (!enableEmsgMetadataCues && !enableID3MetadataCues) {\n      return;\n    }\n    const {\n      samples\n    } = data;\n\n    // create track dynamically\n    if (!this.id3Track) {\n      this.id3Track = this.createTrack(this.media);\n    }\n    const Cue = getCueClass();\n    if (!Cue) {\n      return;\n    }\n    for (let i = 0; i < samples.length; i++) {\n      const type = samples[i].type;\n      if (type === MetadataSchema.emsg && !enableEmsgMetadataCues || !enableID3MetadataCues) {\n        continue;\n      }\n      const frames = getID3Frames(samples[i].data);\n      if (frames) {\n        const startTime = samples[i].pts;\n        let endTime = startTime + samples[i].duration;\n        if (endTime > MAX_CUE_ENDTIME) {\n          endTime = MAX_CUE_ENDTIME;\n        }\n        const timeDiff = endTime - startTime;\n        if (timeDiff <= 0) {\n          endTime = startTime + MIN_CUE_DURATION;\n        }\n        for (let j = 0; j < frames.length; j++) {\n          const frame = frames[j];\n          // Safari doesn't put the timestamp frame in the TextTrack\n          if (!isTimeStampFrame(frame)) {\n            // add a bounds to any unbounded cues\n            this.updateId3CueEnds(startTime, type);\n            const cue = createCueWithDataFields(Cue, startTime, endTime, frame, type);\n            if (cue) {\n              this.id3Track.addCue(cue);\n            }\n          }\n        }\n      }\n    }\n  }\n  updateId3CueEnds(startTime, type) {\n    var _this$id3Track;\n    const cues = (_this$id3Track = this.id3Track) == null ? void 0 : _this$id3Track.cues;\n    if (cues) {\n      for (let i = cues.length; i--;) {\n        const cue = cues[i];\n        if (cue.type === type && cue.startTime < startTime && cue.endTime === MAX_CUE_ENDTIME) {\n          cue.endTime = startTime;\n        }\n      }\n    }\n  }\n  onBufferFlushing(event, {\n    startOffset,\n    endOffset,\n    type\n  }) {\n    const {\n      id3Track,\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    const {\n      config: {\n        enableEmsgMetadataCues,\n        enableID3MetadataCues\n      }\n    } = hls;\n    if (id3Track && (enableEmsgMetadataCues || enableID3MetadataCues)) {\n      let predicate;\n      if (type === 'audio') {\n        predicate = cue => cue.type === MetadataSchema.audioId3 && enableID3MetadataCues;\n      } else if (type === 'video') {\n        predicate = cue => cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;\n      } else {\n        predicate = cue => cue.type === MetadataSchema.audioId3 && enableID3MetadataCues || cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;\n      }\n      removeCuesInRange(id3Track, startOffset, endOffset, predicate);\n    }\n  }\n  onLevelUpdated(event, {\n    details\n  }) {\n    if (!this.media || !details.hasProgramDateTime || !this.hls.config.enableDateRangeMetadataCues) {\n      return;\n    }\n    const {\n      dateRangeCuesAppended,\n      id3Track\n    } = this;\n    const {\n      dateRanges\n    } = details;\n    const ids = Object.keys(dateRanges);\n    // Remove cues from track not found in details.dateRanges\n    if (id3Track) {\n      const idsToRemove = Object.keys(dateRangeCuesAppended).filter(id => !ids.includes(id));\n      for (let i = idsToRemove.length; i--;) {\n        const id = idsToRemove[i];\n        Object.keys(dateRangeCuesAppended[id].cues).forEach(key => {\n          id3Track.removeCue(dateRangeCuesAppended[id].cues[key]);\n        });\n        delete dateRangeCuesAppended[id];\n      }\n    }\n    // Exit if the playlist does not have Date Ranges or does not have Program Date Time\n    const lastFragment = details.fragments[details.fragments.length - 1];\n    if (ids.length === 0 || !isFiniteNumber(lastFragment == null ? void 0 : lastFragment.programDateTime)) {\n      return;\n    }\n    if (!this.id3Track) {\n      this.id3Track = this.createTrack(this.media);\n    }\n    const dateTimeOffset = lastFragment.programDateTime / 1000 - lastFragment.start;\n    const Cue = getCueClass();\n    for (let i = 0; i < ids.length; i++) {\n      const id = ids[i];\n      const dateRange = dateRanges[id];\n      const startTime = dateRangeDateToTimelineSeconds(dateRange.startDate, dateTimeOffset);\n\n      // Process DateRanges to determine end-time (known DURATION, END-DATE, or END-ON-NEXT)\n      const appendedDateRangeCues = dateRangeCuesAppended[id];\n      const cues = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.cues) || {};\n      let durationKnown = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.durationKnown) || false;\n      let endTime = MAX_CUE_ENDTIME;\n      const endDate = dateRange.endDate;\n      if (endDate) {\n        endTime = dateRangeDateToTimelineSeconds(endDate, dateTimeOffset);\n        durationKnown = true;\n      } else if (dateRange.endOnNext && !durationKnown) {\n        const nextDateRangeWithSameClass = ids.reduce((candidateDateRange, id) => {\n          if (id !== dateRange.id) {\n            const otherDateRange = dateRanges[id];\n            if (otherDateRange.class === dateRange.class && otherDateRange.startDate > dateRange.startDate && (!candidateDateRange || dateRange.startDate < candidateDateRange.startDate)) {\n              return otherDateRange;\n            }\n          }\n          return candidateDateRange;\n        }, null);\n        if (nextDateRangeWithSameClass) {\n          endTime = dateRangeDateToTimelineSeconds(nextDateRangeWithSameClass.startDate, dateTimeOffset);\n          durationKnown = true;\n        }\n      }\n\n      // Create TextTrack Cues for each MetadataGroup Item (select DateRange attribute)\n      // This is to emulate Safari HLS playback handling of DateRange tags\n      const attributes = Object.keys(dateRange.attr);\n      for (let j = 0; j < attributes.length; j++) {\n        const key = attributes[j];\n        if (!isDateRangeCueAttribute(key)) {\n          continue;\n        }\n        const cue = cues[key];\n        if (cue) {\n          if (durationKnown && !appendedDateRangeCues.durationKnown) {\n            cue.endTime = endTime;\n          }\n        } else if (Cue) {\n          let data = dateRange.attr[key];\n          if (isSCTE35Attribute(key)) {\n            data = hexToArrayBuffer(data);\n          }\n          const _cue = createCueWithDataFields(Cue, startTime, endTime, {\n            key,\n            data\n          }, MetadataSchema.dateRange);\n          if (_cue) {\n            _cue.id = id;\n            this.id3Track.addCue(_cue);\n            cues[key] = _cue;\n          }\n        }\n      }\n\n      // Keep track of processed DateRanges by ID for updating cues with new DateRange tag attributes\n      dateRangeCuesAppended[id] = {\n        cues,\n        dateRange,\n        durationKnown\n      };\n    }\n  }\n}\n\nclass LatencyController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.config = void 0;\n    this.media = null;\n    this.levelDetails = null;\n    this.currentTime = 0;\n    this.stallCount = 0;\n    this._latency = null;\n    this.timeupdateHandler = () => this.timeupdate();\n    this.hls = hls;\n    this.config = hls.config;\n    this.registerListeners();\n  }\n  get latency() {\n    return this._latency || 0;\n  }\n  get maxLatency() {\n    const {\n      config,\n      levelDetails\n    } = this;\n    if (config.liveMaxLatencyDuration !== undefined) {\n      return config.liveMaxLatencyDuration;\n    }\n    return levelDetails ? config.liveMaxLatencyDurationCount * levelDetails.targetduration : 0;\n  }\n  get targetLatency() {\n    const {\n      levelDetails\n    } = this;\n    if (levelDetails === null) {\n      return null;\n    }\n    const {\n      holdBack,\n      partHoldBack,\n      targetduration\n    } = levelDetails;\n    const {\n      liveSyncDuration,\n      liveSyncDurationCount,\n      lowLatencyMode\n    } = this.config;\n    const userConfig = this.hls.userConfig;\n    let targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;\n    if (userConfig.liveSyncDuration || userConfig.liveSyncDurationCount || targetLatency === 0) {\n      targetLatency = liveSyncDuration !== undefined ? liveSyncDuration : liveSyncDurationCount * targetduration;\n    }\n    const maxLiveSyncOnStallIncrease = targetduration;\n    const liveSyncOnStallIncrease = 1.0;\n    return targetLatency + Math.min(this.stallCount * liveSyncOnStallIncrease, maxLiveSyncOnStallIncrease);\n  }\n  get liveSyncPosition() {\n    const liveEdge = this.estimateLiveEdge();\n    const targetLatency = this.targetLatency;\n    const levelDetails = this.levelDetails;\n    if (liveEdge === null || targetLatency === null || levelDetails === null) {\n      return null;\n    }\n    const edge = levelDetails.edge;\n    const syncPosition = liveEdge - targetLatency - this.edgeStalled;\n    const min = edge - levelDetails.totalduration;\n    const max = edge - (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration);\n    return Math.min(Math.max(min, syncPosition), max);\n  }\n  get drift() {\n    const {\n      levelDetails\n    } = this;\n    if (levelDetails === null) {\n      return 1;\n    }\n    return levelDetails.drift;\n  }\n  get edgeStalled() {\n    const {\n      levelDetails\n    } = this;\n    if (levelDetails === null) {\n      return 0;\n    }\n    const maxLevelUpdateAge = (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration) * 3;\n    return Math.max(levelDetails.age - maxLevelUpdateAge, 0);\n  }\n  get forwardBufferLength() {\n    const {\n      media,\n      levelDetails\n    } = this;\n    if (!media || !levelDetails) {\n      return 0;\n    }\n    const bufferedRanges = media.buffered.length;\n    return (bufferedRanges ? media.buffered.end(bufferedRanges - 1) : levelDetails.edge) - this.currentTime;\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.onMediaDetaching();\n    this.levelDetails = null;\n    // @ts-ignore\n    this.hls = this.timeupdateHandler = null;\n  }\n  registerListeners() {\n    this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    this.hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    this.hls.off(Events.ERROR, this.onError, this);\n  }\n  onMediaAttached(event, data) {\n    this.media = data.media;\n    this.media.addEventListener('timeupdate', this.timeupdateHandler);\n  }\n  onMediaDetaching() {\n    if (this.media) {\n      this.media.removeEventListener('timeupdate', this.timeupdateHandler);\n      this.media = null;\n    }\n  }\n  onManifestLoading() {\n    this.levelDetails = null;\n    this._latency = null;\n    this.stallCount = 0;\n  }\n  onLevelUpdated(event, {\n    details\n  }) {\n    this.levelDetails = details;\n    if (details.advanced) {\n      this.timeupdate();\n    }\n    if (!details.live && this.media) {\n      this.media.removeEventListener('timeupdate', this.timeupdateHandler);\n    }\n  }\n  onError(event, data) {\n    var _this$levelDetails;\n    if (data.details !== ErrorDetails.BUFFER_STALLED_ERROR) {\n      return;\n    }\n    this.stallCount++;\n    if ((_this$levelDetails = this.levelDetails) != null && _this$levelDetails.live) {\n      logger.warn('[playback-rate-controller]: Stall detected, adjusting target latency');\n    }\n  }\n  timeupdate() {\n    const {\n      media,\n      levelDetails\n    } = this;\n    if (!media || !levelDetails) {\n      return;\n    }\n    this.currentTime = media.currentTime;\n    const latency = this.computeLatency();\n    if (latency === null) {\n      return;\n    }\n    this._latency = latency;\n\n    // Adapt playbackRate to meet target latency in low-latency mode\n    const {\n      lowLatencyMode,\n      maxLiveSyncPlaybackRate\n    } = this.config;\n    if (!lowLatencyMode || maxLiveSyncPlaybackRate === 1 || !levelDetails.live) {\n      return;\n    }\n    const targetLatency = this.targetLatency;\n    if (targetLatency === null) {\n      return;\n    }\n    const distanceFromTarget = latency - targetLatency;\n    // Only adjust playbackRate when within one target duration of targetLatency\n    // and more than one second from under-buffering.\n    // Playback further than one target duration from target can be considered DVR playback.\n    const liveMinLatencyDuration = Math.min(this.maxLatency, targetLatency + levelDetails.targetduration);\n    const inLiveRange = distanceFromTarget < liveMinLatencyDuration;\n    if (inLiveRange && distanceFromTarget > 0.05 && this.forwardBufferLength > 1) {\n      const max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));\n      const rate = Math.round(2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled)) * 20) / 20;\n      media.playbackRate = Math.min(max, Math.max(1, rate));\n    } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {\n      media.playbackRate = 1;\n    }\n  }\n  estimateLiveEdge() {\n    const {\n      levelDetails\n    } = this;\n    if (levelDetails === null) {\n      return null;\n    }\n    return levelDetails.edge + levelDetails.age;\n  }\n  computeLatency() {\n    const liveEdge = this.estimateLiveEdge();\n    if (liveEdge === null) {\n      return null;\n    }\n    return liveEdge - this.currentTime;\n  }\n}\n\nconst HdcpLevels = ['NONE', 'TYPE-0', 'TYPE-1', null];\nfunction isHdcpLevel(value) {\n  return HdcpLevels.indexOf(value) > -1;\n}\nconst VideoRangeValues = ['SDR', 'PQ', 'HLG'];\nfunction isVideoRange(value) {\n  return !!value && VideoRangeValues.indexOf(value) > -1;\n}\nvar HlsSkip = {\n  No: \"\",\n  Yes: \"YES\",\n  v2: \"v2\"\n};\nfunction getSkipValue(details) {\n  const {\n    canSkipUntil,\n    canSkipDateRanges,\n    age\n  } = details;\n  // A Client SHOULD NOT request a Playlist Delta Update unless it already\n  // has a version of the Playlist that is no older than one-half of the Skip Boundary.\n  // @see: https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis#section-6.3.7\n  const playlistRecentEnough = age < canSkipUntil / 2;\n  if (canSkipUntil && playlistRecentEnough) {\n    if (canSkipDateRanges) {\n      return HlsSkip.v2;\n    }\n    return HlsSkip.Yes;\n  }\n  return HlsSkip.No;\n}\nclass HlsUrlParameters {\n  constructor(msn, part, skip) {\n    this.msn = void 0;\n    this.part = void 0;\n    this.skip = void 0;\n    this.msn = msn;\n    this.part = part;\n    this.skip = skip;\n  }\n  addDirectives(uri) {\n    const url = new self.URL(uri);\n    if (this.msn !== undefined) {\n      url.searchParams.set('_HLS_msn', this.msn.toString());\n    }\n    if (this.part !== undefined) {\n      url.searchParams.set('_HLS_part', this.part.toString());\n    }\n    if (this.skip) {\n      url.searchParams.set('_HLS_skip', this.skip);\n    }\n    return url.href;\n  }\n}\nclass Level {\n  constructor(data) {\n    this._attrs = void 0;\n    this.audioCodec = void 0;\n    this.bitrate = void 0;\n    this.codecSet = void 0;\n    this.url = void 0;\n    this.frameRate = void 0;\n    this.height = void 0;\n    this.id = void 0;\n    this.name = void 0;\n    this.videoCodec = void 0;\n    this.width = void 0;\n    this.details = void 0;\n    this.fragmentError = 0;\n    this.loadError = 0;\n    this.loaded = void 0;\n    this.realBitrate = 0;\n    this.supportedPromise = void 0;\n    this.supportedResult = void 0;\n    this._avgBitrate = 0;\n    this._audioGroups = void 0;\n    this._subtitleGroups = void 0;\n    // Deprecated (retained for backwards compatibility)\n    this._urlId = 0;\n    this.url = [data.url];\n    this._attrs = [data.attrs];\n    this.bitrate = data.bitrate;\n    if (data.details) {\n      this.details = data.details;\n    }\n    this.id = data.id || 0;\n    this.name = data.name;\n    this.width = data.width || 0;\n    this.height = data.height || 0;\n    this.frameRate = data.attrs.optionalFloat('FRAME-RATE', 0);\n    this._avgBitrate = data.attrs.decimalInteger('AVERAGE-BANDWIDTH');\n    this.audioCodec = data.audioCodec;\n    this.videoCodec = data.videoCodec;\n    this.codecSet = [data.videoCodec, data.audioCodec].filter(c => !!c).map(s => s.substring(0, 4)).join(',');\n    this.addGroupId('audio', data.attrs.AUDIO);\n    this.addGroupId('text', data.attrs.SUBTITLES);\n  }\n  get maxBitrate() {\n    return Math.max(this.realBitrate, this.bitrate);\n  }\n  get averageBitrate() {\n    return this._avgBitrate || this.realBitrate || this.bitrate;\n  }\n  get attrs() {\n    return this._attrs[0];\n  }\n  get codecs() {\n    return this.attrs.CODECS || '';\n  }\n  get pathwayId() {\n    return this.attrs['PATHWAY-ID'] || '.';\n  }\n  get videoRange() {\n    return this.attrs['VIDEO-RANGE'] || 'SDR';\n  }\n  get score() {\n    return this.attrs.optionalFloat('SCORE', 0);\n  }\n  get uri() {\n    return this.url[0] || '';\n  }\n  hasAudioGroup(groupId) {\n    return hasGroup(this._audioGroups, groupId);\n  }\n  hasSubtitleGroup(groupId) {\n    return hasGroup(this._subtitleGroups, groupId);\n  }\n  get audioGroups() {\n    return this._audioGroups;\n  }\n  get subtitleGroups() {\n    return this._subtitleGroups;\n  }\n  addGroupId(type, groupId) {\n    if (!groupId) {\n      return;\n    }\n    if (type === 'audio') {\n      let audioGroups = this._audioGroups;\n      if (!audioGroups) {\n        audioGroups = this._audioGroups = [];\n      }\n      if (audioGroups.indexOf(groupId) === -1) {\n        audioGroups.push(groupId);\n      }\n    } else if (type === 'text') {\n      let subtitleGroups = this._subtitleGroups;\n      if (!subtitleGroups) {\n        subtitleGroups = this._subtitleGroups = [];\n      }\n      if (subtitleGroups.indexOf(groupId) === -1) {\n        subtitleGroups.push(groupId);\n      }\n    }\n  }\n\n  // Deprecated methods (retained for backwards compatibility)\n  get urlId() {\n    return 0;\n  }\n  set urlId(value) {}\n  get audioGroupIds() {\n    return this.audioGroups ? [this.audioGroupId] : undefined;\n  }\n  get textGroupIds() {\n    return this.subtitleGroups ? [this.textGroupId] : undefined;\n  }\n  get audioGroupId() {\n    var _this$audioGroups;\n    return (_this$audioGroups = this.audioGroups) == null ? void 0 : _this$audioGroups[0];\n  }\n  get textGroupId() {\n    var _this$subtitleGroups;\n    return (_this$subtitleGroups = this.subtitleGroups) == null ? void 0 : _this$subtitleGroups[0];\n  }\n  addFallback() {}\n}\nfunction hasGroup(groups, groupId) {\n  if (!groupId || !groups) {\n    return false;\n  }\n  return groups.indexOf(groupId) !== -1;\n}\n\nfunction updateFromToPTS(fragFrom, fragTo) {\n  const fragToPTS = fragTo.startPTS;\n  // if we know startPTS[toIdx]\n  if (isFiniteNumber(fragToPTS)) {\n    // update fragment duration.\n    // it helps to fix drifts between playlist reported duration and fragment real duration\n    let duration = 0;\n    let frag;\n    if (fragTo.sn > fragFrom.sn) {\n      duration = fragToPTS - fragFrom.start;\n      frag = fragFrom;\n    } else {\n      duration = fragFrom.start - fragToPTS;\n      frag = fragTo;\n    }\n    if (frag.duration !== duration) {\n      frag.duration = duration;\n    }\n    // we dont know startPTS[toIdx]\n  } else if (fragTo.sn > fragFrom.sn) {\n    const contiguous = fragFrom.cc === fragTo.cc;\n    // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS\n    if (contiguous && fragFrom.minEndPTS) {\n      fragTo.start = fragFrom.start + (fragFrom.minEndPTS - fragFrom.start);\n    } else {\n      fragTo.start = fragFrom.start + fragFrom.duration;\n    }\n  } else {\n    fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);\n  }\n}\nfunction updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS) {\n  const parsedMediaDuration = endPTS - startPTS;\n  if (parsedMediaDuration <= 0) {\n    logger.warn('Fragment should have a positive duration', frag);\n    endPTS = startPTS + frag.duration;\n    endDTS = startDTS + frag.duration;\n  }\n  let maxStartPTS = startPTS;\n  let minEndPTS = endPTS;\n  const fragStartPts = frag.startPTS;\n  const fragEndPts = frag.endPTS;\n  if (isFiniteNumber(fragStartPts)) {\n    // delta PTS between audio and video\n    const deltaPTS = Math.abs(fragStartPts - startPTS);\n    if (!isFiniteNumber(frag.deltaPTS)) {\n      frag.deltaPTS = deltaPTS;\n    } else {\n      frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);\n    }\n    maxStartPTS = Math.max(startPTS, fragStartPts);\n    startPTS = Math.min(startPTS, fragStartPts);\n    startDTS = Math.min(startDTS, frag.startDTS);\n    minEndPTS = Math.min(endPTS, fragEndPts);\n    endPTS = Math.max(endPTS, fragEndPts);\n    endDTS = Math.max(endDTS, frag.endDTS);\n  }\n  const drift = startPTS - frag.start;\n  if (frag.start !== 0) {\n    frag.start = startPTS;\n  }\n  frag.duration = endPTS - frag.start;\n  frag.startPTS = startPTS;\n  frag.maxStartPTS = maxStartPTS;\n  frag.startDTS = startDTS;\n  frag.endPTS = endPTS;\n  frag.minEndPTS = minEndPTS;\n  frag.endDTS = endDTS;\n  const sn = frag.sn; // 'initSegment'\n  // exit if sn out of range\n  if (!details || sn < details.startSN || sn > details.endSN) {\n    return 0;\n  }\n  let i;\n  const fragIdx = sn - details.startSN;\n  const fragments = details.fragments;\n  // update frag reference in fragments array\n  // rationale is that fragments array might not contain this frag object.\n  // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()\n  // if we don't update frag, we won't be able to propagate PTS info on the playlist\n  // resulting in invalid sliding computation\n  fragments[fragIdx] = frag;\n  // adjust fragment PTS/duration from seqnum-1 to frag 0\n  for (i = fragIdx; i > 0; i--) {\n    updateFromToPTS(fragments[i], fragments[i - 1]);\n  }\n\n  // adjust fragment PTS/duration from seqnum to last frag\n  for (i = fragIdx; i < fragments.length - 1; i++) {\n    updateFromToPTS(fragments[i], fragments[i + 1]);\n  }\n  if (details.fragmentHint) {\n    updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);\n  }\n  details.PTSKnown = details.alignedSliding = true;\n  return drift;\n}\nfunction mergeDetails(oldDetails, newDetails) {\n  // Track the last initSegment processed. Initialize it to the last one on the timeline.\n  let currentInitSegment = null;\n  const oldFragments = oldDetails.fragments;\n  for (let i = oldFragments.length - 1; i >= 0; i--) {\n    const oldInit = oldFragments[i].initSegment;\n    if (oldInit) {\n      currentInitSegment = oldInit;\n      break;\n    }\n  }\n  if (oldDetails.fragmentHint) {\n    // prevent PTS and duration from being adjusted on the next hint\n    delete oldDetails.fragmentHint.endPTS;\n  }\n  // check if old/new playlists have fragments in common\n  // loop through overlapping SN and update startPTS , cc, and duration if any found\n  let ccOffset = 0;\n  let PTSFrag;\n  mapFragmentIntersection(oldDetails, newDetails, (oldFrag, newFrag) => {\n    if (oldFrag.relurl) {\n      // Do not compare CC if the old fragment has no url. This is a level.fragmentHint used by LL-HLS parts.\n      // It maybe be off by 1 if it was created before any parts or discontinuity tags were appended to the end\n      // of the playlist.\n      ccOffset = oldFrag.cc - newFrag.cc;\n    }\n    if (isFiniteNumber(oldFrag.startPTS) && isFiniteNumber(oldFrag.endPTS)) {\n      newFrag.start = newFrag.startPTS = oldFrag.startPTS;\n      newFrag.startDTS = oldFrag.startDTS;\n      newFrag.maxStartPTS = oldFrag.maxStartPTS;\n      newFrag.endPTS = oldFrag.endPTS;\n      newFrag.endDTS = oldFrag.endDTS;\n      newFrag.minEndPTS = oldFrag.minEndPTS;\n      newFrag.duration = oldFrag.endPTS - oldFrag.startPTS;\n      if (newFrag.duration) {\n        PTSFrag = newFrag;\n      }\n\n      // PTS is known when any segment has startPTS and endPTS\n      newDetails.PTSKnown = newDetails.alignedSliding = true;\n    }\n    newFrag.elementaryStreams = oldFrag.elementaryStreams;\n    newFrag.loader = oldFrag.loader;\n    newFrag.stats = oldFrag.stats;\n    if (oldFrag.initSegment) {\n      newFrag.initSegment = oldFrag.initSegment;\n      currentInitSegment = oldFrag.initSegment;\n    }\n  });\n  if (currentInitSegment) {\n    const fragmentsToCheck = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;\n    fragmentsToCheck.forEach(frag => {\n      var _currentInitSegment;\n      if (frag && (!frag.initSegment || frag.initSegment.relurl === ((_currentInitSegment = currentInitSegment) == null ? void 0 : _currentInitSegment.relurl))) {\n        frag.initSegment = currentInitSegment;\n      }\n    });\n  }\n  if (newDetails.skippedSegments) {\n    newDetails.deltaUpdateFailed = newDetails.fragments.some(frag => !frag);\n    if (newDetails.deltaUpdateFailed) {\n      logger.warn('[level-helper] Previous playlist missing segments skipped in delta playlist');\n      for (let i = newDetails.skippedSegments; i--;) {\n        newDetails.fragments.shift();\n      }\n      newDetails.startSN = newDetails.fragments[0].sn;\n      newDetails.startCC = newDetails.fragments[0].cc;\n    } else if (newDetails.canSkipDateRanges) {\n      newDetails.dateRanges = mergeDateRanges(oldDetails.dateRanges, newDetails.dateRanges, newDetails.recentlyRemovedDateranges);\n    }\n  }\n  const newFragments = newDetails.fragments;\n  if (ccOffset) {\n    logger.warn('discontinuity sliding from playlist, take drift into account');\n    for (let i = 0; i < newFragments.length; i++) {\n      newFragments[i].cc += ccOffset;\n    }\n  }\n  if (newDetails.skippedSegments) {\n    newDetails.startCC = newDetails.fragments[0].cc;\n  }\n\n  // Merge parts\n  mapPartIntersection(oldDetails.partList, newDetails.partList, (oldPart, newPart) => {\n    newPart.elementaryStreams = oldPart.elementaryStreams;\n    newPart.stats = oldPart.stats;\n  });\n\n  // if at least one fragment contains PTS info, recompute PTS information for all fragments\n  if (PTSFrag) {\n    updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS);\n  } else {\n    // ensure that delta is within oldFragments range\n    // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])\n    // in that case we also need to adjust start offset of all fragments\n    adjustSliding(oldDetails, newDetails);\n  }\n  if (newFragments.length) {\n    newDetails.totalduration = newDetails.edge - newFragments[0].start;\n  }\n  newDetails.driftStartTime = oldDetails.driftStartTime;\n  newDetails.driftStart = oldDetails.driftStart;\n  const advancedDateTime = newDetails.advancedDateTime;\n  if (newDetails.advanced && advancedDateTime) {\n    const edge = newDetails.edge;\n    if (!newDetails.driftStart) {\n      newDetails.driftStartTime = advancedDateTime;\n      newDetails.driftStart = edge;\n    }\n    newDetails.driftEndTime = advancedDateTime;\n    newDetails.driftEnd = edge;\n  } else {\n    newDetails.driftEndTime = oldDetails.driftEndTime;\n    newDetails.driftEnd = oldDetails.driftEnd;\n    newDetails.advancedDateTime = oldDetails.advancedDateTime;\n  }\n}\nfunction mergeDateRanges(oldDateRanges, deltaDateRanges, recentlyRemovedDateranges) {\n  const dateRanges = _extends({}, oldDateRanges);\n  if (recentlyRemovedDateranges) {\n    recentlyRemovedDateranges.forEach(id => {\n      delete dateRanges[id];\n    });\n  }\n  Object.keys(deltaDateRanges).forEach(id => {\n    const dateRange = new DateRange(deltaDateRanges[id].attr, dateRanges[id]);\n    if (dateRange.isValid) {\n      dateRanges[id] = dateRange;\n    } else {\n      logger.warn(`Ignoring invalid Playlist Delta Update DATERANGE tag: \"${JSON.stringify(deltaDateRanges[id].attr)}\"`);\n    }\n  });\n  return dateRanges;\n}\nfunction mapPartIntersection(oldParts, newParts, intersectionFn) {\n  if (oldParts && newParts) {\n    let delta = 0;\n    for (let i = 0, len = oldParts.length; i <= len; i++) {\n      const oldPart = oldParts[i];\n      const newPart = newParts[i + delta];\n      if (oldPart && newPart && oldPart.index === newPart.index && oldPart.fragment.sn === newPart.fragment.sn) {\n        intersectionFn(oldPart, newPart);\n      } else {\n        delta--;\n      }\n    }\n  }\n}\nfunction mapFragmentIntersection(oldDetails, newDetails, intersectionFn) {\n  const skippedSegments = newDetails.skippedSegments;\n  const start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;\n  const end = (oldDetails.fragmentHint ? 1 : 0) + (skippedSegments ? newDetails.endSN : Math.min(oldDetails.endSN, newDetails.endSN)) - newDetails.startSN;\n  const delta = newDetails.startSN - oldDetails.startSN;\n  const newFrags = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;\n  const oldFrags = oldDetails.fragmentHint ? oldDetails.fragments.concat(oldDetails.fragmentHint) : oldDetails.fragments;\n  for (let i = start; i <= end; i++) {\n    const oldFrag = oldFrags[delta + i];\n    let newFrag = newFrags[i];\n    if (skippedSegments && !newFrag && i < skippedSegments) {\n      // Fill in skipped segments in delta playlist\n      newFrag = newDetails.fragments[i] = oldFrag;\n    }\n    if (oldFrag && newFrag) {\n      intersectionFn(oldFrag, newFrag);\n    }\n  }\n}\nfunction adjustSliding(oldDetails, newDetails) {\n  const delta = newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;\n  const oldFragments = oldDetails.fragments;\n  if (delta < 0 || delta >= oldFragments.length) {\n    return;\n  }\n  addSliding(newDetails, oldFragments[delta].start);\n}\nfunction addSliding(details, start) {\n  if (start) {\n    const fragments = details.fragments;\n    for (let i = details.skippedSegments; i < fragments.length; i++) {\n      fragments[i].start += start;\n    }\n    if (details.fragmentHint) {\n      details.fragmentHint.start += start;\n    }\n  }\n}\nfunction computeReloadInterval(newDetails, distanceToLiveEdgeMs = Infinity) {\n  let reloadInterval = 1000 * newDetails.targetduration;\n  if (newDetails.updated) {\n    // Use last segment duration when shorter than target duration and near live edge\n    const fragments = newDetails.fragments;\n    const liveEdgeMaxTargetDurations = 4;\n    if (fragments.length && reloadInterval * liveEdgeMaxTargetDurations > distanceToLiveEdgeMs) {\n      const lastSegmentDuration = fragments[fragments.length - 1].duration * 1000;\n      if (lastSegmentDuration < reloadInterval) {\n        reloadInterval = lastSegmentDuration;\n      }\n    }\n  } else {\n    // estimate = 'miss half average';\n    // follow HLS Spec, If the client reloads a Playlist file and finds that it has not\n    // changed then it MUST wait for a period of one-half the target\n    // duration before retrying.\n    reloadInterval /= 2;\n  }\n  return Math.round(reloadInterval);\n}\nfunction getFragmentWithSN(level, sn, fragCurrent) {\n  if (!(level != null && level.details)) {\n    return null;\n  }\n  const levelDetails = level.details;\n  let fragment = levelDetails.fragments[sn - levelDetails.startSN];\n  if (fragment) {\n    return fragment;\n  }\n  fragment = levelDetails.fragmentHint;\n  if (fragment && fragment.sn === sn) {\n    return fragment;\n  }\n  if (sn < levelDetails.startSN && fragCurrent && fragCurrent.sn === sn) {\n    return fragCurrent;\n  }\n  return null;\n}\nfunction getPartWith(level, sn, partIndex) {\n  var _level$details;\n  if (!(level != null && level.details)) {\n    return null;\n  }\n  return findPart((_level$details = level.details) == null ? void 0 : _level$details.partList, sn, partIndex);\n}\nfunction findPart(partList, sn, partIndex) {\n  if (partList) {\n    for (let i = partList.length; i--;) {\n      const part = partList[i];\n      if (part.index === partIndex && part.fragment.sn === sn) {\n        return part;\n      }\n    }\n  }\n  return null;\n}\nfunction reassignFragmentLevelIndexes(levels) {\n  levels.forEach((level, index) => {\n    const {\n      details\n    } = level;\n    if (details != null && details.fragments) {\n      details.fragments.forEach(fragment => {\n        fragment.level = index;\n      });\n    }\n  });\n}\n\nfunction isTimeoutError(error) {\n  switch (error.details) {\n    case ErrorDetails.FRAG_LOAD_TIMEOUT:\n    case ErrorDetails.KEY_LOAD_TIMEOUT:\n    case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n    case ErrorDetails.MANIFEST_LOAD_TIMEOUT:\n      return true;\n  }\n  return false;\n}\nfunction getRetryConfig(loadPolicy, error) {\n  const isTimeout = isTimeoutError(error);\n  return loadPolicy.default[`${isTimeout ? 'timeout' : 'error'}Retry`];\n}\nfunction getRetryDelay(retryConfig, retryCount) {\n  // exponential backoff capped to max retry delay\n  const backoffFactor = retryConfig.backoff === 'linear' ? 1 : Math.pow(2, retryCount);\n  return Math.min(backoffFactor * retryConfig.retryDelayMs, retryConfig.maxRetryDelayMs);\n}\nfunction getLoaderConfigWithoutReties(loderConfig) {\n  return _objectSpread2(_objectSpread2({}, loderConfig), {\n    errorRetry: null,\n    timeoutRetry: null\n  });\n}\nfunction shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse) {\n  if (!retryConfig) {\n    return false;\n  }\n  const httpStatus = loaderResponse == null ? void 0 : loaderResponse.code;\n  const retry = retryCount < retryConfig.maxNumRetry && (retryForHttpStatus(httpStatus) || !!isTimeout);\n  return retryConfig.shouldRetry ? retryConfig.shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse, retry) : retry;\n}\nfunction retryForHttpStatus(httpStatus) {\n  // Do not retry on status 4xx, status 0 (CORS error), or undefined (decrypt/gap/parse error)\n  return httpStatus === 0 && navigator.onLine === false || !!httpStatus && (httpStatus < 400 || httpStatus > 499);\n}\n\nconst BinarySearch = {\n  /**\n   * Searches for an item in an array which matches a certain condition.\n   * This requires the condition to only match one item in the array,\n   * and for the array to be ordered.\n   *\n   * @param list The array to search.\n   * @param comparisonFn\n   *      Called and provided a candidate item as the first argument.\n   *      Should return:\n   *          > -1 if the item should be located at a lower index than the provided item.\n   *          > 1 if the item should be located at a higher index than the provided item.\n   *          > 0 if the item is the item you're looking for.\n   *\n   * @returns the object if found, otherwise returns null\n   */\n  search: function (list, comparisonFn) {\n    let minIndex = 0;\n    let maxIndex = list.length - 1;\n    let currentIndex = null;\n    let currentElement = null;\n    while (minIndex <= maxIndex) {\n      currentIndex = (minIndex + maxIndex) / 2 | 0;\n      currentElement = list[currentIndex];\n      const comparisonResult = comparisonFn(currentElement);\n      if (comparisonResult > 0) {\n        minIndex = currentIndex + 1;\n      } else if (comparisonResult < 0) {\n        maxIndex = currentIndex - 1;\n      } else {\n        return currentElement;\n      }\n    }\n    return null;\n  }\n};\n\n/**\n * Returns first fragment whose endPdt value exceeds the given PDT, or null.\n * @param fragments - The array of candidate fragments\n * @param PDTValue - The PDT value which must be exceeded\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n */\nfunction findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {\n  if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !isFiniteNumber(PDTValue)) {\n    return null;\n  }\n\n  // if less than start\n  const startPDT = fragments[0].programDateTime;\n  if (PDTValue < (startPDT || 0)) {\n    return null;\n  }\n  const endPDT = fragments[fragments.length - 1].endProgramDateTime;\n  if (PDTValue >= (endPDT || 0)) {\n    return null;\n  }\n  maxFragLookUpTolerance = maxFragLookUpTolerance || 0;\n  for (let seg = 0; seg < fragments.length; ++seg) {\n    const frag = fragments[seg];\n    if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {\n      return frag;\n    }\n  }\n  return null;\n}\n\n/**\n * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.\n * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus\n * breaking any traps which would cause the same fragment to be continuously selected within a small range.\n * @param fragPrevious - The last frag successfully appended\n * @param fragments - The array of candidate fragments\n * @param bufferEnd - The end of the contiguous buffered range the playhead is currently within\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n * @returns a matching fragment or null\n */\nfunction findFragmentByPTS(fragPrevious, fragments, bufferEnd = 0, maxFragLookUpTolerance = 0, nextFragLookupTolerance = 0.005) {\n  let fragNext = null;\n  if (fragPrevious) {\n    fragNext = fragments[fragPrevious.sn - fragments[0].sn + 1] || null;\n    // check for buffer-end rounding error\n    const bufferEdgeError = fragPrevious.endDTS - bufferEnd;\n    if (bufferEdgeError > 0 && bufferEdgeError < 0.0000015) {\n      bufferEnd += 0.0000015;\n    }\n  } else if (bufferEnd === 0 && fragments[0].start === 0) {\n    fragNext = fragments[0];\n  }\n  // Prefer the next fragment if it's within tolerance\n  if (fragNext && ((!fragPrevious || fragPrevious.level === fragNext.level) && fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0 || fragmentWithinFastStartSwitch(fragNext, fragPrevious, Math.min(nextFragLookupTolerance, maxFragLookUpTolerance)))) {\n    return fragNext;\n  }\n  // We might be seeking past the tolerance so find the best match\n  const foundFragment = BinarySearch.search(fragments, fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));\n  if (foundFragment && (foundFragment !== fragPrevious || !fragNext)) {\n    return foundFragment;\n  }\n  // If no match was found return the next fragment after fragPrevious, or null\n  return fragNext;\n}\nfunction fragmentWithinFastStartSwitch(fragNext, fragPrevious, nextFragLookupTolerance) {\n  if (fragPrevious && fragPrevious.start === 0 && fragPrevious.level < fragNext.level && (fragPrevious.endPTS || 0) > 0) {\n    const firstDuration = fragPrevious.tagList.reduce((duration, tag) => {\n      if (tag[0] === 'INF') {\n        duration += parseFloat(tag[1]);\n      }\n      return duration;\n    }, nextFragLookupTolerance);\n    return fragNext.start <= firstDuration;\n  }\n  return false;\n}\n\n/**\n * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.\n * @param candidate - The fragment to test\n * @param bufferEnd - The end of the current buffered range the playhead is currently within\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n * @returns 0 if it matches, 1 if too low, -1 if too high\n */\nfunction fragmentWithinToleranceTest(bufferEnd = 0, maxFragLookUpTolerance = 0, candidate) {\n  // eagerly accept an accurate match (no tolerance)\n  if (candidate.start <= bufferEnd && candidate.start + candidate.duration > bufferEnd) {\n    return 0;\n  }\n  // offset should be within fragment boundary - config.maxFragLookUpTolerance\n  // this is to cope with situations like\n  // bufferEnd = 9.991\n  // frag[] : [0,10]\n  // frag[1] : [10,20]\n  // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\n  //              frag start               frag start+duration\n  //                  |-----------------------------|\n  //              <--->                         <--->\n  //  ...--------><-----------------------------><---------....\n  // previous frag         matching fragment         next frag\n  //  return -1             return 0                 return 1\n  // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\n  // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\n  const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));\n  if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {\n    return 1;\n  } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {\n    // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\n    return -1;\n  }\n  return 0;\n}\n\n/**\n * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.\n * This function tests the candidate's program date time values, as represented in Unix time\n * @param candidate - The fragment to test\n * @param pdtBufferEnd - The Unix time representing the end of the current buffered range\n * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n * @returns true if contiguous, false otherwise\n */\nfunction pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {\n  const candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000;\n\n  // endProgramDateTime can be null, default to zero\n  const endProgramDateTime = candidate.endProgramDateTime || 0;\n  return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;\n}\nfunction findFragWithCC(fragments, cc) {\n  return BinarySearch.search(fragments, candidate => {\n    if (candidate.cc < cc) {\n      return 1;\n    } else if (candidate.cc > cc) {\n      return -1;\n    } else {\n      return 0;\n    }\n  });\n}\n\nvar NetworkErrorAction = {\n  DoNothing: 0,\n  SendEndCallback: 1,\n  SendAlternateToPenaltyBox: 2,\n  RemoveAlternatePermanently: 3,\n  InsertDiscontinuity: 4,\n  RetryRequest: 5\n};\nvar ErrorActionFlags = {\n  None: 0,\n  MoveAllAlternatesMatchingHost: 1,\n  MoveAllAlternatesMatchingHDCP: 2,\n  SwitchToSDR: 4\n}; // Reserved for future use\nclass ErrorController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.playlistError = 0;\n    this.penalizedRenditions = {};\n    this.log = void 0;\n    this.warn = void 0;\n    this.error = void 0;\n    this.hls = hls;\n    this.log = logger.log.bind(logger, `[info]:`);\n    this.warn = logger.warn.bind(logger, `[warning]:`);\n    this.error = logger.error.bind(logger, `[error]:`);\n    this.registerListeners();\n  }\n  registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.ERROR, this.onError, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.ERROR, this.onError, this);\n    hls.off(Events.ERROR, this.onErrorOut, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    // @ts-ignore\n    this.hls = null;\n    this.penalizedRenditions = {};\n  }\n  startLoad(startPosition) {}\n  stopLoad() {\n    this.playlistError = 0;\n  }\n  getVariantLevelIndex(frag) {\n    return (frag == null ? void 0 : frag.type) === PlaylistLevelType.MAIN ? frag.level : this.hls.loadLevel;\n  }\n  onManifestLoading() {\n    this.playlistError = 0;\n    this.penalizedRenditions = {};\n  }\n  onLevelUpdated() {\n    this.playlistError = 0;\n  }\n  onError(event, data) {\n    var _data$frag, _data$level;\n    if (data.fatal) {\n      return;\n    }\n    const hls = this.hls;\n    const context = data.context;\n    switch (data.details) {\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        data.errorAction = this.getFragRetryOrSwitchAction(data);\n        return;\n      case ErrorDetails.FRAG_PARSING_ERROR:\n        // ignore empty segment errors marked as gap\n        if ((_data$frag = data.frag) != null && _data$frag.gap) {\n          data.errorAction = {\n            action: NetworkErrorAction.DoNothing,\n            flags: ErrorActionFlags.None\n          };\n          return;\n        }\n      // falls through\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_DECRYPT_ERROR:\n        {\n          // Switch level if possible, otherwise allow retry count to reach max error retries\n          data.errorAction = this.getFragRetryOrSwitchAction(data);\n          data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n          return;\n        }\n      case ErrorDetails.LEVEL_EMPTY_ERROR:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        {\n          var _data$context, _data$context$levelDe;\n          // Only retry when empty and live\n          const levelIndex = data.parent === PlaylistLevelType.MAIN ? data.level : hls.loadLevel;\n          if (data.details === ErrorDetails.LEVEL_EMPTY_ERROR && !!((_data$context = data.context) != null && (_data$context$levelDe = _data$context.levelDetails) != null && _data$context$levelDe.live)) {\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(data, levelIndex);\n          } else {\n            // Escalate to fatal if not retrying or switching\n            data.levelRetry = false;\n            data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n          }\n        }\n        return;\n      case ErrorDetails.LEVEL_LOAD_ERROR:\n      case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n        if (typeof (context == null ? void 0 : context.level) === 'number') {\n          data.errorAction = this.getPlaylistRetryOrSwitchAction(data, context.level);\n        }\n        return;\n      case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n      case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n      case ErrorDetails.SUBTITLE_LOAD_ERROR:\n      case ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT:\n        if (context) {\n          const level = hls.levels[hls.loadLevel];\n          if (level && (context.type === PlaylistContextType.AUDIO_TRACK && level.hasAudioGroup(context.groupId) || context.type === PlaylistContextType.SUBTITLE_TRACK && level.hasSubtitleGroup(context.groupId))) {\n            // Perform Pathway switch or Redundant failover if possible for fastest recovery\n            // otherwise allow playlist retry count to reach max error retries\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(data, hls.loadLevel);\n            data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n            data.errorAction.flags = ErrorActionFlags.MoveAllAlternatesMatchingHost;\n            return;\n          }\n        }\n        return;\n      case ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED:\n        {\n          const level = hls.levels[hls.loadLevel];\n          const restrictedHdcpLevel = level == null ? void 0 : level.attrs['HDCP-LEVEL'];\n          if (restrictedHdcpLevel) {\n            data.errorAction = {\n              action: NetworkErrorAction.SendAlternateToPenaltyBox,\n              flags: ErrorActionFlags.MoveAllAlternatesMatchingHDCP,\n              hdcpLevel: restrictedHdcpLevel\n            };\n          } else {\n            this.keySystemError(data);\n          }\n        }\n        return;\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.REMUX_ALLOC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        data.errorAction = this.getLevelSwitchAction(data, (_data$level = data.level) != null ? _data$level : hls.loadLevel);\n        return;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n      case ErrorDetails.BUFFER_APPENDING_ERROR:\n      case ErrorDetails.BUFFER_FULL_ERROR:\n      case ErrorDetails.LEVEL_SWITCH_ERROR:\n      case ErrorDetails.BUFFER_STALLED_ERROR:\n      case ErrorDetails.BUFFER_SEEK_OVER_HOLE:\n      case ErrorDetails.BUFFER_NUDGE_ON_STALL:\n        data.errorAction = {\n          action: NetworkErrorAction.DoNothing,\n          flags: ErrorActionFlags.None\n        };\n        return;\n    }\n    if (data.type === ErrorTypes.KEY_SYSTEM_ERROR) {\n      this.keySystemError(data);\n    }\n  }\n  keySystemError(data) {\n    const levelIndex = this.getVariantLevelIndex(data.frag);\n    // Do not retry level. Escalate to fatal if switching levels fails.\n    data.levelRetry = false;\n    data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n  }\n  getPlaylistRetryOrSwitchAction(data, levelIndex) {\n    const hls = this.hls;\n    const retryConfig = getRetryConfig(hls.config.playlistLoadPolicy, data);\n    const retryCount = this.playlistError++;\n    const retry = shouldRetry(retryConfig, retryCount, isTimeoutError(data), data.response);\n    if (retry) {\n      return {\n        action: NetworkErrorAction.RetryRequest,\n        flags: ErrorActionFlags.None,\n        retryConfig,\n        retryCount\n      };\n    }\n    const errorAction = this.getLevelSwitchAction(data, levelIndex);\n    if (retryConfig) {\n      errorAction.retryConfig = retryConfig;\n      errorAction.retryCount = retryCount;\n    }\n    return errorAction;\n  }\n  getFragRetryOrSwitchAction(data) {\n    const hls = this.hls;\n    // Share fragment error count accross media options (main, audio, subs)\n    // This allows for level based rendition switching when media option assets fail\n    const variantLevelIndex = this.getVariantLevelIndex(data.frag);\n    const level = hls.levels[variantLevelIndex];\n    const {\n      fragLoadPolicy,\n      keyLoadPolicy\n    } = hls.config;\n    const retryConfig = getRetryConfig(data.details.startsWith('key') ? keyLoadPolicy : fragLoadPolicy, data);\n    const fragmentErrors = hls.levels.reduce((acc, level) => acc + level.fragmentError, 0);\n    // Switch levels when out of retried or level index out of bounds\n    if (level) {\n      if (data.details !== ErrorDetails.FRAG_GAP) {\n        level.fragmentError++;\n      }\n      const retry = shouldRetry(retryConfig, fragmentErrors, isTimeoutError(data), data.response);\n      if (retry) {\n        return {\n          action: NetworkErrorAction.RetryRequest,\n          flags: ErrorActionFlags.None,\n          retryConfig,\n          retryCount: fragmentErrors\n        };\n      }\n    }\n    // Reach max retry count, or Missing level reference\n    // Switch to valid index\n    const errorAction = this.getLevelSwitchAction(data, variantLevelIndex);\n    // Add retry details to allow skipping of FRAG_PARSING_ERROR\n    if (retryConfig) {\n      errorAction.retryConfig = retryConfig;\n      errorAction.retryCount = fragmentErrors;\n    }\n    return errorAction;\n  }\n  getLevelSwitchAction(data, levelIndex) {\n    const hls = this.hls;\n    if (levelIndex === null || levelIndex === undefined) {\n      levelIndex = hls.loadLevel;\n    }\n    const level = this.hls.levels[levelIndex];\n    if (level) {\n      var _data$frag2, _data$context2;\n      const errorDetails = data.details;\n      level.loadError++;\n      if (errorDetails === ErrorDetails.BUFFER_APPEND_ERROR) {\n        level.fragmentError++;\n      }\n      // Search for next level to retry\n      let nextLevel = -1;\n      const {\n        levels,\n        loadLevel,\n        minAutoLevel,\n        maxAutoLevel\n      } = hls;\n      if (!hls.autoLevelEnabled) {\n        hls.loadLevel = -1;\n      }\n      const fragErrorType = (_data$frag2 = data.frag) == null ? void 0 : _data$frag2.type;\n      // Find alternate audio codec if available on audio codec error\n      const isAudioCodecError = fragErrorType === PlaylistLevelType.AUDIO && errorDetails === ErrorDetails.FRAG_PARSING_ERROR || data.sourceBufferName === 'audio' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n      const findAudioCodecAlternate = isAudioCodecError && levels.some(({\n        audioCodec\n      }) => level.audioCodec !== audioCodec);\n      // Find alternate video codec if available on video codec error\n      const isVideoCodecError = data.sourceBufferName === 'video' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n      const findVideoCodecAlternate = isVideoCodecError && levels.some(({\n        codecSet,\n        audioCodec\n      }) => level.codecSet !== codecSet && level.audioCodec === audioCodec);\n      const {\n        type: playlistErrorType,\n        groupId: playlistErrorGroupId\n      } = (_data$context2 = data.context) != null ? _data$context2 : {};\n      for (let i = levels.length; i--;) {\n        const candidate = (i + loadLevel) % levels.length;\n        if (candidate !== loadLevel && candidate >= minAutoLevel && candidate <= maxAutoLevel && levels[candidate].loadError === 0) {\n          var _level$audioGroups, _level$subtitleGroups;\n          const levelCandidate = levels[candidate];\n          // Skip level switch if GAP tag is found in next level at same position\n          if (errorDetails === ErrorDetails.FRAG_GAP && fragErrorType === PlaylistLevelType.MAIN && data.frag) {\n            const levelDetails = levels[candidate].details;\n            if (levelDetails) {\n              const fragCandidate = findFragmentByPTS(data.frag, levelDetails.fragments, data.frag.start);\n              if (fragCandidate != null && fragCandidate.gap) {\n                continue;\n              }\n            }\n          } else if (playlistErrorType === PlaylistContextType.AUDIO_TRACK && levelCandidate.hasAudioGroup(playlistErrorGroupId) || playlistErrorType === PlaylistContextType.SUBTITLE_TRACK && levelCandidate.hasSubtitleGroup(playlistErrorGroupId)) {\n            // For audio/subs playlist errors find another group ID or fallthrough to redundant fail-over\n            continue;\n          } else if (fragErrorType === PlaylistLevelType.AUDIO && (_level$audioGroups = level.audioGroups) != null && _level$audioGroups.some(groupId => levelCandidate.hasAudioGroup(groupId)) || fragErrorType === PlaylistLevelType.SUBTITLE && (_level$subtitleGroups = level.subtitleGroups) != null && _level$subtitleGroups.some(groupId => levelCandidate.hasSubtitleGroup(groupId)) || findAudioCodecAlternate && level.audioCodec === levelCandidate.audioCodec || !findAudioCodecAlternate && level.audioCodec !== levelCandidate.audioCodec || findVideoCodecAlternate && level.codecSet === levelCandidate.codecSet) {\n            // For video/audio/subs frag errors find another group ID or fallthrough to redundant fail-over\n            continue;\n          }\n          nextLevel = candidate;\n          break;\n        }\n      }\n      if (nextLevel > -1 && hls.loadLevel !== nextLevel) {\n        data.levelRetry = true;\n        this.playlistError = 0;\n        return {\n          action: NetworkErrorAction.SendAlternateToPenaltyBox,\n          flags: ErrorActionFlags.None,\n          nextAutoLevel: nextLevel\n        };\n      }\n    }\n    // No levels to switch / Manual level selection / Level not found\n    // Resolve with Pathway switch, Redundant fail-over, or stay on lowest Level\n    return {\n      action: NetworkErrorAction.SendAlternateToPenaltyBox,\n      flags: ErrorActionFlags.MoveAllAlternatesMatchingHost\n    };\n  }\n  onErrorOut(event, data) {\n    var _data$errorAction;\n    switch ((_data$errorAction = data.errorAction) == null ? void 0 : _data$errorAction.action) {\n      case NetworkErrorAction.DoNothing:\n        break;\n      case NetworkErrorAction.SendAlternateToPenaltyBox:\n        this.sendAlternateToPenaltyBox(data);\n        if (!data.errorAction.resolved && data.details !== ErrorDetails.FRAG_GAP) {\n          data.fatal = true;\n        } else if (/MediaSource readyState: ended/.test(data.error.message)) {\n          this.warn(`MediaSource ended after \"${data.sourceBufferName}\" sourceBuffer append error. Attempting to recover from media error.`);\n          this.hls.recoverMediaError();\n        }\n        break;\n      case NetworkErrorAction.RetryRequest:\n        // handled by stream and playlist/level controllers\n        break;\n    }\n    if (data.fatal) {\n      this.hls.stopLoad();\n      return;\n    }\n  }\n  sendAlternateToPenaltyBox(data) {\n    const hls = this.hls;\n    const errorAction = data.errorAction;\n    if (!errorAction) {\n      return;\n    }\n    const {\n      flags,\n      hdcpLevel,\n      nextAutoLevel\n    } = errorAction;\n    switch (flags) {\n      case ErrorActionFlags.None:\n        this.switchLevel(data, nextAutoLevel);\n        break;\n      case ErrorActionFlags.MoveAllAlternatesMatchingHDCP:\n        if (hdcpLevel) {\n          hls.maxHdcpLevel = HdcpLevels[HdcpLevels.indexOf(hdcpLevel) - 1];\n          errorAction.resolved = true;\n        }\n        this.warn(`Restricting playback to HDCP-LEVEL of \"${hls.maxHdcpLevel}\" or lower`);\n        break;\n    }\n    // If not resolved by previous actions try to switch to next level\n    if (!errorAction.resolved) {\n      this.switchLevel(data, nextAutoLevel);\n    }\n  }\n  switchLevel(data, levelIndex) {\n    if (levelIndex !== undefined && data.errorAction) {\n      this.warn(`switching to level ${levelIndex} after ${data.details}`);\n      this.hls.nextAutoLevel = levelIndex;\n      data.errorAction.resolved = true;\n      // Stream controller is responsible for this but won't switch on false start\n      this.hls.nextLoadLevel = this.hls.nextAutoLevel;\n    }\n  }\n}\n\nclass BasePlaylistController {\n  constructor(hls, logPrefix) {\n    this.hls = void 0;\n    this.timer = -1;\n    this.requestScheduled = -1;\n    this.canLoad = false;\n    this.log = void 0;\n    this.warn = void 0;\n    this.log = logger.log.bind(logger, `${logPrefix}:`);\n    this.warn = logger.warn.bind(logger, `${logPrefix}:`);\n    this.hls = hls;\n  }\n  destroy() {\n    this.clearTimer();\n    // @ts-ignore\n    this.hls = this.log = this.warn = null;\n  }\n  clearTimer() {\n    if (this.timer !== -1) {\n      self.clearTimeout(this.timer);\n      this.timer = -1;\n    }\n  }\n  startLoad() {\n    this.canLoad = true;\n    this.requestScheduled = -1;\n    this.loadPlaylist();\n  }\n  stopLoad() {\n    this.canLoad = false;\n    this.clearTimer();\n  }\n  switchParams(playlistUri, previous, current) {\n    const renditionReports = previous == null ? void 0 : previous.renditionReports;\n    if (renditionReports) {\n      let foundIndex = -1;\n      for (let i = 0; i < renditionReports.length; i++) {\n        const attr = renditionReports[i];\n        let uri;\n        try {\n          uri = new self.URL(attr.URI, previous.url).href;\n        } catch (error) {\n          logger.warn(`Could not construct new URL for Rendition Report: ${error}`);\n          uri = attr.URI || '';\n        }\n        // Use exact match. Otherwise, the last partial match, if any, will be used\n        // (Playlist URI includes a query string that the Rendition Report does not)\n        if (uri === playlistUri) {\n          foundIndex = i;\n          break;\n        } else if (uri === playlistUri.substring(0, uri.length)) {\n          foundIndex = i;\n        }\n      }\n      if (foundIndex !== -1) {\n        const attr = renditionReports[foundIndex];\n        const msn = parseInt(attr['LAST-MSN']) || (previous == null ? void 0 : previous.lastPartSn);\n        let part = parseInt(attr['LAST-PART']) || (previous == null ? void 0 : previous.lastPartIndex);\n        if (this.hls.config.lowLatencyMode) {\n          const currentGoal = Math.min(previous.age - previous.partTarget, previous.targetduration);\n          if (part >= 0 && currentGoal > previous.partTarget) {\n            part += 1;\n          }\n        }\n        const skip = current && getSkipValue(current);\n        return new HlsUrlParameters(msn, part >= 0 ? part : undefined, skip);\n      }\n    }\n  }\n  loadPlaylist(hlsUrlParameters) {\n    if (this.requestScheduled === -1) {\n      this.requestScheduled = self.performance.now();\n    }\n    // Loading is handled by the subclasses\n  }\n  shouldLoadPlaylist(playlist) {\n    return this.canLoad && !!playlist && !!playlist.url && (!playlist.details || playlist.details.live);\n  }\n  shouldReloadPlaylist(playlist) {\n    return this.timer === -1 && this.requestScheduled === -1 && this.shouldLoadPlaylist(playlist);\n  }\n  playlistLoaded(index, data, previousDetails) {\n    const {\n      details,\n      stats\n    } = data;\n\n    // Set last updated date-time\n    const now = self.performance.now();\n    const elapsed = stats.loading.first ? Math.max(0, now - stats.loading.first) : 0;\n    details.advancedDateTime = Date.now() - elapsed;\n\n    // if current playlist is a live playlist, arm a timer to reload it\n    if (details.live || previousDetails != null && previousDetails.live) {\n      details.reloaded(previousDetails);\n      if (previousDetails) {\n        this.log(`live playlist ${index} ${details.advanced ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex : details.updated ? 'UPDATED' : 'MISSED'}`);\n      }\n      // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments\n      if (previousDetails && details.fragments.length > 0) {\n        mergeDetails(previousDetails, details);\n      }\n      if (!this.canLoad || !details.live) {\n        return;\n      }\n      let deliveryDirectives;\n      let msn = undefined;\n      let part = undefined;\n      if (details.canBlockReload && details.endSN && details.advanced) {\n        // Load level with LL-HLS delivery directives\n        const lowLatencyMode = this.hls.config.lowLatencyMode;\n        const lastPartSn = details.lastPartSn;\n        const endSn = details.endSN;\n        const lastPartIndex = details.lastPartIndex;\n        const hasParts = lastPartIndex !== -1;\n        const lastPart = lastPartSn === endSn;\n        // When low latency mode is disabled, we'll skip part requests once the last part index is found\n        const nextSnStartIndex = lowLatencyMode ? 0 : lastPartIndex;\n        if (hasParts) {\n          msn = lastPart ? endSn + 1 : lastPartSn;\n          part = lastPart ? nextSnStartIndex : lastPartIndex + 1;\n        } else {\n          msn = endSn + 1;\n        }\n        // Low-Latency CDN Tune-in: \"age\" header and time since load indicates we're behind by more than one part\n        // Update directives to obtain the Playlist that has the estimated additional duration of media\n        const lastAdvanced = details.age;\n        const cdnAge = lastAdvanced + details.ageHeader;\n        let currentGoal = Math.min(cdnAge - details.partTarget, details.targetduration * 1.5);\n        if (currentGoal > 0) {\n          if (previousDetails && currentGoal > previousDetails.tuneInGoal) {\n            // If we attempted to get the next or latest playlist update, but currentGoal increased,\n            // then we either can't catchup, or the \"age\" header cannot be trusted.\n            this.warn(`CDN Tune-in goal increased from: ${previousDetails.tuneInGoal} to: ${currentGoal} with playlist age: ${details.age}`);\n            currentGoal = 0;\n          } else {\n            const segments = Math.floor(currentGoal / details.targetduration);\n            msn += segments;\n            if (part !== undefined) {\n              const parts = Math.round(currentGoal % details.targetduration / details.partTarget);\n              part += parts;\n            }\n            this.log(`CDN Tune-in age: ${details.ageHeader}s last advanced ${lastAdvanced.toFixed(2)}s goal: ${currentGoal} skip sn ${segments} to part ${part}`);\n          }\n          details.tuneInGoal = currentGoal;\n        }\n        deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);\n        if (lowLatencyMode || !lastPart) {\n          this.loadPlaylist(deliveryDirectives);\n          return;\n        }\n      } else if (details.canBlockReload || details.canSkipUntil) {\n        deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);\n      }\n      const bufferInfo = this.hls.mainForwardBufferInfo;\n      const position = bufferInfo ? bufferInfo.end - bufferInfo.len : 0;\n      const distanceToLiveEdgeMs = (details.edge - position) * 1000;\n      const reloadInterval = computeReloadInterval(details, distanceToLiveEdgeMs);\n      if (details.updated && now > this.requestScheduled + reloadInterval) {\n        this.requestScheduled = stats.loading.start;\n      }\n      if (msn !== undefined && details.canBlockReload) {\n        this.requestScheduled = stats.loading.first + reloadInterval - (details.partTarget * 1000 || 1000);\n      } else if (this.requestScheduled === -1 || this.requestScheduled + reloadInterval < now) {\n        this.requestScheduled = now;\n      } else if (this.requestScheduled - now <= 0) {\n        this.requestScheduled += reloadInterval;\n      }\n      let estimatedTimeUntilUpdate = this.requestScheduled - now;\n      estimatedTimeUntilUpdate = Math.max(0, estimatedTimeUntilUpdate);\n      this.log(`reload live playlist ${index} in ${Math.round(estimatedTimeUntilUpdate)} ms`);\n      // this.log(\n      //   `live reload ${details.updated ? 'REFRESHED' : 'MISSED'}\n      // reload in ${estimatedTimeUntilUpdate / 1000}\n      // round trip ${(stats.loading.end - stats.loading.start) / 1000}\n      // diff ${\n      //   (reloadInterval -\n      //     (estimatedTimeUntilUpdate +\n      //       stats.loading.end -\n      //       stats.loading.start)) /\n      //   1000\n      // }\n      // reload interval ${reloadInterval / 1000}\n      // target duration ${details.targetduration}\n      // distance to edge ${distanceToLiveEdgeMs / 1000}`\n      // );\n\n      this.timer = self.setTimeout(() => this.loadPlaylist(deliveryDirectives), estimatedTimeUntilUpdate);\n    } else {\n      this.clearTimer();\n    }\n  }\n  getDeliveryDirectives(details, previousDeliveryDirectives, msn, part) {\n    let skip = getSkipValue(details);\n    if (previousDeliveryDirectives != null && previousDeliveryDirectives.skip && details.deltaUpdateFailed) {\n      msn = previousDeliveryDirectives.msn;\n      part = previousDeliveryDirectives.part;\n      skip = HlsSkip.No;\n    }\n    return new HlsUrlParameters(msn, part, skip);\n  }\n  checkRetry(errorEvent) {\n    const errorDetails = errorEvent.details;\n    const isTimeout = isTimeoutError(errorEvent);\n    const errorAction = errorEvent.errorAction;\n    const {\n      action,\n      retryCount = 0,\n      retryConfig\n    } = errorAction || {};\n    const retry = !!errorAction && !!retryConfig && (action === NetworkErrorAction.RetryRequest || !errorAction.resolved && action === NetworkErrorAction.SendAlternateToPenaltyBox);\n    if (retry) {\n      var _errorEvent$context;\n      this.requestScheduled = -1;\n      if (retryCount >= retryConfig.maxNumRetry) {\n        return false;\n      }\n      if (isTimeout && (_errorEvent$context = errorEvent.context) != null && _errorEvent$context.deliveryDirectives) {\n        // The LL-HLS request already timed out so retry immediately\n        this.warn(`Retrying playlist loading ${retryCount + 1}/${retryConfig.maxNumRetry} after \"${errorDetails}\" without delivery-directives`);\n        this.loadPlaylist();\n      } else {\n        const delay = getRetryDelay(retryConfig, retryCount);\n        // Schedule level/track reload\n        this.timer = self.setTimeout(() => this.loadPlaylist(), delay);\n        this.warn(`Retrying playlist loading ${retryCount + 1}/${retryConfig.maxNumRetry} after \"${errorDetails}\" in ${delay}ms`);\n      }\n      // `levelRetry = true` used to inform other controllers that a retry is happening\n      errorEvent.levelRetry = true;\n      errorAction.resolved = true;\n    }\n    return retry;\n  }\n}\n\n/*\n * compute an Exponential Weighted moving average\n * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\n *  - heavily inspired from shaka-player\n */\n\nclass EWMA {\n  //  About half of the estimated value will be from the last |halfLife| samples by weight.\n  constructor(halfLife, estimate = 0, weight = 0) {\n    this.halfLife = void 0;\n    this.alpha_ = void 0;\n    this.estimate_ = void 0;\n    this.totalWeight_ = void 0;\n    this.halfLife = halfLife;\n    // Larger values of alpha expire historical data more slowly.\n    this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;\n    this.estimate_ = estimate;\n    this.totalWeight_ = weight;\n  }\n  sample(weight, value) {\n    const adjAlpha = Math.pow(this.alpha_, weight);\n    this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;\n    this.totalWeight_ += weight;\n  }\n  getTotalWeight() {\n    return this.totalWeight_;\n  }\n  getEstimate() {\n    if (this.alpha_) {\n      const zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);\n      if (zeroFactor) {\n        return this.estimate_ / zeroFactor;\n      }\n    }\n    return this.estimate_;\n  }\n}\n\n/*\n * EWMA Bandwidth Estimator\n *  - heavily inspired from shaka-player\n * Tracks bandwidth samples and estimates available bandwidth.\n * Based on the minimum of two exponentially-weighted moving averages with\n * different half-lives.\n */\n\nclass EwmaBandWidthEstimator {\n  constructor(slow, fast, defaultEstimate, defaultTTFB = 100) {\n    this.defaultEstimate_ = void 0;\n    this.minWeight_ = void 0;\n    this.minDelayMs_ = void 0;\n    this.slow_ = void 0;\n    this.fast_ = void 0;\n    this.defaultTTFB_ = void 0;\n    this.ttfb_ = void 0;\n    this.defaultEstimate_ = defaultEstimate;\n    this.minWeight_ = 0.001;\n    this.minDelayMs_ = 50;\n    this.slow_ = new EWMA(slow);\n    this.fast_ = new EWMA(fast);\n    this.defaultTTFB_ = defaultTTFB;\n    this.ttfb_ = new EWMA(slow);\n  }\n  update(slow, fast) {\n    const {\n      slow_,\n      fast_,\n      ttfb_\n    } = this;\n    if (slow_.halfLife !== slow) {\n      this.slow_ = new EWMA(slow, slow_.getEstimate(), slow_.getTotalWeight());\n    }\n    if (fast_.halfLife !== fast) {\n      this.fast_ = new EWMA(fast, fast_.getEstimate(), fast_.getTotalWeight());\n    }\n    if (ttfb_.halfLife !== slow) {\n      this.ttfb_ = new EWMA(slow, ttfb_.getEstimate(), ttfb_.getTotalWeight());\n    }\n  }\n  sample(durationMs, numBytes) {\n    durationMs = Math.max(durationMs, this.minDelayMs_);\n    const numBits = 8 * numBytes;\n    // weight is duration in seconds\n    const durationS = durationMs / 1000;\n    // value is bandwidth in bits/s\n    const bandwidthInBps = numBits / durationS;\n    this.fast_.sample(durationS, bandwidthInBps);\n    this.slow_.sample(durationS, bandwidthInBps);\n  }\n  sampleTTFB(ttfb) {\n    // weight is frequency curve applied to TTFB in seconds\n    // (longer times have less weight with expected input under 1 second)\n    const seconds = ttfb / 1000;\n    const weight = Math.sqrt(2) * Math.exp(-Math.pow(seconds, 2) / 2);\n    this.ttfb_.sample(weight, Math.max(ttfb, 5));\n  }\n  canEstimate() {\n    return this.fast_.getTotalWeight() >= this.minWeight_;\n  }\n  getEstimate() {\n    if (this.canEstimate()) {\n      // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));\n      // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));\n      // Take the minimum of these two estimates.  This should have the effect of\n      // adapting down quickly, but up more slowly.\n      return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());\n    } else {\n      return this.defaultEstimate_;\n    }\n  }\n  getEstimateTTFB() {\n    if (this.ttfb_.getTotalWeight() >= this.minWeight_) {\n      return this.ttfb_.getEstimate();\n    } else {\n      return this.defaultTTFB_;\n    }\n  }\n  destroy() {}\n}\n\nconst SUPPORTED_INFO_DEFAULT = {\n  supported: true,\n  configurations: [],\n  decodingInfoResults: [{\n    supported: true,\n    powerEfficient: true,\n    smooth: true\n  }]\n};\nconst SUPPORTED_INFO_CACHE = {};\nfunction requiresMediaCapabilitiesDecodingInfo(level, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference) {\n  // Only test support when configuration is exceeds minimum options\n  const audioGroups = level.audioCodec ? level.audioGroups : null;\n  const audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;\n  const channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;\n  const maxChannels = channelsPreference ? parseInt(channelsPreference) : audioCodecPreference ? Infinity : 2;\n  let audioChannels = null;\n  if (audioGroups != null && audioGroups.length) {\n    try {\n      if (audioGroups.length === 1 && audioGroups[0]) {\n        audioChannels = audioTracksByGroup.groups[audioGroups[0]].channels;\n      } else {\n        audioChannels = audioGroups.reduce((acc, groupId) => {\n          if (groupId) {\n            const audioTrackGroup = audioTracksByGroup.groups[groupId];\n            if (!audioTrackGroup) {\n              throw new Error(`Audio track group ${groupId} not found`);\n            }\n            // Sum all channel key values\n            Object.keys(audioTrackGroup.channels).forEach(key => {\n              acc[key] = (acc[key] || 0) + audioTrackGroup.channels[key];\n            });\n          }\n          return acc;\n        }, {\n          2: 0\n        });\n      }\n    } catch (error) {\n      return true;\n    }\n  }\n  return level.videoCodec !== undefined && (level.width > 1920 && level.height > 1088 || level.height > 1920 && level.width > 1088 || level.frameRate > Math.max(currentFrameRate, 30) || level.videoRange !== 'SDR' && level.videoRange !== currentVideoRange || level.bitrate > Math.max(currentBw, 8e6)) || !!audioChannels && isFiniteNumber(maxChannels) && Object.keys(audioChannels).some(channels => parseInt(channels) > maxChannels);\n}\nfunction getMediaDecodingInfoPromise(level, audioTracksByGroup, mediaCapabilities) {\n  const videoCodecs = level.videoCodec;\n  const audioCodecs = level.audioCodec;\n  if (!videoCodecs || !audioCodecs || !mediaCapabilities) {\n    return Promise.resolve(SUPPORTED_INFO_DEFAULT);\n  }\n  const baseVideoConfiguration = {\n    width: level.width,\n    height: level.height,\n    bitrate: Math.ceil(Math.max(level.bitrate * 0.9, level.averageBitrate)),\n    // Assume a framerate of 30fps since MediaCapabilities will not accept Level default of 0.\n    framerate: level.frameRate || 30\n  };\n  const videoRange = level.videoRange;\n  if (videoRange !== 'SDR') {\n    baseVideoConfiguration.transferFunction = videoRange.toLowerCase();\n  }\n  const configurations = videoCodecs.split(',').map(videoCodec => ({\n    type: 'media-source',\n    video: _objectSpread2(_objectSpread2({}, baseVideoConfiguration), {}, {\n      contentType: mimeTypeForCodec(videoCodec, 'video')\n    })\n  }));\n  if (audioCodecs && level.audioGroups) {\n    level.audioGroups.forEach(audioGroupId => {\n      var _audioTracksByGroup$g;\n      if (!audioGroupId) {\n        return;\n      }\n      (_audioTracksByGroup$g = audioTracksByGroup.groups[audioGroupId]) == null ? void 0 : _audioTracksByGroup$g.tracks.forEach(audioTrack => {\n        if (audioTrack.groupId === audioGroupId) {\n          const channels = audioTrack.channels || '';\n          const channelsNumber = parseFloat(channels);\n          if (isFiniteNumber(channelsNumber) && channelsNumber > 2) {\n            configurations.push.apply(configurations, audioCodecs.split(',').map(audioCodec => ({\n              type: 'media-source',\n              audio: {\n                contentType: mimeTypeForCodec(audioCodec, 'audio'),\n                channels: '' + channelsNumber\n                // spatialRendering:\n                //   audioCodec === 'ec-3' && channels.indexOf('JOC'),\n              }\n            })));\n          }\n        }\n      });\n    });\n  }\n  return Promise.all(configurations.map(configuration => {\n    // Cache MediaCapabilities promises\n    const decodingInfoKey = getMediaDecodingInfoKey(configuration);\n    return SUPPORTED_INFO_CACHE[decodingInfoKey] || (SUPPORTED_INFO_CACHE[decodingInfoKey] = mediaCapabilities.decodingInfo(configuration));\n  })).then(decodingInfoResults => ({\n    supported: !decodingInfoResults.some(info => !info.supported),\n    configurations,\n    decodingInfoResults\n  })).catch(error => ({\n    supported: false,\n    configurations,\n    decodingInfoResults: [],\n    error\n  }));\n}\nfunction getMediaDecodingInfoKey(config) {\n  const {\n    audio,\n    video\n  } = config;\n  const mediaConfig = video || audio;\n  if (mediaConfig) {\n    const codec = mediaConfig.contentType.split('\"')[1];\n    if (video) {\n      return `r${video.height}x${video.width}f${Math.ceil(video.framerate)}${video.transferFunction || 'sd'}_${codec}_${Math.ceil(video.bitrate / 1e5)}`;\n    }\n    if (audio) {\n      return `c${audio.channels}${audio.spatialRendering ? 's' : 'n'}_${codec}`;\n    }\n  }\n  return '';\n}\n\n/**\n * @returns Whether we can detect and validate HDR capability within the window context\n */\nfunction isHdrSupported() {\n  if (typeof matchMedia === 'function') {\n    const mediaQueryList = matchMedia('(dynamic-range: high)');\n    const badQuery = matchMedia('bad query');\n    if (mediaQueryList.media !== badQuery.media) {\n      return mediaQueryList.matches === true;\n    }\n  }\n  return false;\n}\n\n/**\n * Sanitizes inputs to return the active video selection options for HDR/SDR.\n * When both inputs are null:\n *\n *    `{ preferHDR: false, allowedVideoRanges: [] }`\n *\n * When `currentVideoRange` non-null, maintain the active range:\n *\n *    `{ preferHDR: currentVideoRange !== 'SDR', allowedVideoRanges: [currentVideoRange] }`\n *\n * When VideoSelectionOption non-null:\n *\n *  - Allow all video ranges if `allowedVideoRanges` unspecified.\n *  - If `preferHDR` is non-null use the value to filter `allowedVideoRanges`.\n *  - Else check window for HDR support and set `preferHDR` to the result.\n *\n * @param currentVideoRange\n * @param videoPreference\n */\nfunction getVideoSelectionOptions(currentVideoRange, videoPreference) {\n  let preferHDR = false;\n  let allowedVideoRanges = [];\n  if (currentVideoRange) {\n    preferHDR = currentVideoRange !== 'SDR';\n    allowedVideoRanges = [currentVideoRange];\n  }\n  if (videoPreference) {\n    allowedVideoRanges = videoPreference.allowedVideoRanges || VideoRangeValues.slice(0);\n    preferHDR = videoPreference.preferHDR !== undefined ? videoPreference.preferHDR : isHdrSupported();\n    if (preferHDR) {\n      allowedVideoRanges = allowedVideoRanges.filter(range => range !== 'SDR');\n    } else {\n      allowedVideoRanges = ['SDR'];\n    }\n  }\n  return {\n    preferHDR,\n    allowedVideoRanges\n  };\n}\n\nfunction getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference) {\n  const codecSets = Object.keys(codecTiers);\n  const channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;\n  const audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;\n  const preferStereo = channelsPreference && parseInt(channelsPreference) === 2;\n  // Use first level set to determine stereo, and minimum resolution and framerate\n  let hasStereo = true;\n  let hasCurrentVideoRange = false;\n  let minHeight = Infinity;\n  let minFramerate = Infinity;\n  let minBitrate = Infinity;\n  let selectedScore = 0;\n  let videoRanges = [];\n  const {\n    preferHDR,\n    allowedVideoRanges\n  } = getVideoSelectionOptions(currentVideoRange, videoPreference);\n  for (let i = codecSets.length; i--;) {\n    const tier = codecTiers[codecSets[i]];\n    hasStereo = tier.channels[2] > 0;\n    minHeight = Math.min(minHeight, tier.minHeight);\n    minFramerate = Math.min(minFramerate, tier.minFramerate);\n    minBitrate = Math.min(minBitrate, tier.minBitrate);\n    const matchingVideoRanges = allowedVideoRanges.filter(range => tier.videoRanges[range] > 0);\n    if (matchingVideoRanges.length > 0) {\n      hasCurrentVideoRange = true;\n      videoRanges = matchingVideoRanges;\n    }\n  }\n  minHeight = isFiniteNumber(minHeight) ? minHeight : 0;\n  minFramerate = isFiniteNumber(minFramerate) ? minFramerate : 0;\n  const maxHeight = Math.max(1080, minHeight);\n  const maxFramerate = Math.max(30, minFramerate);\n  minBitrate = isFiniteNumber(minBitrate) ? minBitrate : currentBw;\n  currentBw = Math.max(minBitrate, currentBw);\n  // If there are no variants with matching preference, set currentVideoRange to undefined\n  if (!hasCurrentVideoRange) {\n    currentVideoRange = undefined;\n    videoRanges = [];\n  }\n  const codecSet = codecSets.reduce((selected, candidate) => {\n    // Remove candiates which do not meet bitrate, default audio, stereo or channels preference, 1080p or lower, 30fps or lower, or SDR/HDR selection if present\n    const candidateTier = codecTiers[candidate];\n    if (candidate === selected) {\n      return selected;\n    }\n    if (candidateTier.minBitrate > currentBw) {\n      logStartCodecCandidateIgnored(candidate, `min bitrate of ${candidateTier.minBitrate} > current estimate of ${currentBw}`);\n      return selected;\n    }\n    if (!candidateTier.hasDefaultAudio) {\n      logStartCodecCandidateIgnored(candidate, `no renditions with default or auto-select sound found`);\n      return selected;\n    }\n    if (audioCodecPreference && candidate.indexOf(audioCodecPreference.substring(0, 4)) % 5 !== 0) {\n      logStartCodecCandidateIgnored(candidate, `audio codec preference \"${audioCodecPreference}\" not found`);\n      return selected;\n    }\n    if (channelsPreference && !preferStereo) {\n      if (!candidateTier.channels[channelsPreference]) {\n        logStartCodecCandidateIgnored(candidate, `no renditions with ${channelsPreference} channel sound found (channels options: ${Object.keys(candidateTier.channels)})`);\n        return selected;\n      }\n    } else if ((!audioCodecPreference || preferStereo) && hasStereo && candidateTier.channels['2'] === 0) {\n      logStartCodecCandidateIgnored(candidate, `no renditions with stereo sound found`);\n      return selected;\n    }\n    if (candidateTier.minHeight > maxHeight) {\n      logStartCodecCandidateIgnored(candidate, `min resolution of ${candidateTier.minHeight} > maximum of ${maxHeight}`);\n      return selected;\n    }\n    if (candidateTier.minFramerate > maxFramerate) {\n      logStartCodecCandidateIgnored(candidate, `min framerate of ${candidateTier.minFramerate} > maximum of ${maxFramerate}`);\n      return selected;\n    }\n    if (!videoRanges.some(range => candidateTier.videoRanges[range] > 0)) {\n      logStartCodecCandidateIgnored(candidate, `no variants with VIDEO-RANGE of ${JSON.stringify(videoRanges)} found`);\n      return selected;\n    }\n    if (candidateTier.maxScore < selectedScore) {\n      logStartCodecCandidateIgnored(candidate, `max score of ${candidateTier.maxScore} < selected max of ${selectedScore}`);\n      return selected;\n    }\n    // Remove candiates with less preferred codecs or more errors\n    if (selected && (codecsSetSelectionPreferenceValue(candidate) >= codecsSetSelectionPreferenceValue(selected) || candidateTier.fragmentError > codecTiers[selected].fragmentError)) {\n      return selected;\n    }\n    selectedScore = candidateTier.maxScore;\n    return candidate;\n  }, undefined);\n  return {\n    codecSet,\n    videoRanges,\n    preferHDR,\n    minFramerate,\n    minBitrate\n  };\n}\nfunction logStartCodecCandidateIgnored(codeSet, reason) {\n  logger.log(`[abr] start candidates with \"${codeSet}\" ignored because ${reason}`);\n}\nfunction getAudioTracksByGroup(allAudioTracks) {\n  return allAudioTracks.reduce((audioTracksByGroup, track) => {\n    let trackGroup = audioTracksByGroup.groups[track.groupId];\n    if (!trackGroup) {\n      trackGroup = audioTracksByGroup.groups[track.groupId] = {\n        tracks: [],\n        channels: {\n          2: 0\n        },\n        hasDefault: false,\n        hasAutoSelect: false\n      };\n    }\n    trackGroup.tracks.push(track);\n    const channelsKey = track.channels || '2';\n    trackGroup.channels[channelsKey] = (trackGroup.channels[channelsKey] || 0) + 1;\n    trackGroup.hasDefault = trackGroup.hasDefault || track.default;\n    trackGroup.hasAutoSelect = trackGroup.hasAutoSelect || track.autoselect;\n    if (trackGroup.hasDefault) {\n      audioTracksByGroup.hasDefaultAudio = true;\n    }\n    if (trackGroup.hasAutoSelect) {\n      audioTracksByGroup.hasAutoSelectAudio = true;\n    }\n    return audioTracksByGroup;\n  }, {\n    hasDefaultAudio: false,\n    hasAutoSelectAudio: false,\n    groups: {}\n  });\n}\nfunction getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel) {\n  return levels.slice(minAutoLevel, maxAutoLevel + 1).reduce((tiers, level) => {\n    if (!level.codecSet) {\n      return tiers;\n    }\n    const audioGroups = level.audioGroups;\n    let tier = tiers[level.codecSet];\n    if (!tier) {\n      tiers[level.codecSet] = tier = {\n        minBitrate: Infinity,\n        minHeight: Infinity,\n        minFramerate: Infinity,\n        maxScore: 0,\n        videoRanges: {\n          SDR: 0\n        },\n        channels: {\n          '2': 0\n        },\n        hasDefaultAudio: !audioGroups,\n        fragmentError: 0\n      };\n    }\n    tier.minBitrate = Math.min(tier.minBitrate, level.bitrate);\n    const lesserWidthOrHeight = Math.min(level.height, level.width);\n    tier.minHeight = Math.min(tier.minHeight, lesserWidthOrHeight);\n    tier.minFramerate = Math.min(tier.minFramerate, level.frameRate);\n    tier.maxScore = Math.max(tier.maxScore, level.score);\n    tier.fragmentError += level.fragmentError;\n    tier.videoRanges[level.videoRange] = (tier.videoRanges[level.videoRange] || 0) + 1;\n    if (audioGroups) {\n      audioGroups.forEach(audioGroupId => {\n        if (!audioGroupId) {\n          return;\n        }\n        const audioGroup = audioTracksByGroup.groups[audioGroupId];\n        if (!audioGroup) {\n          return;\n        }\n        // Default audio is any group with DEFAULT=YES, or if missing then any group with AUTOSELECT=YES, or all variants\n        tier.hasDefaultAudio = tier.hasDefaultAudio || audioTracksByGroup.hasDefaultAudio ? audioGroup.hasDefault : audioGroup.hasAutoSelect || !audioTracksByGroup.hasDefaultAudio && !audioTracksByGroup.hasAutoSelectAudio;\n        Object.keys(audioGroup.channels).forEach(channels => {\n          tier.channels[channels] = (tier.channels[channels] || 0) + audioGroup.channels[channels];\n        });\n      });\n    }\n    return tiers;\n  }, {});\n}\nfunction findMatchingOption(option, tracks, matchPredicate) {\n  if ('attrs' in option) {\n    const index = tracks.indexOf(option);\n    if (index !== -1) {\n      return index;\n    }\n  }\n  for (let i = 0; i < tracks.length; i++) {\n    const track = tracks[i];\n    if (matchesOption(option, track, matchPredicate)) {\n      return i;\n    }\n  }\n  return -1;\n}\nfunction matchesOption(option, track, matchPredicate) {\n  const {\n    groupId,\n    name,\n    lang,\n    assocLang,\n    characteristics,\n    default: isDefault\n  } = option;\n  const forced = option.forced;\n  return (groupId === undefined || track.groupId === groupId) && (name === undefined || track.name === name) && (lang === undefined || track.lang === lang) && (lang === undefined || track.assocLang === assocLang) && (isDefault === undefined || track.default === isDefault) && (forced === undefined || track.forced === forced) && (characteristics === undefined || characteristicsMatch(characteristics, track.characteristics)) && (matchPredicate === undefined || matchPredicate(option, track));\n}\nfunction characteristicsMatch(characteristicsA, characteristicsB = '') {\n  const arrA = characteristicsA.split(',');\n  const arrB = characteristicsB.split(',');\n  // Expects each item to be unique:\n  return arrA.length === arrB.length && !arrA.some(el => arrB.indexOf(el) === -1);\n}\nfunction audioMatchPredicate(option, track) {\n  const {\n    audioCodec,\n    channels\n  } = option;\n  return (audioCodec === undefined || (track.audioCodec || '').substring(0, 4) === audioCodec.substring(0, 4)) && (channels === undefined || channels === (track.channels || '2'));\n}\nfunction findClosestLevelWithAudioGroup(option, levels, allAudioTracks, searchIndex, matchPredicate) {\n  const currentLevel = levels[searchIndex];\n  // Are there variants with same URI as current level?\n  // If so, find a match that does not require any level URI change\n  const variants = levels.reduce((variantMap, level, index) => {\n    const uri = level.uri;\n    const renditions = variantMap[uri] || (variantMap[uri] = []);\n    renditions.push(index);\n    return variantMap;\n  }, {});\n  const renditions = variants[currentLevel.uri];\n  if (renditions.length > 1) {\n    searchIndex = Math.max.apply(Math, renditions);\n  }\n  // Find best match\n  const currentVideoRange = currentLevel.videoRange;\n  const currentFrameRate = currentLevel.frameRate;\n  const currentVideoCodec = currentLevel.codecSet.substring(0, 4);\n  const matchingVideo = searchDownAndUpList(levels, searchIndex, level => {\n    if (level.videoRange !== currentVideoRange || level.frameRate !== currentFrameRate || level.codecSet.substring(0, 4) !== currentVideoCodec) {\n      return false;\n    }\n    const audioGroups = level.audioGroups;\n    const tracks = allAudioTracks.filter(track => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);\n    return findMatchingOption(option, tracks, matchPredicate) > -1;\n  });\n  if (matchingVideo > -1) {\n    return matchingVideo;\n  }\n  return searchDownAndUpList(levels, searchIndex, level => {\n    const audioGroups = level.audioGroups;\n    const tracks = allAudioTracks.filter(track => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);\n    return findMatchingOption(option, tracks, matchPredicate) > -1;\n  });\n}\nfunction searchDownAndUpList(arr, searchIndex, predicate) {\n  for (let i = searchIndex; i; i--) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  for (let i = searchIndex + 1; i < arr.length; i++) {\n    if (predicate(arr[i])) {\n      return i;\n    }\n  }\n  return -1;\n}\n\nclass AbrController {\n  constructor(_hls) {\n    this.hls = void 0;\n    this.lastLevelLoadSec = 0;\n    this.lastLoadedFragLevel = -1;\n    this.firstSelection = -1;\n    this._nextAutoLevel = -1;\n    this.nextAutoLevelKey = '';\n    this.audioTracksByGroup = null;\n    this.codecTiers = null;\n    this.timer = -1;\n    this.fragCurrent = null;\n    this.partCurrent = null;\n    this.bitrateTestDelay = 0;\n    this.bwEstimator = void 0;\n    /*\n        This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load\n        quickly enough to prevent underbuffering\n      */\n    this._abandonRulesCheck = () => {\n      const {\n        fragCurrent: frag,\n        partCurrent: part,\n        hls\n      } = this;\n      const {\n        autoLevelEnabled,\n        media\n      } = hls;\n      if (!frag || !media) {\n        return;\n      }\n      const now = performance.now();\n      const stats = part ? part.stats : frag.stats;\n      const duration = part ? part.duration : frag.duration;\n      const timeLoading = now - stats.loading.start;\n      const minAutoLevel = hls.minAutoLevel;\n      // If frag loading is aborted, complete, or from lowest level, stop timer and return\n      if (stats.aborted || stats.loaded && stats.loaded === stats.total || frag.level <= minAutoLevel) {\n        this.clearTimer();\n        // reset forced auto level value so that next level will be selected\n        this._nextAutoLevel = -1;\n        return;\n      }\n\n      // This check only runs if we're in ABR mode and actually playing\n      if (!autoLevelEnabled || media.paused || !media.playbackRate || !media.readyState) {\n        return;\n      }\n      const bufferInfo = hls.mainForwardBufferInfo;\n      if (bufferInfo === null) {\n        return;\n      }\n      const ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n      const playbackRate = Math.abs(media.playbackRate);\n      // To maintain stable adaptive playback, only begin monitoring frag loading after half or more of its playback duration has passed\n      if (timeLoading <= Math.max(ttfbEstimate, 1000 * (duration / (playbackRate * 2)))) {\n        return;\n      }\n\n      // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer\n      const bufferStarvationDelay = bufferInfo.len / playbackRate;\n      const ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;\n      const loadedFirstByte = stats.loaded && ttfb > -1;\n      const bwEstimate = this.getBwEstimate();\n      const levels = hls.levels;\n      const level = levels[frag.level];\n      const expectedLen = stats.total || Math.max(stats.loaded, Math.round(duration * level.averageBitrate / 8));\n      let timeStreaming = loadedFirstByte ? timeLoading - ttfb : timeLoading;\n      if (timeStreaming < 1 && loadedFirstByte) {\n        timeStreaming = Math.min(timeLoading, stats.loaded * 8 / bwEstimate);\n      }\n      const loadRate = loadedFirstByte ? stats.loaded * 1000 / timeStreaming : 0;\n      // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the remainder of the fragment\n      const fragLoadedDelay = loadRate ? (expectedLen - stats.loaded) / loadRate : expectedLen * 8 / bwEstimate + ttfbEstimate / 1000;\n      // Only downswitch if the time to finish loading the current fragment is greater than the amount of buffer left\n      if (fragLoadedDelay <= bufferStarvationDelay) {\n        return;\n      }\n      const bwe = loadRate ? loadRate * 8 : bwEstimate;\n      let fragLevelNextLoadedDelay = Number.POSITIVE_INFINITY;\n      let nextLoadLevel;\n      // Iterate through lower level and try to find the largest one that avoids rebuffering\n      for (nextLoadLevel = frag.level - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {\n        // compute time to load next fragment at lower level\n        // 8 = bits per byte (bps/Bps)\n        const levelNextBitrate = levels[nextLoadLevel].maxBitrate;\n        fragLevelNextLoadedDelay = this.getTimeToLoadFrag(ttfbEstimate / 1000, bwe, duration * levelNextBitrate, !levels[nextLoadLevel].details);\n        if (fragLevelNextLoadedDelay < bufferStarvationDelay) {\n          break;\n        }\n      }\n      // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing\n      // to load the current one\n      if (fragLevelNextLoadedDelay >= fragLoadedDelay) {\n        return;\n      }\n\n      // if estimated load time of new segment is completely unreasonable, ignore and do not emergency switch down\n      if (fragLevelNextLoadedDelay > duration * 10) {\n        return;\n      }\n      hls.nextLoadLevel = hls.nextAutoLevel = nextLoadLevel;\n      if (loadedFirstByte) {\n        // If there has been loading progress, sample bandwidth using loading time offset by minimum TTFB time\n        this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);\n      } else {\n        // If there has been no loading progress, sample TTFB\n        this.bwEstimator.sampleTTFB(timeLoading);\n      }\n      const nextLoadLevelBitrate = levels[nextLoadLevel].maxBitrate;\n      if (this.getBwEstimate() * this.hls.config.abrBandWidthUpFactor > nextLoadLevelBitrate) {\n        this.resetEstimator(nextLoadLevelBitrate);\n      }\n      this.clearTimer();\n      logger.warn(`[abr] Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of level ${frag.level} is loading too slowly;\n      Time to underbuffer: ${bufferStarvationDelay.toFixed(3)} s\n      Estimated load time for current fragment: ${fragLoadedDelay.toFixed(3)} s\n      Estimated load time for down switch fragment: ${fragLevelNextLoadedDelay.toFixed(3)} s\n      TTFB estimate: ${ttfb | 0} ms\n      Current BW estimate: ${isFiniteNumber(bwEstimate) ? bwEstimate | 0 : 'Unknown'} bps\n      New BW estimate: ${this.getBwEstimate() | 0} bps\n      Switching to level ${nextLoadLevel} @ ${nextLoadLevelBitrate | 0} bps`);\n      hls.trigger(Events.FRAG_LOAD_EMERGENCY_ABORTED, {\n        frag,\n        part,\n        stats\n      });\n    };\n    this.hls = _hls;\n    this.bwEstimator = this.initEstimator();\n    this.registerListeners();\n  }\n  resetEstimator(abrEwmaDefaultEstimate) {\n    if (abrEwmaDefaultEstimate) {\n      logger.log(`setting initial bwe to ${abrEwmaDefaultEstimate}`);\n      this.hls.config.abrEwmaDefaultEstimate = abrEwmaDefaultEstimate;\n    }\n    this.firstSelection = -1;\n    this.bwEstimator = this.initEstimator();\n  }\n  initEstimator() {\n    const config = this.hls.config;\n    return new EwmaBandWidthEstimator(config.abrEwmaSlowVoD, config.abrEwmaFastVoD, config.abrEwmaDefaultEstimate);\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.clearTimer();\n    // @ts-ignore\n    this.hls = this._abandonRulesCheck = null;\n    this.fragCurrent = this.partCurrent = null;\n  }\n  onManifestLoading(event, data) {\n    this.lastLoadedFragLevel = -1;\n    this.firstSelection = -1;\n    this.lastLevelLoadSec = 0;\n    this.fragCurrent = this.partCurrent = null;\n    this.onLevelsUpdated();\n    this.clearTimer();\n  }\n  onLevelsUpdated() {\n    if (this.lastLoadedFragLevel > -1 && this.fragCurrent) {\n      this.lastLoadedFragLevel = this.fragCurrent.level;\n    }\n    this._nextAutoLevel = -1;\n    this.onMaxAutoLevelUpdated();\n    this.codecTiers = null;\n    this.audioTracksByGroup = null;\n  }\n  onMaxAutoLevelUpdated() {\n    this.firstSelection = -1;\n    this.nextAutoLevelKey = '';\n  }\n  onFragLoading(event, data) {\n    const frag = data.frag;\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    if (!frag.bitrateTest) {\n      var _data$part;\n      this.fragCurrent = frag;\n      this.partCurrent = (_data$part = data.part) != null ? _data$part : null;\n    }\n    this.clearTimer();\n    this.timer = self.setInterval(this._abandonRulesCheck, 100);\n  }\n  onLevelSwitching(event, data) {\n    this.clearTimer();\n  }\n  onError(event, data) {\n    if (data.fatal) {\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n        // Reset last loaded level so that a new selection can be made after calling recoverMediaError\n        this.lastLoadedFragLevel = -1;\n        this.firstSelection = -1;\n        break;\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n        {\n          const frag = data.frag;\n          const {\n            fragCurrent,\n            partCurrent: part\n          } = this;\n          if (frag && fragCurrent && frag.sn === fragCurrent.sn && frag.level === fragCurrent.level) {\n            const now = performance.now();\n            const stats = part ? part.stats : frag.stats;\n            const timeLoading = now - stats.loading.start;\n            const ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;\n            const loadedFirstByte = stats.loaded && ttfb > -1;\n            if (loadedFirstByte) {\n              const ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n              this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);\n            } else {\n              this.bwEstimator.sampleTTFB(timeLoading);\n            }\n          }\n          break;\n        }\n    }\n  }\n  getTimeToLoadFrag(timeToFirstByteSec, bandwidth, fragSizeBits, isSwitch) {\n    const fragLoadSec = timeToFirstByteSec + fragSizeBits / bandwidth;\n    const playlistLoadSec = isSwitch ? this.lastLevelLoadSec : 0;\n    return fragLoadSec + playlistLoadSec;\n  }\n  onLevelLoaded(event, data) {\n    const config = this.hls.config;\n    const {\n      loading\n    } = data.stats;\n    const timeLoadingMs = loading.end - loading.start;\n    if (isFiniteNumber(timeLoadingMs)) {\n      this.lastLevelLoadSec = timeLoadingMs / 1000;\n    }\n    if (data.details.live) {\n      this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);\n    } else {\n      this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);\n    }\n  }\n  onFragLoaded(event, {\n    frag,\n    part\n  }) {\n    const stats = part ? part.stats : frag.stats;\n    if (frag.type === PlaylistLevelType.MAIN) {\n      this.bwEstimator.sampleTTFB(stats.loading.first - stats.loading.start);\n    }\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    // stop monitoring bw once frag loaded\n    this.clearTimer();\n    // reset forced auto level value so that next level will be selected\n    if (frag.level === this._nextAutoLevel) {\n      this._nextAutoLevel = -1;\n    }\n    this.firstSelection = -1;\n\n    // compute level average bitrate\n    if (this.hls.config.abrMaxWithRealBitrate) {\n      const duration = part ? part.duration : frag.duration;\n      const level = this.hls.levels[frag.level];\n      const loadedBytes = (level.loaded ? level.loaded.bytes : 0) + stats.loaded;\n      const loadedDuration = (level.loaded ? level.loaded.duration : 0) + duration;\n      level.loaded = {\n        bytes: loadedBytes,\n        duration: loadedDuration\n      };\n      level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);\n    }\n    if (frag.bitrateTest) {\n      const fragBufferedData = {\n        stats,\n        frag,\n        part,\n        id: frag.type\n      };\n      this.onFragBuffered(Events.FRAG_BUFFERED, fragBufferedData);\n      frag.bitrateTest = false;\n    } else {\n      // store level id after successful fragment load for playback\n      this.lastLoadedFragLevel = frag.level;\n    }\n  }\n  onFragBuffered(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    const stats = part != null && part.stats.loaded ? part.stats : frag.stats;\n    if (stats.aborted) {\n      return;\n    }\n    if (this.ignoreFragment(frag)) {\n      return;\n    }\n    // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;\n    // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch\n    // is used. If we used buffering in that case, our BW estimate sample will be very large.\n    const processingMs = stats.parsing.end - stats.loading.start - Math.min(stats.loading.first - stats.loading.start, this.bwEstimator.getEstimateTTFB());\n    this.bwEstimator.sample(processingMs, stats.loaded);\n    stats.bwEstimate = this.getBwEstimate();\n    if (frag.bitrateTest) {\n      this.bitrateTestDelay = processingMs / 1000;\n    } else {\n      this.bitrateTestDelay = 0;\n    }\n  }\n  ignoreFragment(frag) {\n    // Only count non-alt-audio frags which were actually buffered in our BW calculations\n    return frag.type !== PlaylistLevelType.MAIN || frag.sn === 'initSegment';\n  }\n  clearTimer() {\n    if (this.timer > -1) {\n      self.clearInterval(this.timer);\n      this.timer = -1;\n    }\n  }\n  get firstAutoLevel() {\n    const {\n      maxAutoLevel,\n      minAutoLevel\n    } = this.hls;\n    const bwEstimate = this.getBwEstimate();\n    const maxStartDelay = this.hls.config.maxStarvationDelay;\n    const abrAutoLevel = this.findBestLevel(bwEstimate, minAutoLevel, maxAutoLevel, 0, maxStartDelay, 1, 1);\n    if (abrAutoLevel > -1) {\n      return abrAutoLevel;\n    }\n    const firstLevel = this.hls.firstLevel;\n    const clamped = Math.min(Math.max(firstLevel, minAutoLevel), maxAutoLevel);\n    logger.warn(`[abr] Could not find best starting auto level. Defaulting to first in playlist ${firstLevel} clamped to ${clamped}`);\n    return clamped;\n  }\n  get forcedAutoLevel() {\n    if (this.nextAutoLevelKey) {\n      return -1;\n    }\n    return this._nextAutoLevel;\n  }\n\n  // return next auto level\n  get nextAutoLevel() {\n    const forcedAutoLevel = this.forcedAutoLevel;\n    const bwEstimator = this.bwEstimator;\n    const useEstimate = bwEstimator.canEstimate();\n    const loadedFirstFrag = this.lastLoadedFragLevel > -1;\n    // in case next auto level has been forced, and bw not available or not reliable, return forced value\n    if (forcedAutoLevel !== -1 && (!useEstimate || !loadedFirstFrag || this.nextAutoLevelKey === this.getAutoLevelKey())) {\n      return forcedAutoLevel;\n    }\n\n    // compute next level using ABR logic\n    const nextABRAutoLevel = useEstimate && loadedFirstFrag ? this.getNextABRAutoLevel() : this.firstAutoLevel;\n\n    // use forced auto level while it hasn't errored more than ABR selection\n    if (forcedAutoLevel !== -1) {\n      const levels = this.hls.levels;\n      if (levels.length > Math.max(forcedAutoLevel, nextABRAutoLevel) && levels[forcedAutoLevel].loadError <= levels[nextABRAutoLevel].loadError) {\n        return forcedAutoLevel;\n      }\n    }\n\n    // save result until state has changed\n    this._nextAutoLevel = nextABRAutoLevel;\n    this.nextAutoLevelKey = this.getAutoLevelKey();\n    return nextABRAutoLevel;\n  }\n  getAutoLevelKey() {\n    return `${this.getBwEstimate()}_${this.getStarvationDelay().toFixed(2)}`;\n  }\n  getNextABRAutoLevel() {\n    const {\n      fragCurrent,\n      partCurrent,\n      hls\n    } = this;\n    const {\n      maxAutoLevel,\n      config,\n      minAutoLevel\n    } = hls;\n    const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;\n    const avgbw = this.getBwEstimate();\n    // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.\n    const bufferStarvationDelay = this.getStarvationDelay();\n    let bwFactor = config.abrBandWidthFactor;\n    let bwUpFactor = config.abrBandWidthUpFactor;\n\n    // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all\n    if (bufferStarvationDelay) {\n      const _bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, 0, bwFactor, bwUpFactor);\n      if (_bestLevel >= 0) {\n        return _bestLevel;\n      }\n    }\n    // not possible to get rid of rebuffering... try to find level that will guarantee less than maxStarvationDelay of rebuffering\n    let maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;\n    if (!bufferStarvationDelay) {\n      // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test\n      const bitrateTestDelay = this.bitrateTestDelay;\n      if (bitrateTestDelay) {\n        // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value\n        // max video loading delay used in  automatic start level selection :\n        // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +\n        // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )\n        // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration\n        const maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;\n        maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;\n        logger.info(`[abr] bitrate test took ${Math.round(1000 * bitrateTestDelay)}ms, set first fragment max fetchDuration to ${Math.round(1000 * maxStarvationDelay)} ms`);\n        // don't use conservative factor on bitrate test\n        bwFactor = bwUpFactor = 1;\n      }\n    }\n    const bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor);\n    logger.info(`[abr] ${bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty'}, optimal quality level ${bestLevel}`);\n    if (bestLevel > -1) {\n      return bestLevel;\n    }\n    // If no matching level found, see if min auto level would be a better option\n    const minLevel = hls.levels[minAutoLevel];\n    const autoLevel = hls.levels[hls.loadLevel];\n    if ((minLevel == null ? void 0 : minLevel.bitrate) < (autoLevel == null ? void 0 : autoLevel.bitrate)) {\n      return minAutoLevel;\n    }\n    // or if bitrate is not lower, continue to use loadLevel\n    return hls.loadLevel;\n  }\n  getStarvationDelay() {\n    const hls = this.hls;\n    const media = hls.media;\n    if (!media) {\n      return Infinity;\n    }\n    // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as\n    // if we're playing back at the normal rate.\n    const playbackRate = media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;\n    const bufferInfo = hls.mainForwardBufferInfo;\n    return (bufferInfo ? bufferInfo.len : 0) / playbackRate;\n  }\n  getBwEstimate() {\n    return this.bwEstimator.canEstimate() ? this.bwEstimator.getEstimate() : this.hls.config.abrEwmaDefaultEstimate;\n  }\n  findBestLevel(currentBw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor) {\n    var _level$details;\n    const maxFetchDuration = bufferStarvationDelay + maxStarvationDelay;\n    const lastLoadedFragLevel = this.lastLoadedFragLevel;\n    const selectionBaseLevel = lastLoadedFragLevel === -1 ? this.hls.firstLevel : lastLoadedFragLevel;\n    const {\n      fragCurrent,\n      partCurrent\n    } = this;\n    const {\n      levels,\n      allAudioTracks,\n      loadLevel,\n      config\n    } = this.hls;\n    if (levels.length === 1) {\n      return 0;\n    }\n    const level = levels[selectionBaseLevel];\n    const live = !!(level != null && (_level$details = level.details) != null && _level$details.live);\n    const firstSelection = loadLevel === -1 || lastLoadedFragLevel === -1;\n    let currentCodecSet;\n    let currentVideoRange = 'SDR';\n    let currentFrameRate = (level == null ? void 0 : level.frameRate) || 0;\n    const {\n      audioPreference,\n      videoPreference\n    } = config;\n    const audioTracksByGroup = this.audioTracksByGroup || (this.audioTracksByGroup = getAudioTracksByGroup(allAudioTracks));\n    if (firstSelection) {\n      if (this.firstSelection !== -1) {\n        return this.firstSelection;\n      }\n      const codecTiers = this.codecTiers || (this.codecTiers = getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel));\n      const startTier = getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference);\n      const {\n        codecSet,\n        videoRanges,\n        minFramerate,\n        minBitrate,\n        preferHDR\n      } = startTier;\n      currentCodecSet = codecSet;\n      currentVideoRange = preferHDR ? videoRanges[videoRanges.length - 1] : videoRanges[0];\n      currentFrameRate = minFramerate;\n      currentBw = Math.max(currentBw, minBitrate);\n      logger.log(`[abr] picked start tier ${JSON.stringify(startTier)}`);\n    } else {\n      currentCodecSet = level == null ? void 0 : level.codecSet;\n      currentVideoRange = level == null ? void 0 : level.videoRange;\n    }\n    const currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;\n    const ttfbEstimateSec = this.bwEstimator.getEstimateTTFB() / 1000;\n    const levelsSkipped = [];\n    for (let i = maxAutoLevel; i >= minAutoLevel; i--) {\n      var _levelInfo$supportedR;\n      const levelInfo = levels[i];\n      const upSwitch = i > selectionBaseLevel;\n      if (!levelInfo) {\n        continue;\n      }\n      if (config.useMediaCapabilities && !levelInfo.supportedResult && !levelInfo.supportedPromise) {\n        const mediaCapabilities = navigator.mediaCapabilities;\n        if (typeof (mediaCapabilities == null ? void 0 : mediaCapabilities.decodingInfo) === 'function' && requiresMediaCapabilitiesDecodingInfo(levelInfo, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference)) {\n          levelInfo.supportedPromise = getMediaDecodingInfoPromise(levelInfo, audioTracksByGroup, mediaCapabilities);\n          levelInfo.supportedPromise.then(decodingInfo => {\n            if (!this.hls) {\n              return;\n            }\n            levelInfo.supportedResult = decodingInfo;\n            const levels = this.hls.levels;\n            const index = levels.indexOf(levelInfo);\n            if (decodingInfo.error) {\n              logger.warn(`[abr] MediaCapabilities decodingInfo error: \"${decodingInfo.error}\" for level ${index} ${JSON.stringify(decodingInfo)}`);\n            } else if (!decodingInfo.supported) {\n              logger.warn(`[abr] Unsupported MediaCapabilities decodingInfo result for level ${index} ${JSON.stringify(decodingInfo)}`);\n              if (index > -1 && levels.length > 1) {\n                logger.log(`[abr] Removing unsupported level ${index}`);\n                this.hls.removeLevel(index);\n              }\n            }\n          });\n        } else {\n          levelInfo.supportedResult = SUPPORTED_INFO_DEFAULT;\n        }\n      }\n\n      // skip candidates which change codec-family or video-range,\n      // and which decrease or increase frame-rate for up and down-switch respectfully\n      if (currentCodecSet && levelInfo.codecSet !== currentCodecSet || currentVideoRange && levelInfo.videoRange !== currentVideoRange || upSwitch && currentFrameRate > levelInfo.frameRate || !upSwitch && currentFrameRate > 0 && currentFrameRate < levelInfo.frameRate || levelInfo.supportedResult && !((_levelInfo$supportedR = levelInfo.supportedResult.decodingInfoResults) != null && _levelInfo$supportedR[0].smooth)) {\n        levelsSkipped.push(i);\n        continue;\n      }\n      const levelDetails = levelInfo.details;\n      const avgDuration = (partCurrent ? levelDetails == null ? void 0 : levelDetails.partTarget : levelDetails == null ? void 0 : levelDetails.averagetargetduration) || currentFragDuration;\n      let adjustedbw;\n      // follow algorithm captured from stagefright :\n      // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp\n      // Pick the highest bandwidth stream below or equal to estimated bandwidth.\n      // consider only 80% of the available bandwidth, but if we are switching up,\n      // be even more conservative (70%) to avoid overestimating and immediately\n      // switching back.\n      if (!upSwitch) {\n        adjustedbw = bwFactor * currentBw;\n      } else {\n        adjustedbw = bwUpFactor * currentBw;\n      }\n\n      // Use average bitrate when starvation delay (buffer length) is gt or eq two segment durations and rebuffering is not expected (maxStarvationDelay > 0)\n      const bitrate = currentFragDuration && bufferStarvationDelay >= currentFragDuration * 2 && maxStarvationDelay === 0 ? levels[i].averageBitrate : levels[i].maxBitrate;\n      const fetchDuration = this.getTimeToLoadFrag(ttfbEstimateSec, adjustedbw, bitrate * avgDuration, levelDetails === undefined);\n      const canSwitchWithinTolerance =\n      // if adjusted bw is greater than level bitrate AND\n      adjustedbw >= bitrate && (\n      // no level change, or new level has no error history\n      i === lastLoadedFragLevel || levelInfo.loadError === 0 && levelInfo.fragmentError === 0) && (\n      // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches\n      // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...\n      // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1\n      fetchDuration <= ttfbEstimateSec || !isFiniteNumber(fetchDuration) || live && !this.bitrateTestDelay || fetchDuration < maxFetchDuration);\n      if (canSwitchWithinTolerance) {\n        const forcedAutoLevel = this.forcedAutoLevel;\n        if (i !== loadLevel && (forcedAutoLevel === -1 || forcedAutoLevel !== loadLevel)) {\n          if (levelsSkipped.length) {\n            logger.trace(`[abr] Skipped level(s) ${levelsSkipped.join(',')} of ${maxAutoLevel} max with CODECS and VIDEO-RANGE:\"${levels[levelsSkipped[0]].codecs}\" ${levels[levelsSkipped[0]].videoRange}; not compatible with \"${level.codecs}\" ${currentVideoRange}`);\n          }\n          logger.info(`[abr] switch candidate:${selectionBaseLevel}->${i} adjustedbw(${Math.round(adjustedbw)})-bitrate=${Math.round(adjustedbw - bitrate)} ttfb:${ttfbEstimateSec.toFixed(1)} avgDuration:${avgDuration.toFixed(1)} maxFetchDuration:${maxFetchDuration.toFixed(1)} fetchDuration:${fetchDuration.toFixed(1)} firstSelection:${firstSelection} codecSet:${currentCodecSet} videoRange:${currentVideoRange} hls.loadLevel:${loadLevel}`);\n        }\n        if (firstSelection) {\n          this.firstSelection = i;\n        }\n        // as we are looping from highest to lowest, this will return the best achievable quality level\n        return i;\n      }\n    }\n    // not enough time budget even with quality level 0 ... rebuffering might happen\n    return -1;\n  }\n  set nextAutoLevel(nextLevel) {\n    const {\n      maxAutoLevel,\n      minAutoLevel\n    } = this.hls;\n    const value = Math.min(Math.max(nextLevel, minAutoLevel), maxAutoLevel);\n    if (this._nextAutoLevel !== value) {\n      this.nextAutoLevelKey = '';\n      this._nextAutoLevel = value;\n    }\n  }\n}\n\n/**\n * @ignore\n * Sub-class specialization of EventHandler base class.\n *\n * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,\n * scheduled asynchroneously, avoiding recursive calls in the same tick.\n *\n * The task itself is implemented in `doTick`. It can be requested and called for single execution\n * using the `tick` method.\n *\n * It will be assured that the task execution method (`tick`) only gets called once per main loop \"tick\",\n * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.\n *\n * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,\n * and cancelled with `clearNextTick`.\n *\n * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).\n *\n * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.\n *\n * Further explanations:\n *\n * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously\n * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.\n *\n * When the task execution (`tick` method) is called in re-entrant way this is detected and\n * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further\n * task processing on the next main loop iteration (also known as \"next tick\" in the Node/JS runtime lingo).\n */\nclass TaskLoop {\n  constructor() {\n    this._boundTick = void 0;\n    this._tickTimer = null;\n    this._tickInterval = null;\n    this._tickCallCount = 0;\n    this._boundTick = this.tick.bind(this);\n  }\n  destroy() {\n    this.onHandlerDestroying();\n    this.onHandlerDestroyed();\n  }\n  onHandlerDestroying() {\n    // clear all timers before unregistering from event bus\n    this.clearNextTick();\n    this.clearInterval();\n  }\n  onHandlerDestroyed() {}\n  hasInterval() {\n    return !!this._tickInterval;\n  }\n  hasNextTick() {\n    return !!this._tickTimer;\n  }\n\n  /**\n   * @param millis - Interval time (ms)\n   * @eturns True when interval has been scheduled, false when already scheduled (no effect)\n   */\n  setInterval(millis) {\n    if (!this._tickInterval) {\n      this._tickCallCount = 0;\n      this._tickInterval = self.setInterval(this._boundTick, millis);\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * @returns True when interval was cleared, false when none was set (no effect)\n   */\n  clearInterval() {\n    if (this._tickInterval) {\n      self.clearInterval(this._tickInterval);\n      this._tickInterval = null;\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * @returns True when timeout was cleared, false when none was set (no effect)\n   */\n  clearNextTick() {\n    if (this._tickTimer) {\n      self.clearTimeout(this._tickTimer);\n      this._tickTimer = null;\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Will call the subclass doTick implementation in this main loop tick\n   * or in the next one (via setTimeout(,0)) in case it has already been called\n   * in this tick (in case this is a re-entrant call).\n   */\n  tick() {\n    this._tickCallCount++;\n    if (this._tickCallCount === 1) {\n      this.doTick();\n      // re-entrant call to tick from previous doTick call stack\n      // -> schedule a call on the next main loop iteration to process this task processing request\n      if (this._tickCallCount > 1) {\n        // make sure only one timer exists at any time at max\n        this.tickImmediate();\n      }\n      this._tickCallCount = 0;\n    }\n  }\n  tickImmediate() {\n    this.clearNextTick();\n    this._tickTimer = self.setTimeout(this._boundTick, 0);\n  }\n\n  /**\n   * For subclass to implement task logic\n   * @abstract\n   */\n  doTick() {}\n}\n\nvar FragmentState = {\n  NOT_LOADED: \"NOT_LOADED\",\n  APPENDING: \"APPENDING\",\n  PARTIAL: \"PARTIAL\",\n  OK: \"OK\"\n};\nclass FragmentTracker {\n  constructor(hls) {\n    this.activePartLists = Object.create(null);\n    this.endListFragments = Object.create(null);\n    this.fragments = Object.create(null);\n    this.timeRanges = Object.create(null);\n    this.bufferPadding = 0.2;\n    this.hls = void 0;\n    this.hasGaps = false;\n    this.hls = hls;\n    this._registerListeners();\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n  }\n  destroy() {\n    this._unregisterListeners();\n    // @ts-ignore\n    this.fragments =\n    // @ts-ignore\n    this.activePartLists =\n    // @ts-ignore\n    this.endListFragments = this.timeRanges = null;\n  }\n\n  /**\n   * Return a Fragment or Part with an appended range that matches the position and levelType\n   * Otherwise, return null\n   */\n  getAppendedFrag(position, levelType) {\n    const activeParts = this.activePartLists[levelType];\n    if (activeParts) {\n      for (let i = activeParts.length; i--;) {\n        const activePart = activeParts[i];\n        if (!activePart) {\n          break;\n        }\n        const appendedPTS = activePart.end;\n        if (activePart.start <= position && appendedPTS !== null && position <= appendedPTS) {\n          return activePart;\n        }\n      }\n    }\n    return this.getBufferedFrag(position, levelType);\n  }\n\n  /**\n   * Return a buffered Fragment that matches the position and levelType.\n   * A buffered Fragment is one whose loading, parsing and appending is done (completed or \"partial\" meaning aborted).\n   * If not found any Fragment, return null\n   */\n  getBufferedFrag(position, levelType) {\n    const {\n      fragments\n    } = this;\n    const keys = Object.keys(fragments);\n    for (let i = keys.length; i--;) {\n      const fragmentEntity = fragments[keys[i]];\n      if ((fragmentEntity == null ? void 0 : fragmentEntity.body.type) === levelType && fragmentEntity.buffered) {\n        const frag = fragmentEntity.body;\n        if (frag.start <= position && position <= frag.end) {\n          return frag;\n        }\n      }\n    }\n    return null;\n  }\n\n  /**\n   * Partial fragments effected by coded frame eviction will be removed\n   * The browser will unload parts of the buffer to free up memory for new buffer data\n   * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)\n   */\n  detectEvictedFragments(elementaryStream, timeRange, playlistType, appendedPart) {\n    if (this.timeRanges) {\n      this.timeRanges[elementaryStream] = timeRange;\n    }\n    // Check if any flagged fragments have been unloaded\n    // excluding anything newer than appendedPartSn\n    const appendedPartSn = (appendedPart == null ? void 0 : appendedPart.fragment.sn) || -1;\n    Object.keys(this.fragments).forEach(key => {\n      const fragmentEntity = this.fragments[key];\n      if (!fragmentEntity) {\n        return;\n      }\n      if (appendedPartSn >= fragmentEntity.body.sn) {\n        return;\n      }\n      if (!fragmentEntity.buffered && !fragmentEntity.loaded) {\n        if (fragmentEntity.body.type === playlistType) {\n          this.removeFragment(fragmentEntity.body);\n        }\n        return;\n      }\n      const esData = fragmentEntity.range[elementaryStream];\n      if (!esData) {\n        return;\n      }\n      esData.time.some(time => {\n        const isNotBuffered = !this.isTimeBuffered(time.startPTS, time.endPTS, timeRange);\n        if (isNotBuffered) {\n          // Unregister partial fragment as it needs to load again to be reused\n          this.removeFragment(fragmentEntity.body);\n        }\n        return isNotBuffered;\n      });\n    });\n  }\n\n  /**\n   * Checks if the fragment passed in is loaded in the buffer properly\n   * Partially loaded fragments will be registered as a partial fragment\n   */\n  detectPartialFragments(data) {\n    const timeRanges = this.timeRanges;\n    const {\n      frag,\n      part\n    } = data;\n    if (!timeRanges || frag.sn === 'initSegment') {\n      return;\n    }\n    const fragKey = getFragmentKey(frag);\n    const fragmentEntity = this.fragments[fragKey];\n    if (!fragmentEntity || fragmentEntity.buffered && frag.gap) {\n      return;\n    }\n    const isFragHint = !frag.relurl;\n    Object.keys(timeRanges).forEach(elementaryStream => {\n      const streamInfo = frag.elementaryStreams[elementaryStream];\n      if (!streamInfo) {\n        return;\n      }\n      const timeRange = timeRanges[elementaryStream];\n      const partial = isFragHint || streamInfo.partial === true;\n      fragmentEntity.range[elementaryStream] = this.getBufferedTimes(frag, part, partial, timeRange);\n    });\n    fragmentEntity.loaded = null;\n    if (Object.keys(fragmentEntity.range).length) {\n      fragmentEntity.buffered = true;\n      const endList = fragmentEntity.body.endList = frag.endList || fragmentEntity.body.endList;\n      if (endList) {\n        this.endListFragments[fragmentEntity.body.type] = fragmentEntity;\n      }\n      if (!isPartial(fragmentEntity)) {\n        // Remove older fragment parts from lookup after frag is tracked as buffered\n        this.removeParts(frag.sn - 1, frag.type);\n      }\n    } else {\n      // remove fragment if nothing was appended\n      this.removeFragment(fragmentEntity.body);\n    }\n  }\n  removeParts(snToKeep, levelType) {\n    const activeParts = this.activePartLists[levelType];\n    if (!activeParts) {\n      return;\n    }\n    this.activePartLists[levelType] = activeParts.filter(part => part.fragment.sn >= snToKeep);\n  }\n  fragBuffered(frag, force) {\n    const fragKey = getFragmentKey(frag);\n    let fragmentEntity = this.fragments[fragKey];\n    if (!fragmentEntity && force) {\n      fragmentEntity = this.fragments[fragKey] = {\n        body: frag,\n        appendedPTS: null,\n        loaded: null,\n        buffered: false,\n        range: Object.create(null)\n      };\n      if (frag.gap) {\n        this.hasGaps = true;\n      }\n    }\n    if (fragmentEntity) {\n      fragmentEntity.loaded = null;\n      fragmentEntity.buffered = true;\n    }\n  }\n  getBufferedTimes(fragment, part, partial, timeRange) {\n    const buffered = {\n      time: [],\n      partial\n    };\n    const startPTS = fragment.start;\n    const endPTS = fragment.end;\n    const minEndPTS = fragment.minEndPTS || endPTS;\n    const maxStartPTS = fragment.maxStartPTS || startPTS;\n    for (let i = 0; i < timeRange.length; i++) {\n      const startTime = timeRange.start(i) - this.bufferPadding;\n      const endTime = timeRange.end(i) + this.bufferPadding;\n      if (maxStartPTS >= startTime && minEndPTS <= endTime) {\n        // Fragment is entirely contained in buffer\n        // No need to check the other timeRange times since it's completely playable\n        buffered.time.push({\n          startPTS: Math.max(startPTS, timeRange.start(i)),\n          endPTS: Math.min(endPTS, timeRange.end(i))\n        });\n        break;\n      } else if (startPTS < endTime && endPTS > startTime) {\n        const start = Math.max(startPTS, timeRange.start(i));\n        const end = Math.min(endPTS, timeRange.end(i));\n        if (end > start) {\n          buffered.partial = true;\n          // Check for intersection with buffer\n          // Get playable sections of the fragment\n          buffered.time.push({\n            startPTS: start,\n            endPTS: end\n          });\n        }\n      } else if (endPTS <= startTime) {\n        // No need to check the rest of the timeRange as it is in order\n        break;\n      }\n    }\n    return buffered;\n  }\n\n  /**\n   * Gets the partial fragment for a certain time\n   */\n  getPartialFragment(time) {\n    let bestFragment = null;\n    let timePadding;\n    let startTime;\n    let endTime;\n    let bestOverlap = 0;\n    const {\n      bufferPadding,\n      fragments\n    } = this;\n    Object.keys(fragments).forEach(key => {\n      const fragmentEntity = fragments[key];\n      if (!fragmentEntity) {\n        return;\n      }\n      if (isPartial(fragmentEntity)) {\n        startTime = fragmentEntity.body.start - bufferPadding;\n        endTime = fragmentEntity.body.end + bufferPadding;\n        if (time >= startTime && time <= endTime) {\n          // Use the fragment that has the most padding from start and end time\n          timePadding = Math.min(time - startTime, endTime - time);\n          if (bestOverlap <= timePadding) {\n            bestFragment = fragmentEntity.body;\n            bestOverlap = timePadding;\n          }\n        }\n      }\n    });\n    return bestFragment;\n  }\n  isEndListAppended(type) {\n    const lastFragmentEntity = this.endListFragments[type];\n    return lastFragmentEntity !== undefined && (lastFragmentEntity.buffered || isPartial(lastFragmentEntity));\n  }\n  getState(fragment) {\n    const fragKey = getFragmentKey(fragment);\n    const fragmentEntity = this.fragments[fragKey];\n    if (fragmentEntity) {\n      if (!fragmentEntity.buffered) {\n        return FragmentState.APPENDING;\n      } else if (isPartial(fragmentEntity)) {\n        return FragmentState.PARTIAL;\n      } else {\n        return FragmentState.OK;\n      }\n    }\n    return FragmentState.NOT_LOADED;\n  }\n  isTimeBuffered(startPTS, endPTS, timeRange) {\n    let startTime;\n    let endTime;\n    for (let i = 0; i < timeRange.length; i++) {\n      startTime = timeRange.start(i) - this.bufferPadding;\n      endTime = timeRange.end(i) + this.bufferPadding;\n      if (startPTS >= startTime && endPTS <= endTime) {\n        return true;\n      }\n      if (endPTS <= startTime) {\n        // No need to check the rest of the timeRange as it is in order\n        return false;\n      }\n    }\n    return false;\n  }\n  onFragLoaded(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    // don't track initsegment (for which sn is not a number)\n    // don't track frags used for bitrateTest, they're irrelevant.\n    if (frag.sn === 'initSegment' || frag.bitrateTest) {\n      return;\n    }\n\n    // Fragment entity `loaded` FragLoadedData is null when loading parts\n    const loaded = part ? null : data;\n    const fragKey = getFragmentKey(frag);\n    this.fragments[fragKey] = {\n      body: frag,\n      appendedPTS: null,\n      loaded,\n      buffered: false,\n      range: Object.create(null)\n    };\n  }\n  onBufferAppended(event, data) {\n    const {\n      frag,\n      part,\n      timeRanges\n    } = data;\n    if (frag.sn === 'initSegment') {\n      return;\n    }\n    const playlistType = frag.type;\n    if (part) {\n      let activeParts = this.activePartLists[playlistType];\n      if (!activeParts) {\n        this.activePartLists[playlistType] = activeParts = [];\n      }\n      activeParts.push(part);\n    }\n    // Store the latest timeRanges loaded in the buffer\n    this.timeRanges = timeRanges;\n    Object.keys(timeRanges).forEach(elementaryStream => {\n      const timeRange = timeRanges[elementaryStream];\n      this.detectEvictedFragments(elementaryStream, timeRange, playlistType, part);\n    });\n  }\n  onFragBuffered(event, data) {\n    this.detectPartialFragments(data);\n  }\n  hasFragment(fragment) {\n    const fragKey = getFragmentKey(fragment);\n    return !!this.fragments[fragKey];\n  }\n  hasParts(type) {\n    var _this$activePartLists;\n    return !!((_this$activePartLists = this.activePartLists[type]) != null && _this$activePartLists.length);\n  }\n  removeFragmentsInRange(start, end, playlistType, withGapOnly, unbufferedOnly) {\n    if (withGapOnly && !this.hasGaps) {\n      return;\n    }\n    Object.keys(this.fragments).forEach(key => {\n      const fragmentEntity = this.fragments[key];\n      if (!fragmentEntity) {\n        return;\n      }\n      const frag = fragmentEntity.body;\n      if (frag.type !== playlistType || withGapOnly && !frag.gap) {\n        return;\n      }\n      if (frag.start < end && frag.end > start && (fragmentEntity.buffered || unbufferedOnly)) {\n        this.removeFragment(frag);\n      }\n    });\n  }\n  removeFragment(fragment) {\n    const fragKey = getFragmentKey(fragment);\n    fragment.stats.loaded = 0;\n    fragment.clearElementaryStreamInfo();\n    const activeParts = this.activePartLists[fragment.type];\n    if (activeParts) {\n      const snToRemove = fragment.sn;\n      this.activePartLists[fragment.type] = activeParts.filter(part => part.fragment.sn !== snToRemove);\n    }\n    delete this.fragments[fragKey];\n    if (fragment.endList) {\n      delete this.endListFragments[fragment.type];\n    }\n  }\n  removeAllFragments() {\n    this.fragments = Object.create(null);\n    this.endListFragments = Object.create(null);\n    this.activePartLists = Object.create(null);\n    this.hasGaps = false;\n  }\n}\nfunction isPartial(fragmentEntity) {\n  var _fragmentEntity$range, _fragmentEntity$range2, _fragmentEntity$range3;\n  return fragmentEntity.buffered && (fragmentEntity.body.gap || ((_fragmentEntity$range = fragmentEntity.range.video) == null ? void 0 : _fragmentEntity$range.partial) || ((_fragmentEntity$range2 = fragmentEntity.range.audio) == null ? void 0 : _fragmentEntity$range2.partial) || ((_fragmentEntity$range3 = fragmentEntity.range.audiovideo) == null ? void 0 : _fragmentEntity$range3.partial));\n}\nfunction getFragmentKey(fragment) {\n  return `${fragment.type}_${fragment.level}_${fragment.sn}`;\n}\n\n/**\n * Provides methods dealing with buffer length retrieval for example.\n *\n * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.\n *\n * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered\n */\n\nconst noopBuffered = {\n  length: 0,\n  start: () => 0,\n  end: () => 0\n};\nclass BufferHelper {\n  /**\n   * Return true if `media`'s buffered include `position`\n   */\n  static isBuffered(media, position) {\n    try {\n      if (media) {\n        const buffered = BufferHelper.getBuffered(media);\n        for (let i = 0; i < buffered.length; i++) {\n          if (position >= buffered.start(i) && position <= buffered.end(i)) {\n            return true;\n          }\n        }\n      }\n    } catch (error) {\n      // this is to catch\n      // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\n      // This SourceBuffer has been removed from the parent media source\n    }\n    return false;\n  }\n  static bufferInfo(media, pos, maxHoleDuration) {\n    try {\n      if (media) {\n        const vbuffered = BufferHelper.getBuffered(media);\n        const buffered = [];\n        let i;\n        for (i = 0; i < vbuffered.length; i++) {\n          buffered.push({\n            start: vbuffered.start(i),\n            end: vbuffered.end(i)\n          });\n        }\n        return this.bufferedInfo(buffered, pos, maxHoleDuration);\n      }\n    } catch (error) {\n      // this is to catch\n      // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\n      // This SourceBuffer has been removed from the parent media source\n    }\n    return {\n      len: 0,\n      start: pos,\n      end: pos,\n      nextStart: undefined\n    };\n  }\n  static bufferedInfo(buffered, pos, maxHoleDuration) {\n    pos = Math.max(0, pos);\n    // sort on buffer.start/smaller end (IE does not always return sorted buffered range)\n    buffered.sort(function (a, b) {\n      const diff = a.start - b.start;\n      if (diff) {\n        return diff;\n      } else {\n        return b.end - a.end;\n      }\n    });\n    let buffered2 = [];\n    if (maxHoleDuration) {\n      // there might be some small holes between buffer time range\n      // consider that holes smaller than maxHoleDuration are irrelevant and build another\n      // buffer time range representations that discards those holes\n      for (let i = 0; i < buffered.length; i++) {\n        const buf2len = buffered2.length;\n        if (buf2len) {\n          const buf2end = buffered2[buf2len - 1].end;\n          // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)\n          if (buffered[i].start - buf2end < maxHoleDuration) {\n            // merge overlapping time ranges\n            // update lastRange.end only if smaller than item.end\n            // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)\n            // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])\n            if (buffered[i].end > buf2end) {\n              buffered2[buf2len - 1].end = buffered[i].end;\n            }\n          } else {\n            // big hole\n            buffered2.push(buffered[i]);\n          }\n        } else {\n          // first value\n          buffered2.push(buffered[i]);\n        }\n      }\n    } else {\n      buffered2 = buffered;\n    }\n    let bufferLen = 0;\n\n    // bufferStartNext can possibly be undefined based on the conditional logic below\n    let bufferStartNext;\n\n    // bufferStart and bufferEnd are buffer boundaries around current video position\n    let bufferStart = pos;\n    let bufferEnd = pos;\n    for (let i = 0; i < buffered2.length; i++) {\n      const start = buffered2[i].start;\n      const end = buffered2[i].end;\n      // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));\n      if (pos + maxHoleDuration >= start && pos < end) {\n        // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length\n        bufferStart = start;\n        bufferEnd = end;\n        bufferLen = bufferEnd - pos;\n      } else if (pos + maxHoleDuration < start) {\n        bufferStartNext = start;\n        break;\n      }\n    }\n    return {\n      len: bufferLen,\n      start: bufferStart || 0,\n      end: bufferEnd || 0,\n      nextStart: bufferStartNext\n    };\n  }\n\n  /**\n   * Safe method to get buffered property.\n   * SourceBuffer.buffered may throw if SourceBuffer is removed from it's MediaSource\n   */\n  static getBuffered(media) {\n    try {\n      return media.buffered;\n    } catch (e) {\n      logger.log('failed to get media.buffered', e);\n      return noopBuffered;\n    }\n  }\n}\n\nclass ChunkMetadata {\n  constructor(level, sn, id, size = 0, part = -1, partial = false) {\n    this.level = void 0;\n    this.sn = void 0;\n    this.part = void 0;\n    this.id = void 0;\n    this.size = void 0;\n    this.partial = void 0;\n    this.transmuxing = getNewPerformanceTiming();\n    this.buffering = {\n      audio: getNewPerformanceTiming(),\n      video: getNewPerformanceTiming(),\n      audiovideo: getNewPerformanceTiming()\n    };\n    this.level = level;\n    this.sn = sn;\n    this.id = id;\n    this.size = size;\n    this.part = part;\n    this.partial = partial;\n  }\n}\nfunction getNewPerformanceTiming() {\n  return {\n    start: 0,\n    executeStart: 0,\n    executeEnd: 0,\n    end: 0\n  };\n}\n\nfunction findFirstFragWithCC(fragments, cc) {\n  for (let i = 0, len = fragments.length; i < len; i++) {\n    var _fragments$i;\n    if (((_fragments$i = fragments[i]) == null ? void 0 : _fragments$i.cc) === cc) {\n      return fragments[i];\n    }\n  }\n  return null;\n}\nfunction shouldAlignOnDiscontinuities(lastFrag, switchDetails, details) {\n  if (switchDetails) {\n    if (details.endCC > details.startCC || lastFrag && lastFrag.cc < details.startCC) {\n      return true;\n    }\n  }\n  return false;\n}\n\n// Find the first frag in the previous level which matches the CC of the first frag of the new level\nfunction findDiscontinuousReferenceFrag(prevDetails, curDetails) {\n  const prevFrags = prevDetails.fragments;\n  const curFrags = curDetails.fragments;\n  if (!curFrags.length || !prevFrags.length) {\n    logger.log('No fragments to align');\n    return;\n  }\n  const prevStartFrag = findFirstFragWithCC(prevFrags, curFrags[0].cc);\n  if (!prevStartFrag || prevStartFrag && !prevStartFrag.startPTS) {\n    logger.log('No frag in previous level to align on');\n    return;\n  }\n  return prevStartFrag;\n}\nfunction adjustFragmentStart(frag, sliding) {\n  if (frag) {\n    const start = frag.start + sliding;\n    frag.start = frag.startPTS = start;\n    frag.endPTS = start + frag.duration;\n  }\n}\nfunction adjustSlidingStart(sliding, details) {\n  // Update segments\n  const fragments = details.fragments;\n  for (let i = 0, len = fragments.length; i < len; i++) {\n    adjustFragmentStart(fragments[i], sliding);\n  }\n  // Update LL-HLS parts at the end of the playlist\n  if (details.fragmentHint) {\n    adjustFragmentStart(details.fragmentHint, sliding);\n  }\n  details.alignedSliding = true;\n}\n\n/**\n * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a\n * contiguous stream with the last fragments.\n * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to\n * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time\n * and an extra download.\n * @param lastFrag\n * @param lastLevel\n * @param details\n */\nfunction alignStream(lastFrag, switchDetails, details) {\n  if (!switchDetails) {\n    return;\n  }\n  alignDiscontinuities(lastFrag, details, switchDetails);\n  if (!details.alignedSliding && switchDetails) {\n    // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.\n    // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same\n    // discontinuity sequence.\n    alignMediaPlaylistByPDT(details, switchDetails);\n  }\n  if (!details.alignedSliding && switchDetails && !details.skippedSegments) {\n    // Try to align on sn so that we pick a better start fragment.\n    // Do not perform this on playlists with delta updates as this is only to align levels on switch\n    // and adjustSliding only adjusts fragments after skippedSegments.\n    adjustSliding(switchDetails, details);\n  }\n}\n\n/**\n * Computes the PTS if a new level's fragments using the PTS of a fragment in the last level which shares the same\n * discontinuity sequence.\n * @param lastFrag - The last Fragment which shares the same discontinuity sequence\n * @param lastLevel - The details of the last loaded level\n * @param details - The details of the new level\n */\nfunction alignDiscontinuities(lastFrag, details, switchDetails) {\n  if (shouldAlignOnDiscontinuities(lastFrag, switchDetails, details)) {\n    const referenceFrag = findDiscontinuousReferenceFrag(switchDetails, details);\n    if (referenceFrag && isFiniteNumber(referenceFrag.start)) {\n      logger.log(`Adjusting PTS using last level due to CC increase within current level ${details.url}`);\n      adjustSlidingStart(referenceFrag.start, details);\n    }\n  }\n}\n\n/**\n * Ensures appropriate time-alignment between renditions based on PDT.\n * This function assumes the timelines represented in `refDetails` are accurate, including the PDTs\n * for the last discontinuity sequence number shared by both playlists when present,\n * and uses the \"wallclock\"/PDT timeline as a cross-reference to `details`, adjusting the presentation\n * times/timelines of `details` accordingly.\n * Given the asynchronous nature of fetches and initial loads of live `main` and audio/subtitle tracks,\n * the primary purpose of this function is to ensure the \"local timelines\" of audio/subtitle tracks\n * are aligned to the main/video timeline, using PDT as the cross-reference/\"anchor\" that should\n * be consistent across playlists, per the HLS spec.\n * @param details - The details of the rendition you'd like to time-align (e.g. an audio rendition).\n * @param refDetails - The details of the reference rendition with start and PDT times for alignment.\n */\nfunction alignMediaPlaylistByPDT(details, refDetails) {\n  if (!details.hasProgramDateTime || !refDetails.hasProgramDateTime) {\n    return;\n  }\n  const fragments = details.fragments;\n  const refFragments = refDetails.fragments;\n  if (!fragments.length || !refFragments.length) {\n    return;\n  }\n\n  // Calculate a delta to apply to all fragments according to the delta in PDT times and start times\n  // of a fragment in the reference details, and a fragment in the target details of the same discontinuity.\n  // If a fragment of the same discontinuity was not found use the middle fragment of both.\n  let refFrag;\n  let frag;\n  const targetCC = Math.min(refDetails.endCC, details.endCC);\n  if (refDetails.startCC < targetCC && details.startCC < targetCC) {\n    refFrag = findFirstFragWithCC(refFragments, targetCC);\n    frag = findFirstFragWithCC(fragments, targetCC);\n  }\n  if (!refFrag || !frag) {\n    refFrag = refFragments[Math.floor(refFragments.length / 2)];\n    frag = findFirstFragWithCC(fragments, refFrag.cc) || fragments[Math.floor(fragments.length / 2)];\n  }\n  const refPDT = refFrag.programDateTime;\n  const targetPDT = frag.programDateTime;\n  if (!refPDT || !targetPDT) {\n    return;\n  }\n  const delta = (targetPDT - refPDT) / 1000 - (frag.start - refFrag.start);\n  adjustSlidingStart(delta, details);\n}\n\nconst MIN_CHUNK_SIZE = Math.pow(2, 17); // 128kb\n\nclass FragmentLoader {\n  constructor(config) {\n    this.config = void 0;\n    this.loader = null;\n    this.partLoadTimeout = -1;\n    this.config = config;\n  }\n  destroy() {\n    if (this.loader) {\n      this.loader.destroy();\n      this.loader = null;\n    }\n  }\n  abort() {\n    if (this.loader) {\n      // Abort the loader for current fragment. Only one may load at any given time\n      this.loader.abort();\n    }\n  }\n  load(frag, onProgress) {\n    const url = frag.url;\n    if (!url) {\n      return Promise.reject(new LoadError({\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.FRAG_LOAD_ERROR,\n        fatal: false,\n        frag,\n        error: new Error(`Fragment does not have a ${url ? 'part list' : 'url'}`),\n        networkDetails: null\n      }));\n    }\n    this.abort();\n    const config = this.config;\n    const FragmentILoader = config.fLoader;\n    const DefaultILoader = config.loader;\n    return new Promise((resolve, reject) => {\n      if (this.loader) {\n        this.loader.destroy();\n      }\n      if (frag.gap) {\n        if (frag.tagList.some(tags => tags[0] === 'GAP')) {\n          reject(createGapLoadError(frag));\n          return;\n        } else {\n          // Reset temporary treatment as GAP tag\n          frag.gap = false;\n        }\n      }\n      const loader = this.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);\n      const loaderContext = createLoaderContext(frag);\n      const loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0,\n        highWaterMark: frag.sn === 'initSegment' ? Infinity : MIN_CHUNK_SIZE\n      };\n      // Assign frag stats to the loader's stats reference\n      frag.stats = loader.stats;\n      loader.load(loaderContext, loaderConfig, {\n        onSuccess: (response, stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          let payload = response.data;\n          if (context.resetIV && frag.decryptdata) {\n            frag.decryptdata.iv = new Uint8Array(payload.slice(0, 16));\n            payload = payload.slice(16);\n          }\n          resolve({\n            frag,\n            part: null,\n            payload,\n            networkDetails\n          });\n        },\n        onError: (response, context, networkDetails, stats) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_ERROR,\n            fatal: false,\n            frag,\n            response: _objectSpread2({\n              url,\n              data: undefined\n            }, response),\n            error: new Error(`HTTP Error ${response.code} ${response.text}`),\n            networkDetails,\n            stats\n          }));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.INTERNAL_ABORTED,\n            fatal: false,\n            frag,\n            error: new Error('Aborted'),\n            networkDetails,\n            stats\n          }));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_TIMEOUT,\n            fatal: false,\n            frag,\n            error: new Error(`Timeout after ${loaderConfig.timeout}ms`),\n            networkDetails,\n            stats\n          }));\n        },\n        onProgress: (stats, context, data, networkDetails) => {\n          if (onProgress) {\n            onProgress({\n              frag,\n              part: null,\n              payload: data,\n              networkDetails\n            });\n          }\n        }\n      });\n    });\n  }\n  loadPart(frag, part, onProgress) {\n    this.abort();\n    const config = this.config;\n    const FragmentILoader = config.fLoader;\n    const DefaultILoader = config.loader;\n    return new Promise((resolve, reject) => {\n      if (this.loader) {\n        this.loader.destroy();\n      }\n      if (frag.gap || part.gap) {\n        reject(createGapLoadError(frag, part));\n        return;\n      }\n      const loader = this.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);\n      const loaderContext = createLoaderContext(frag, part);\n      // Should we define another load policy for parts?\n      const loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0,\n        highWaterMark: MIN_CHUNK_SIZE\n      };\n      // Assign part stats to the loader's stats reference\n      part.stats = loader.stats;\n      loader.load(loaderContext, loaderConfig, {\n        onSuccess: (response, stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          this.updateStatsFromPart(frag, part);\n          const partLoadedData = {\n            frag,\n            part,\n            payload: response.data,\n            networkDetails\n          };\n          onProgress(partLoadedData);\n          resolve(partLoadedData);\n        },\n        onError: (response, context, networkDetails, stats) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_ERROR,\n            fatal: false,\n            frag,\n            part,\n            response: _objectSpread2({\n              url: loaderContext.url,\n              data: undefined\n            }, response),\n            error: new Error(`HTTP Error ${response.code} ${response.text}`),\n            networkDetails,\n            stats\n          }));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          frag.stats.aborted = part.stats.aborted;\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.INTERNAL_ABORTED,\n            fatal: false,\n            frag,\n            part,\n            error: new Error('Aborted'),\n            networkDetails,\n            stats\n          }));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          this.resetLoader(frag, loader);\n          reject(new LoadError({\n            type: ErrorTypes.NETWORK_ERROR,\n            details: ErrorDetails.FRAG_LOAD_TIMEOUT,\n            fatal: false,\n            frag,\n            part,\n            error: new Error(`Timeout after ${loaderConfig.timeout}ms`),\n            networkDetails,\n            stats\n          }));\n        }\n      });\n    });\n  }\n  updateStatsFromPart(frag, part) {\n    const fragStats = frag.stats;\n    const partStats = part.stats;\n    const partTotal = partStats.total;\n    fragStats.loaded += partStats.loaded;\n    if (partTotal) {\n      const estTotalParts = Math.round(frag.duration / part.duration);\n      const estLoadedParts = Math.min(Math.round(fragStats.loaded / partTotal), estTotalParts);\n      const estRemainingParts = estTotalParts - estLoadedParts;\n      const estRemainingBytes = estRemainingParts * Math.round(fragStats.loaded / estLoadedParts);\n      fragStats.total = fragStats.loaded + estRemainingBytes;\n    } else {\n      fragStats.total = Math.max(fragStats.loaded, fragStats.total);\n    }\n    const fragLoading = fragStats.loading;\n    const partLoading = partStats.loading;\n    if (fragLoading.start) {\n      // add to fragment loader latency\n      fragLoading.first += partLoading.first - partLoading.start;\n    } else {\n      fragLoading.start = partLoading.start;\n      fragLoading.first = partLoading.first;\n    }\n    fragLoading.end = partLoading.end;\n  }\n  resetLoader(frag, loader) {\n    frag.loader = null;\n    if (this.loader === loader) {\n      self.clearTimeout(this.partLoadTimeout);\n      this.loader = null;\n    }\n    loader.destroy();\n  }\n}\nfunction createLoaderContext(frag, part = null) {\n  const segment = part || frag;\n  const loaderContext = {\n    frag,\n    part,\n    responseType: 'arraybuffer',\n    url: segment.url,\n    headers: {},\n    rangeStart: 0,\n    rangeEnd: 0\n  };\n  const start = segment.byteRangeStartOffset;\n  const end = segment.byteRangeEndOffset;\n  if (isFiniteNumber(start) && isFiniteNumber(end)) {\n    var _frag$decryptdata;\n    let byteRangeStart = start;\n    let byteRangeEnd = end;\n    if (frag.sn === 'initSegment' && ((_frag$decryptdata = frag.decryptdata) == null ? void 0 : _frag$decryptdata.method) === 'AES-128') {\n      // MAP segment encrypted with method 'AES-128', when served with HTTP Range,\n      // has the unencrypted size specified in the range.\n      // Ref: https://tools.ietf.org/html/draft-pantos-hls-rfc8216bis-08#section-6.3.6\n      const fragmentLen = end - start;\n      if (fragmentLen % 16) {\n        byteRangeEnd = end + (16 - fragmentLen % 16);\n      }\n      if (start !== 0) {\n        loaderContext.resetIV = true;\n        byteRangeStart = start - 16;\n      }\n    }\n    loaderContext.rangeStart = byteRangeStart;\n    loaderContext.rangeEnd = byteRangeEnd;\n  }\n  return loaderContext;\n}\nfunction createGapLoadError(frag, part) {\n  const error = new Error(`GAP ${frag.gap ? 'tag' : 'attribute'} found`);\n  const errorData = {\n    type: ErrorTypes.MEDIA_ERROR,\n    details: ErrorDetails.FRAG_GAP,\n    fatal: false,\n    frag,\n    error,\n    networkDetails: null\n  };\n  if (part) {\n    errorData.part = part;\n  }\n  (part ? part : frag).stats.aborted = true;\n  return new LoadError(errorData);\n}\nclass LoadError extends Error {\n  constructor(data) {\n    super(data.error.message);\n    this.data = void 0;\n    this.data = data;\n  }\n}\n\nclass AESCrypto {\n  constructor(subtle, iv) {\n    this.subtle = void 0;\n    this.aesIV = void 0;\n    this.subtle = subtle;\n    this.aesIV = iv;\n  }\n  decrypt(data, key) {\n    return this.subtle.decrypt({\n      name: 'AES-CBC',\n      iv: this.aesIV\n    }, key, data);\n  }\n}\n\nclass FastAESKey {\n  constructor(subtle, key) {\n    this.subtle = void 0;\n    this.key = void 0;\n    this.subtle = subtle;\n    this.key = key;\n  }\n  expandKey() {\n    return this.subtle.importKey('raw', this.key, {\n      name: 'AES-CBC'\n    }, false, ['encrypt', 'decrypt']);\n  }\n}\n\n// PKCS7\nfunction removePadding(array) {\n  const outputBytes = array.byteLength;\n  const paddingBytes = outputBytes && new DataView(array.buffer).getUint8(outputBytes - 1);\n  if (paddingBytes) {\n    return sliceUint8(array, 0, outputBytes - paddingBytes);\n  }\n  return array;\n}\nclass AESDecryptor {\n  constructor() {\n    this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];\n    this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n    this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n    this.sBox = new Uint32Array(256);\n    this.invSBox = new Uint32Array(256);\n    this.key = new Uint32Array(0);\n    this.ksRows = 0;\n    this.keySize = 0;\n    this.keySchedule = void 0;\n    this.invKeySchedule = void 0;\n    this.initTable();\n  }\n\n  // Using view.getUint32() also swaps the byte order.\n  uint8ArrayToUint32Array_(arrayBuffer) {\n    const view = new DataView(arrayBuffer);\n    const newArray = new Uint32Array(4);\n    for (let i = 0; i < 4; i++) {\n      newArray[i] = view.getUint32(i * 4);\n    }\n    return newArray;\n  }\n  initTable() {\n    const sBox = this.sBox;\n    const invSBox = this.invSBox;\n    const subMix = this.subMix;\n    const subMix0 = subMix[0];\n    const subMix1 = subMix[1];\n    const subMix2 = subMix[2];\n    const subMix3 = subMix[3];\n    const invSubMix = this.invSubMix;\n    const invSubMix0 = invSubMix[0];\n    const invSubMix1 = invSubMix[1];\n    const invSubMix2 = invSubMix[2];\n    const invSubMix3 = invSubMix[3];\n    const d = new Uint32Array(256);\n    let x = 0;\n    let xi = 0;\n    let i = 0;\n    for (i = 0; i < 256; i++) {\n      if (i < 128) {\n        d[i] = i << 1;\n      } else {\n        d[i] = i << 1 ^ 0x11b;\n      }\n    }\n    for (i = 0; i < 256; i++) {\n      let sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;\n      sx = sx >>> 8 ^ sx & 0xff ^ 0x63;\n      sBox[x] = sx;\n      invSBox[sx] = x;\n\n      // Compute multiplication\n      const x2 = d[x];\n      const x4 = d[x2];\n      const x8 = d[x4];\n\n      // Compute sub/invSub bytes, mix columns tables\n      let t = d[sx] * 0x101 ^ sx * 0x1010100;\n      subMix0[x] = t << 24 | t >>> 8;\n      subMix1[x] = t << 16 | t >>> 16;\n      subMix2[x] = t << 8 | t >>> 24;\n      subMix3[x] = t;\n\n      // Compute inv sub bytes, inv mix columns tables\n      t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;\n      invSubMix0[sx] = t << 24 | t >>> 8;\n      invSubMix1[sx] = t << 16 | t >>> 16;\n      invSubMix2[sx] = t << 8 | t >>> 24;\n      invSubMix3[sx] = t;\n\n      // Compute next counter\n      if (!x) {\n        x = xi = 1;\n      } else {\n        x = x2 ^ d[d[d[x8 ^ x2]]];\n        xi ^= d[d[xi]];\n      }\n    }\n  }\n  expandKey(keyBuffer) {\n    // convert keyBuffer to Uint32Array\n    const key = this.uint8ArrayToUint32Array_(keyBuffer);\n    let sameKey = true;\n    let offset = 0;\n    while (offset < key.length && sameKey) {\n      sameKey = key[offset] === this.key[offset];\n      offset++;\n    }\n    if (sameKey) {\n      return;\n    }\n    this.key = key;\n    const keySize = this.keySize = key.length;\n    if (keySize !== 4 && keySize !== 6 && keySize !== 8) {\n      throw new Error('Invalid aes key size=' + keySize);\n    }\n    const ksRows = this.ksRows = (keySize + 6 + 1) * 4;\n    let ksRow;\n    let invKsRow;\n    const keySchedule = this.keySchedule = new Uint32Array(ksRows);\n    const invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);\n    const sbox = this.sBox;\n    const rcon = this.rcon;\n    const invSubMix = this.invSubMix;\n    const invSubMix0 = invSubMix[0];\n    const invSubMix1 = invSubMix[1];\n    const invSubMix2 = invSubMix[2];\n    const invSubMix3 = invSubMix[3];\n    let prev;\n    let t;\n    for (ksRow = 0; ksRow < ksRows; ksRow++) {\n      if (ksRow < keySize) {\n        prev = keySchedule[ksRow] = key[ksRow];\n        continue;\n      }\n      t = prev;\n      if (ksRow % keySize === 0) {\n        // Rot word\n        t = t << 8 | t >>> 24;\n\n        // Sub word\n        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n\n        // Mix Rcon\n        t ^= rcon[ksRow / keySize | 0] << 24;\n      } else if (keySize > 6 && ksRow % keySize === 4) {\n        // Sub word\n        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n      }\n      keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;\n    }\n    for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {\n      ksRow = ksRows - invKsRow;\n      if (invKsRow & 3) {\n        t = keySchedule[ksRow];\n      } else {\n        t = keySchedule[ksRow - 4];\n      }\n      if (invKsRow < 4 || ksRow <= 4) {\n        invKeySchedule[invKsRow] = t;\n      } else {\n        invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];\n      }\n      invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;\n    }\n  }\n\n  // Adding this as a method greatly improves performance.\n  networkToHostOrderSwap(word) {\n    return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;\n  }\n  decrypt(inputArrayBuffer, offset, aesIV) {\n    const nRounds = this.keySize + 6;\n    const invKeySchedule = this.invKeySchedule;\n    const invSBOX = this.invSBox;\n    const invSubMix = this.invSubMix;\n    const invSubMix0 = invSubMix[0];\n    const invSubMix1 = invSubMix[1];\n    const invSubMix2 = invSubMix[2];\n    const invSubMix3 = invSubMix[3];\n    const initVector = this.uint8ArrayToUint32Array_(aesIV);\n    let initVector0 = initVector[0];\n    let initVector1 = initVector[1];\n    let initVector2 = initVector[2];\n    let initVector3 = initVector[3];\n    const inputInt32 = new Int32Array(inputArrayBuffer);\n    const outputInt32 = new Int32Array(inputInt32.length);\n    let t0, t1, t2, t3;\n    let s0, s1, s2, s3;\n    let inputWords0, inputWords1, inputWords2, inputWords3;\n    let ksRow, i;\n    const swapWord = this.networkToHostOrderSwap;\n    while (offset < inputInt32.length) {\n      inputWords0 = swapWord(inputInt32[offset]);\n      inputWords1 = swapWord(inputInt32[offset + 1]);\n      inputWords2 = swapWord(inputInt32[offset + 2]);\n      inputWords3 = swapWord(inputInt32[offset + 3]);\n      s0 = inputWords0 ^ invKeySchedule[0];\n      s1 = inputWords3 ^ invKeySchedule[1];\n      s2 = inputWords2 ^ invKeySchedule[2];\n      s3 = inputWords1 ^ invKeySchedule[3];\n      ksRow = 4;\n\n      // Iterate through the rounds of decryption\n      for (i = 1; i < nRounds; i++) {\n        t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];\n        t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n        t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n        t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n        // Update state\n        s0 = t0;\n        s1 = t1;\n        s2 = t2;\n        s3 = t3;\n        ksRow = ksRow + 4;\n      }\n\n      // Shift rows, sub bytes, add round key\n      t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];\n      t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n      t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n      t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n\n      // Write\n      outputInt32[offset] = swapWord(t0 ^ initVector0);\n      outputInt32[offset + 1] = swapWord(t3 ^ initVector1);\n      outputInt32[offset + 2] = swapWord(t2 ^ initVector2);\n      outputInt32[offset + 3] = swapWord(t1 ^ initVector3);\n\n      // reset initVector to last 4 unsigned int\n      initVector0 = inputWords0;\n      initVector1 = inputWords1;\n      initVector2 = inputWords2;\n      initVector3 = inputWords3;\n      offset = offset + 4;\n    }\n    return outputInt32.buffer;\n  }\n}\n\nconst CHUNK_SIZE = 16; // 16 bytes, 128 bits\n\nclass Decrypter {\n  constructor(config, {\n    removePKCS7Padding = true\n  } = {}) {\n    this.logEnabled = true;\n    this.removePKCS7Padding = void 0;\n    this.subtle = null;\n    this.softwareDecrypter = null;\n    this.key = null;\n    this.fastAesKey = null;\n    this.remainderData = null;\n    this.currentIV = null;\n    this.currentResult = null;\n    this.useSoftware = void 0;\n    this.useSoftware = config.enableSoftwareAES;\n    this.removePKCS7Padding = removePKCS7Padding;\n    // built in decryptor expects PKCS7 padding\n    if (removePKCS7Padding) {\n      try {\n        const browserCrypto = self.crypto;\n        if (browserCrypto) {\n          this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;\n        }\n      } catch (e) {\n        /* no-op */\n      }\n    }\n    this.useSoftware = !this.subtle;\n  }\n  destroy() {\n    this.subtle = null;\n    this.softwareDecrypter = null;\n    this.key = null;\n    this.fastAesKey = null;\n    this.remainderData = null;\n    this.currentIV = null;\n    this.currentResult = null;\n  }\n  isSync() {\n    return this.useSoftware;\n  }\n  flush() {\n    const {\n      currentResult,\n      remainderData\n    } = this;\n    if (!currentResult || remainderData) {\n      this.reset();\n      return null;\n    }\n    const data = new Uint8Array(currentResult);\n    this.reset();\n    if (this.removePKCS7Padding) {\n      return removePadding(data);\n    }\n    return data;\n  }\n  reset() {\n    this.currentResult = null;\n    this.currentIV = null;\n    this.remainderData = null;\n    if (this.softwareDecrypter) {\n      this.softwareDecrypter = null;\n    }\n  }\n  decrypt(data, key, iv) {\n    if (this.useSoftware) {\n      return new Promise((resolve, reject) => {\n        this.softwareDecrypt(new Uint8Array(data), key, iv);\n        const decryptResult = this.flush();\n        if (decryptResult) {\n          resolve(decryptResult.buffer);\n        } else {\n          reject(new Error('[softwareDecrypt] Failed to decrypt data'));\n        }\n      });\n    }\n    return this.webCryptoDecrypt(new Uint8Array(data), key, iv);\n  }\n\n  // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached\n  // data is handled in the flush() call\n  softwareDecrypt(data, key, iv) {\n    const {\n      currentIV,\n      currentResult,\n      remainderData\n    } = this;\n    this.logOnce('JS AES decrypt');\n    // The output is staggered during progressive parsing - the current result is cached, and emitted on the next call\n    // This is done in order to strip PKCS7 padding, which is found at the end of each segment. We only know we've reached\n    // the end on flush(), but by that time we have already received all bytes for the segment.\n    // Progressive decryption does not work with WebCrypto\n\n    if (remainderData) {\n      data = appendUint8Array(remainderData, data);\n      this.remainderData = null;\n    }\n\n    // Byte length must be a multiple of 16 (AES-128 = 128 bit blocks = 16 bytes)\n    const currentChunk = this.getValidChunk(data);\n    if (!currentChunk.length) {\n      return null;\n    }\n    if (currentIV) {\n      iv = currentIV;\n    }\n    let softwareDecrypter = this.softwareDecrypter;\n    if (!softwareDecrypter) {\n      softwareDecrypter = this.softwareDecrypter = new AESDecryptor();\n    }\n    softwareDecrypter.expandKey(key);\n    const result = currentResult;\n    this.currentResult = softwareDecrypter.decrypt(currentChunk.buffer, 0, iv);\n    this.currentIV = sliceUint8(currentChunk, -16).buffer;\n    if (!result) {\n      return null;\n    }\n    return result;\n  }\n  webCryptoDecrypt(data, key, iv) {\n    if (this.key !== key || !this.fastAesKey) {\n      if (!this.subtle) {\n        return Promise.resolve(this.onWebCryptoError(data, key, iv));\n      }\n      this.key = key;\n      this.fastAesKey = new FastAESKey(this.subtle, key);\n    }\n    return this.fastAesKey.expandKey().then(aesKey => {\n      // decrypt using web crypto\n      if (!this.subtle) {\n        return Promise.reject(new Error('web crypto not initialized'));\n      }\n      this.logOnce('WebCrypto AES decrypt');\n      const crypto = new AESCrypto(this.subtle, new Uint8Array(iv));\n      return crypto.decrypt(data.buffer, aesKey);\n    }).catch(err => {\n      logger.warn(`[decrypter]: WebCrypto Error, disable WebCrypto API, ${err.name}: ${err.message}`);\n      return this.onWebCryptoError(data, key, iv);\n    });\n  }\n  onWebCryptoError(data, key, iv) {\n    this.useSoftware = true;\n    this.logEnabled = true;\n    this.softwareDecrypt(data, key, iv);\n    const decryptResult = this.flush();\n    if (decryptResult) {\n      return decryptResult.buffer;\n    }\n    throw new Error('WebCrypto and softwareDecrypt: failed to decrypt data');\n  }\n  getValidChunk(data) {\n    let currentChunk = data;\n    const splitPoint = data.length - data.length % CHUNK_SIZE;\n    if (splitPoint !== data.length) {\n      currentChunk = sliceUint8(data, 0, splitPoint);\n      this.remainderData = sliceUint8(data, splitPoint);\n    }\n    return currentChunk;\n  }\n  logOnce(msg) {\n    if (!this.logEnabled) {\n      return;\n    }\n    logger.log(`[decrypter]: ${msg}`);\n    this.logEnabled = false;\n  }\n}\n\n/**\n *  TimeRanges to string helper\n */\n\nconst TimeRanges = {\n  toString: function (r) {\n    let log = '';\n    const len = r.length;\n    for (let i = 0; i < len; i++) {\n      log += `[${r.start(i).toFixed(3)}-${r.end(i).toFixed(3)}]`;\n    }\n    return log;\n  }\n};\n\nconst State = {\n  STOPPED: 'STOPPED',\n  IDLE: 'IDLE',\n  KEY_LOADING: 'KEY_LOADING',\n  FRAG_LOADING: 'FRAG_LOADING',\n  FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',\n  WAITING_TRACK: 'WAITING_TRACK',\n  PARSING: 'PARSING',\n  PARSED: 'PARSED',\n  ENDED: 'ENDED',\n  ERROR: 'ERROR',\n  WAITING_INIT_PTS: 'WAITING_INIT_PTS',\n  WAITING_LEVEL: 'WAITING_LEVEL'\n};\nclass BaseStreamController extends TaskLoop {\n  constructor(hls, fragmentTracker, keyLoader, logPrefix, playlistType) {\n    super();\n    this.hls = void 0;\n    this.fragPrevious = null;\n    this.fragCurrent = null;\n    this.fragmentTracker = void 0;\n    this.transmuxer = null;\n    this._state = State.STOPPED;\n    this.playlistType = void 0;\n    this.media = null;\n    this.mediaBuffer = null;\n    this.config = void 0;\n    this.bitrateTest = false;\n    this.lastCurrentTime = 0;\n    this.nextLoadPosition = 0;\n    this.startPosition = 0;\n    this.startTimeOffset = null;\n    this.loadedmetadata = false;\n    this.retryDate = 0;\n    this.levels = null;\n    this.fragmentLoader = void 0;\n    this.keyLoader = void 0;\n    this.levelLastLoaded = null;\n    this.startFragRequested = false;\n    this.decrypter = void 0;\n    this.initPTS = [];\n    this.onvseeking = null;\n    this.onvended = null;\n    this.logPrefix = '';\n    this.log = void 0;\n    this.warn = void 0;\n    this.playlistType = playlistType;\n    this.logPrefix = logPrefix;\n    this.log = logger.log.bind(logger, `${logPrefix}:`);\n    this.warn = logger.warn.bind(logger, `${logPrefix}:`);\n    this.hls = hls;\n    this.fragmentLoader = new FragmentLoader(hls.config);\n    this.keyLoader = keyLoader;\n    this.fragmentTracker = fragmentTracker;\n    this.config = hls.config;\n    this.decrypter = new Decrypter(hls.config);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n  }\n  doTick() {\n    this.onTickEnd();\n  }\n  onTickEnd() {}\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  startLoad(startPosition) {}\n  stopLoad() {\n    this.fragmentLoader.abort();\n    this.keyLoader.abort(this.playlistType);\n    const frag = this.fragCurrent;\n    if (frag != null && frag.loader) {\n      frag.abortRequests();\n      this.fragmentTracker.removeFragment(frag);\n    }\n    this.resetTransmuxer();\n    this.fragCurrent = null;\n    this.fragPrevious = null;\n    this.clearInterval();\n    this.clearNextTick();\n    this.state = State.STOPPED;\n  }\n  _streamEnded(bufferInfo, levelDetails) {\n    // If playlist is live, there is another buffered range after the current range, nothing buffered, media is detached,\n    // of nothing loading/loaded return false\n    if (levelDetails.live || bufferInfo.nextStart || !bufferInfo.end || !this.media) {\n      return false;\n    }\n    const partList = levelDetails.partList;\n    // Since the last part isn't guaranteed to correspond to the last playlist segment for Low-Latency HLS,\n    // check instead if the last part is buffered.\n    if (partList != null && partList.length) {\n      const lastPart = partList[partList.length - 1];\n\n      // Checking the midpoint of the part for potential margin of error and related issues.\n      // NOTE: Technically I believe parts could yield content that is < the computed duration (including potential a duration of 0)\n      // and still be spec-compliant, so there may still be edge cases here. Likewise, there could be issues in end of stream\n      // part mismatches for independent audio and video playlists/segments.\n      const lastPartBuffered = BufferHelper.isBuffered(this.media, lastPart.start + lastPart.duration / 2);\n      return lastPartBuffered;\n    }\n    const playlistType = levelDetails.fragments[levelDetails.fragments.length - 1].type;\n    return this.fragmentTracker.isEndListAppended(playlistType);\n  }\n  getLevelDetails() {\n    if (this.levels && this.levelLastLoaded !== null) {\n      var _this$levelLastLoaded;\n      return (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details;\n    }\n  }\n  onMediaAttached(event, data) {\n    const media = this.media = this.mediaBuffer = data.media;\n    this.onvseeking = this.onMediaSeeking.bind(this);\n    this.onvended = this.onMediaEnded.bind(this);\n    media.addEventListener('seeking', this.onvseeking);\n    media.addEventListener('ended', this.onvended);\n    const config = this.config;\n    if (this.levels && config.autoStartLoad && this.state === State.STOPPED) {\n      this.startLoad(config.startPosition);\n    }\n  }\n  onMediaDetaching() {\n    const media = this.media;\n    if (media != null && media.ended) {\n      this.log('MSE detaching and video ended, reset startPosition');\n      this.startPosition = this.lastCurrentTime = 0;\n    }\n\n    // remove video listeners\n    if (media && this.onvseeking && this.onvended) {\n      media.removeEventListener('seeking', this.onvseeking);\n      media.removeEventListener('ended', this.onvended);\n      this.onvseeking = this.onvended = null;\n    }\n    if (this.keyLoader) {\n      this.keyLoader.detach();\n    }\n    this.media = this.mediaBuffer = null;\n    this.loadedmetadata = false;\n    this.fragmentTracker.removeAllFragments();\n    this.stopLoad();\n  }\n  onMediaSeeking() {\n    const {\n      config,\n      fragCurrent,\n      media,\n      mediaBuffer,\n      state\n    } = this;\n    const currentTime = media ? media.currentTime : 0;\n    const bufferInfo = BufferHelper.bufferInfo(mediaBuffer ? mediaBuffer : media, currentTime, config.maxBufferHole);\n    this.log(`media seeking to ${isFiniteNumber(currentTime) ? currentTime.toFixed(3) : currentTime}, state: ${state}`);\n    if (this.state === State.ENDED) {\n      this.resetLoadingState();\n    } else if (fragCurrent) {\n      // Seeking while frag load is in progress\n      const tolerance = config.maxFragLookUpTolerance;\n      const fragStartOffset = fragCurrent.start - tolerance;\n      const fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;\n      // if seeking out of buffered range or into new one\n      if (!bufferInfo.len || fragEndOffset < bufferInfo.start || fragStartOffset > bufferInfo.end) {\n        const pastFragment = currentTime > fragEndOffset;\n        // if the seek position is outside the current fragment range\n        if (currentTime < fragStartOffset || pastFragment) {\n          if (pastFragment && fragCurrent.loader) {\n            this.log('seeking outside of buffer while fragment load in progress, cancel fragment load');\n            fragCurrent.abortRequests();\n            this.resetLoadingState();\n          }\n          this.fragPrevious = null;\n        }\n      }\n    }\n    if (media) {\n      // Remove gap fragments\n      this.fragmentTracker.removeFragmentsInRange(currentTime, Infinity, this.playlistType, true);\n      this.lastCurrentTime = currentTime;\n    }\n\n    // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target\n    if (!this.loadedmetadata && !bufferInfo.len) {\n      this.nextLoadPosition = this.startPosition = currentTime;\n    }\n\n    // Async tick to speed up processing\n    this.tickImmediate();\n  }\n  onMediaEnded() {\n    // reset startPosition and lastCurrentTime to restart playback @ stream beginning\n    this.startPosition = this.lastCurrentTime = 0;\n  }\n  onManifestLoaded(event, data) {\n    this.startTimeOffset = data.startTimeOffset;\n    this.initPTS = [];\n  }\n  onHandlerDestroying() {\n    this.hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    this.stopLoad();\n    super.onHandlerDestroying();\n    // @ts-ignore\n    this.hls = null;\n  }\n  onHandlerDestroyed() {\n    this.state = State.STOPPED;\n    if (this.fragmentLoader) {\n      this.fragmentLoader.destroy();\n    }\n    if (this.keyLoader) {\n      this.keyLoader.destroy();\n    }\n    if (this.decrypter) {\n      this.decrypter.destroy();\n    }\n    this.hls = this.log = this.warn = this.decrypter = this.keyLoader = this.fragmentLoader = this.fragmentTracker = null;\n    super.onHandlerDestroyed();\n  }\n  loadFragment(frag, level, targetBufferTime) {\n    this._loadFragForPlayback(frag, level, targetBufferTime);\n  }\n  _loadFragForPlayback(frag, level, targetBufferTime) {\n    const progressCallback = data => {\n      if (this.fragContextChanged(frag)) {\n        this.warn(`Fragment ${frag.sn}${data.part ? ' p: ' + data.part.index : ''} of level ${frag.level} was dropped during download.`);\n        this.fragmentTracker.removeFragment(frag);\n        return;\n      }\n      frag.stats.chunkCount++;\n      this._handleFragmentLoadProgress(data);\n    };\n    this._doFragLoad(frag, level, targetBufferTime, progressCallback).then(data => {\n      if (!data) {\n        // if we're here we probably needed to backtrack or are waiting for more parts\n        return;\n      }\n      const state = this.state;\n      if (this.fragContextChanged(frag)) {\n        if (state === State.FRAG_LOADING || !this.fragCurrent && state === State.PARSING) {\n          this.fragmentTracker.removeFragment(frag);\n          this.state = State.IDLE;\n        }\n        return;\n      }\n      if ('payload' in data) {\n        this.log(`Loaded fragment ${frag.sn} of level ${frag.level}`);\n        this.hls.trigger(Events.FRAG_LOADED, data);\n      }\n\n      // Pass through the whole payload; controllers not implementing progressive loading receive data from this callback\n      this._handleFragmentLoadComplete(data);\n    }).catch(reason => {\n      if (this.state === State.STOPPED || this.state === State.ERROR) {\n        return;\n      }\n      this.warn(`Frag error: ${(reason == null ? void 0 : reason.message) || reason}`);\n      this.resetFragmentLoading(frag);\n    });\n  }\n  clearTrackerIfNeeded(frag) {\n    var _this$mediaBuffer;\n    const {\n      fragmentTracker\n    } = this;\n    const fragState = fragmentTracker.getState(frag);\n    if (fragState === FragmentState.APPENDING) {\n      // Lower the max buffer length and try again\n      const playlistType = frag.type;\n      const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);\n      const minForwardBufferLength = Math.max(frag.duration, bufferedInfo ? bufferedInfo.len : this.config.maxBufferLength);\n      // If backtracking, always remove from the tracker without reducing max buffer length\n      const backtrackFragment = this.backtrackFragment;\n      const backtracked = backtrackFragment ? frag.sn - backtrackFragment.sn : 0;\n      if (backtracked === 1 || this.reduceMaxBufferLength(minForwardBufferLength, frag.duration)) {\n        fragmentTracker.removeFragment(frag);\n      }\n    } else if (((_this$mediaBuffer = this.mediaBuffer) == null ? void 0 : _this$mediaBuffer.buffered.length) === 0) {\n      // Stop gap for bad tracker / buffer flush behavior\n      fragmentTracker.removeAllFragments();\n    } else if (fragmentTracker.hasParts(frag.type)) {\n      // In low latency mode, remove fragments for which only some parts were buffered\n      fragmentTracker.detectPartialFragments({\n        frag,\n        part: null,\n        stats: frag.stats,\n        id: frag.type\n      });\n      if (fragmentTracker.getState(frag) === FragmentState.PARTIAL) {\n        fragmentTracker.removeFragment(frag);\n      }\n    }\n  }\n  checkLiveUpdate(details) {\n    if (details.updated && !details.live) {\n      // Live stream ended, update fragment tracker\n      const lastFragment = details.fragments[details.fragments.length - 1];\n      this.fragmentTracker.detectPartialFragments({\n        frag: lastFragment,\n        part: null,\n        stats: lastFragment.stats,\n        id: lastFragment.type\n      });\n    }\n    if (!details.fragments[0]) {\n      details.deltaUpdateFailed = true;\n    }\n  }\n  flushMainBuffer(startOffset, endOffset, type = null) {\n    if (!(startOffset - endOffset)) {\n      return;\n    }\n    // When alternate audio is playing, the audio-stream-controller is responsible for the audio buffer. Otherwise,\n    // passing a null type flushes both buffers\n    const flushScope = {\n      startOffset,\n      endOffset,\n      type\n    };\n    this.hls.trigger(Events.BUFFER_FLUSHING, flushScope);\n  }\n  _loadInitSegment(frag, level) {\n    this._doFragLoad(frag, level).then(data => {\n      if (!data || this.fragContextChanged(frag) || !this.levels) {\n        throw new Error('init load aborted');\n      }\n      return data;\n    }).then(data => {\n      const {\n        hls\n      } = this;\n      const {\n        payload\n      } = data;\n      const decryptData = frag.decryptdata;\n\n      // check to see if the payload needs to be decrypted\n      if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {\n        const startTime = self.performance.now();\n        // decrypt init segment data\n        return this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).catch(err => {\n          hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.FRAG_DECRYPT_ERROR,\n            fatal: false,\n            error: err,\n            reason: err.message,\n            frag\n          });\n          throw err;\n        }).then(decryptedData => {\n          const endTime = self.performance.now();\n          hls.trigger(Events.FRAG_DECRYPTED, {\n            frag,\n            payload: decryptedData,\n            stats: {\n              tstart: startTime,\n              tdecrypt: endTime\n            }\n          });\n          data.payload = decryptedData;\n          return this.completeInitSegmentLoad(data);\n        });\n      }\n      return this.completeInitSegmentLoad(data);\n    }).catch(reason => {\n      if (this.state === State.STOPPED || this.state === State.ERROR) {\n        return;\n      }\n      this.warn(reason);\n      this.resetFragmentLoading(frag);\n    });\n  }\n  completeInitSegmentLoad(data) {\n    const {\n      levels\n    } = this;\n    if (!levels) {\n      throw new Error('init load aborted, missing levels');\n    }\n    const stats = data.frag.stats;\n    this.state = State.IDLE;\n    data.frag.data = new Uint8Array(data.payload);\n    stats.parsing.start = stats.buffering.start = self.performance.now();\n    stats.parsing.end = stats.buffering.end = self.performance.now();\n    this.tick();\n  }\n  fragContextChanged(frag) {\n    const {\n      fragCurrent\n    } = this;\n    return !frag || !fragCurrent || frag.sn !== fragCurrent.sn || frag.level !== fragCurrent.level;\n  }\n  fragBufferedComplete(frag, part) {\n    var _frag$startPTS, _frag$endPTS, _this$fragCurrent, _this$fragPrevious;\n    const media = this.mediaBuffer ? this.mediaBuffer : this.media;\n    this.log(`Buffered ${frag.type} sn: ${frag.sn}${part ? ' part: ' + part.index : ''} of ${this.playlistType === PlaylistLevelType.MAIN ? 'level' : 'track'} ${frag.level} (frag:[${((_frag$startPTS = frag.startPTS) != null ? _frag$startPTS : NaN).toFixed(3)}-${((_frag$endPTS = frag.endPTS) != null ? _frag$endPTS : NaN).toFixed(3)}] > buffer:${media ? TimeRanges.toString(BufferHelper.getBuffered(media)) : '(detached)'})`);\n    if (frag.sn !== 'initSegment') {\n      var _this$levels;\n      if (frag.type !== PlaylistLevelType.SUBTITLE) {\n        const el = frag.elementaryStreams;\n        if (!Object.keys(el).some(type => !!el[type])) {\n          // empty segment\n          this.state = State.IDLE;\n          return;\n        }\n      }\n      const level = (_this$levels = this.levels) == null ? void 0 : _this$levels[frag.level];\n      if (level != null && level.fragmentError) {\n        this.log(`Resetting level fragment error count of ${level.fragmentError} on frag buffered`);\n        level.fragmentError = 0;\n      }\n    }\n    this.state = State.IDLE;\n    if (!media) {\n      return;\n    }\n    if (!this.loadedmetadata && frag.type == PlaylistLevelType.MAIN && media.buffered.length && ((_this$fragCurrent = this.fragCurrent) == null ? void 0 : _this$fragCurrent.sn) === ((_this$fragPrevious = this.fragPrevious) == null ? void 0 : _this$fragPrevious.sn)) {\n      this.loadedmetadata = true;\n      this.seekToStartPos();\n    }\n    this.tick();\n  }\n  seekToStartPos() {}\n  _handleFragmentLoadComplete(fragLoadedEndData) {\n    const {\n      transmuxer\n    } = this;\n    if (!transmuxer) {\n      return;\n    }\n    const {\n      frag,\n      part,\n      partsLoaded\n    } = fragLoadedEndData;\n    // If we did not load parts, or loaded all parts, we have complete (not partial) fragment data\n    const complete = !partsLoaded || partsLoaded.length === 0 || partsLoaded.some(fragLoaded => !fragLoaded);\n    const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount + 1, 0, part ? part.index : -1, !complete);\n    transmuxer.flush(chunkMeta);\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  _handleFragmentLoadProgress(frag) {}\n  _doFragLoad(frag, level, targetBufferTime = null, progressCallback) {\n    var _frag$decryptdata;\n    const details = level == null ? void 0 : level.details;\n    if (!this.levels || !details) {\n      throw new Error(`frag load aborted, missing level${details ? '' : ' detail'}s`);\n    }\n    let keyLoadingPromise = null;\n    if (frag.encrypted && !((_frag$decryptdata = frag.decryptdata) != null && _frag$decryptdata.key)) {\n      this.log(`Loading key for ${frag.sn} of [${details.startSN}-${details.endSN}], ${this.logPrefix === '[stream-controller]' ? 'level' : 'track'} ${frag.level}`);\n      this.state = State.KEY_LOADING;\n      this.fragCurrent = frag;\n      keyLoadingPromise = this.keyLoader.load(frag).then(keyLoadedData => {\n        if (!this.fragContextChanged(keyLoadedData.frag)) {\n          this.hls.trigger(Events.KEY_LOADED, keyLoadedData);\n          if (this.state === State.KEY_LOADING) {\n            this.state = State.IDLE;\n          }\n          return keyLoadedData;\n        }\n      });\n      this.hls.trigger(Events.KEY_LOADING, {\n        frag\n      });\n      if (this.fragCurrent === null) {\n        keyLoadingPromise = Promise.reject(new Error(`frag load aborted, context changed in KEY_LOADING`));\n      }\n    } else if (!frag.encrypted && details.encryptedFragments.length) {\n      this.keyLoader.loadClear(frag, details.encryptedFragments);\n    }\n    targetBufferTime = Math.max(frag.start, targetBufferTime || 0);\n    if (this.config.lowLatencyMode && frag.sn !== 'initSegment') {\n      const partList = details.partList;\n      if (partList && progressCallback) {\n        if (targetBufferTime > frag.end && details.fragmentHint) {\n          frag = details.fragmentHint;\n        }\n        const partIndex = this.getNextPart(partList, frag, targetBufferTime);\n        if (partIndex > -1) {\n          const part = partList[partIndex];\n          this.log(`Loading part sn: ${frag.sn} p: ${part.index} cc: ${frag.cc} of playlist [${details.startSN}-${details.endSN}] parts [0-${partIndex}-${partList.length - 1}] ${this.logPrefix === '[stream-controller]' ? 'level' : 'track'}: ${frag.level}, target: ${parseFloat(targetBufferTime.toFixed(3))}`);\n          this.nextLoadPosition = part.start + part.duration;\n          this.state = State.FRAG_LOADING;\n          let _result;\n          if (keyLoadingPromise) {\n            _result = keyLoadingPromise.then(keyLoadedData => {\n              if (!keyLoadedData || this.fragContextChanged(keyLoadedData.frag)) {\n                return null;\n              }\n              return this.doFragPartsLoad(frag, part, level, progressCallback);\n            }).catch(error => this.handleFragLoadError(error));\n          } else {\n            _result = this.doFragPartsLoad(frag, part, level, progressCallback).catch(error => this.handleFragLoadError(error));\n          }\n          this.hls.trigger(Events.FRAG_LOADING, {\n            frag,\n            part,\n            targetBufferTime\n          });\n          if (this.fragCurrent === null) {\n            return Promise.reject(new Error(`frag load aborted, context changed in FRAG_LOADING parts`));\n          }\n          return _result;\n        } else if (!frag.url || this.loadedEndOfParts(partList, targetBufferTime)) {\n          // Fragment hint has no parts\n          return Promise.resolve(null);\n        }\n      }\n    }\n    this.log(`Loading fragment ${frag.sn} cc: ${frag.cc} ${details ? 'of [' + details.startSN + '-' + details.endSN + '] ' : ''}${this.logPrefix === '[stream-controller]' ? 'level' : 'track'}: ${frag.level}, target: ${parseFloat(targetBufferTime.toFixed(3))}`);\n    // Don't update nextLoadPosition for fragments which are not buffered\n    if (isFiniteNumber(frag.sn) && !this.bitrateTest) {\n      this.nextLoadPosition = frag.start + frag.duration;\n    }\n    this.state = State.FRAG_LOADING;\n\n    // Load key before streaming fragment data\n    const dataOnProgress = this.config.progressive;\n    let result;\n    if (dataOnProgress && keyLoadingPromise) {\n      result = keyLoadingPromise.then(keyLoadedData => {\n        if (!keyLoadedData || this.fragContextChanged(keyLoadedData == null ? void 0 : keyLoadedData.frag)) {\n          return null;\n        }\n        return this.fragmentLoader.load(frag, progressCallback);\n      }).catch(error => this.handleFragLoadError(error));\n    } else {\n      // load unencrypted fragment data with progress event,\n      // or handle fragment result after key and fragment are finished loading\n      result = Promise.all([this.fragmentLoader.load(frag, dataOnProgress ? progressCallback : undefined), keyLoadingPromise]).then(([fragLoadedData]) => {\n        if (!dataOnProgress && fragLoadedData && progressCallback) {\n          progressCallback(fragLoadedData);\n        }\n        return fragLoadedData;\n      }).catch(error => this.handleFragLoadError(error));\n    }\n    this.hls.trigger(Events.FRAG_LOADING, {\n      frag,\n      targetBufferTime\n    });\n    if (this.fragCurrent === null) {\n      return Promise.reject(new Error(`frag load aborted, context changed in FRAG_LOADING`));\n    }\n    return result;\n  }\n  doFragPartsLoad(frag, fromPart, level, progressCallback) {\n    return new Promise((resolve, reject) => {\n      var _level$details;\n      const partsLoaded = [];\n      const initialPartList = (_level$details = level.details) == null ? void 0 : _level$details.partList;\n      const loadPart = part => {\n        this.fragmentLoader.loadPart(frag, part, progressCallback).then(partLoadedData => {\n          partsLoaded[part.index] = partLoadedData;\n          const loadedPart = partLoadedData.part;\n          this.hls.trigger(Events.FRAG_LOADED, partLoadedData);\n          const nextPart = getPartWith(level, frag.sn, part.index + 1) || findPart(initialPartList, frag.sn, part.index + 1);\n          if (nextPart) {\n            loadPart(nextPart);\n          } else {\n            return resolve({\n              frag,\n              part: loadedPart,\n              partsLoaded\n            });\n          }\n        }).catch(reject);\n      };\n      loadPart(fromPart);\n    });\n  }\n  handleFragLoadError(error) {\n    if ('data' in error) {\n      const data = error.data;\n      if (error.data && data.details === ErrorDetails.INTERNAL_ABORTED) {\n        this.handleFragLoadAborted(data.frag, data.part);\n      } else {\n        this.hls.trigger(Events.ERROR, data);\n      }\n    } else {\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.INTERNAL_EXCEPTION,\n        err: error,\n        error,\n        fatal: true\n      });\n    }\n    return null;\n  }\n  _handleTransmuxerFlush(chunkMeta) {\n    const context = this.getCurrentContext(chunkMeta);\n    if (!context || this.state !== State.PARSING) {\n      if (!this.fragCurrent && this.state !== State.STOPPED && this.state !== State.ERROR) {\n        this.state = State.IDLE;\n      }\n      return;\n    }\n    const {\n      frag,\n      part,\n      level\n    } = context;\n    const now = self.performance.now();\n    frag.stats.parsing.end = now;\n    if (part) {\n      part.stats.parsing.end = now;\n    }\n    this.updateLevelTiming(frag, part, level, chunkMeta.partial);\n  }\n  getCurrentContext(chunkMeta) {\n    const {\n      levels,\n      fragCurrent\n    } = this;\n    const {\n      level: levelIndex,\n      sn,\n      part: partIndex\n    } = chunkMeta;\n    if (!(levels != null && levels[levelIndex])) {\n      this.warn(`Levels object was unset while buffering fragment ${sn} of level ${levelIndex}. The current chunk will not be buffered.`);\n      return null;\n    }\n    const level = levels[levelIndex];\n    const part = partIndex > -1 ? getPartWith(level, sn, partIndex) : null;\n    const frag = part ? part.fragment : getFragmentWithSN(level, sn, fragCurrent);\n    if (!frag) {\n      return null;\n    }\n    if (fragCurrent && fragCurrent !== frag) {\n      frag.stats = fragCurrent.stats;\n    }\n    return {\n      frag,\n      part,\n      level\n    };\n  }\n  bufferFragmentData(data, frag, part, chunkMeta, noBacktracking) {\n    var _buffer;\n    if (!data || this.state !== State.PARSING) {\n      return;\n    }\n    const {\n      data1,\n      data2\n    } = data;\n    let buffer = data1;\n    if (data1 && data2) {\n      // Combine the moof + mdat so that we buffer with a single append\n      buffer = appendUint8Array(data1, data2);\n    }\n    if (!((_buffer = buffer) != null && _buffer.length)) {\n      return;\n    }\n    const segment = {\n      type: data.type,\n      frag,\n      part,\n      chunkMeta,\n      parent: frag.type,\n      data: buffer\n    };\n    this.hls.trigger(Events.BUFFER_APPENDING, segment);\n    if (data.dropped && data.independent && !part) {\n      if (noBacktracking) {\n        return;\n      }\n      // Clear buffer so that we reload previous segments sequentially if required\n      this.flushBufferGap(frag);\n    }\n  }\n  flushBufferGap(frag) {\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    // If currentTime is not buffered, clear the back buffer so that we can backtrack as much as needed\n    if (!BufferHelper.isBuffered(media, media.currentTime)) {\n      this.flushMainBuffer(0, frag.start);\n      return;\n    }\n    // Remove back-buffer without interrupting playback to allow back tracking\n    const currentTime = media.currentTime;\n    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n    const fragDuration = frag.duration;\n    const segmentFraction = Math.min(this.config.maxFragLookUpTolerance * 2, fragDuration * 0.25);\n    const start = Math.max(Math.min(frag.start - segmentFraction, bufferInfo.end - segmentFraction), currentTime + segmentFraction);\n    if (frag.start - start > segmentFraction) {\n      this.flushMainBuffer(start, frag.start);\n    }\n  }\n  getFwdBufferInfo(bufferable, type) {\n    const pos = this.getLoadPosition();\n    if (!isFiniteNumber(pos)) {\n      return null;\n    }\n    return this.getFwdBufferInfoAtPos(bufferable, pos, type);\n  }\n  getFwdBufferInfoAtPos(bufferable, pos, type) {\n    const {\n      config: {\n        maxBufferHole\n      }\n    } = this;\n    const bufferInfo = BufferHelper.bufferInfo(bufferable, pos, maxBufferHole);\n    // Workaround flaw in getting forward buffer when maxBufferHole is smaller than gap at current pos\n    if (bufferInfo.len === 0 && bufferInfo.nextStart !== undefined) {\n      const bufferedFragAtPos = this.fragmentTracker.getBufferedFrag(pos, type);\n      if (bufferedFragAtPos && bufferInfo.nextStart < bufferedFragAtPos.end) {\n        return BufferHelper.bufferInfo(bufferable, pos, Math.max(bufferInfo.nextStart, maxBufferHole));\n      }\n    }\n    return bufferInfo;\n  }\n  getMaxBufferLength(levelBitrate) {\n    const {\n      config\n    } = this;\n    let maxBufLen;\n    if (levelBitrate) {\n      maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);\n    } else {\n      maxBufLen = config.maxBufferLength;\n    }\n    return Math.min(maxBufLen, config.maxMaxBufferLength);\n  }\n  reduceMaxBufferLength(threshold, fragDuration) {\n    const config = this.config;\n    const minLength = Math.max(Math.min(threshold - fragDuration, config.maxBufferLength), fragDuration);\n    const reducedLength = Math.max(threshold - fragDuration * 3, config.maxMaxBufferLength / 2, minLength);\n    if (reducedLength >= minLength) {\n      // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\n      config.maxMaxBufferLength = reducedLength;\n      this.warn(`Reduce max buffer length to ${reducedLength}s`);\n      return true;\n    }\n    return false;\n  }\n  getAppendedFrag(position, playlistType = PlaylistLevelType.MAIN) {\n    const fragOrPart = this.fragmentTracker.getAppendedFrag(position, PlaylistLevelType.MAIN);\n    if (fragOrPart && 'fragment' in fragOrPart) {\n      return fragOrPart.fragment;\n    }\n    return fragOrPart;\n  }\n  getNextFragment(pos, levelDetails) {\n    const fragments = levelDetails.fragments;\n    const fragLen = fragments.length;\n    if (!fragLen) {\n      return null;\n    }\n\n    // find fragment index, contiguous with end of buffer position\n    const {\n      config\n    } = this;\n    const start = fragments[0].start;\n    let frag;\n    if (levelDetails.live) {\n      const initialLiveManifestSize = config.initialLiveManifestSize;\n      if (fragLen < initialLiveManifestSize) {\n        this.warn(`Not enough fragments to start playback (have: ${fragLen}, need: ${initialLiveManifestSize})`);\n        return null;\n      }\n      // The real fragment start times for a live stream are only known after the PTS range for that level is known.\n      // In order to discover the range, we load the best matching fragment for that level and demux it.\n      // Do not load using live logic if the starting frag is requested - we want to use getFragmentAtPosition() so that\n      // we get the fragment matching that start time\n      if (!levelDetails.PTSKnown && !this.startFragRequested && this.startPosition === -1 || pos < start) {\n        frag = this.getInitialLiveFragment(levelDetails, fragments);\n        this.startPosition = this.nextLoadPosition = frag ? this.hls.liveSyncPosition || frag.start : pos;\n      }\n    } else if (pos <= start) {\n      // VoD playlist: if loadPosition before start of playlist, load first fragment\n      frag = fragments[0];\n    }\n\n    // If we haven't run into any special cases already, just load the fragment most closely matching the requested position\n    if (!frag) {\n      const end = config.lowLatencyMode ? levelDetails.partEnd : levelDetails.fragmentEnd;\n      frag = this.getFragmentAtPosition(pos, end, levelDetails);\n    }\n    return this.mapToInitFragWhenRequired(frag);\n  }\n  isLoopLoading(frag, targetBufferTime) {\n    const trackerState = this.fragmentTracker.getState(frag);\n    return (trackerState === FragmentState.OK || trackerState === FragmentState.PARTIAL && !!frag.gap) && this.nextLoadPosition > targetBufferTime;\n  }\n  getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, playlistType, maxBufLen) {\n    const gapStart = frag.gap;\n    const nextFragment = this.getNextFragment(this.nextLoadPosition, levelDetails);\n    if (nextFragment === null) {\n      return nextFragment;\n    }\n    frag = nextFragment;\n    if (gapStart && frag && !frag.gap && bufferInfo.nextStart) {\n      // Media buffered after GAP tags should not make the next buffer timerange exceed forward buffer length\n      const nextbufferInfo = this.getFwdBufferInfoAtPos(this.mediaBuffer ? this.mediaBuffer : this.media, bufferInfo.nextStart, playlistType);\n      if (nextbufferInfo !== null && bufferInfo.len + nextbufferInfo.len >= maxBufLen) {\n        // Returning here might result in not finding an audio and video candiate to skip to\n        this.log(`buffer full after gaps in \"${playlistType}\" playlist starting at sn: ${frag.sn}`);\n        return null;\n      }\n    }\n    return frag;\n  }\n  mapToInitFragWhenRequired(frag) {\n    // If an initSegment is present, it must be buffered first\n    if (frag != null && frag.initSegment && !(frag != null && frag.initSegment.data) && !this.bitrateTest) {\n      return frag.initSegment;\n    }\n    return frag;\n  }\n  getNextPart(partList, frag, targetBufferTime) {\n    let nextPart = -1;\n    let contiguous = false;\n    let independentAttrOmitted = true;\n    for (let i = 0, len = partList.length; i < len; i++) {\n      const part = partList[i];\n      independentAttrOmitted = independentAttrOmitted && !part.independent;\n      if (nextPart > -1 && targetBufferTime < part.start) {\n        break;\n      }\n      const loaded = part.loaded;\n      if (loaded) {\n        nextPart = -1;\n      } else if ((contiguous || part.independent || independentAttrOmitted) && part.fragment === frag) {\n        nextPart = i;\n      }\n      contiguous = loaded;\n    }\n    return nextPart;\n  }\n  loadedEndOfParts(partList, targetBufferTime) {\n    const lastPart = partList[partList.length - 1];\n    return lastPart && targetBufferTime > lastPart.start && lastPart.loaded;\n  }\n\n  /*\n   This method is used find the best matching first fragment for a live playlist. This fragment is used to calculate the\n   \"sliding\" of the playlist, which is its offset from the start of playback. After sliding we can compute the real\n   start and end times for each fragment in the playlist (after which this method will not need to be called).\n  */\n  getInitialLiveFragment(levelDetails, fragments) {\n    const fragPrevious = this.fragPrevious;\n    let frag = null;\n    if (fragPrevious) {\n      if (levelDetails.hasProgramDateTime) {\n        // Prefer using PDT, because it can be accurate enough to choose the correct fragment without knowing the level sliding\n        this.log(`Live playlist, switching playlist, load frag with same PDT: ${fragPrevious.programDateTime}`);\n        frag = findFragmentByPDT(fragments, fragPrevious.endProgramDateTime, this.config.maxFragLookUpTolerance);\n      }\n      if (!frag) {\n        // SN does not need to be accurate between renditions, but depending on the packaging it may be so.\n        const targetSN = fragPrevious.sn + 1;\n        if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {\n          const fragNext = fragments[targetSN - levelDetails.startSN];\n          // Ensure that we're staying within the continuity range, since PTS resets upon a new range\n          if (fragPrevious.cc === fragNext.cc) {\n            frag = fragNext;\n            this.log(`Live playlist, switching playlist, load frag with next SN: ${frag.sn}`);\n          }\n        }\n        // It's important to stay within the continuity range if available; otherwise the fragments in the playlist\n        // will have the wrong start times\n        if (!frag) {\n          frag = findFragWithCC(fragments, fragPrevious.cc);\n          if (frag) {\n            this.log(`Live playlist, switching playlist, load frag with same CC: ${frag.sn}`);\n          }\n        }\n      }\n    } else {\n      // Find a new start fragment when fragPrevious is null\n      const liveStart = this.hls.liveSyncPosition;\n      if (liveStart !== null) {\n        frag = this.getFragmentAtPosition(liveStart, this.bitrateTest ? levelDetails.fragmentEnd : levelDetails.edge, levelDetails);\n      }\n    }\n    return frag;\n  }\n\n  /*\n  This method finds the best matching fragment given the provided position.\n   */\n  getFragmentAtPosition(bufferEnd, end, levelDetails) {\n    const {\n      config\n    } = this;\n    let {\n      fragPrevious\n    } = this;\n    let {\n      fragments,\n      endSN\n    } = levelDetails;\n    const {\n      fragmentHint\n    } = levelDetails;\n    const {\n      maxFragLookUpTolerance\n    } = config;\n    const partList = levelDetails.partList;\n    const loadingParts = !!(config.lowLatencyMode && partList != null && partList.length && fragmentHint);\n    if (loadingParts && fragmentHint && !this.bitrateTest) {\n      // Include incomplete fragment with parts at end\n      fragments = fragments.concat(fragmentHint);\n      endSN = fragmentHint.sn;\n    }\n    let frag;\n    if (bufferEnd < end) {\n      const lookupTolerance = bufferEnd > end - maxFragLookUpTolerance ? 0 : maxFragLookUpTolerance;\n      // Remove the tolerance if it would put the bufferEnd past the actual end of stream\n      // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\n      frag = findFragmentByPTS(fragPrevious, fragments, bufferEnd, lookupTolerance);\n    } else {\n      // reach end of playlist\n      frag = fragments[fragments.length - 1];\n    }\n    if (frag) {\n      const curSNIdx = frag.sn - levelDetails.startSN;\n      // Move fragPrevious forward to support forcing the next fragment to load\n      // when the buffer catches up to a previously buffered range.\n      const fragState = this.fragmentTracker.getState(frag);\n      if (fragState === FragmentState.OK || fragState === FragmentState.PARTIAL && frag.gap) {\n        fragPrevious = frag;\n      }\n      if (fragPrevious && frag.sn === fragPrevious.sn && (!loadingParts || partList[0].fragment.sn > frag.sn)) {\n        // Force the next fragment to load if the previous one was already selected. This can occasionally happen with\n        // non-uniform fragment durations\n        const sameLevel = fragPrevious && frag.level === fragPrevious.level;\n        if (sameLevel) {\n          const nextFrag = fragments[curSNIdx + 1];\n          if (frag.sn < endSN && this.fragmentTracker.getState(nextFrag) !== FragmentState.OK) {\n            frag = nextFrag;\n          } else {\n            frag = null;\n          }\n        }\n      }\n    }\n    return frag;\n  }\n  synchronizeToLiveEdge(levelDetails) {\n    const {\n      config,\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const liveSyncPosition = this.hls.liveSyncPosition;\n    const currentTime = media.currentTime;\n    const start = levelDetails.fragments[0].start;\n    const end = levelDetails.edge;\n    const withinSlidingWindow = currentTime >= start - config.maxFragLookUpTolerance && currentTime <= end;\n    // Continue if we can seek forward to sync position or if current time is outside of sliding window\n    if (liveSyncPosition !== null && media.duration > liveSyncPosition && (currentTime < liveSyncPosition || !withinSlidingWindow)) {\n      // Continue if buffer is starving or if current time is behind max latency\n      const maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;\n      if (!withinSlidingWindow && media.readyState < 4 || currentTime < end - maxLatency) {\n        if (!this.loadedmetadata) {\n          this.nextLoadPosition = liveSyncPosition;\n        }\n        // Only seek if ready and there is not a significant forward buffer available for playback\n        if (media.readyState) {\n          this.warn(`Playback: ${currentTime.toFixed(3)} is located too far from the end of live sliding playlist: ${end}, reset currentTime to : ${liveSyncPosition.toFixed(3)}`);\n          media.currentTime = liveSyncPosition;\n        }\n      }\n    }\n  }\n  alignPlaylists(details, previousDetails, switchDetails) {\n    // FIXME: If not for `shouldAlignOnDiscontinuities` requiring fragPrevious.cc,\n    //  this could all go in level-helper mergeDetails()\n    const length = details.fragments.length;\n    if (!length) {\n      this.warn(`No fragments in live playlist`);\n      return 0;\n    }\n    const slidingStart = details.fragments[0].start;\n    const firstLevelLoad = !previousDetails;\n    const aligned = details.alignedSliding && isFiniteNumber(slidingStart);\n    if (firstLevelLoad || !aligned && !slidingStart) {\n      const {\n        fragPrevious\n      } = this;\n      alignStream(fragPrevious, switchDetails, details);\n      const alignedSlidingStart = details.fragments[0].start;\n      this.log(`Live playlist sliding: ${alignedSlidingStart.toFixed(2)} start-sn: ${previousDetails ? previousDetails.startSN : 'na'}->${details.startSN} prev-sn: ${fragPrevious ? fragPrevious.sn : 'na'} fragments: ${length}`);\n      return alignedSlidingStart;\n    }\n    return slidingStart;\n  }\n  waitForCdnTuneIn(details) {\n    // Wait for Low-Latency CDN Tune-in to get an updated playlist\n    const advancePartLimit = 3;\n    return details.live && details.canBlockReload && details.partTarget && details.tuneInGoal > Math.max(details.partHoldBack, details.partTarget * advancePartLimit);\n  }\n  setStartPosition(details, sliding) {\n    // compute start position if set to -1. use it straight away if value is defined\n    let startPosition = this.startPosition;\n    if (startPosition < sliding) {\n      startPosition = -1;\n    }\n    if (startPosition === -1 || this.lastCurrentTime === -1) {\n      // Use Playlist EXT-X-START:TIME-OFFSET when set\n      // Prioritize Multivariant Playlist offset so that main, audio, and subtitle stream-controller start times match\n      const offsetInMultivariantPlaylist = this.startTimeOffset !== null;\n      const startTimeOffset = offsetInMultivariantPlaylist ? this.startTimeOffset : details.startTimeOffset;\n      if (startTimeOffset !== null && isFiniteNumber(startTimeOffset)) {\n        startPosition = sliding + startTimeOffset;\n        if (startTimeOffset < 0) {\n          startPosition += details.totalduration;\n        }\n        startPosition = Math.min(Math.max(sliding, startPosition), sliding + details.totalduration);\n        this.log(`Start time offset ${startTimeOffset} found in ${offsetInMultivariantPlaylist ? 'multivariant' : 'media'} playlist, adjust startPosition to ${startPosition}`);\n        this.startPosition = startPosition;\n      } else if (details.live) {\n        // Leave this.startPosition at -1, so that we can use `getInitialLiveFragment` logic when startPosition has\n        // not been specified via the config or an as an argument to startLoad (#3736).\n        startPosition = this.hls.liveSyncPosition || sliding;\n      } else {\n        this.startPosition = startPosition = 0;\n      }\n      this.lastCurrentTime = startPosition;\n    }\n    this.nextLoadPosition = startPosition;\n  }\n  getLoadPosition() {\n    const {\n      media\n    } = this;\n    // if we have not yet loaded any fragment, start loading from start position\n    let pos = 0;\n    if (this.loadedmetadata && media) {\n      pos = media.currentTime;\n    } else if (this.nextLoadPosition) {\n      pos = this.nextLoadPosition;\n    }\n    return pos;\n  }\n  handleFragLoadAborted(frag, part) {\n    if (this.transmuxer && frag.sn !== 'initSegment' && frag.stats.aborted) {\n      this.warn(`Fragment ${frag.sn}${part ? ' part ' + part.index : ''} of level ${frag.level} was aborted`);\n      this.resetFragmentLoading(frag);\n    }\n  }\n  resetFragmentLoading(frag) {\n    if (!this.fragCurrent || !this.fragContextChanged(frag) && this.state !== State.FRAG_LOADING_WAITING_RETRY) {\n      this.state = State.IDLE;\n    }\n  }\n  onFragmentOrKeyLoadError(filterType, data) {\n    if (data.chunkMeta && !data.frag) {\n      const context = this.getCurrentContext(data.chunkMeta);\n      if (context) {\n        data.frag = context.frag;\n      }\n    }\n    const frag = data.frag;\n    // Handle frag error related to caller's filterType\n    if (!frag || frag.type !== filterType || !this.levels) {\n      return;\n    }\n    if (this.fragContextChanged(frag)) {\n      var _this$fragCurrent2;\n      this.warn(`Frag load error must match current frag to retry ${frag.url} > ${(_this$fragCurrent2 = this.fragCurrent) == null ? void 0 : _this$fragCurrent2.url}`);\n      return;\n    }\n    const gapTagEncountered = data.details === ErrorDetails.FRAG_GAP;\n    if (gapTagEncountered) {\n      this.fragmentTracker.fragBuffered(frag, true);\n    }\n    // keep retrying until the limit will be reached\n    const errorAction = data.errorAction;\n    const {\n      action,\n      retryCount = 0,\n      retryConfig\n    } = errorAction || {};\n    if (errorAction && action === NetworkErrorAction.RetryRequest && retryConfig) {\n      this.resetStartWhenNotLoaded(this.levelLastLoaded);\n      const delay = getRetryDelay(retryConfig, retryCount);\n      this.warn(`Fragment ${frag.sn} of ${filterType} ${frag.level} errored with ${data.details}, retrying loading ${retryCount + 1}/${retryConfig.maxNumRetry} in ${delay}ms`);\n      errorAction.resolved = true;\n      this.retryDate = self.performance.now() + delay;\n      this.state = State.FRAG_LOADING_WAITING_RETRY;\n    } else if (retryConfig && errorAction) {\n      this.resetFragmentErrors(filterType);\n      if (retryCount < retryConfig.maxNumRetry) {\n        // Network retry is skipped when level switch is preferred\n        if (!gapTagEncountered && action !== NetworkErrorAction.RemoveAlternatePermanently) {\n          errorAction.resolved = true;\n        }\n      } else {\n        logger.warn(`${data.details} reached or exceeded max retry (${retryCount})`);\n        return;\n      }\n    } else if ((errorAction == null ? void 0 : errorAction.action) === NetworkErrorAction.SendAlternateToPenaltyBox) {\n      this.state = State.WAITING_LEVEL;\n    } else {\n      this.state = State.ERROR;\n    }\n    // Perform next async tick sooner to speed up error action resolution\n    this.tickImmediate();\n  }\n  reduceLengthAndFlushBuffer(data) {\n    // if in appending state\n    if (this.state === State.PARSING || this.state === State.PARSED) {\n      const frag = data.frag;\n      const playlistType = data.parent;\n      const bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);\n      // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end\n      // reduce max buf len if current position is buffered\n      const buffered = bufferedInfo && bufferedInfo.len > 0.5;\n      if (buffered) {\n        this.reduceMaxBufferLength(bufferedInfo.len, (frag == null ? void 0 : frag.duration) || 10);\n      }\n      const flushBuffer = !buffered;\n      if (flushBuffer) {\n        // current position is not buffered, but browser is still complaining about buffer full error\n        // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\n        // in that case flush the whole audio buffer to recover\n        this.warn(`Buffer full error while media.currentTime is not buffered, flush ${playlistType} buffer`);\n      }\n      if (frag) {\n        this.fragmentTracker.removeFragment(frag);\n        this.nextLoadPosition = frag.start;\n      }\n      this.resetLoadingState();\n      return flushBuffer;\n    }\n    return false;\n  }\n  resetFragmentErrors(filterType) {\n    if (filterType === PlaylistLevelType.AUDIO) {\n      // Reset current fragment since audio track audio is essential and may not have a fail-over track\n      this.fragCurrent = null;\n    }\n    // Fragment errors that result in a level switch or redundant fail-over\n    // should reset the stream controller state to idle\n    if (!this.loadedmetadata) {\n      this.startFragRequested = false;\n    }\n    if (this.state !== State.STOPPED) {\n      this.state = State.IDLE;\n    }\n  }\n  afterBufferFlushed(media, bufferType, playlistType) {\n    if (!media) {\n      return;\n    }\n    // After successful buffer flushing, filter flushed fragments from bufferedFrags use mediaBuffered instead of media\n    // (so that we will check against video.buffered ranges in case of alt audio track)\n    const bufferedTimeRanges = BufferHelper.getBuffered(media);\n    this.fragmentTracker.detectEvictedFragments(bufferType, bufferedTimeRanges, playlistType);\n    if (this.state === State.ENDED) {\n      this.resetLoadingState();\n    }\n  }\n  resetLoadingState() {\n    this.log('Reset loading state');\n    this.fragCurrent = null;\n    this.fragPrevious = null;\n    this.state = State.IDLE;\n  }\n  resetStartWhenNotLoaded(level) {\n    // if loadedmetadata is not set, it means that first frag request failed\n    // in that case, reset startFragRequested flag\n    if (!this.loadedmetadata) {\n      this.startFragRequested = false;\n      const details = level ? level.details : null;\n      if (details != null && details.live) {\n        // Update the start position and return to IDLE to recover live start\n        this.startPosition = -1;\n        this.setStartPosition(details, 0);\n        this.resetLoadingState();\n      } else {\n        this.nextLoadPosition = this.startPosition;\n      }\n    }\n  }\n  resetWhenMissingContext(chunkMeta) {\n    this.warn(`The loading context changed while buffering fragment ${chunkMeta.sn} of level ${chunkMeta.level}. This chunk will not be buffered.`);\n    this.removeUnbufferedFrags();\n    this.resetStartWhenNotLoaded(this.levelLastLoaded);\n    this.resetLoadingState();\n  }\n  removeUnbufferedFrags(start = 0) {\n    this.fragmentTracker.removeFragmentsInRange(start, Infinity, this.playlistType, false, true);\n  }\n  updateLevelTiming(frag, part, level, partial) {\n    var _this$transmuxer;\n    const details = level.details;\n    if (!details) {\n      this.warn('level.details undefined');\n      return;\n    }\n    const parsed = Object.keys(frag.elementaryStreams).reduce((result, type) => {\n      const info = frag.elementaryStreams[type];\n      if (info) {\n        const parsedDuration = info.endPTS - info.startPTS;\n        if (parsedDuration <= 0) {\n          // Destroy the transmuxer after it's next time offset failed to advance because duration was <= 0.\n          // The new transmuxer will be configured with a time offset matching the next fragment start,\n          // preventing the timeline from shifting.\n          this.warn(`Could not parse fragment ${frag.sn} ${type} duration reliably (${parsedDuration})`);\n          return result || false;\n        }\n        const drift = partial ? 0 : updateFragPTSDTS(details, frag, info.startPTS, info.endPTS, info.startDTS, info.endDTS);\n        this.hls.trigger(Events.LEVEL_PTS_UPDATED, {\n          details,\n          level,\n          drift,\n          type,\n          frag,\n          start: info.startPTS,\n          end: info.endPTS\n        });\n        return true;\n      }\n      return result;\n    }, false);\n    if (!parsed && ((_this$transmuxer = this.transmuxer) == null ? void 0 : _this$transmuxer.error) === null) {\n      const error = new Error(`Found no media in fragment ${frag.sn} of level ${frag.level} resetting transmuxer to fallback to playlist timing`);\n      if (level.fragmentError === 0) {\n        // Mark and track the odd empty segment as a gap to avoid reloading\n        level.fragmentError++;\n        frag.gap = true;\n        this.fragmentTracker.removeFragment(frag);\n        this.fragmentTracker.fragBuffered(frag, true);\n      }\n      this.warn(error.message);\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.FRAG_PARSING_ERROR,\n        fatal: false,\n        error,\n        frag,\n        reason: `Found no media in msn ${frag.sn} of level \"${level.url}\"`\n      });\n      if (!this.hls) {\n        return;\n      }\n      this.resetTransmuxer();\n      // For this error fallthrough. Marking parsed will allow advancing to next fragment.\n    }\n    this.state = State.PARSED;\n    this.hls.trigger(Events.FRAG_PARSED, {\n      frag,\n      part\n    });\n  }\n  resetTransmuxer() {\n    if (this.transmuxer) {\n      this.transmuxer.destroy();\n      this.transmuxer = null;\n    }\n  }\n  recoverWorkerError(data) {\n    if (data.event === 'demuxerWorker') {\n      this.fragmentTracker.removeAllFragments();\n      this.resetTransmuxer();\n      this.resetStartWhenNotLoaded(this.levelLastLoaded);\n      this.resetLoadingState();\n    }\n  }\n  set state(nextState) {\n    const previousState = this._state;\n    if (previousState !== nextState) {\n      this._state = nextState;\n      this.log(`${previousState}->${nextState}`);\n    }\n  }\n  get state() {\n    return this._state;\n  }\n}\n\nclass ChunkCache {\n  constructor() {\n    this.chunks = [];\n    this.dataLength = 0;\n  }\n  push(chunk) {\n    this.chunks.push(chunk);\n    this.dataLength += chunk.length;\n  }\n  flush() {\n    const {\n      chunks,\n      dataLength\n    } = this;\n    let result;\n    if (!chunks.length) {\n      return new Uint8Array(0);\n    } else if (chunks.length === 1) {\n      result = chunks[0];\n    } else {\n      result = concatUint8Arrays(chunks, dataLength);\n    }\n    this.reset();\n    return result;\n  }\n  reset() {\n    this.chunks.length = 0;\n    this.dataLength = 0;\n  }\n}\nfunction concatUint8Arrays(chunks, dataLength) {\n  const result = new Uint8Array(dataLength);\n  let offset = 0;\n  for (let i = 0; i < chunks.length; i++) {\n    const chunk = chunks[i];\n    result.set(chunk, offset);\n    offset += chunk.length;\n  }\n  return result;\n}\n\n// ensure the worker ends up in the bundle\n// If the worker should not be included this gets aliased to empty.js\nfunction hasUMDWorker() {\n  return typeof __HLS_WORKER_BUNDLE__ === 'function';\n}\nfunction injectWorker() {\n  const blob = new self.Blob([`var exports={};var module={exports:exports};function define(f){f()};define.amd=true;(${__HLS_WORKER_BUNDLE__.toString()})(true);`], {\n    type: 'text/javascript'\n  });\n  const objectURL = self.URL.createObjectURL(blob);\n  const worker = new self.Worker(objectURL);\n  return {\n    worker,\n    objectURL\n  };\n}\nfunction loadWorker(path) {\n  const scriptURL = new self.URL(path, self.location.href).href;\n  const worker = new self.Worker(scriptURL);\n  return {\n    worker,\n    scriptURL\n  };\n}\n\nfunction dummyTrack(type = '', inputTimeScale = 90000) {\n  return {\n    type,\n    id: -1,\n    pid: -1,\n    inputTimeScale,\n    sequenceNumber: -1,\n    samples: [],\n    dropped: 0\n  };\n}\n\nclass BaseAudioDemuxer {\n  constructor() {\n    this._audioTrack = void 0;\n    this._id3Track = void 0;\n    this.frameIndex = 0;\n    this.cachedData = null;\n    this.basePTS = null;\n    this.initPTS = null;\n    this.lastPTS = null;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    this._id3Track = {\n      type: 'id3',\n      id: 3,\n      pid: -1,\n      inputTimeScale: 90000,\n      sequenceNumber: 0,\n      samples: [],\n      dropped: 0\n    };\n  }\n  resetTimeStamp(deaultTimestamp) {\n    this.initPTS = deaultTimestamp;\n    this.resetContiguity();\n  }\n  resetContiguity() {\n    this.basePTS = null;\n    this.lastPTS = null;\n    this.frameIndex = 0;\n  }\n  canParse(data, offset) {\n    return false;\n  }\n  appendFrame(track, data, offset) {}\n\n  // feed incoming data to the front of the parsing pipeline\n  demux(data, timeOffset) {\n    if (this.cachedData) {\n      data = appendUint8Array(this.cachedData, data);\n      this.cachedData = null;\n    }\n    let id3Data = getID3Data(data, 0);\n    let offset = id3Data ? id3Data.length : 0;\n    let lastDataIndex;\n    const track = this._audioTrack;\n    const id3Track = this._id3Track;\n    const timestamp = id3Data ? getTimeStamp(id3Data) : undefined;\n    const length = data.length;\n    if (this.basePTS === null || this.frameIndex === 0 && isFiniteNumber(timestamp)) {\n      this.basePTS = initPTSFn(timestamp, timeOffset, this.initPTS);\n      this.lastPTS = this.basePTS;\n    }\n    if (this.lastPTS === null) {\n      this.lastPTS = this.basePTS;\n    }\n\n    // more expressive than alternative: id3Data?.length\n    if (id3Data && id3Data.length > 0) {\n      id3Track.samples.push({\n        pts: this.lastPTS,\n        dts: this.lastPTS,\n        data: id3Data,\n        type: MetadataSchema.audioId3,\n        duration: Number.POSITIVE_INFINITY\n      });\n    }\n    while (offset < length) {\n      if (this.canParse(data, offset)) {\n        const frame = this.appendFrame(track, data, offset);\n        if (frame) {\n          this.frameIndex++;\n          this.lastPTS = frame.sample.pts;\n          offset += frame.length;\n          lastDataIndex = offset;\n        } else {\n          offset = length;\n        }\n      } else if (canParse$2(data, offset)) {\n        // after a ID3.canParse, a call to ID3.getID3Data *should* always returns some data\n        id3Data = getID3Data(data, offset);\n        id3Track.samples.push({\n          pts: this.lastPTS,\n          dts: this.lastPTS,\n          data: id3Data,\n          type: MetadataSchema.audioId3,\n          duration: Number.POSITIVE_INFINITY\n        });\n        offset += id3Data.length;\n        lastDataIndex = offset;\n      } else {\n        offset++;\n      }\n      if (offset === length && lastDataIndex !== length) {\n        const partialData = sliceUint8(data, lastDataIndex);\n        if (this.cachedData) {\n          this.cachedData = appendUint8Array(this.cachedData, partialData);\n        } else {\n          this.cachedData = partialData;\n        }\n      }\n    }\n    return {\n      audioTrack: track,\n      videoTrack: dummyTrack(),\n      id3Track,\n      textTrack: dummyTrack()\n    };\n  }\n  demuxSampleAes(data, keyData, timeOffset) {\n    return Promise.reject(new Error(`[${this}] This demuxer does not support Sample-AES decryption`));\n  }\n  flush(timeOffset) {\n    // Parse cache in case of remaining frames.\n    const cachedData = this.cachedData;\n    if (cachedData) {\n      this.cachedData = null;\n      this.demux(cachedData, 0);\n    }\n    return {\n      audioTrack: this._audioTrack,\n      videoTrack: dummyTrack(),\n      id3Track: this._id3Track,\n      textTrack: dummyTrack()\n    };\n  }\n  destroy() {}\n}\n\n/**\n * Initialize PTS\n * <p>\n *    use timestamp unless it is undefined, NaN or Infinity\n * </p>\n */\nconst initPTSFn = (timestamp, timeOffset, initPTS) => {\n  if (isFiniteNumber(timestamp)) {\n    return timestamp * 90;\n  }\n  const init90kHz = initPTS ? initPTS.baseTime * 90000 / initPTS.timescale : 0;\n  return timeOffset * 90000 + init90kHz;\n};\n\n/**\n * ADTS parser helper\n * @link https://wiki.multimedia.cx/index.php?title=ADTS\n */\nfunction getAudioConfig(observer, data, offset, audioCodec) {\n  let adtsObjectType;\n  let adtsExtensionSamplingIndex;\n  let adtsChannelConfig;\n  let config;\n  const userAgent = navigator.userAgent.toLowerCase();\n  const manifestCodec = audioCodec;\n  const adtsSamplingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n  // byte 2\n  adtsObjectType = ((data[offset + 2] & 0xc0) >>> 6) + 1;\n  const adtsSamplingIndex = (data[offset + 2] & 0x3c) >>> 2;\n  if (adtsSamplingIndex > adtsSamplingRates.length - 1) {\n    const error = new Error(`invalid ADTS sampling index:${adtsSamplingIndex}`);\n    observer.emit(Events.ERROR, Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.FRAG_PARSING_ERROR,\n      fatal: true,\n      error,\n      reason: error.message\n    });\n    return;\n  }\n  adtsChannelConfig = (data[offset + 2] & 0x01) << 2;\n  // byte 3\n  adtsChannelConfig |= (data[offset + 3] & 0xc0) >>> 6;\n  logger.log(`manifest codec:${audioCodec}, ADTS type:${adtsObjectType}, samplingIndex:${adtsSamplingIndex}`);\n  // firefox: freq less than 24kHz = AAC SBR (HE-AAC)\n  if (/firefox/i.test(userAgent)) {\n    if (adtsSamplingIndex >= 6) {\n      adtsObjectType = 5;\n      config = new Array(4);\n      // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n      // there is a factor 2 between frame sample rate and output sample rate\n      // multiply frequency by 2 (see table below, equivalent to substract 3)\n      adtsExtensionSamplingIndex = adtsSamplingIndex - 3;\n    } else {\n      adtsObjectType = 2;\n      config = new Array(2);\n      adtsExtensionSamplingIndex = adtsSamplingIndex;\n    }\n    // Android : always use AAC\n  } else if (userAgent.indexOf('android') !== -1) {\n    adtsObjectType = 2;\n    config = new Array(2);\n    adtsExtensionSamplingIndex = adtsSamplingIndex;\n  } else {\n    /*  for other browsers (Chrome/Vivaldi/Opera ...)\n        always force audio type to be HE-AAC SBR, as some browsers do not support audio codec switch properly (like Chrome ...)\n    */\n    adtsObjectType = 5;\n    config = new Array(4);\n    // if (manifest codec is HE-AAC or HE-AACv2) OR (manifest codec not specified AND frequency less than 24kHz)\n    if (audioCodec && (audioCodec.indexOf('mp4a.40.29') !== -1 || audioCodec.indexOf('mp4a.40.5') !== -1) || !audioCodec && adtsSamplingIndex >= 6) {\n      // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n      // there is a factor 2 between frame sample rate and output sample rate\n      // multiply frequency by 2 (see table below, equivalent to substract 3)\n      adtsExtensionSamplingIndex = adtsSamplingIndex - 3;\n    } else {\n      // if (manifest codec is AAC) AND (frequency less than 24kHz AND nb channel is 1) OR (manifest codec not specified and mono audio)\n      // Chrome fails to play back with low frequency AAC LC mono when initialized with HE-AAC.  This is not a problem with stereo.\n      if (audioCodec && audioCodec.indexOf('mp4a.40.2') !== -1 && (adtsSamplingIndex >= 6 && adtsChannelConfig === 1 || /vivaldi/i.test(userAgent)) || !audioCodec && adtsChannelConfig === 1) {\n        adtsObjectType = 2;\n        config = new Array(2);\n      }\n      adtsExtensionSamplingIndex = adtsSamplingIndex;\n    }\n  }\n  /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config\n      ISO 14496-3 (AAC).pdf - Table 1.13  Syntax of AudioSpecificConfig()\n    Audio Profile / Audio Object Type\n    0: Null\n    1: AAC Main\n    2: AAC LC (Low Complexity)\n    3: AAC SSR (Scalable Sample Rate)\n    4: AAC LTP (Long Term Prediction)\n    5: SBR (Spectral Band Replication)\n    6: AAC Scalable\n   sampling freq\n    0: 96000 Hz\n    1: 88200 Hz\n    2: 64000 Hz\n    3: 48000 Hz\n    4: 44100 Hz\n    5: 32000 Hz\n    6: 24000 Hz\n    7: 22050 Hz\n    8: 16000 Hz\n    9: 12000 Hz\n    10: 11025 Hz\n    11: 8000 Hz\n    12: 7350 Hz\n    13: Reserved\n    14: Reserved\n    15: frequency is written explictly\n    Channel Configurations\n    These are the channel configurations:\n    0: Defined in AOT Specifc Config\n    1: 1 channel: front-center\n    2: 2 channels: front-left, front-right\n  */\n  // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1\n  config[0] = adtsObjectType << 3;\n  // samplingFrequencyIndex\n  config[0] |= (adtsSamplingIndex & 0x0e) >> 1;\n  config[1] |= (adtsSamplingIndex & 0x01) << 7;\n  // channelConfiguration\n  config[1] |= adtsChannelConfig << 3;\n  if (adtsObjectType === 5) {\n    // adtsExtensionSamplingIndex\n    config[1] |= (adtsExtensionSamplingIndex & 0x0e) >> 1;\n    config[2] = (adtsExtensionSamplingIndex & 0x01) << 7;\n    // adtsObjectType (force to 2, chrome is checking that object type is less than 5 ???\n    //    https://chromium.googlesource.com/chromium/src.git/+/master/media/formats/mp4/aac.cc\n    config[2] |= 2 << 2;\n    config[3] = 0;\n  }\n  return {\n    config,\n    samplerate: adtsSamplingRates[adtsSamplingIndex],\n    channelCount: adtsChannelConfig,\n    codec: 'mp4a.40.' + adtsObjectType,\n    manifestCodec\n  };\n}\nfunction isHeaderPattern$1(data, offset) {\n  return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;\n}\nfunction getHeaderLength(data, offset) {\n  return data[offset + 1] & 0x01 ? 7 : 9;\n}\nfunction getFullFrameLength(data, offset) {\n  return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xe0) >>> 5;\n}\nfunction canGetFrameLength(data, offset) {\n  return offset + 5 < data.length;\n}\nfunction isHeader$1(data, offset) {\n  // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n  // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n  // More info https://wiki.multimedia.cx/index.php?title=ADTS\n  return offset + 1 < data.length && isHeaderPattern$1(data, offset);\n}\nfunction canParse$1(data, offset) {\n  return canGetFrameLength(data, offset) && isHeaderPattern$1(data, offset) && getFullFrameLength(data, offset) <= data.length - offset;\n}\nfunction probe$1(data, offset) {\n  // same as isHeader but we also check that ADTS frame follows last ADTS frame\n  // or end of data is reached\n  if (isHeader$1(data, offset)) {\n    // ADTS header Length\n    const headerLength = getHeaderLength(data, offset);\n    if (offset + headerLength >= data.length) {\n      return false;\n    }\n    // ADTS frame Length\n    const frameLength = getFullFrameLength(data, offset);\n    if (frameLength <= headerLength) {\n      return false;\n    }\n    const newOffset = offset + frameLength;\n    return newOffset === data.length || isHeader$1(data, newOffset);\n  }\n  return false;\n}\nfunction initTrackConfig(track, observer, data, offset, audioCodec) {\n  if (!track.samplerate) {\n    const config = getAudioConfig(observer, data, offset, audioCodec);\n    if (!config) {\n      return;\n    }\n    track.config = config.config;\n    track.samplerate = config.samplerate;\n    track.channelCount = config.channelCount;\n    track.codec = config.codec;\n    track.manifestCodec = config.manifestCodec;\n    logger.log(`parsed codec:${track.codec}, rate:${config.samplerate}, channels:${config.channelCount}`);\n  }\n}\nfunction getFrameDuration(samplerate) {\n  return 1024 * 90000 / samplerate;\n}\nfunction parseFrameHeader(data, offset) {\n  // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header\n  const headerLength = getHeaderLength(data, offset);\n  if (offset + headerLength <= data.length) {\n    // retrieve frame size\n    const frameLength = getFullFrameLength(data, offset) - headerLength;\n    if (frameLength > 0) {\n      // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}`);\n      return {\n        headerLength,\n        frameLength\n      };\n    }\n  }\n}\nfunction appendFrame$2(track, data, offset, pts, frameIndex) {\n  const frameDuration = getFrameDuration(track.samplerate);\n  const stamp = pts + frameIndex * frameDuration;\n  const header = parseFrameHeader(data, offset);\n  let unit;\n  if (header) {\n    const {\n      frameLength,\n      headerLength\n    } = header;\n    const _length = headerLength + frameLength;\n    const missing = Math.max(0, offset + _length - data.length);\n    // logger.log(`AAC frame ${frameIndex}, pts:${stamp} length@offset/total: ${frameLength}@${offset+headerLength}/${data.byteLength} missing: ${missing}`);\n    if (missing) {\n      unit = new Uint8Array(_length - headerLength);\n      unit.set(data.subarray(offset + headerLength, data.length), 0);\n    } else {\n      unit = data.subarray(offset + headerLength, offset + _length);\n    }\n    const _sample = {\n      unit,\n      pts: stamp\n    };\n    if (!missing) {\n      track.samples.push(_sample);\n    }\n    return {\n      sample: _sample,\n      length: _length,\n      missing\n    };\n  }\n  // overflow incomplete header\n  const length = data.length - offset;\n  unit = new Uint8Array(length);\n  unit.set(data.subarray(offset, data.length), 0);\n  const sample = {\n    unit,\n    pts: stamp\n  };\n  return {\n    sample,\n    length,\n    missing: -1\n  };\n}\n\n/**\n *  MPEG parser helper\n */\n\nlet chromeVersion$1 = null;\nconst BitratesMap = [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160];\nconst SamplingRateMap = [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000];\nconst SamplesCoefficients = [\n// MPEG 2.5\n[0,\n// Reserved\n72,\n// Layer3\n144,\n// Layer2\n12 // Layer1\n],\n// Reserved\n[0,\n// Reserved\n0,\n// Layer3\n0,\n// Layer2\n0 // Layer1\n],\n// MPEG 2\n[0,\n// Reserved\n72,\n// Layer3\n144,\n// Layer2\n12 // Layer1\n],\n// MPEG 1\n[0,\n// Reserved\n144,\n// Layer3\n144,\n// Layer2\n12 // Layer1\n]];\nconst BytesInSlot = [0,\n// Reserved\n1,\n// Layer3\n1,\n// Layer2\n4 // Layer1\n];\nfunction appendFrame$1(track, data, offset, pts, frameIndex) {\n  // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference\n  if (offset + 24 > data.length) {\n    return;\n  }\n  const header = parseHeader(data, offset);\n  if (header && offset + header.frameLength <= data.length) {\n    const frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;\n    const stamp = pts + frameIndex * frameDuration;\n    const sample = {\n      unit: data.subarray(offset, offset + header.frameLength),\n      pts: stamp,\n      dts: stamp\n    };\n    track.config = [];\n    track.channelCount = header.channelCount;\n    track.samplerate = header.sampleRate;\n    track.samples.push(sample);\n    return {\n      sample,\n      length: header.frameLength,\n      missing: 0\n    };\n  }\n}\nfunction parseHeader(data, offset) {\n  const mpegVersion = data[offset + 1] >> 3 & 3;\n  const mpegLayer = data[offset + 1] >> 1 & 3;\n  const bitRateIndex = data[offset + 2] >> 4 & 15;\n  const sampleRateIndex = data[offset + 2] >> 2 & 3;\n  if (mpegVersion !== 1 && bitRateIndex !== 0 && bitRateIndex !== 15 && sampleRateIndex !== 3) {\n    const paddingBit = data[offset + 2] >> 1 & 1;\n    const channelMode = data[offset + 3] >> 6;\n    const columnInBitrates = mpegVersion === 3 ? 3 - mpegLayer : mpegLayer === 3 ? 3 : 4;\n    const bitRate = BitratesMap[columnInBitrates * 14 + bitRateIndex - 1] * 1000;\n    const columnInSampleRates = mpegVersion === 3 ? 0 : mpegVersion === 2 ? 1 : 2;\n    const sampleRate = SamplingRateMap[columnInSampleRates * 3 + sampleRateIndex];\n    const channelCount = channelMode === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)\n    const sampleCoefficient = SamplesCoefficients[mpegVersion][mpegLayer];\n    const bytesInSlot = BytesInSlot[mpegLayer];\n    const samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;\n    const frameLength = Math.floor(sampleCoefficient * bitRate / sampleRate + paddingBit) * bytesInSlot;\n    if (chromeVersion$1 === null) {\n      const userAgent = navigator.userAgent || '';\n      const result = userAgent.match(/Chrome\\/(\\d+)/i);\n      chromeVersion$1 = result ? parseInt(result[1]) : 0;\n    }\n    const needChromeFix = !!chromeVersion$1 && chromeVersion$1 <= 87;\n    if (needChromeFix && mpegLayer === 2 && bitRate >= 224000 && channelMode === 0) {\n      // Work around bug in Chromium by setting channelMode to dual-channel (01) instead of stereo (00)\n      data[offset + 3] = data[offset + 3] | 0x80;\n    }\n    return {\n      sampleRate,\n      channelCount,\n      frameLength,\n      samplesPerFrame\n    };\n  }\n}\nfunction isHeaderPattern(data, offset) {\n  return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;\n}\nfunction isHeader(data, offset) {\n  // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n  // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n  // More info http://www.mp3-tech.org/programmer/frame_header.html\n  return offset + 1 < data.length && isHeaderPattern(data, offset);\n}\nfunction canParse(data, offset) {\n  const headerSize = 4;\n  return isHeaderPattern(data, offset) && headerSize <= data.length - offset;\n}\nfunction probe(data, offset) {\n  // same as isHeader but we also check that MPEG frame follows last MPEG frame\n  // or end of data is reached\n  if (offset + 1 < data.length && isHeaderPattern(data, offset)) {\n    // MPEG header Length\n    const headerLength = 4;\n    // MPEG frame Length\n    const header = parseHeader(data, offset);\n    let frameLength = headerLength;\n    if (header != null && header.frameLength) {\n      frameLength = header.frameLength;\n    }\n    const newOffset = offset + frameLength;\n    return newOffset === data.length || isHeader(data, newOffset);\n  }\n  return false;\n}\n\n/**\n * AAC demuxer\n */\nclass AACDemuxer extends BaseAudioDemuxer {\n  constructor(observer, config) {\n    super();\n    this.observer = void 0;\n    this.config = void 0;\n    this.observer = observer;\n    this.config = config;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);\n    this._audioTrack = {\n      container: 'audio/adts',\n      type: 'audio',\n      id: 2,\n      pid: -1,\n      sequenceNumber: 0,\n      segmentCodec: 'aac',\n      samples: [],\n      manifestCodec: audioCodec,\n      duration: trackDuration,\n      inputTimeScale: 90000,\n      dropped: 0\n    };\n  }\n\n  // Source for probe info - https://wiki.multimedia.cx/index.php?title=ADTS\n  static probe(data) {\n    if (!data) {\n      return false;\n    }\n\n    // Check for the ADTS sync word\n    // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n    // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n    // More info https://wiki.multimedia.cx/index.php?title=ADTS\n    const id3Data = getID3Data(data, 0);\n    let offset = (id3Data == null ? void 0 : id3Data.length) || 0;\n    if (probe(data, offset)) {\n      return false;\n    }\n    for (let length = data.length; offset < length; offset++) {\n      if (probe$1(data, offset)) {\n        logger.log('ADTS sync word found !');\n        return true;\n      }\n    }\n    return false;\n  }\n  canParse(data, offset) {\n    return canParse$1(data, offset);\n  }\n  appendFrame(track, data, offset) {\n    initTrackConfig(track, this.observer, data, offset, track.manifestCodec);\n    const frame = appendFrame$2(track, data, offset, this.basePTS, this.frameIndex);\n    if (frame && frame.missing === 0) {\n      return frame;\n    }\n  }\n}\n\nconst emsgSchemePattern = /\\/emsg[-/]ID3/i;\nclass MP4Demuxer {\n  constructor(observer, config) {\n    this.remainderData = null;\n    this.timeOffset = 0;\n    this.config = void 0;\n    this.videoTrack = void 0;\n    this.audioTrack = void 0;\n    this.id3Track = void 0;\n    this.txtTrack = void 0;\n    this.config = config;\n  }\n  resetTimeStamp() {}\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    const videoTrack = this.videoTrack = dummyTrack('video', 1);\n    const audioTrack = this.audioTrack = dummyTrack('audio', 1);\n    const captionTrack = this.txtTrack = dummyTrack('text', 1);\n    this.id3Track = dummyTrack('id3', 1);\n    this.timeOffset = 0;\n    if (!(initSegment != null && initSegment.byteLength)) {\n      return;\n    }\n    const initData = parseInitSegment(initSegment);\n    if (initData.video) {\n      const {\n        id,\n        timescale,\n        codec\n      } = initData.video;\n      videoTrack.id = id;\n      videoTrack.timescale = captionTrack.timescale = timescale;\n      videoTrack.codec = codec;\n    }\n    if (initData.audio) {\n      const {\n        id,\n        timescale,\n        codec\n      } = initData.audio;\n      audioTrack.id = id;\n      audioTrack.timescale = timescale;\n      audioTrack.codec = codec;\n    }\n    captionTrack.id = RemuxerTrackIdConfig.text;\n    videoTrack.sampleDuration = 0;\n    videoTrack.duration = audioTrack.duration = trackDuration;\n  }\n  resetContiguity() {\n    this.remainderData = null;\n  }\n  static probe(data) {\n    return hasMoofData(data);\n  }\n  demux(data, timeOffset) {\n    this.timeOffset = timeOffset;\n    // Load all data into the avc track. The CMAF remuxer will look for the data in the samples object; the rest of the fields do not matter\n    let videoSamples = data;\n    const videoTrack = this.videoTrack;\n    const textTrack = this.txtTrack;\n    if (this.config.progressive) {\n      // Split the bytestream into two ranges: one encompassing all data up until the start of the last moof, and everything else.\n      // This is done to guarantee that we're sending valid data to MSE - when demuxing progressively, we have no guarantee\n      // that the fetch loader gives us flush moof+mdat pairs. If we push jagged data to MSE, it will throw an exception.\n      if (this.remainderData) {\n        videoSamples = appendUint8Array(this.remainderData, data);\n      }\n      const segmentedData = segmentValidRange(videoSamples);\n      this.remainderData = segmentedData.remainder;\n      videoTrack.samples = segmentedData.valid || new Uint8Array();\n    } else {\n      videoTrack.samples = videoSamples;\n    }\n    const id3Track = this.extractID3Track(videoTrack, timeOffset);\n    textTrack.samples = parseSamples(timeOffset, videoTrack);\n    return {\n      videoTrack,\n      audioTrack: this.audioTrack,\n      id3Track,\n      textTrack: this.txtTrack\n    };\n  }\n  flush() {\n    const timeOffset = this.timeOffset;\n    const videoTrack = this.videoTrack;\n    const textTrack = this.txtTrack;\n    videoTrack.samples = this.remainderData || new Uint8Array();\n    this.remainderData = null;\n    const id3Track = this.extractID3Track(videoTrack, this.timeOffset);\n    textTrack.samples = parseSamples(timeOffset, videoTrack);\n    return {\n      videoTrack,\n      audioTrack: dummyTrack(),\n      id3Track,\n      textTrack: dummyTrack()\n    };\n  }\n  extractID3Track(videoTrack, timeOffset) {\n    const id3Track = this.id3Track;\n    if (videoTrack.samples.length) {\n      const emsgs = findBox(videoTrack.samples, ['emsg']);\n      if (emsgs) {\n        emsgs.forEach(data => {\n          const emsgInfo = parseEmsg(data);\n          if (emsgSchemePattern.test(emsgInfo.schemeIdUri)) {\n            const pts = isFiniteNumber(emsgInfo.presentationTime) ? emsgInfo.presentationTime / emsgInfo.timeScale : timeOffset + emsgInfo.presentationTimeDelta / emsgInfo.timeScale;\n            let duration = emsgInfo.eventDuration === 0xffffffff ? Number.POSITIVE_INFINITY : emsgInfo.eventDuration / emsgInfo.timeScale;\n            // Safari takes anything <= 0.001 seconds and maps it to Infinity\n            if (duration <= 0.001) {\n              duration = Number.POSITIVE_INFINITY;\n            }\n            const payload = emsgInfo.payload;\n            id3Track.samples.push({\n              data: payload,\n              len: payload.byteLength,\n              dts: pts,\n              pts: pts,\n              type: MetadataSchema.emsg,\n              duration: duration\n            });\n          }\n        });\n      }\n    }\n    return id3Track;\n  }\n  demuxSampleAes(data, keyData, timeOffset) {\n    return Promise.reject(new Error('The MP4 demuxer does not support SAMPLE-AES decryption'));\n  }\n  destroy() {}\n}\n\nconst getAudioBSID = (data, offset) => {\n  // check the bsid to confirm ac-3 | ec-3\n  let bsid = 0;\n  let numBits = 5;\n  offset += numBits;\n  const temp = new Uint32Array(1); // unsigned 32 bit for temporary storage\n  const mask = new Uint32Array(1); // unsigned 32 bit mask value\n  const byte = new Uint8Array(1); // unsigned 8 bit for temporary storage\n  while (numBits > 0) {\n    byte[0] = data[offset];\n    // read remaining bits, upto 8 bits at a time\n    const bits = Math.min(numBits, 8);\n    const shift = 8 - bits;\n    mask[0] = 0xff000000 >>> 24 + shift << shift;\n    temp[0] = (byte[0] & mask[0]) >> shift;\n    bsid = !bsid ? temp[0] : bsid << bits | temp[0];\n    offset += 1;\n    numBits -= bits;\n  }\n  return bsid;\n};\n\nclass AC3Demuxer extends BaseAudioDemuxer {\n  constructor(observer) {\n    super();\n    this.observer = void 0;\n    this.observer = observer;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);\n    this._audioTrack = {\n      container: 'audio/ac-3',\n      type: 'audio',\n      id: 2,\n      pid: -1,\n      sequenceNumber: 0,\n      segmentCodec: 'ac3',\n      samples: [],\n      manifestCodec: audioCodec,\n      duration: trackDuration,\n      inputTimeScale: 90000,\n      dropped: 0\n    };\n  }\n  canParse(data, offset) {\n    return offset + 64 < data.length;\n  }\n  appendFrame(track, data, offset) {\n    const frameLength = appendFrame(track, data, offset, this.basePTS, this.frameIndex);\n    if (frameLength !== -1) {\n      const sample = track.samples[track.samples.length - 1];\n      return {\n        sample,\n        length: frameLength,\n        missing: 0\n      };\n    }\n  }\n  static probe(data) {\n    if (!data) {\n      return false;\n    }\n    const id3Data = getID3Data(data, 0);\n    if (!id3Data) {\n      return false;\n    }\n\n    // look for the ac-3 sync bytes\n    const offset = id3Data.length;\n    if (data[offset] === 0x0b && data[offset + 1] === 0x77 && getTimeStamp(id3Data) !== undefined &&\n    // check the bsid to confirm ac-3\n    getAudioBSID(data, offset) < 16) {\n      return true;\n    }\n    return false;\n  }\n}\nfunction appendFrame(track, data, start, pts, frameIndex) {\n  if (start + 8 > data.length) {\n    return -1; // not enough bytes left\n  }\n  if (data[start] !== 0x0b || data[start + 1] !== 0x77) {\n    return -1; // invalid magic\n  }\n\n  // get sample rate\n  const samplingRateCode = data[start + 4] >> 6;\n  if (samplingRateCode >= 3) {\n    return -1; // invalid sampling rate\n  }\n  const samplingRateMap = [48000, 44100, 32000];\n  const sampleRate = samplingRateMap[samplingRateCode];\n\n  // get frame size\n  const frameSizeCode = data[start + 4] & 0x3f;\n  const frameSizeMap = [64, 69, 96, 64, 70, 96, 80, 87, 120, 80, 88, 120, 96, 104, 144, 96, 105, 144, 112, 121, 168, 112, 122, 168, 128, 139, 192, 128, 140, 192, 160, 174, 240, 160, 175, 240, 192, 208, 288, 192, 209, 288, 224, 243, 336, 224, 244, 336, 256, 278, 384, 256, 279, 384, 320, 348, 480, 320, 349, 480, 384, 417, 576, 384, 418, 576, 448, 487, 672, 448, 488, 672, 512, 557, 768, 512, 558, 768, 640, 696, 960, 640, 697, 960, 768, 835, 1152, 768, 836, 1152, 896, 975, 1344, 896, 976, 1344, 1024, 1114, 1536, 1024, 1115, 1536, 1152, 1253, 1728, 1152, 1254, 1728, 1280, 1393, 1920, 1280, 1394, 1920];\n  const frameLength = frameSizeMap[frameSizeCode * 3 + samplingRateCode] * 2;\n  if (start + frameLength > data.length) {\n    return -1;\n  }\n\n  // get channel count\n  const channelMode = data[start + 6] >> 5;\n  let skipCount = 0;\n  if (channelMode === 2) {\n    skipCount += 2;\n  } else {\n    if (channelMode & 1 && channelMode !== 1) {\n      skipCount += 2;\n    }\n    if (channelMode & 4) {\n      skipCount += 2;\n    }\n  }\n  const lfeon = (data[start + 6] << 8 | data[start + 7]) >> 12 - skipCount & 1;\n  const channelsMap = [2, 1, 2, 3, 3, 4, 4, 5];\n  const channelCount = channelsMap[channelMode] + lfeon;\n\n  // build dac3 box\n  const bsid = data[start + 5] >> 3;\n  const bsmod = data[start + 5] & 7;\n  const config = new Uint8Array([samplingRateCode << 6 | bsid << 1 | bsmod >> 2, (bsmod & 3) << 6 | channelMode << 3 | lfeon << 2 | frameSizeCode >> 4, frameSizeCode << 4 & 0xe0]);\n  const frameDuration = 1536 / sampleRate * 90000;\n  const stamp = pts + frameIndex * frameDuration;\n  const unit = data.subarray(start, start + frameLength);\n  track.config = config;\n  track.channelCount = channelCount;\n  track.samplerate = sampleRate;\n  track.samples.push({\n    unit,\n    pts: stamp\n  });\n  return frameLength;\n}\n\nclass BaseVideoParser {\n  constructor() {\n    this.VideoSample = null;\n  }\n  createVideoSample(key, pts, dts, debug) {\n    return {\n      key,\n      frame: false,\n      pts,\n      dts,\n      units: [],\n      debug,\n      length: 0\n    };\n  }\n  getLastNalUnit(samples) {\n    var _VideoSample;\n    let VideoSample = this.VideoSample;\n    let lastUnit;\n    // try to fallback to previous sample if current one is empty\n    if (!VideoSample || VideoSample.units.length === 0) {\n      VideoSample = samples[samples.length - 1];\n    }\n    if ((_VideoSample = VideoSample) != null && _VideoSample.units) {\n      const units = VideoSample.units;\n      lastUnit = units[units.length - 1];\n    }\n    return lastUnit;\n  }\n  pushAccessUnit(VideoSample, videoTrack) {\n    if (VideoSample.units.length && VideoSample.frame) {\n      // if sample does not have PTS/DTS, patch with last sample PTS/DTS\n      if (VideoSample.pts === undefined) {\n        const samples = videoTrack.samples;\n        const nbSamples = samples.length;\n        if (nbSamples) {\n          const lastSample = samples[nbSamples - 1];\n          VideoSample.pts = lastSample.pts;\n          VideoSample.dts = lastSample.dts;\n        } else {\n          // dropping samples, no timestamp found\n          videoTrack.dropped++;\n          return;\n        }\n      }\n      videoTrack.samples.push(VideoSample);\n    }\n    if (VideoSample.debug.length) {\n      logger.log(VideoSample.pts + '/' + VideoSample.dts + ':' + VideoSample.debug);\n    }\n  }\n}\n\n/**\n * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.\n */\n\nclass ExpGolomb {\n  constructor(data) {\n    this.data = void 0;\n    this.bytesAvailable = void 0;\n    this.word = void 0;\n    this.bitsAvailable = void 0;\n    this.data = data;\n    // the number of bytes left to examine in this.data\n    this.bytesAvailable = data.byteLength;\n    // the current word being examined\n    this.word = 0; // :uint\n    // the number of bits left to examine in the current word\n    this.bitsAvailable = 0; // :uint\n  }\n\n  // ():void\n  loadWord() {\n    const data = this.data;\n    const bytesAvailable = this.bytesAvailable;\n    const position = data.byteLength - bytesAvailable;\n    const workingBytes = new Uint8Array(4);\n    const availableBytes = Math.min(4, bytesAvailable);\n    if (availableBytes === 0) {\n      throw new Error('no bytes available');\n    }\n    workingBytes.set(data.subarray(position, position + availableBytes));\n    this.word = new DataView(workingBytes.buffer).getUint32(0);\n    // track the amount of this.data that has been processed\n    this.bitsAvailable = availableBytes * 8;\n    this.bytesAvailable -= availableBytes;\n  }\n\n  // (count:int):void\n  skipBits(count) {\n    let skipBytes; // :int\n    count = Math.min(count, this.bytesAvailable * 8 + this.bitsAvailable);\n    if (this.bitsAvailable > count) {\n      this.word <<= count;\n      this.bitsAvailable -= count;\n    } else {\n      count -= this.bitsAvailable;\n      skipBytes = count >> 3;\n      count -= skipBytes << 3;\n      this.bytesAvailable -= skipBytes;\n      this.loadWord();\n      this.word <<= count;\n      this.bitsAvailable -= count;\n    }\n  }\n\n  // (size:int):uint\n  readBits(size) {\n    let bits = Math.min(this.bitsAvailable, size); // :uint\n    const valu = this.word >>> 32 - bits; // :uint\n    if (size > 32) {\n      logger.error('Cannot read more than 32 bits at a time');\n    }\n    this.bitsAvailable -= bits;\n    if (this.bitsAvailable > 0) {\n      this.word <<= bits;\n    } else if (this.bytesAvailable > 0) {\n      this.loadWord();\n    } else {\n      throw new Error('no bits available');\n    }\n    bits = size - bits;\n    if (bits > 0 && this.bitsAvailable) {\n      return valu << bits | this.readBits(bits);\n    } else {\n      return valu;\n    }\n  }\n\n  // ():uint\n  skipLZ() {\n    let leadingZeroCount; // :uint\n    for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {\n      if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {\n        // the first bit of working word is 1\n        this.word <<= leadingZeroCount;\n        this.bitsAvailable -= leadingZeroCount;\n        return leadingZeroCount;\n      }\n    }\n    // we exhausted word and still have not found a 1\n    this.loadWord();\n    return leadingZeroCount + this.skipLZ();\n  }\n\n  // ():void\n  skipUEG() {\n    this.skipBits(1 + this.skipLZ());\n  }\n\n  // ():void\n  skipEG() {\n    this.skipBits(1 + this.skipLZ());\n  }\n\n  // ():uint\n  readUEG() {\n    const clz = this.skipLZ(); // :uint\n    return this.readBits(clz + 1) - 1;\n  }\n\n  // ():int\n  readEG() {\n    const valu = this.readUEG(); // :int\n    if (0x01 & valu) {\n      // the number is odd if the low order bit is set\n      return 1 + valu >>> 1; // add 1 to make it even, and divide by 2\n    } else {\n      return -1 * (valu >>> 1); // divide by two then make it negative\n    }\n  }\n\n  // Some convenience functions\n  // :Boolean\n  readBoolean() {\n    return this.readBits(1) === 1;\n  }\n\n  // ():int\n  readUByte() {\n    return this.readBits(8);\n  }\n\n  // ():int\n  readUShort() {\n    return this.readBits(16);\n  }\n\n  // ():int\n  readUInt() {\n    return this.readBits(32);\n  }\n\n  /**\n   * Advance the ExpGolomb decoder past a scaling list. The scaling\n   * list is optionally transmitted as part of a sequence parameter\n   * set and is not relevant to transmuxing.\n   * @param count the number of entries in this scaling list\n   * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n   */\n  skipScalingList(count) {\n    let lastScale = 8;\n    let nextScale = 8;\n    let deltaScale;\n    for (let j = 0; j < count; j++) {\n      if (nextScale !== 0) {\n        deltaScale = this.readEG();\n        nextScale = (lastScale + deltaScale + 256) % 256;\n      }\n      lastScale = nextScale === 0 ? lastScale : nextScale;\n    }\n  }\n\n  /**\n   * Read a sequence parameter set and return some interesting video\n   * properties. A sequence parameter set is the H264 metadata that\n   * describes the properties of upcoming video frames.\n   * @returns an object with configuration parsed from the\n   * sequence parameter set, including the dimensions of the\n   * associated video frames.\n   */\n  readSPS() {\n    let frameCropLeftOffset = 0;\n    let frameCropRightOffset = 0;\n    let frameCropTopOffset = 0;\n    let frameCropBottomOffset = 0;\n    let numRefFramesInPicOrderCntCycle;\n    let scalingListCount;\n    let i;\n    const readUByte = this.readUByte.bind(this);\n    const readBits = this.readBits.bind(this);\n    const readUEG = this.readUEG.bind(this);\n    const readBoolean = this.readBoolean.bind(this);\n    const skipBits = this.skipBits.bind(this);\n    const skipEG = this.skipEG.bind(this);\n    const skipUEG = this.skipUEG.bind(this);\n    const skipScalingList = this.skipScalingList.bind(this);\n    readUByte();\n    const profileIdc = readUByte(); // profile_idc\n    readBits(5); // profileCompat constraint_set[0-4]_flag, u(5)\n    skipBits(3); // reserved_zero_3bits u(3),\n    readUByte(); // level_idc u(8)\n    skipUEG(); // seq_parameter_set_id\n    // some profiles have more optional data we don't need\n    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\n      const chromaFormatIdc = readUEG();\n      if (chromaFormatIdc === 3) {\n        skipBits(1);\n      } // separate_colour_plane_flag\n\n      skipUEG(); // bit_depth_luma_minus8\n      skipUEG(); // bit_depth_chroma_minus8\n      skipBits(1); // qpprime_y_zero_transform_bypass_flag\n      if (readBoolean()) {\n        // seq_scaling_matrix_present_flag\n        scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;\n        for (i = 0; i < scalingListCount; i++) {\n          if (readBoolean()) {\n            // seq_scaling_list_present_flag[ i ]\n            if (i < 6) {\n              skipScalingList(16);\n            } else {\n              skipScalingList(64);\n            }\n          }\n        }\n      }\n    }\n    skipUEG(); // log2_max_frame_num_minus4\n    const picOrderCntType = readUEG();\n    if (picOrderCntType === 0) {\n      readUEG(); // log2_max_pic_order_cnt_lsb_minus4\n    } else if (picOrderCntType === 1) {\n      skipBits(1); // delta_pic_order_always_zero_flag\n      skipEG(); // offset_for_non_ref_pic\n      skipEG(); // offset_for_top_to_bottom_field\n      numRefFramesInPicOrderCntCycle = readUEG();\n      for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n        skipEG();\n      } // offset_for_ref_frame[ i ]\n    }\n    skipUEG(); // max_num_ref_frames\n    skipBits(1); // gaps_in_frame_num_value_allowed_flag\n    const picWidthInMbsMinus1 = readUEG();\n    const picHeightInMapUnitsMinus1 = readUEG();\n    const frameMbsOnlyFlag = readBits(1);\n    if (frameMbsOnlyFlag === 0) {\n      skipBits(1);\n    } // mb_adaptive_frame_field_flag\n\n    skipBits(1); // direct_8x8_inference_flag\n    if (readBoolean()) {\n      // frame_cropping_flag\n      frameCropLeftOffset = readUEG();\n      frameCropRightOffset = readUEG();\n      frameCropTopOffset = readUEG();\n      frameCropBottomOffset = readUEG();\n    }\n    let pixelRatio = [1, 1];\n    if (readBoolean()) {\n      // vui_parameters_present_flag\n      if (readBoolean()) {\n        // aspect_ratio_info_present_flag\n        const aspectRatioIdc = readUByte();\n        switch (aspectRatioIdc) {\n          case 1:\n            pixelRatio = [1, 1];\n            break;\n          case 2:\n            pixelRatio = [12, 11];\n            break;\n          case 3:\n            pixelRatio = [10, 11];\n            break;\n          case 4:\n            pixelRatio = [16, 11];\n            break;\n          case 5:\n            pixelRatio = [40, 33];\n            break;\n          case 6:\n            pixelRatio = [24, 11];\n            break;\n          case 7:\n            pixelRatio = [20, 11];\n            break;\n          case 8:\n            pixelRatio = [32, 11];\n            break;\n          case 9:\n            pixelRatio = [80, 33];\n            break;\n          case 10:\n            pixelRatio = [18, 11];\n            break;\n          case 11:\n            pixelRatio = [15, 11];\n            break;\n          case 12:\n            pixelRatio = [64, 33];\n            break;\n          case 13:\n            pixelRatio = [160, 99];\n            break;\n          case 14:\n            pixelRatio = [4, 3];\n            break;\n          case 15:\n            pixelRatio = [3, 2];\n            break;\n          case 16:\n            pixelRatio = [2, 1];\n            break;\n          case 255:\n            {\n              pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];\n              break;\n            }\n        }\n      }\n    }\n    return {\n      width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),\n      height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),\n      pixelRatio: pixelRatio\n    };\n  }\n  readSliceType() {\n    // skip NALu type\n    this.readUByte();\n    // discard first_mb_in_slice\n    this.readUEG();\n    // return slice_type\n    return this.readUEG();\n  }\n}\n\nclass AvcVideoParser extends BaseVideoParser {\n  parseAVCPES(track, textTrack, pes, last, duration) {\n    const units = this.parseAVCNALu(track, pes.data);\n    let VideoSample = this.VideoSample;\n    let push;\n    let spsfound = false;\n    // free pes.data to save up some memory\n    pes.data = null;\n\n    // if new NAL units found and last sample still there, let's push ...\n    // this helps parsing streams with missing AUD (only do this if AUD never found)\n    if (VideoSample && units.length && !track.audFound) {\n      this.pushAccessUnit(VideoSample, track);\n      VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts, '');\n    }\n    units.forEach(unit => {\n      var _VideoSample2;\n      switch (unit.type) {\n        // NDR\n        case 1:\n          {\n            let iskey = false;\n            push = true;\n            const data = unit.data;\n            // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)\n            if (spsfound && data.length > 4) {\n              // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR\n              const sliceType = new ExpGolomb(data).readSliceType();\n              // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice\n              // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.\n              // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.\n              // I slice: A slice that is not an SI slice that is decoded using intra prediction only.\n              // if (sliceType === 2 || sliceType === 7) {\n              if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {\n                iskey = true;\n              }\n            }\n            if (iskey) {\n              var _VideoSample;\n              // if we have non-keyframe data already, that cannot belong to the same frame as a keyframe, so force a push\n              if ((_VideoSample = VideoSample) != null && _VideoSample.frame && !VideoSample.key) {\n                this.pushAccessUnit(VideoSample, track);\n                VideoSample = this.VideoSample = null;\n              }\n            }\n            if (!VideoSample) {\n              VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts, '');\n            }\n            VideoSample.frame = true;\n            VideoSample.key = iskey;\n            break;\n            // IDR\n          }\n        case 5:\n          push = true;\n          // handle PES not starting with AUD\n          // if we have frame data already, that cannot belong to the same frame, so force a push\n          if ((_VideoSample2 = VideoSample) != null && _VideoSample2.frame && !VideoSample.key) {\n            this.pushAccessUnit(VideoSample, track);\n            VideoSample = this.VideoSample = null;\n          }\n          if (!VideoSample) {\n            VideoSample = this.VideoSample = this.createVideoSample(true, pes.pts, pes.dts, '');\n          }\n          VideoSample.key = true;\n          VideoSample.frame = true;\n          break;\n        // SEI\n        case 6:\n          {\n            push = true;\n            parseSEIMessageFromNALu(unit.data, 1, pes.pts, textTrack.samples);\n            break;\n            // SPS\n          }\n        case 7:\n          {\n            var _track$pixelRatio, _track$pixelRatio2;\n            push = true;\n            spsfound = true;\n            const sps = unit.data;\n            const expGolombDecoder = new ExpGolomb(sps);\n            const config = expGolombDecoder.readSPS();\n            if (!track.sps || track.width !== config.width || track.height !== config.height || ((_track$pixelRatio = track.pixelRatio) == null ? void 0 : _track$pixelRatio[0]) !== config.pixelRatio[0] || ((_track$pixelRatio2 = track.pixelRatio) == null ? void 0 : _track$pixelRatio2[1]) !== config.pixelRatio[1]) {\n              track.width = config.width;\n              track.height = config.height;\n              track.pixelRatio = config.pixelRatio;\n              track.sps = [sps];\n              track.duration = duration;\n              const codecarray = sps.subarray(1, 4);\n              let codecstring = 'avc1.';\n              for (let i = 0; i < 3; i++) {\n                let h = codecarray[i].toString(16);\n                if (h.length < 2) {\n                  h = '0' + h;\n                }\n                codecstring += h;\n              }\n              track.codec = codecstring;\n            }\n            break;\n          }\n        // PPS\n        case 8:\n          push = true;\n          track.pps = [unit.data];\n          break;\n        // AUD\n        case 9:\n          push = true;\n          track.audFound = true;\n          if (VideoSample) {\n            this.pushAccessUnit(VideoSample, track);\n          }\n          VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts, '');\n          break;\n        // Filler Data\n        case 12:\n          push = true;\n          break;\n        default:\n          push = false;\n          if (VideoSample) {\n            VideoSample.debug += 'unknown NAL ' + unit.type + ' ';\n          }\n          break;\n      }\n      if (VideoSample && push) {\n        const units = VideoSample.units;\n        units.push(unit);\n      }\n    });\n    // if last PES packet, push samples\n    if (last && VideoSample) {\n      this.pushAccessUnit(VideoSample, track);\n      this.VideoSample = null;\n    }\n  }\n  parseAVCNALu(track, array) {\n    const len = array.byteLength;\n    let state = track.naluState || 0;\n    const lastState = state;\n    const units = [];\n    let i = 0;\n    let value;\n    let overflow;\n    let unitType;\n    let lastUnitStart = -1;\n    let lastUnitType = 0;\n    // logger.log('PES:' + Hex.hexDump(array));\n\n    if (state === -1) {\n      // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet\n      lastUnitStart = 0;\n      // NALu type is value read from offset 0\n      lastUnitType = array[0] & 0x1f;\n      state = 0;\n      i = 1;\n    }\n    while (i < len) {\n      value = array[i++];\n      // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case\n      if (!state) {\n        state = value ? 0 : 1;\n        continue;\n      }\n      if (state === 1) {\n        state = value ? 0 : 2;\n        continue;\n      }\n      // here we have state either equal to 2 or 3\n      if (!value) {\n        state = 3;\n      } else if (value === 1) {\n        overflow = i - state - 1;\n        if (lastUnitStart >= 0) {\n          const unit = {\n            data: array.subarray(lastUnitStart, overflow),\n            type: lastUnitType\n          };\n          // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);\n          units.push(unit);\n        } else {\n          // lastUnitStart is undefined => this is the first start code found in this PES packet\n          // first check if start code delimiter is overlapping between 2 PES packets,\n          // ie it started in last packet (lastState not zero)\n          // and ended at the beginning of this PES packet (i <= 4 - lastState)\n          const lastUnit = this.getLastNalUnit(track.samples);\n          if (lastUnit) {\n            if (lastState && i <= 4 - lastState) {\n              // start delimiter overlapping between PES packets\n              // strip start delimiter bytes from the end of last NAL unit\n              // check if lastUnit had a state different from zero\n              if (lastUnit.state) {\n                // strip last bytes\n                lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);\n              }\n            }\n            // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.\n\n            if (overflow > 0) {\n              // logger.log('first NALU found with overflow:' + overflow);\n              lastUnit.data = appendUint8Array(lastUnit.data, array.subarray(0, overflow));\n              lastUnit.state = 0;\n            }\n          }\n        }\n        // check if we can read unit type\n        if (i < len) {\n          unitType = array[i] & 0x1f;\n          // logger.log('find NALU @ offset:' + i + ',type:' + unitType);\n          lastUnitStart = i;\n          lastUnitType = unitType;\n          state = 0;\n        } else {\n          // not enough byte to read unit type. let's read it on next PES parsing\n          state = -1;\n        }\n      } else {\n        state = 0;\n      }\n    }\n    if (lastUnitStart >= 0 && state >= 0) {\n      const unit = {\n        data: array.subarray(lastUnitStart, len),\n        type: lastUnitType,\n        state: state\n      };\n      units.push(unit);\n      // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);\n    }\n    // no NALu found\n    if (units.length === 0) {\n      // append pes.data to previous NAL unit\n      const lastUnit = this.getLastNalUnit(track.samples);\n      if (lastUnit) {\n        lastUnit.data = appendUint8Array(lastUnit.data, array);\n      }\n    }\n    track.naluState = state;\n    return units;\n  }\n}\n\n/**\n * SAMPLE-AES decrypter\n */\n\nclass SampleAesDecrypter {\n  constructor(observer, config, keyData) {\n    this.keyData = void 0;\n    this.decrypter = void 0;\n    this.keyData = keyData;\n    this.decrypter = new Decrypter(config, {\n      removePKCS7Padding: false\n    });\n  }\n  decryptBuffer(encryptedData) {\n    return this.decrypter.decrypt(encryptedData, this.keyData.key.buffer, this.keyData.iv.buffer);\n  }\n\n  // AAC - encrypt all full 16 bytes blocks starting from offset 16\n  decryptAacSample(samples, sampleIndex, callback) {\n    const curUnit = samples[sampleIndex].unit;\n    if (curUnit.length <= 16) {\n      // No encrypted portion in this sample (first 16 bytes is not\n      // encrypted, see https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/HLS_Sample_Encryption/Encryption/Encryption.html),\n      return;\n    }\n    const encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);\n    const encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);\n    this.decryptBuffer(encryptedBuffer).then(decryptedBuffer => {\n      const decryptedData = new Uint8Array(decryptedBuffer);\n      curUnit.set(decryptedData, 16);\n      if (!this.decrypter.isSync()) {\n        this.decryptAacSamples(samples, sampleIndex + 1, callback);\n      }\n    });\n  }\n  decryptAacSamples(samples, sampleIndex, callback) {\n    for (;; sampleIndex++) {\n      if (sampleIndex >= samples.length) {\n        callback();\n        return;\n      }\n      if (samples[sampleIndex].unit.length < 32) {\n        continue;\n      }\n      this.decryptAacSample(samples, sampleIndex, callback);\n      if (!this.decrypter.isSync()) {\n        return;\n      }\n    }\n  }\n\n  // AVC - encrypt one 16 bytes block out of ten, starting from offset 32\n  getAvcEncryptedData(decodedData) {\n    const encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;\n    const encryptedData = new Int8Array(encryptedDataLen);\n    let outputPos = 0;\n    for (let inputPos = 32; inputPos < decodedData.length - 16; inputPos += 160, outputPos += 16) {\n      encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);\n    }\n    return encryptedData;\n  }\n  getAvcDecryptedUnit(decodedData, decryptedData) {\n    const uint8DecryptedData = new Uint8Array(decryptedData);\n    let inputPos = 0;\n    for (let outputPos = 32; outputPos < decodedData.length - 16; outputPos += 160, inputPos += 16) {\n      decodedData.set(uint8DecryptedData.subarray(inputPos, inputPos + 16), outputPos);\n    }\n    return decodedData;\n  }\n  decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit) {\n    const decodedData = discardEPB(curUnit.data);\n    const encryptedData = this.getAvcEncryptedData(decodedData);\n    this.decryptBuffer(encryptedData.buffer).then(decryptedBuffer => {\n      curUnit.data = this.getAvcDecryptedUnit(decodedData, decryptedBuffer);\n      if (!this.decrypter.isSync()) {\n        this.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);\n      }\n    });\n  }\n  decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {\n    if (samples instanceof Uint8Array) {\n      throw new Error('Cannot decrypt samples of type Uint8Array');\n    }\n    for (;; sampleIndex++, unitIndex = 0) {\n      if (sampleIndex >= samples.length) {\n        callback();\n        return;\n      }\n      const curUnits = samples[sampleIndex].units;\n      for (;; unitIndex++) {\n        if (unitIndex >= curUnits.length) {\n          break;\n        }\n        const curUnit = curUnits[unitIndex];\n        if (curUnit.data.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) {\n          continue;\n        }\n        this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit);\n        if (!this.decrypter.isSync()) {\n          return;\n        }\n      }\n    }\n  }\n}\n\nconst PACKET_LENGTH = 188;\nclass TSDemuxer {\n  constructor(observer, config, typeSupported) {\n    this.observer = void 0;\n    this.config = void 0;\n    this.typeSupported = void 0;\n    this.sampleAes = null;\n    this.pmtParsed = false;\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this._duration = 0;\n    this._pmtId = -1;\n    this._videoTrack = void 0;\n    this._audioTrack = void 0;\n    this._id3Track = void 0;\n    this._txtTrack = void 0;\n    this.aacOverFlow = null;\n    this.remainderData = null;\n    this.videoParser = void 0;\n    this.observer = observer;\n    this.config = config;\n    this.typeSupported = typeSupported;\n    this.videoParser = new AvcVideoParser();\n  }\n  static probe(data) {\n    const syncOffset = TSDemuxer.syncOffset(data);\n    if (syncOffset > 0) {\n      logger.warn(`MPEG2-TS detected but first sync word found @ offset ${syncOffset}`);\n    }\n    return syncOffset !== -1;\n  }\n  static syncOffset(data) {\n    const length = data.length;\n    let scanwindow = Math.min(PACKET_LENGTH * 5, length - PACKET_LENGTH) + 1;\n    let i = 0;\n    while (i < scanwindow) {\n      // a TS init segment should contain at least 2 TS packets: PAT and PMT, each starting with 0x47\n      let foundPat = false;\n      let packetStart = -1;\n      let tsPackets = 0;\n      for (let j = i; j < length; j += PACKET_LENGTH) {\n        if (data[j] === 0x47 && (length - j === PACKET_LENGTH || data[j + PACKET_LENGTH] === 0x47)) {\n          tsPackets++;\n          if (packetStart === -1) {\n            packetStart = j;\n            // First sync word found at offset, increase scan length (#5251)\n            if (packetStart !== 0) {\n              scanwindow = Math.min(packetStart + PACKET_LENGTH * 99, data.length - PACKET_LENGTH) + 1;\n            }\n          }\n          if (!foundPat) {\n            foundPat = parsePID(data, j) === 0;\n          }\n          // Sync word found at 0 with 3 packets, or found at offset least 2 packets up to scanwindow (#5501)\n          if (foundPat && tsPackets > 1 && (packetStart === 0 && tsPackets > 2 || j + PACKET_LENGTH > scanwindow)) {\n            return packetStart;\n          }\n        } else if (tsPackets) {\n          // Exit if sync word found, but does not contain contiguous packets\n          return -1;\n        } else {\n          break;\n        }\n      }\n      i++;\n    }\n    return -1;\n  }\n\n  /**\n   * Creates a track model internal to demuxer used to drive remuxing input\n   */\n  static createTrack(type, duration) {\n    return {\n      container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,\n      type,\n      id: RemuxerTrackIdConfig[type],\n      pid: -1,\n      inputTimeScale: 90000,\n      sequenceNumber: 0,\n      samples: [],\n      dropped: 0,\n      duration: type === 'audio' ? duration : undefined\n    };\n  }\n\n  /**\n   * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)\n   * Resets all internal track instances of the demuxer.\n   */\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    this.pmtParsed = false;\n    this._pmtId = -1;\n    this._videoTrack = TSDemuxer.createTrack('video');\n    this._audioTrack = TSDemuxer.createTrack('audio', trackDuration);\n    this._id3Track = TSDemuxer.createTrack('id3');\n    this._txtTrack = TSDemuxer.createTrack('text');\n    this._audioTrack.segmentCodec = 'aac';\n\n    // flush any partial content\n    this.aacOverFlow = null;\n    this.remainderData = null;\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this._duration = trackDuration;\n  }\n  resetTimeStamp() {}\n  resetContiguity() {\n    const {\n      _audioTrack,\n      _videoTrack,\n      _id3Track\n    } = this;\n    if (_audioTrack) {\n      _audioTrack.pesData = null;\n    }\n    if (_videoTrack) {\n      _videoTrack.pesData = null;\n    }\n    if (_id3Track) {\n      _id3Track.pesData = null;\n    }\n    this.aacOverFlow = null;\n    this.remainderData = null;\n  }\n  demux(data, timeOffset, isSampleAes = false, flush = false) {\n    if (!isSampleAes) {\n      this.sampleAes = null;\n    }\n    let pes;\n    const videoTrack = this._videoTrack;\n    const audioTrack = this._audioTrack;\n    const id3Track = this._id3Track;\n    const textTrack = this._txtTrack;\n    let videoPid = videoTrack.pid;\n    let videoData = videoTrack.pesData;\n    let audioPid = audioTrack.pid;\n    let id3Pid = id3Track.pid;\n    let audioData = audioTrack.pesData;\n    let id3Data = id3Track.pesData;\n    let unknownPID = null;\n    let pmtParsed = this.pmtParsed;\n    let pmtId = this._pmtId;\n    let len = data.length;\n    if (this.remainderData) {\n      data = appendUint8Array(this.remainderData, data);\n      len = data.length;\n      this.remainderData = null;\n    }\n    if (len < PACKET_LENGTH && !flush) {\n      this.remainderData = data;\n      return {\n        audioTrack,\n        videoTrack,\n        id3Track,\n        textTrack\n      };\n    }\n    const syncOffset = Math.max(0, TSDemuxer.syncOffset(data));\n    len -= (len - syncOffset) % PACKET_LENGTH;\n    if (len < data.byteLength && !flush) {\n      this.remainderData = new Uint8Array(data.buffer, len, data.buffer.byteLength - len);\n    }\n\n    // loop through TS packets\n    let tsPacketErrors = 0;\n    for (let start = syncOffset; start < len; start += PACKET_LENGTH) {\n      if (data[start] === 0x47) {\n        const stt = !!(data[start + 1] & 0x40);\n        const pid = parsePID(data, start);\n        const atf = (data[start + 3] & 0x30) >> 4;\n\n        // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.\n        let offset;\n        if (atf > 1) {\n          offset = start + 5 + data[start + 4];\n          // continue if there is only adaptation field\n          if (offset === start + PACKET_LENGTH) {\n            continue;\n          }\n        } else {\n          offset = start + 4;\n        }\n        switch (pid) {\n          case videoPid:\n            if (stt) {\n              if (videoData && (pes = parsePES(videoData))) {\n                this.videoParser.parseAVCPES(videoTrack, textTrack, pes, false, this._duration);\n              }\n              videoData = {\n                data: [],\n                size: 0\n              };\n            }\n            if (videoData) {\n              videoData.data.push(data.subarray(offset, start + PACKET_LENGTH));\n              videoData.size += start + PACKET_LENGTH - offset;\n            }\n            break;\n          case audioPid:\n            if (stt) {\n              if (audioData && (pes = parsePES(audioData))) {\n                switch (audioTrack.segmentCodec) {\n                  case 'aac':\n                    this.parseAACPES(audioTrack, pes);\n                    break;\n                  case 'mp3':\n                    this.parseMPEGPES(audioTrack, pes);\n                    break;\n                  case 'ac3':\n                    {\n                      this.parseAC3PES(audioTrack, pes);\n                    }\n                    break;\n                }\n              }\n              audioData = {\n                data: [],\n                size: 0\n              };\n            }\n            if (audioData) {\n              audioData.data.push(data.subarray(offset, start + PACKET_LENGTH));\n              audioData.size += start + PACKET_LENGTH - offset;\n            }\n            break;\n          case id3Pid:\n            if (stt) {\n              if (id3Data && (pes = parsePES(id3Data))) {\n                this.parseID3PES(id3Track, pes);\n              }\n              id3Data = {\n                data: [],\n                size: 0\n              };\n            }\n            if (id3Data) {\n              id3Data.data.push(data.subarray(offset, start + PACKET_LENGTH));\n              id3Data.size += start + PACKET_LENGTH - offset;\n            }\n            break;\n          case 0:\n            if (stt) {\n              offset += data[offset] + 1;\n            }\n            pmtId = this._pmtId = parsePAT(data, offset);\n            // logger.log('PMT PID:'  + this._pmtId);\n            break;\n          case pmtId:\n            {\n              if (stt) {\n                offset += data[offset] + 1;\n              }\n              const parsedPIDs = parsePMT(data, offset, this.typeSupported, isSampleAes, this.observer);\n\n              // only update track id if track PID found while parsing PMT\n              // this is to avoid resetting the PID to -1 in case\n              // track PID transiently disappears from the stream\n              // this could happen in case of transient missing audio samples for example\n              // NOTE this is only the PID of the track as found in TS,\n              // but we are not using this for MP4 track IDs.\n              videoPid = parsedPIDs.videoPid;\n              if (videoPid > 0) {\n                videoTrack.pid = videoPid;\n                videoTrack.segmentCodec = parsedPIDs.segmentVideoCodec;\n              }\n              audioPid = parsedPIDs.audioPid;\n              if (audioPid > 0) {\n                audioTrack.pid = audioPid;\n                audioTrack.segmentCodec = parsedPIDs.segmentAudioCodec;\n              }\n              id3Pid = parsedPIDs.id3Pid;\n              if (id3Pid > 0) {\n                id3Track.pid = id3Pid;\n              }\n              if (unknownPID !== null && !pmtParsed) {\n                logger.warn(`MPEG-TS PMT found at ${start} after unknown PID '${unknownPID}'. Backtracking to sync byte @${syncOffset} to parse all TS packets.`);\n                unknownPID = null;\n                // we set it to -188, the += 188 in the for loop will reset start to 0\n                start = syncOffset - 188;\n              }\n              pmtParsed = this.pmtParsed = true;\n              break;\n            }\n          case 0x11:\n          case 0x1fff:\n            break;\n          default:\n            unknownPID = pid;\n            break;\n        }\n      } else {\n        tsPacketErrors++;\n      }\n    }\n    if (tsPacketErrors > 0) {\n      emitParsingError(this.observer, new Error(`Found ${tsPacketErrors} TS packet/s that do not start with 0x47`));\n    }\n    videoTrack.pesData = videoData;\n    audioTrack.pesData = audioData;\n    id3Track.pesData = id3Data;\n    const demuxResult = {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    };\n    if (flush) {\n      this.extractRemainingSamples(demuxResult);\n    }\n    return demuxResult;\n  }\n  flush() {\n    const {\n      remainderData\n    } = this;\n    this.remainderData = null;\n    let result;\n    if (remainderData) {\n      result = this.demux(remainderData, -1, false, true);\n    } else {\n      result = {\n        videoTrack: this._videoTrack,\n        audioTrack: this._audioTrack,\n        id3Track: this._id3Track,\n        textTrack: this._txtTrack\n      };\n    }\n    this.extractRemainingSamples(result);\n    if (this.sampleAes) {\n      return this.decrypt(result, this.sampleAes);\n    }\n    return result;\n  }\n  extractRemainingSamples(demuxResult) {\n    const {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    } = demuxResult;\n    const videoData = videoTrack.pesData;\n    const audioData = audioTrack.pesData;\n    const id3Data = id3Track.pesData;\n    // try to parse last PES packets\n    let pes;\n    if (videoData && (pes = parsePES(videoData))) {\n      this.videoParser.parseAVCPES(videoTrack, textTrack, pes, true, this._duration);\n      videoTrack.pesData = null;\n    } else {\n      // either avcData null or PES truncated, keep it for next frag parsing\n      videoTrack.pesData = videoData;\n    }\n    if (audioData && (pes = parsePES(audioData))) {\n      switch (audioTrack.segmentCodec) {\n        case 'aac':\n          this.parseAACPES(audioTrack, pes);\n          break;\n        case 'mp3':\n          this.parseMPEGPES(audioTrack, pes);\n          break;\n        case 'ac3':\n          {\n            this.parseAC3PES(audioTrack, pes);\n          }\n          break;\n      }\n      audioTrack.pesData = null;\n    } else {\n      if (audioData != null && audioData.size) {\n        logger.log('last AAC PES packet truncated,might overlap between fragments');\n      }\n\n      // either audioData null or PES truncated, keep it for next frag parsing\n      audioTrack.pesData = audioData;\n    }\n    if (id3Data && (pes = parsePES(id3Data))) {\n      this.parseID3PES(id3Track, pes);\n      id3Track.pesData = null;\n    } else {\n      // either id3Data null or PES truncated, keep it for next frag parsing\n      id3Track.pesData = id3Data;\n    }\n  }\n  demuxSampleAes(data, keyData, timeOffset) {\n    const demuxResult = this.demux(data, timeOffset, true, !this.config.progressive);\n    const sampleAes = this.sampleAes = new SampleAesDecrypter(this.observer, this.config, keyData);\n    return this.decrypt(demuxResult, sampleAes);\n  }\n  decrypt(demuxResult, sampleAes) {\n    return new Promise(resolve => {\n      const {\n        audioTrack,\n        videoTrack\n      } = demuxResult;\n      if (audioTrack.samples && audioTrack.segmentCodec === 'aac') {\n        sampleAes.decryptAacSamples(audioTrack.samples, 0, () => {\n          if (videoTrack.samples) {\n            sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {\n              resolve(demuxResult);\n            });\n          } else {\n            resolve(demuxResult);\n          }\n        });\n      } else if (videoTrack.samples) {\n        sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, () => {\n          resolve(demuxResult);\n        });\n      }\n    });\n  }\n  destroy() {\n    this._duration = 0;\n  }\n  parseAACPES(track, pes) {\n    let startOffset = 0;\n    const aacOverFlow = this.aacOverFlow;\n    let data = pes.data;\n    if (aacOverFlow) {\n      this.aacOverFlow = null;\n      const frameMissingBytes = aacOverFlow.missing;\n      const sampleLength = aacOverFlow.sample.unit.byteLength;\n      // logger.log(`AAC: append overflowing ${sampleLength} bytes to beginning of new PES`);\n      if (frameMissingBytes === -1) {\n        data = appendUint8Array(aacOverFlow.sample.unit, data);\n      } else {\n        const frameOverflowBytes = sampleLength - frameMissingBytes;\n        aacOverFlow.sample.unit.set(data.subarray(0, frameMissingBytes), frameOverflowBytes);\n        track.samples.push(aacOverFlow.sample);\n        startOffset = aacOverFlow.missing;\n      }\n    }\n    // look for ADTS header (0xFFFx)\n    let offset;\n    let len;\n    for (offset = startOffset, len = data.length; offset < len - 1; offset++) {\n      if (isHeader$1(data, offset)) {\n        break;\n      }\n    }\n    // if ADTS header does not start straight from the beginning of the PES payload, raise an error\n    if (offset !== startOffset) {\n      let reason;\n      const recoverable = offset < len - 1;\n      if (recoverable) {\n        reason = `AAC PES did not start with ADTS header,offset:${offset}`;\n      } else {\n        reason = 'No ADTS header found in AAC PES';\n      }\n      emitParsingError(this.observer, new Error(reason), recoverable);\n      if (!recoverable) {\n        return;\n      }\n    }\n    initTrackConfig(track, this.observer, data, offset, this.audioCodec);\n    let pts;\n    if (pes.pts !== undefined) {\n      pts = pes.pts;\n    } else if (aacOverFlow) {\n      // if last AAC frame is overflowing, we should ensure timestamps are contiguous:\n      // first sample PTS should be equal to last sample PTS + frameDuration\n      const frameDuration = getFrameDuration(track.samplerate);\n      pts = aacOverFlow.sample.pts + frameDuration;\n    } else {\n      logger.warn('[tsdemuxer]: AAC PES unknown PTS');\n      return;\n    }\n\n    // scan for aac samples\n    let frameIndex = 0;\n    let frame;\n    while (offset < len) {\n      frame = appendFrame$2(track, data, offset, pts, frameIndex);\n      offset += frame.length;\n      if (!frame.missing) {\n        frameIndex++;\n        for (; offset < len - 1; offset++) {\n          if (isHeader$1(data, offset)) {\n            break;\n          }\n        }\n      } else {\n        this.aacOverFlow = frame;\n        break;\n      }\n    }\n  }\n  parseMPEGPES(track, pes) {\n    const data = pes.data;\n    const length = data.length;\n    let frameIndex = 0;\n    let offset = 0;\n    const pts = pes.pts;\n    if (pts === undefined) {\n      logger.warn('[tsdemuxer]: MPEG PES unknown PTS');\n      return;\n    }\n    while (offset < length) {\n      if (isHeader(data, offset)) {\n        const frame = appendFrame$1(track, data, offset, pts, frameIndex);\n        if (frame) {\n          offset += frame.length;\n          frameIndex++;\n        } else {\n          // logger.log('Unable to parse Mpeg audio frame');\n          break;\n        }\n      } else {\n        // nothing found, keep looking\n        offset++;\n      }\n    }\n  }\n  parseAC3PES(track, pes) {\n    {\n      const data = pes.data;\n      const pts = pes.pts;\n      if (pts === undefined) {\n        logger.warn('[tsdemuxer]: AC3 PES unknown PTS');\n        return;\n      }\n      const length = data.length;\n      let frameIndex = 0;\n      let offset = 0;\n      let parsed;\n      while (offset < length && (parsed = appendFrame(track, data, offset, pts, frameIndex++)) > 0) {\n        offset += parsed;\n      }\n    }\n  }\n  parseID3PES(id3Track, pes) {\n    if (pes.pts === undefined) {\n      logger.warn('[tsdemuxer]: ID3 PES unknown PTS');\n      return;\n    }\n    const id3Sample = _extends({}, pes, {\n      type: this._videoTrack ? MetadataSchema.emsg : MetadataSchema.audioId3,\n      duration: Number.POSITIVE_INFINITY\n    });\n    id3Track.samples.push(id3Sample);\n  }\n}\nfunction parsePID(data, offset) {\n  // pid is a 13-bit field starting at the last bit of TS[1]\n  return ((data[offset + 1] & 0x1f) << 8) + data[offset + 2];\n}\nfunction parsePAT(data, offset) {\n  // skip the PSI header and parse the first PMT entry\n  return (data[offset + 10] & 0x1f) << 8 | data[offset + 11];\n}\nfunction parsePMT(data, offset, typeSupported, isSampleAes, observer) {\n  const result = {\n    audioPid: -1,\n    videoPid: -1,\n    id3Pid: -1,\n    segmentVideoCodec: 'avc',\n    segmentAudioCodec: 'aac'\n  };\n  const sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];\n  const tableEnd = offset + 3 + sectionLength - 4;\n  // to determine where the table is, we have to figure out how\n  // long the program info descriptors are\n  const programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11];\n  // advance the offset to the first entry in the mapping table\n  offset += 12 + programInfoLength;\n  while (offset < tableEnd) {\n    const pid = parsePID(data, offset);\n    const esInfoLength = (data[offset + 3] & 0x0f) << 8 | data[offset + 4];\n    switch (data[offset]) {\n      case 0xcf:\n        // SAMPLE-AES AAC\n        if (!isSampleAes) {\n          logEncryptedSamplesFoundInUnencryptedStream('ADTS AAC');\n          break;\n        }\n      /* falls through */\n      case 0x0f:\n        // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)\n        // logger.log('AAC PID:'  + pid);\n        if (result.audioPid === -1) {\n          result.audioPid = pid;\n        }\n        break;\n\n      // Packetized metadata (ID3)\n      case 0x15:\n        // logger.log('ID3 PID:'  + pid);\n        if (result.id3Pid === -1) {\n          result.id3Pid = pid;\n        }\n        break;\n      case 0xdb:\n        // SAMPLE-AES AVC\n        if (!isSampleAes) {\n          logEncryptedSamplesFoundInUnencryptedStream('H.264');\n          break;\n        }\n      /* falls through */\n      case 0x1b:\n        // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)\n        // logger.log('AVC PID:'  + pid);\n        if (result.videoPid === -1) {\n          result.videoPid = pid;\n          result.segmentVideoCodec = 'avc';\n        }\n        break;\n\n      // ISO/IEC 11172-3 (MPEG-1 audio)\n      // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)\n      case 0x03:\n      case 0x04:\n        // logger.log('MPEG PID:'  + pid);\n        if (!typeSupported.mpeg && !typeSupported.mp3) {\n          logger.log('MPEG audio found, not supported in this browser');\n        } else if (result.audioPid === -1) {\n          result.audioPid = pid;\n          result.segmentAudioCodec = 'mp3';\n        }\n        break;\n      case 0xc1:\n        // SAMPLE-AES AC3\n        if (!isSampleAes) {\n          logEncryptedSamplesFoundInUnencryptedStream('AC-3');\n          break;\n        }\n      /* falls through */\n      case 0x81:\n        {\n          if (!typeSupported.ac3) {\n            logger.log('AC-3 audio found, not supported in this browser');\n          } else if (result.audioPid === -1) {\n            result.audioPid = pid;\n            result.segmentAudioCodec = 'ac3';\n          }\n        }\n        break;\n      case 0x06:\n        // stream_type 6 can mean a lot of different things in case of DVB.\n        // We need to look at the descriptors. Right now, we're only interested\n        // in AC-3 audio, so we do the descriptor parsing only when we don't have\n        // an audio PID yet.\n        if (result.audioPid === -1 && esInfoLength > 0) {\n          let parsePos = offset + 5;\n          let remaining = esInfoLength;\n          while (remaining > 2) {\n            const descriptorId = data[parsePos];\n            switch (descriptorId) {\n              case 0x6a:\n                // DVB Descriptor for AC-3\n                {\n                  if (typeSupported.ac3 !== true) {\n                    logger.log('AC-3 audio found, not supported in this browser for now');\n                  } else {\n                    result.audioPid = pid;\n                    result.segmentAudioCodec = 'ac3';\n                  }\n                }\n                break;\n            }\n            const descriptorLen = data[parsePos + 1] + 2;\n            parsePos += descriptorLen;\n            remaining -= descriptorLen;\n          }\n        }\n        break;\n      case 0xc2: // SAMPLE-AES EC3\n      /* falls through */\n      case 0x87:\n        emitParsingError(observer, new Error('Unsupported EC-3 in M2TS found'));\n        return result;\n      case 0x24:\n        emitParsingError(observer, new Error('Unsupported HEVC in M2TS found'));\n        return result;\n    }\n    // move to the next table entry\n    // skip past the elementary stream descriptors, if present\n    offset += esInfoLength + 5;\n  }\n  return result;\n}\nfunction emitParsingError(observer, error, levelRetry) {\n  logger.warn(`parsing error: ${error.message}`);\n  observer.emit(Events.ERROR, Events.ERROR, {\n    type: ErrorTypes.MEDIA_ERROR,\n    details: ErrorDetails.FRAG_PARSING_ERROR,\n    fatal: false,\n    levelRetry,\n    error,\n    reason: error.message\n  });\n}\nfunction logEncryptedSamplesFoundInUnencryptedStream(type) {\n  logger.log(`${type} with AES-128-CBC encryption found in unencrypted stream`);\n}\nfunction parsePES(stream) {\n  let i = 0;\n  let frag;\n  let pesLen;\n  let pesHdrLen;\n  let pesPts;\n  let pesDts;\n  const data = stream.data;\n  // safety check\n  if (!stream || stream.size === 0) {\n    return null;\n  }\n\n  // we might need up to 19 bytes to read PES header\n  // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes\n  // usually only one merge is needed (and this is rare ...)\n  while (data[0].length < 19 && data.length > 1) {\n    data[0] = appendUint8Array(data[0], data[1]);\n    data.splice(1, 1);\n  }\n  // retrieve PTS/DTS from first fragment\n  frag = data[0];\n  const pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];\n  if (pesPrefix === 1) {\n    pesLen = (frag[4] << 8) + frag[5];\n    // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated\n    // minus 6 : PES header size\n    if (pesLen && pesLen > stream.size - 6) {\n      return null;\n    }\n    const pesFlags = frag[7];\n    if (pesFlags & 0xc0) {\n      /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n          as PTS / DTS is 33 bit we cannot use bitwise operator in JS,\n          as Bitwise operators treat their operands as a sequence of 32 bits */\n      pesPts = (frag[9] & 0x0e) * 536870912 +\n      // 1 << 29\n      (frag[10] & 0xff) * 4194304 +\n      // 1 << 22\n      (frag[11] & 0xfe) * 16384 +\n      // 1 << 14\n      (frag[12] & 0xff) * 128 +\n      // 1 << 7\n      (frag[13] & 0xfe) / 2;\n      if (pesFlags & 0x40) {\n        pesDts = (frag[14] & 0x0e) * 536870912 +\n        // 1 << 29\n        (frag[15] & 0xff) * 4194304 +\n        // 1 << 22\n        (frag[16] & 0xfe) * 16384 +\n        // 1 << 14\n        (frag[17] & 0xff) * 128 +\n        // 1 << 7\n        (frag[18] & 0xfe) / 2;\n        if (pesPts - pesDts > 60 * 90000) {\n          logger.warn(`${Math.round((pesPts - pesDts) / 90000)}s delta between PTS and DTS, align them`);\n          pesPts = pesDts;\n        }\n      } else {\n        pesDts = pesPts;\n      }\n    }\n    pesHdrLen = frag[8];\n    // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension\n    let payloadStartOffset = pesHdrLen + 9;\n    if (stream.size <= payloadStartOffset) {\n      return null;\n    }\n    stream.size -= payloadStartOffset;\n    // reassemble PES packet\n    const pesData = new Uint8Array(stream.size);\n    for (let j = 0, dataLen = data.length; j < dataLen; j++) {\n      frag = data[j];\n      let len = frag.byteLength;\n      if (payloadStartOffset) {\n        if (payloadStartOffset > len) {\n          // trim full frag if PES header bigger than frag\n          payloadStartOffset -= len;\n          continue;\n        } else {\n          // trim partial frag if PES header smaller than frag\n          frag = frag.subarray(payloadStartOffset);\n          len -= payloadStartOffset;\n          payloadStartOffset = 0;\n        }\n      }\n      pesData.set(frag, i);\n      i += len;\n    }\n    if (pesLen) {\n      // payload size : remove PES header + PES extension\n      pesLen -= pesHdrLen + 3;\n    }\n    return {\n      data: pesData,\n      pts: pesPts,\n      dts: pesDts,\n      len: pesLen\n    };\n  }\n  return null;\n}\n\n/**\n * MP3 demuxer\n */\nclass MP3Demuxer extends BaseAudioDemuxer {\n  resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n    super.resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration);\n    this._audioTrack = {\n      container: 'audio/mpeg',\n      type: 'audio',\n      id: 2,\n      pid: -1,\n      sequenceNumber: 0,\n      segmentCodec: 'mp3',\n      samples: [],\n      manifestCodec: audioCodec,\n      duration: trackDuration,\n      inputTimeScale: 90000,\n      dropped: 0\n    };\n  }\n  static probe(data) {\n    if (!data) {\n      return false;\n    }\n\n    // check if data contains ID3 timestamp and MPEG sync word\n    // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n    // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n    // More info http://www.mp3-tech.org/programmer/frame_header.html\n    const id3Data = getID3Data(data, 0);\n    let offset = (id3Data == null ? void 0 : id3Data.length) || 0;\n\n    // Check for ac-3|ec-3 sync bytes and return false if present\n    if (id3Data && data[offset] === 0x0b && data[offset + 1] === 0x77 && getTimeStamp(id3Data) !== undefined &&\n    // check the bsid to confirm ac-3 or ec-3 (not mp3)\n    getAudioBSID(data, offset) <= 16) {\n      return false;\n    }\n    for (let length = data.length; offset < length; offset++) {\n      if (probe(data, offset)) {\n        logger.log('MPEG Audio sync word found !');\n        return true;\n      }\n    }\n    return false;\n  }\n  canParse(data, offset) {\n    return canParse(data, offset);\n  }\n  appendFrame(track, data, offset) {\n    if (this.basePTS === null) {\n      return;\n    }\n    return appendFrame$1(track, data, offset, this.basePTS, this.frameIndex);\n  }\n}\n\n/**\n *  AAC helper\n */\n\nclass AAC {\n  static getSilentFrame(codec, channelCount) {\n    switch (codec) {\n      case 'mp4a.40.2':\n        if (channelCount === 1) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);\n        } else if (channelCount === 2) {\n          return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);\n        } else if (channelCount === 3) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);\n        } else if (channelCount === 4) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);\n        } else if (channelCount === 5) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);\n        } else if (channelCount === 6) {\n          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\n        }\n        break;\n      // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)\n      default:\n        if (channelCount === 1) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0:d=0.05\" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        } else if (channelCount === 2) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        } else if (channelCount === 3) {\n          // ffmpeg -y -f lavfi -i \"aevalsrc=0|0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n        }\n        break;\n    }\n    return undefined;\n  }\n}\n\n/**\n * Generate MP4 Box\n */\n\nconst UINT32_MAX = Math.pow(2, 32) - 1;\nclass MP4 {\n  static init() {\n    MP4.types = {\n      avc1: [],\n      // codingname\n      avcC: [],\n      btrt: [],\n      dinf: [],\n      dref: [],\n      esds: [],\n      ftyp: [],\n      hdlr: [],\n      mdat: [],\n      mdhd: [],\n      mdia: [],\n      mfhd: [],\n      minf: [],\n      moof: [],\n      moov: [],\n      mp4a: [],\n      '.mp3': [],\n      dac3: [],\n      'ac-3': [],\n      mvex: [],\n      mvhd: [],\n      pasp: [],\n      sdtp: [],\n      stbl: [],\n      stco: [],\n      stsc: [],\n      stsd: [],\n      stsz: [],\n      stts: [],\n      tfdt: [],\n      tfhd: [],\n      traf: [],\n      trak: [],\n      trun: [],\n      trex: [],\n      tkhd: [],\n      vmhd: [],\n      smhd: []\n    };\n    let i;\n    for (i in MP4.types) {\n      if (MP4.types.hasOwnProperty(i)) {\n        MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\n      }\n    }\n    const videoHdlr = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    0x76, 0x69, 0x64, 0x65,\n    // handler_type: 'vide'\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n    ]);\n    const audioHdlr = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    0x73, 0x6f, 0x75, 0x6e,\n    // handler_type: 'soun'\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n    ]);\n    MP4.HDLR_TYPES = {\n      video: videoHdlr,\n      audio: audioHdlr\n    };\n    const dref = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x01,\n    // entry_count\n    0x00, 0x00, 0x00, 0x0c,\n    // entry_size\n    0x75, 0x72, 0x6c, 0x20,\n    // 'url' type\n    0x00,\n    // version 0\n    0x00, 0x00, 0x01 // entry_flags\n    ]);\n    const stco = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00 // entry_count\n    ]);\n    MP4.STTS = MP4.STSC = MP4.STCO = stco;\n    MP4.STSZ = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00,\n    // sample_size\n    0x00, 0x00, 0x00, 0x00 // sample_count\n    ]);\n    MP4.VMHD = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x01,\n    // flags\n    0x00, 0x00,\n    // graphicsmode\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n    ]);\n    MP4.SMHD = new Uint8Array([0x00,\n    // version\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00,\n    // balance\n    0x00, 0x00 // reserved\n    ]);\n    MP4.STSD = new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x01]); // entry_count\n\n    const majorBrand = new Uint8Array([105, 115, 111, 109]); // isom\n    const avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1\n    const minorVersion = new Uint8Array([0, 0, 0, 1]);\n    MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);\n    MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));\n  }\n  static box(type, ...payload) {\n    let size = 8;\n    let i = payload.length;\n    const len = i;\n    // calculate the total size we need to allocate\n    while (i--) {\n      size += payload[i].byteLength;\n    }\n    const result = new Uint8Array(size);\n    result[0] = size >> 24 & 0xff;\n    result[1] = size >> 16 & 0xff;\n    result[2] = size >> 8 & 0xff;\n    result[3] = size & 0xff;\n    result.set(type, 4);\n    // copy the payload into the result\n    for (i = 0, size = 8; i < len; i++) {\n      // copy payload[i] array @ offset size\n      result.set(payload[i], size);\n      size += payload[i].byteLength;\n    }\n    return result;\n  }\n  static hdlr(type) {\n    return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);\n  }\n  static mdat(data) {\n    return MP4.box(MP4.types.mdat, data);\n  }\n  static mdhd(timescale, duration) {\n    duration *= timescale;\n    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.mdhd, new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n    // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n    // modification_time\n    timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,\n    // timescale\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x55, 0xc4,\n    // 'und' language (undetermined)\n    0x00, 0x00]));\n  }\n  static mdia(track) {\n    return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale, track.duration), MP4.hdlr(track.type), MP4.minf(track));\n  }\n  static mfhd(sequenceNumber) {\n    return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00,\n    // flags\n    sequenceNumber >> 24, sequenceNumber >> 16 & 0xff, sequenceNumber >> 8 & 0xff, sequenceNumber & 0xff // sequence_number\n    ]));\n  }\n  static minf(track) {\n    if (track.type === 'audio') {\n      return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));\n    } else {\n      return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));\n    }\n  }\n  static moof(sn, baseMediaDecodeTime, track) {\n    return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));\n  }\n  static moov(tracks) {\n    let i = tracks.length;\n    const boxes = [];\n    while (i--) {\n      boxes[i] = MP4.trak(tracks[i]);\n    }\n    return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale, tracks[0].duration)].concat(boxes).concat(MP4.mvex(tracks)));\n  }\n  static mvex(tracks) {\n    let i = tracks.length;\n    const boxes = [];\n    while (i--) {\n      boxes[i] = MP4.trex(tracks[i]);\n    }\n    return MP4.box.apply(null, [MP4.types.mvex, ...boxes]);\n  }\n  static mvhd(timescale, duration) {\n    duration *= timescale;\n    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    const bytes = new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x00,\n    // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n    // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n    // modification_time\n    timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,\n    // timescale\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x01, 0x00, 0x00,\n    // 1.0 rate\n    0x01, 0x00,\n    // 1.0 volume\n    0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n    // transformation: unity matrix\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    0xff, 0xff, 0xff, 0xff // next_track_ID\n    ]);\n    return MP4.box(MP4.types.mvhd, bytes);\n  }\n  static sdtp(track) {\n    const samples = track.samples || [];\n    const bytes = new Uint8Array(4 + samples.length);\n    let i;\n    let flags;\n    // leave the full box header (4 bytes) all zero\n    // write the sample table\n    for (i = 0; i < samples.length; i++) {\n      flags = samples[i].flags;\n      bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\n    }\n    return MP4.box(MP4.types.sdtp, bytes);\n  }\n  static stbl(track) {\n    return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));\n  }\n  static avc1(track) {\n    let sps = [];\n    let pps = [];\n    let i;\n    let data;\n    let len;\n    // assemble the SPSs\n\n    for (i = 0; i < track.sps.length; i++) {\n      data = track.sps[i];\n      len = data.byteLength;\n      sps.push(len >>> 8 & 0xff);\n      sps.push(len & 0xff);\n\n      // SPS\n      sps = sps.concat(Array.prototype.slice.call(data));\n    }\n\n    // assemble the PPSs\n    for (i = 0; i < track.pps.length; i++) {\n      data = track.pps[i];\n      len = data.byteLength;\n      pps.push(len >>> 8 & 0xff);\n      pps.push(len & 0xff);\n      pps = pps.concat(Array.prototype.slice.call(data));\n    }\n    const avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01,\n    // version\n    sps[3],\n    // profile\n    sps[4],\n    // profile compat\n    sps[5],\n    // level\n    0xfc | 3,\n    // lengthSizeMinusOne, hard-coded to 4 bytes\n    0xe0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets\n    ].concat(sps).concat([track.pps.length // numOfPictureParameterSets\n    ]).concat(pps))); // \"PPS\"\n    const width = track.width;\n    const height = track.height;\n    const hSpacing = track.pixelRatio[0];\n    const vSpacing = track.pixelRatio[1];\n    return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // data_reference_index\n    0x00, 0x00,\n    // pre_defined\n    0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // pre_defined\n    width >> 8 & 0xff, width & 0xff,\n    // width\n    height >> 8 & 0xff, height & 0xff,\n    // height\n    0x00, 0x48, 0x00, 0x00,\n    // horizresolution\n    0x00, 0x48, 0x00, 0x00,\n    // vertresolution\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // frame_count\n    0x12, 0x64, 0x61, 0x69, 0x6c,\n    // dailymotion/hls.js\n    0x79, 0x6d, 0x6f, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x68, 0x6c, 0x73, 0x2e, 0x6a, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // compressorname\n    0x00, 0x18,\n    // depth = 24\n    0x11, 0x11]),\n    // pre_defined = -1\n    avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80,\n    // bufferSizeDB\n    0x00, 0x2d, 0xc6, 0xc0,\n    // maxBitrate\n    0x00, 0x2d, 0xc6, 0xc0])),\n    // avgBitrate\n    MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24,\n    // hSpacing\n    hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24,\n    // vSpacing\n    vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff])));\n  }\n  static esds(track) {\n    const configlen = track.config.length;\n    return new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n\n    0x03,\n    // descriptor_type\n    0x17 + configlen,\n    // length\n    0x00, 0x01,\n    // es_id\n    0x00,\n    // stream_priority\n\n    0x04,\n    // descriptor_type\n    0x0f + configlen,\n    // length\n    0x40,\n    // codec : mpeg4_audio\n    0x15,\n    // stream_type\n    0x00, 0x00, 0x00,\n    // buffer_size\n    0x00, 0x00, 0x00, 0x00,\n    // maxBitrate\n    0x00, 0x00, 0x00, 0x00,\n    // avgBitrate\n\n    0x05 // descriptor_type\n    ].concat([configlen]).concat(track.config).concat([0x06, 0x01, 0x02])); // GASpecificConfig)); // length + audio config descriptor\n  }\n  static audioStsd(track) {\n    const samplerate = track.samplerate;\n    return new Uint8Array([0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x01,\n    // data_reference_index\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, track.channelCount,\n    // channelcount\n    0x00, 0x10,\n    // sampleSize:16bits\n    0x00, 0x00, 0x00, 0x00,\n    // reserved2\n    samplerate >> 8 & 0xff, samplerate & 0xff,\n    //\n    0x00, 0x00]);\n  }\n  static mp4a(track) {\n    return MP4.box(MP4.types.mp4a, MP4.audioStsd(track), MP4.box(MP4.types.esds, MP4.esds(track)));\n  }\n  static mp3(track) {\n    return MP4.box(MP4.types['.mp3'], MP4.audioStsd(track));\n  }\n  static ac3(track) {\n    return MP4.box(MP4.types['ac-3'], MP4.audioStsd(track), MP4.box(MP4.types.dac3, track.config));\n  }\n  static stsd(track) {\n    if (track.type === 'audio') {\n      if (track.segmentCodec === 'mp3' && track.codec === 'mp3') {\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));\n      }\n      if (track.segmentCodec === 'ac3') {\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.ac3(track));\n      }\n      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));\n    } else {\n      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));\n    }\n  }\n  static tkhd(track) {\n    const id = track.id;\n    const duration = track.duration * track.timescale;\n    const width = track.width;\n    const height = track.height;\n    const upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n    const lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.tkhd, new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x07,\n    // flags\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n    // creation_time\n    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n    // modification_time\n    id >> 24 & 0xff, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,\n    // track_ID\n    0x00, 0x00, 0x00, 0x00,\n    // reserved\n    upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n    // reserved\n    0x00, 0x00,\n    // layer\n    0x00, 0x00,\n    // alternate_group\n    0x00, 0x00,\n    // non-audio track volume\n    0x00, 0x00,\n    // reserved\n    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n    // transformation: unity matrix\n    width >> 8 & 0xff, width & 0xff, 0x00, 0x00,\n    // width\n    height >> 8 & 0xff, height & 0xff, 0x00, 0x00 // height\n    ]));\n  }\n  static traf(track, baseMediaDecodeTime) {\n    const sampleDependencyTable = MP4.sdtp(track);\n    const id = track.id;\n    const upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));\n    const lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\n    return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff // track_ID\n    ])), MP4.box(MP4.types.tfdt, new Uint8Array([0x01,\n    // version 1\n    0x00, 0x00, 0x00,\n    // flags\n    upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0xff, upperWordBaseMediaDecodeTime >> 8 & 0xff, upperWordBaseMediaDecodeTime & 0xff, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0xff, lowerWordBaseMediaDecodeTime >> 8 & 0xff, lowerWordBaseMediaDecodeTime & 0xff])), MP4.trun(track, sampleDependencyTable.length + 16 +\n    // tfhd\n    20 +\n    // tfdt\n    8 +\n    // traf header\n    16 +\n    // mfhd\n    8 +\n    // moof header\n    8),\n    // mdat header\n    sampleDependencyTable);\n  }\n\n  /**\n   * Generate a track box.\n   * @param track a track definition\n   */\n  static trak(track) {\n    track.duration = track.duration || 0xffffffff;\n    return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));\n  }\n  static trex(track) {\n    const id = track.id;\n    return MP4.box(MP4.types.trex, new Uint8Array([0x00,\n    // version 0\n    0x00, 0x00, 0x00,\n    // flags\n    id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,\n    // track_ID\n    0x00, 0x00, 0x00, 0x01,\n    // default_sample_description_index\n    0x00, 0x00, 0x00, 0x00,\n    // default_sample_duration\n    0x00, 0x00, 0x00, 0x00,\n    // default_sample_size\n    0x00, 0x01, 0x00, 0x01 // default_sample_flags\n    ]));\n  }\n  static trun(track, offset) {\n    const samples = track.samples || [];\n    const len = samples.length;\n    const arraylen = 12 + 16 * len;\n    const array = new Uint8Array(arraylen);\n    let i;\n    let sample;\n    let duration;\n    let size;\n    let flags;\n    let cts;\n    offset += 8 + arraylen;\n    array.set([track.type === 'video' ? 0x01 : 0x00,\n    // version 1 for video with signed-int sample_composition_time_offset\n    0x00, 0x0f, 0x01,\n    // flags\n    len >>> 24 & 0xff, len >>> 16 & 0xff, len >>> 8 & 0xff, len & 0xff,\n    // sample_count\n    offset >>> 24 & 0xff, offset >>> 16 & 0xff, offset >>> 8 & 0xff, offset & 0xff // data_offset\n    ], 0);\n    for (i = 0; i < len; i++) {\n      sample = samples[i];\n      duration = sample.duration;\n      size = sample.size;\n      flags = sample.flags;\n      cts = sample.cts;\n      array.set([duration >>> 24 & 0xff, duration >>> 16 & 0xff, duration >>> 8 & 0xff, duration & 0xff,\n      // sample_duration\n      size >>> 24 & 0xff, size >>> 16 & 0xff, size >>> 8 & 0xff, size & 0xff,\n      // sample_size\n      flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xf0 << 8, flags.degradPrio & 0x0f,\n      // sample_flags\n      cts >>> 24 & 0xff, cts >>> 16 & 0xff, cts >>> 8 & 0xff, cts & 0xff // sample_composition_time_offset\n      ], 12 + 16 * i);\n    }\n    return MP4.box(MP4.types.trun, array);\n  }\n  static initSegment(tracks) {\n    if (!MP4.types) {\n      MP4.init();\n    }\n    const movie = MP4.moov(tracks);\n    const result = appendUint8Array(MP4.FTYP, movie);\n    return result;\n  }\n}\nMP4.types = void 0;\nMP4.HDLR_TYPES = void 0;\nMP4.STTS = void 0;\nMP4.STSC = void 0;\nMP4.STCO = void 0;\nMP4.STSZ = void 0;\nMP4.VMHD = void 0;\nMP4.SMHD = void 0;\nMP4.STSD = void 0;\nMP4.FTYP = void 0;\nMP4.DINF = void 0;\n\nconst MPEG_TS_CLOCK_FREQ_HZ = 90000;\nfunction toTimescaleFromBase(baseTime, destScale, srcBase = 1, round = false) {\n  const result = baseTime * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`\n  return round ? Math.round(result) : result;\n}\nfunction toTimescaleFromScale(baseTime, destScale, srcScale = 1, round = false) {\n  return toTimescaleFromBase(baseTime, destScale, 1 / srcScale, round);\n}\nfunction toMsFromMpegTsClock(baseTime, round = false) {\n  return toTimescaleFromBase(baseTime, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);\n}\nfunction toMpegTsClockFromTimescale(baseTime, srcScale = 1) {\n  return toTimescaleFromBase(baseTime, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);\n}\n\nconst MAX_SILENT_FRAME_DURATION = 10 * 1000; // 10 seconds\nconst AAC_SAMPLES_PER_FRAME = 1024;\nconst MPEG_AUDIO_SAMPLE_PER_FRAME = 1152;\nconst AC3_SAMPLES_PER_FRAME = 1536;\nlet chromeVersion = null;\nlet safariWebkitVersion = null;\nclass MP4Remuxer {\n  constructor(observer, config, typeSupported, vendor = '') {\n    this.observer = void 0;\n    this.config = void 0;\n    this.typeSupported = void 0;\n    this.ISGenerated = false;\n    this._initPTS = null;\n    this._initDTS = null;\n    this.nextAvcDts = null;\n    this.nextAudioPts = null;\n    this.videoSampleDuration = null;\n    this.isAudioContiguous = false;\n    this.isVideoContiguous = false;\n    this.videoTrackConfig = void 0;\n    this.observer = observer;\n    this.config = config;\n    this.typeSupported = typeSupported;\n    this.ISGenerated = false;\n    if (chromeVersion === null) {\n      const userAgent = navigator.userAgent || '';\n      const result = userAgent.match(/Chrome\\/(\\d+)/i);\n      chromeVersion = result ? parseInt(result[1]) : 0;\n    }\n    if (safariWebkitVersion === null) {\n      const result = navigator.userAgent.match(/Safari\\/(\\d+)/i);\n      safariWebkitVersion = result ? parseInt(result[1]) : 0;\n    }\n  }\n  destroy() {\n    // @ts-ignore\n    this.config = this.videoTrackConfig = this._initPTS = this._initDTS = null;\n  }\n  resetTimeStamp(defaultTimeStamp) {\n    logger.log('[mp4-remuxer]: initPTS & initDTS reset');\n    this._initPTS = this._initDTS = defaultTimeStamp;\n  }\n  resetNextTimestamp() {\n    logger.log('[mp4-remuxer]: reset next timestamp');\n    this.isVideoContiguous = false;\n    this.isAudioContiguous = false;\n  }\n  resetInitSegment() {\n    logger.log('[mp4-remuxer]: ISGenerated flag reset');\n    this.ISGenerated = false;\n    this.videoTrackConfig = undefined;\n  }\n  getVideoStartPts(videoSamples) {\n    let rolloverDetected = false;\n    const startPTS = videoSamples.reduce((minPTS, sample) => {\n      const delta = sample.pts - minPTS;\n      if (delta < -4294967296) {\n        // 2^32, see PTSNormalize for reasoning, but we're hitting a rollover here, and we don't want that to impact the timeOffset calculation\n        rolloverDetected = true;\n        return normalizePts(minPTS, sample.pts);\n      } else if (delta > 0) {\n        return minPTS;\n      } else {\n        return sample.pts;\n      }\n    }, videoSamples[0].pts);\n    if (rolloverDetected) {\n      logger.debug('PTS rollover detected');\n    }\n    return startPTS;\n  }\n  remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, flush, playlistType) {\n    let video;\n    let audio;\n    let initSegment;\n    let text;\n    let id3;\n    let independent;\n    let audioTimeOffset = timeOffset;\n    let videoTimeOffset = timeOffset;\n\n    // If we're remuxing audio and video progressively, wait until we've received enough samples for each track before proceeding.\n    // This is done to synchronize the audio and video streams. We know if the current segment will have samples if the \"pid\"\n    // parameter is greater than -1. The pid is set when the PMT is parsed, which contains the tracks list.\n    // However, if the initSegment has already been generated, or we've reached the end of a segment (flush),\n    // then we can remux one track without waiting for the other.\n    const hasAudio = audioTrack.pid > -1;\n    const hasVideo = videoTrack.pid > -1;\n    const length = videoTrack.samples.length;\n    const enoughAudioSamples = audioTrack.samples.length > 0;\n    const enoughVideoSamples = flush && length > 0 || length > 1;\n    const canRemuxAvc = (!hasAudio || enoughAudioSamples) && (!hasVideo || enoughVideoSamples) || this.ISGenerated || flush;\n    if (canRemuxAvc) {\n      if (this.ISGenerated) {\n        var _videoTrack$pixelRati, _config$pixelRatio, _videoTrack$pixelRati2, _config$pixelRatio2;\n        const config = this.videoTrackConfig;\n        if (config && (videoTrack.width !== config.width || videoTrack.height !== config.height || ((_videoTrack$pixelRati = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati[0]) !== ((_config$pixelRatio = config.pixelRatio) == null ? void 0 : _config$pixelRatio[0]) || ((_videoTrack$pixelRati2 = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati2[1]) !== ((_config$pixelRatio2 = config.pixelRatio) == null ? void 0 : _config$pixelRatio2[1]))) {\n          this.resetInitSegment();\n        }\n      } else {\n        initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n      }\n      const isVideoContiguous = this.isVideoContiguous;\n      let firstKeyFrameIndex = -1;\n      let firstKeyFramePTS;\n      if (enoughVideoSamples) {\n        firstKeyFrameIndex = findKeyframeIndex(videoTrack.samples);\n        if (!isVideoContiguous && this.config.forceKeyFrameOnDiscontinuity) {\n          independent = true;\n          if (firstKeyFrameIndex > 0) {\n            logger.warn(`[mp4-remuxer]: Dropped ${firstKeyFrameIndex} out of ${length} video samples due to a missing keyframe`);\n            const startPTS = this.getVideoStartPts(videoTrack.samples);\n            videoTrack.samples = videoTrack.samples.slice(firstKeyFrameIndex);\n            videoTrack.dropped += firstKeyFrameIndex;\n            videoTimeOffset += (videoTrack.samples[0].pts - startPTS) / videoTrack.inputTimeScale;\n            firstKeyFramePTS = videoTimeOffset;\n          } else if (firstKeyFrameIndex === -1) {\n            logger.warn(`[mp4-remuxer]: No keyframe found out of ${length} video samples`);\n            independent = false;\n          }\n        }\n      }\n      if (this.ISGenerated) {\n        if (enoughAudioSamples && enoughVideoSamples) {\n          // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)\n          // if first audio DTS is not aligned with first video DTS then we need to take that into account\n          // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small\n          // drift between audio and video streams\n          const startPTS = this.getVideoStartPts(videoTrack.samples);\n          const tsDelta = normalizePts(audioTrack.samples[0].pts, startPTS) - startPTS;\n          const audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;\n          audioTimeOffset += Math.max(0, audiovideoTimestampDelta);\n          videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);\n        }\n\n        // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is calculated in remuxAudio.\n        if (enoughAudioSamples) {\n          // if initSegment was generated without audio samples, regenerate it again\n          if (!audioTrack.samplerate) {\n            logger.warn('[mp4-remuxer]: regenerate InitSegment as audio detected');\n            initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n          }\n          audio = this.remuxAudio(audioTrack, audioTimeOffset, this.isAudioContiguous, accurateTimeOffset, hasVideo || enoughVideoSamples || playlistType === PlaylistLevelType.AUDIO ? videoTimeOffset : undefined);\n          if (enoughVideoSamples) {\n            const audioTrackLength = audio ? audio.endPTS - audio.startPTS : 0;\n            // if initSegment was generated without video samples, regenerate it again\n            if (!videoTrack.inputTimeScale) {\n              logger.warn('[mp4-remuxer]: regenerate InitSegment as video detected');\n              initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n            }\n            video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, audioTrackLength);\n          }\n        } else if (enoughVideoSamples) {\n          video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, 0);\n        }\n        if (video) {\n          video.firstKeyFrame = firstKeyFrameIndex;\n          video.independent = firstKeyFrameIndex !== -1;\n          video.firstKeyFramePTS = firstKeyFramePTS;\n        }\n      }\n    }\n\n    // Allow ID3 and text to remux, even if more audio/video samples are required\n    if (this.ISGenerated && this._initPTS && this._initDTS) {\n      if (id3Track.samples.length) {\n        id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, this._initPTS, this._initDTS);\n      }\n      if (textTrack.samples.length) {\n        text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, this._initPTS);\n      }\n    }\n    return {\n      audio,\n      video,\n      initSegment,\n      independent,\n      text,\n      id3\n    };\n  }\n  generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset) {\n    const audioSamples = audioTrack.samples;\n    const videoSamples = videoTrack.samples;\n    const typeSupported = this.typeSupported;\n    const tracks = {};\n    const _initPTS = this._initPTS;\n    let computePTSDTS = !_initPTS || accurateTimeOffset;\n    let container = 'audio/mp4';\n    let initPTS;\n    let initDTS;\n    let timescale;\n    if (computePTSDTS) {\n      initPTS = initDTS = Infinity;\n    }\n    if (audioTrack.config && audioSamples.length) {\n      // let's use audio sampling rate as MP4 time scale.\n      // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)\n      // using audio sampling rate here helps having an integer MP4 frame duration\n      // this avoids potential rounding issue and AV sync issue\n      audioTrack.timescale = audioTrack.samplerate;\n      switch (audioTrack.segmentCodec) {\n        case 'mp3':\n          if (typeSupported.mpeg) {\n            // Chrome and Safari\n            container = 'audio/mpeg';\n            audioTrack.codec = '';\n          } else if (typeSupported.mp3) {\n            // Firefox\n            audioTrack.codec = 'mp3';\n          }\n          break;\n        case 'ac3':\n          audioTrack.codec = 'ac-3';\n          break;\n      }\n      tracks.audio = {\n        id: 'audio',\n        container: container,\n        codec: audioTrack.codec,\n        initSegment: audioTrack.segmentCodec === 'mp3' && typeSupported.mpeg ? new Uint8Array(0) : MP4.initSegment([audioTrack]),\n        metadata: {\n          channelCount: audioTrack.channelCount\n        }\n      };\n      if (computePTSDTS) {\n        timescale = audioTrack.inputTimeScale;\n        if (!_initPTS || timescale !== _initPTS.timescale) {\n          // remember first PTS of this demuxing context. for audio, PTS = DTS\n          initPTS = initDTS = audioSamples[0].pts - Math.round(timescale * timeOffset);\n        } else {\n          computePTSDTS = false;\n        }\n      }\n    }\n    if (videoTrack.sps && videoTrack.pps && videoSamples.length) {\n      // let's use input time scale as MP4 video timescale\n      // we use input time scale straight away to avoid rounding issues on frame duration / cts computation\n      videoTrack.timescale = videoTrack.inputTimeScale;\n      tracks.video = {\n        id: 'main',\n        container: 'video/mp4',\n        codec: videoTrack.codec,\n        initSegment: MP4.initSegment([videoTrack]),\n        metadata: {\n          width: videoTrack.width,\n          height: videoTrack.height\n        }\n      };\n      if (computePTSDTS) {\n        timescale = videoTrack.inputTimeScale;\n        if (!_initPTS || timescale !== _initPTS.timescale) {\n          const startPTS = this.getVideoStartPts(videoSamples);\n          const startOffset = Math.round(timescale * timeOffset);\n          initDTS = Math.min(initDTS, normalizePts(videoSamples[0].dts, startPTS) - startOffset);\n          initPTS = Math.min(initPTS, startPTS - startOffset);\n        } else {\n          computePTSDTS = false;\n        }\n      }\n      this.videoTrackConfig = {\n        width: videoTrack.width,\n        height: videoTrack.height,\n        pixelRatio: videoTrack.pixelRatio\n      };\n    }\n    if (Object.keys(tracks).length) {\n      this.ISGenerated = true;\n      if (computePTSDTS) {\n        this._initPTS = {\n          baseTime: initPTS,\n          timescale: timescale\n        };\n        this._initDTS = {\n          baseTime: initDTS,\n          timescale: timescale\n        };\n      } else {\n        initPTS = timescale = undefined;\n      }\n      return {\n        tracks,\n        initPTS,\n        timescale\n      };\n    }\n  }\n  remuxVideo(track, timeOffset, contiguous, audioTrackLength) {\n    const timeScale = track.inputTimeScale;\n    const inputSamples = track.samples;\n    const outputSamples = [];\n    const nbSamples = inputSamples.length;\n    const initPTS = this._initPTS;\n    let nextAvcDts = this.nextAvcDts;\n    let offset = 8;\n    let mp4SampleDuration = this.videoSampleDuration;\n    let firstDTS;\n    let lastDTS;\n    let minPTS = Number.POSITIVE_INFINITY;\n    let maxPTS = Number.NEGATIVE_INFINITY;\n    let sortSamples = false;\n\n    // if parsed fragment is contiguous with last one, let's use last DTS value as reference\n    if (!contiguous || nextAvcDts === null) {\n      const pts = timeOffset * timeScale;\n      const cts = inputSamples[0].pts - normalizePts(inputSamples[0].dts, inputSamples[0].pts);\n      if (chromeVersion && nextAvcDts !== null && Math.abs(pts - cts - nextAvcDts) < 15000) {\n        // treat as contigous to adjust samples that would otherwise produce video buffer gaps in Chrome\n        contiguous = true;\n      } else {\n        // if not contiguous, let's use target timeOffset\n        nextAvcDts = pts - cts;\n      }\n    }\n\n    // PTS is coded on 33bits, and can loop from -2^32 to 2^32\n    // PTSNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value\n    const initTime = initPTS.baseTime * timeScale / initPTS.timescale;\n    for (let i = 0; i < nbSamples; i++) {\n      const sample = inputSamples[i];\n      sample.pts = normalizePts(sample.pts - initTime, nextAvcDts);\n      sample.dts = normalizePts(sample.dts - initTime, nextAvcDts);\n      if (sample.dts < inputSamples[i > 0 ? i - 1 : i].dts) {\n        sortSamples = true;\n      }\n    }\n\n    // sort video samples by DTS then PTS then demux id order\n    if (sortSamples) {\n      inputSamples.sort(function (a, b) {\n        const deltadts = a.dts - b.dts;\n        const deltapts = a.pts - b.pts;\n        return deltadts || deltapts;\n      });\n    }\n\n    // Get first/last DTS\n    firstDTS = inputSamples[0].dts;\n    lastDTS = inputSamples[inputSamples.length - 1].dts;\n\n    // Sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS\n    // set this constant duration as being the avg delta between consecutive DTS.\n    const inputDuration = lastDTS - firstDTS;\n    const averageSampleDuration = inputDuration ? Math.round(inputDuration / (nbSamples - 1)) : mp4SampleDuration || track.inputTimeScale / 30;\n\n    // if fragment are contiguous, detect hole/overlapping between fragments\n    if (contiguous) {\n      // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)\n      const delta = firstDTS - nextAvcDts;\n      const foundHole = delta > averageSampleDuration;\n      const foundOverlap = delta < -1;\n      if (foundHole || foundOverlap) {\n        if (foundHole) {\n          logger.warn(`AVC: ${toMsFromMpegTsClock(delta, true)} ms (${delta}dts) hole between fragments detected at ${timeOffset.toFixed(3)}`);\n        } else {\n          logger.warn(`AVC: ${toMsFromMpegTsClock(-delta, true)} ms (${delta}dts) overlapping between fragments detected at ${timeOffset.toFixed(3)}`);\n        }\n        if (!foundOverlap || nextAvcDts >= inputSamples[0].pts || chromeVersion) {\n          firstDTS = nextAvcDts;\n          const firstPTS = inputSamples[0].pts - delta;\n          if (foundHole) {\n            inputSamples[0].dts = firstDTS;\n            inputSamples[0].pts = firstPTS;\n          } else {\n            for (let i = 0; i < inputSamples.length; i++) {\n              if (inputSamples[i].dts > firstPTS) {\n                break;\n              }\n              inputSamples[i].dts -= delta;\n              inputSamples[i].pts -= delta;\n            }\n          }\n          logger.log(`Video: Initial PTS/DTS adjusted: ${toMsFromMpegTsClock(firstPTS, true)}/${toMsFromMpegTsClock(firstDTS, true)}, delta: ${toMsFromMpegTsClock(delta, true)} ms`);\n        }\n      }\n    }\n    firstDTS = Math.max(0, firstDTS);\n    let nbNalu = 0;\n    let naluLen = 0;\n    let dtsStep = firstDTS;\n    for (let i = 0; i < nbSamples; i++) {\n      // compute total/avc sample length and nb of NAL units\n      const sample = inputSamples[i];\n      const units = sample.units;\n      const nbUnits = units.length;\n      let sampleLen = 0;\n      for (let j = 0; j < nbUnits; j++) {\n        sampleLen += units[j].data.length;\n      }\n      naluLen += sampleLen;\n      nbNalu += nbUnits;\n      sample.length = sampleLen;\n\n      // ensure sample monotonic DTS\n      if (sample.dts < dtsStep) {\n        sample.dts = dtsStep;\n        dtsStep += averageSampleDuration / 4 | 0 || 1;\n      } else {\n        dtsStep = sample.dts;\n      }\n      minPTS = Math.min(sample.pts, minPTS);\n      maxPTS = Math.max(sample.pts, maxPTS);\n    }\n    lastDTS = inputSamples[nbSamples - 1].dts;\n\n    /* concatenate the video data and construct the mdat in place\n      (need 8 more bytes to fill length and mpdat type) */\n    const mdatSize = naluLen + 4 * nbNalu + 8;\n    let mdat;\n    try {\n      mdat = new Uint8Array(mdatSize);\n    } catch (err) {\n      this.observer.emit(Events.ERROR, Events.ERROR, {\n        type: ErrorTypes.MUX_ERROR,\n        details: ErrorDetails.REMUX_ALLOC_ERROR,\n        fatal: false,\n        error: err,\n        bytes: mdatSize,\n        reason: `fail allocating video mdat ${mdatSize}`\n      });\n      return;\n    }\n    const view = new DataView(mdat.buffer);\n    view.setUint32(0, mdatSize);\n    mdat.set(MP4.types.mdat, 4);\n    let stretchedLastFrame = false;\n    let minDtsDelta = Number.POSITIVE_INFINITY;\n    let minPtsDelta = Number.POSITIVE_INFINITY;\n    let maxDtsDelta = Number.NEGATIVE_INFINITY;\n    let maxPtsDelta = Number.NEGATIVE_INFINITY;\n    for (let i = 0; i < nbSamples; i++) {\n      const VideoSample = inputSamples[i];\n      const VideoSampleUnits = VideoSample.units;\n      let mp4SampleLength = 0;\n      // convert NALU bitstream to MP4 format (prepend NALU with size field)\n      for (let j = 0, nbUnits = VideoSampleUnits.length; j < nbUnits; j++) {\n        const unit = VideoSampleUnits[j];\n        const unitData = unit.data;\n        const unitDataLen = unit.data.byteLength;\n        view.setUint32(offset, unitDataLen);\n        offset += 4;\n        mdat.set(unitData, offset);\n        offset += unitDataLen;\n        mp4SampleLength += 4 + unitDataLen;\n      }\n\n      // expected sample duration is the Decoding Timestamp diff of consecutive samples\n      let ptsDelta;\n      if (i < nbSamples - 1) {\n        mp4SampleDuration = inputSamples[i + 1].dts - VideoSample.dts;\n        ptsDelta = inputSamples[i + 1].pts - VideoSample.pts;\n      } else {\n        const config = this.config;\n        const lastFrameDuration = i > 0 ? VideoSample.dts - inputSamples[i - 1].dts : averageSampleDuration;\n        ptsDelta = i > 0 ? VideoSample.pts - inputSamples[i - 1].pts : averageSampleDuration;\n        if (config.stretchShortVideoTrack && this.nextAudioPts !== null) {\n          // In some cases, a segment's audio track duration may exceed the video track duration.\n          // Since we've already remuxed audio, and we know how long the audio track is, we look to\n          // see if the delta to the next segment is longer than maxBufferHole.\n          // If so, playback would potentially get stuck, so we artificially inflate\n          // the duration of the last frame to minimize any potential gap between segments.\n          const gapTolerance = Math.floor(config.maxBufferHole * timeScale);\n          const deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioPts) - VideoSample.pts;\n          if (deltaToFrameEnd > gapTolerance) {\n            // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video\n            // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.\n            mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;\n            if (mp4SampleDuration < 0) {\n              mp4SampleDuration = lastFrameDuration;\n            } else {\n              stretchedLastFrame = true;\n            }\n            logger.log(`[mp4-remuxer]: It is approximately ${deltaToFrameEnd / 90} ms to the next segment; using duration ${mp4SampleDuration / 90} ms for the last video frame.`);\n          } else {\n            mp4SampleDuration = lastFrameDuration;\n          }\n        } else {\n          mp4SampleDuration = lastFrameDuration;\n        }\n      }\n      const compositionTimeOffset = Math.round(VideoSample.pts - VideoSample.dts);\n      minDtsDelta = Math.min(minDtsDelta, mp4SampleDuration);\n      maxDtsDelta = Math.max(maxDtsDelta, mp4SampleDuration);\n      minPtsDelta = Math.min(minPtsDelta, ptsDelta);\n      maxPtsDelta = Math.max(maxPtsDelta, ptsDelta);\n      outputSamples.push(new Mp4Sample(VideoSample.key, mp4SampleDuration, mp4SampleLength, compositionTimeOffset));\n    }\n    if (outputSamples.length) {\n      if (chromeVersion) {\n        if (chromeVersion < 70) {\n          // Chrome workaround, mark first sample as being a Random Access Point (keyframe) to avoid sourcebuffer append issue\n          // https://code.google.com/p/chromium/issues/detail?id=229412\n          const flags = outputSamples[0].flags;\n          flags.dependsOn = 2;\n          flags.isNonSync = 0;\n        }\n      } else if (safariWebkitVersion) {\n        // Fix for \"CNN special report, with CC\" in test-streams (Safari browser only)\n        // Ignore DTS when frame durations are irregular. Safari MSE does not handle this leading to gaps.\n        if (maxPtsDelta - minPtsDelta < maxDtsDelta - minDtsDelta && averageSampleDuration / maxDtsDelta < 0.025 && outputSamples[0].cts === 0) {\n          logger.warn('Found irregular gaps in sample duration. Using PTS instead of DTS to determine MP4 sample duration.');\n          let dts = firstDTS;\n          for (let i = 0, len = outputSamples.length; i < len; i++) {\n            const nextDts = dts + outputSamples[i].duration;\n            const pts = dts + outputSamples[i].cts;\n            if (i < len - 1) {\n              const nextPts = nextDts + outputSamples[i + 1].cts;\n              outputSamples[i].duration = nextPts - pts;\n            } else {\n              outputSamples[i].duration = i ? outputSamples[i - 1].duration : averageSampleDuration;\n            }\n            outputSamples[i].cts = 0;\n            dts = nextDts;\n          }\n        }\n      }\n    }\n    // next AVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)\n    mp4SampleDuration = stretchedLastFrame || !mp4SampleDuration ? averageSampleDuration : mp4SampleDuration;\n    this.nextAvcDts = nextAvcDts = lastDTS + mp4SampleDuration;\n    this.videoSampleDuration = mp4SampleDuration;\n    this.isVideoContiguous = true;\n    const moof = MP4.moof(track.sequenceNumber++, firstDTS, _extends({}, track, {\n      samples: outputSamples\n    }));\n    const type = 'video';\n    const data = {\n      data1: moof,\n      data2: mdat,\n      startPTS: minPTS / timeScale,\n      endPTS: (maxPTS + mp4SampleDuration) / timeScale,\n      startDTS: firstDTS / timeScale,\n      endDTS: nextAvcDts / timeScale,\n      type,\n      hasAudio: false,\n      hasVideo: true,\n      nb: outputSamples.length,\n      dropped: track.dropped\n    };\n    track.samples = [];\n    track.dropped = 0;\n    return data;\n  }\n  getSamplesPerFrame(track) {\n    switch (track.segmentCodec) {\n      case 'mp3':\n        return MPEG_AUDIO_SAMPLE_PER_FRAME;\n      case 'ac3':\n        return AC3_SAMPLES_PER_FRAME;\n      default:\n        return AAC_SAMPLES_PER_FRAME;\n    }\n  }\n  remuxAudio(track, timeOffset, contiguous, accurateTimeOffset, videoTimeOffset) {\n    const inputTimeScale = track.inputTimeScale;\n    const mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;\n    const scaleFactor = inputTimeScale / mp4timeScale;\n    const mp4SampleDuration = this.getSamplesPerFrame(track);\n    const inputSampleDuration = mp4SampleDuration * scaleFactor;\n    const initPTS = this._initPTS;\n    const rawMPEG = track.segmentCodec === 'mp3' && this.typeSupported.mpeg;\n    const outputSamples = [];\n    const alignedWithVideo = videoTimeOffset !== undefined;\n    let inputSamples = track.samples;\n    let offset = rawMPEG ? 0 : 8;\n    let nextAudioPts = this.nextAudioPts || -1;\n\n    // window.audioSamples ? window.audioSamples.push(inputSamples.map(s => s.pts)) : (window.audioSamples = [inputSamples.map(s => s.pts)]);\n\n    // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),\n    // for sake of clarity:\n    // consecutive fragments are frags with\n    //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\n    //  - less than 20 audio frames distance\n    // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\n    // this helps ensuring audio continuity\n    // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame\n    const timeOffsetMpegTS = timeOffset * inputTimeScale;\n    const initTime = initPTS.baseTime * inputTimeScale / initPTS.timescale;\n    this.isAudioContiguous = contiguous = contiguous || inputSamples.length && nextAudioPts > 0 && (accurateTimeOffset && Math.abs(timeOffsetMpegTS - nextAudioPts) < 9000 || Math.abs(normalizePts(inputSamples[0].pts - initTime, timeOffsetMpegTS) - nextAudioPts) < 20 * inputSampleDuration);\n\n    // compute normalized PTS\n    inputSamples.forEach(function (sample) {\n      sample.pts = normalizePts(sample.pts - initTime, timeOffsetMpegTS);\n    });\n    if (!contiguous || nextAudioPts < 0) {\n      // filter out sample with negative PTS that are not playable anyway\n      // if we don't remove these negative samples, they will shift all audio samples forward.\n      // leading to audio overlap between current / next fragment\n      inputSamples = inputSamples.filter(sample => sample.pts >= 0);\n\n      // in case all samples have negative PTS, and have been filtered out, return now\n      if (!inputSamples.length) {\n        return;\n      }\n      if (videoTimeOffset === 0) {\n        // Set the start to 0 to match video so that start gaps larger than inputSampleDuration are filled with silence\n        nextAudioPts = 0;\n      } else if (accurateTimeOffset && !alignedWithVideo) {\n        // When not seeking, not live, and LevelDetails.PTSKnown, use fragment start as predicted next audio PTS\n        nextAudioPts = Math.max(0, timeOffsetMpegTS);\n      } else {\n        // if frags are not contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS\n        nextAudioPts = inputSamples[0].pts;\n      }\n    }\n\n    // If the audio track is missing samples, the frames seem to get \"left-shifted\" within the\n    // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.\n    // In an effort to prevent this from happening, we inject frames here where there are gaps.\n    // When possible, we inject a silent frame; when that's not possible, we duplicate the last\n    // frame.\n\n    if (track.segmentCodec === 'aac') {\n      const maxAudioFramesDrift = this.config.maxAudioFramesDrift;\n      for (let i = 0, nextPts = nextAudioPts; i < inputSamples.length; i++) {\n        // First, let's see how far off this frame is from where we expect it to be\n        const sample = inputSamples[i];\n        const pts = sample.pts;\n        const delta = pts - nextPts;\n        const duration = Math.abs(1000 * delta / inputTimeScale);\n\n        // When remuxing with video, if we're overlapping by more than a duration, drop this sample to stay in sync\n        if (delta <= -maxAudioFramesDrift * inputSampleDuration && alignedWithVideo) {\n          if (i === 0) {\n            logger.warn(`Audio frame @ ${(pts / inputTimeScale).toFixed(3)}s overlaps nextAudioPts by ${Math.round(1000 * delta / inputTimeScale)} ms.`);\n            this.nextAudioPts = nextAudioPts = nextPts = pts;\n          }\n        } // eslint-disable-line brace-style\n\n        // Insert missing frames if:\n        // 1: We're more than maxAudioFramesDrift frame away\n        // 2: Not more than MAX_SILENT_FRAME_DURATION away\n        // 3: currentTime (aka nextPtsNorm) is not 0\n        // 4: remuxing with video (videoTimeOffset !== undefined)\n        else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && alignedWithVideo) {\n          let missing = Math.round(delta / inputSampleDuration);\n          // Adjust nextPts so that silent samples are aligned with media pts. This will prevent media samples from\n          // later being shifted if nextPts is based on timeOffset and delta is not a multiple of inputSampleDuration.\n          nextPts = pts - missing * inputSampleDuration;\n          if (nextPts < 0) {\n            missing--;\n            nextPts += inputSampleDuration;\n          }\n          if (i === 0) {\n            this.nextAudioPts = nextAudioPts = nextPts;\n          }\n          logger.warn(`[mp4-remuxer]: Injecting ${missing} audio frame @ ${(nextPts / inputTimeScale).toFixed(3)}s due to ${Math.round(1000 * delta / inputTimeScale)} ms gap.`);\n          for (let j = 0; j < missing; j++) {\n            const newStamp = Math.max(nextPts, 0);\n            let fillFrame = AAC.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n            if (!fillFrame) {\n              logger.log('[mp4-remuxer]: Unable to get silent frame for given audio codec; duplicating last frame instead.');\n              fillFrame = sample.unit.subarray();\n            }\n            inputSamples.splice(i, 0, {\n              unit: fillFrame,\n              pts: newStamp\n            });\n            nextPts += inputSampleDuration;\n            i++;\n          }\n        }\n        sample.pts = nextPts;\n        nextPts += inputSampleDuration;\n      }\n    }\n    let firstPTS = null;\n    let lastPTS = null;\n    let mdat;\n    let mdatSize = 0;\n    let sampleLength = inputSamples.length;\n    while (sampleLength--) {\n      mdatSize += inputSamples[sampleLength].unit.byteLength;\n    }\n    for (let j = 0, _nbSamples = inputSamples.length; j < _nbSamples; j++) {\n      const audioSample = inputSamples[j];\n      const unit = audioSample.unit;\n      let pts = audioSample.pts;\n      if (lastPTS !== null) {\n        // If we have more than one sample, set the duration of the sample to the \"real\" duration; the PTS diff with\n        // the previous sample\n        const prevSample = outputSamples[j - 1];\n        prevSample.duration = Math.round((pts - lastPTS) / scaleFactor);\n      } else {\n        if (contiguous && track.segmentCodec === 'aac') {\n          // set PTS/DTS to expected PTS/DTS\n          pts = nextAudioPts;\n        }\n        // remember first PTS of our audioSamples\n        firstPTS = pts;\n        if (mdatSize > 0) {\n          /* concatenate the audio data and construct the mdat in place\n            (need 8 more bytes to fill length and mdat type) */\n          mdatSize += offset;\n          try {\n            mdat = new Uint8Array(mdatSize);\n          } catch (err) {\n            this.observer.emit(Events.ERROR, Events.ERROR, {\n              type: ErrorTypes.MUX_ERROR,\n              details: ErrorDetails.REMUX_ALLOC_ERROR,\n              fatal: false,\n              error: err,\n              bytes: mdatSize,\n              reason: `fail allocating audio mdat ${mdatSize}`\n            });\n            return;\n          }\n          if (!rawMPEG) {\n            const view = new DataView(mdat.buffer);\n            view.setUint32(0, mdatSize);\n            mdat.set(MP4.types.mdat, 4);\n          }\n        } else {\n          // no audio samples\n          return;\n        }\n      }\n      mdat.set(unit, offset);\n      const unitLen = unit.byteLength;\n      offset += unitLen;\n      // Default the sample's duration to the computed mp4SampleDuration, which will either be 1024 for AAC or 1152 for MPEG\n      // In the case that we have 1 sample, this will be the duration. If we have more than one sample, the duration\n      // becomes the PTS diff with the previous sample\n      outputSamples.push(new Mp4Sample(true, mp4SampleDuration, unitLen, 0));\n      lastPTS = pts;\n    }\n\n    // We could end up with no audio samples if all input samples were overlapping with the previously remuxed ones\n    const nbSamples = outputSamples.length;\n    if (!nbSamples) {\n      return;\n    }\n\n    // The next audio sample PTS should be equal to last sample PTS + duration\n    const lastSample = outputSamples[outputSamples.length - 1];\n    this.nextAudioPts = nextAudioPts = lastPTS + scaleFactor * lastSample.duration;\n\n    // Set the track samples from inputSamples to outputSamples before remuxing\n    const moof = rawMPEG ? new Uint8Array(0) : MP4.moof(track.sequenceNumber++, firstPTS / scaleFactor, _extends({}, track, {\n      samples: outputSamples\n    }));\n\n    // Clear the track samples. This also clears the samples array in the demuxer, since the reference is shared\n    track.samples = [];\n    const start = firstPTS / inputTimeScale;\n    const end = nextAudioPts / inputTimeScale;\n    const type = 'audio';\n    const audioData = {\n      data1: moof,\n      data2: mdat,\n      startPTS: start,\n      endPTS: end,\n      startDTS: start,\n      endDTS: end,\n      type,\n      hasAudio: true,\n      hasVideo: false,\n      nb: nbSamples\n    };\n    this.isAudioContiguous = true;\n    return audioData;\n  }\n  remuxEmptyAudio(track, timeOffset, contiguous, videoData) {\n    const inputTimeScale = track.inputTimeScale;\n    const mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;\n    const scaleFactor = inputTimeScale / mp4timeScale;\n    const nextAudioPts = this.nextAudioPts;\n    // sync with video's timestamp\n    const initDTS = this._initDTS;\n    const init90kHz = initDTS.baseTime * 90000 / initDTS.timescale;\n    const startDTS = (nextAudioPts !== null ? nextAudioPts : videoData.startDTS * inputTimeScale) + init90kHz;\n    const endDTS = videoData.endDTS * inputTimeScale + init90kHz;\n    // one sample's duration value\n    const frameDuration = scaleFactor * AAC_SAMPLES_PER_FRAME;\n    // samples count of this segment's duration\n    const nbSamples = Math.ceil((endDTS - startDTS) / frameDuration);\n    // silent frame\n    const silentFrame = AAC.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n    logger.warn('[mp4-remuxer]: remux empty Audio');\n    // Can't remux if we can't generate a silent frame...\n    if (!silentFrame) {\n      logger.trace('[mp4-remuxer]: Unable to remuxEmptyAudio since we were unable to get a silent frame for given audio codec');\n      return;\n    }\n    const samples = [];\n    for (let i = 0; i < nbSamples; i++) {\n      const stamp = startDTS + i * frameDuration;\n      samples.push({\n        unit: silentFrame,\n        pts: stamp,\n        dts: stamp\n      });\n    }\n    track.samples = samples;\n    return this.remuxAudio(track, timeOffset, contiguous, false);\n  }\n}\nfunction normalizePts(value, reference) {\n  let offset;\n  if (reference === null) {\n    return value;\n  }\n  if (reference < value) {\n    // - 2^33\n    offset = -8589934592;\n  } else {\n    // + 2^33\n    offset = 8589934592;\n  }\n  /* PTS is 33bit (from 0 to 2^33 -1)\n    if diff between value and reference is bigger than half of the amplitude (2^32) then it means that\n    PTS looping occured. fill the gap */\n  while (Math.abs(value - reference) > 4294967296) {\n    value += offset;\n  }\n  return value;\n}\nfunction findKeyframeIndex(samples) {\n  for (let i = 0; i < samples.length; i++) {\n    if (samples[i].key) {\n      return i;\n    }\n  }\n  return -1;\n}\nfunction flushTextTrackMetadataCueSamples(track, timeOffset, initPTS, initDTS) {\n  const length = track.samples.length;\n  if (!length) {\n    return;\n  }\n  const inputTimeScale = track.inputTimeScale;\n  for (let index = 0; index < length; index++) {\n    const sample = track.samples[index];\n    // setting id3 pts, dts to relative time\n    // using this._initPTS and this._initDTS to calculate relative time\n    sample.pts = normalizePts(sample.pts - initPTS.baseTime * inputTimeScale / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n    sample.dts = normalizePts(sample.dts - initDTS.baseTime * inputTimeScale / initDTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n  }\n  const samples = track.samples;\n  track.samples = [];\n  return {\n    samples\n  };\n}\nfunction flushTextTrackUserdataCueSamples(track, timeOffset, initPTS) {\n  const length = track.samples.length;\n  if (!length) {\n    return;\n  }\n  const inputTimeScale = track.inputTimeScale;\n  for (let index = 0; index < length; index++) {\n    const sample = track.samples[index];\n    // setting text pts, dts to relative time\n    // using this._initPTS and this._initDTS to calculate relative time\n    sample.pts = normalizePts(sample.pts - initPTS.baseTime * inputTimeScale / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n  }\n  track.samples.sort((a, b) => a.pts - b.pts);\n  const samples = track.samples;\n  track.samples = [];\n  return {\n    samples\n  };\n}\nclass Mp4Sample {\n  constructor(isKeyframe, duration, size, cts) {\n    this.size = void 0;\n    this.duration = void 0;\n    this.cts = void 0;\n    this.flags = void 0;\n    this.duration = duration;\n    this.size = size;\n    this.cts = cts;\n    this.flags = {\n      isLeading: 0,\n      isDependedOn: 0,\n      hasRedundancy: 0,\n      degradPrio: 0,\n      dependsOn: isKeyframe ? 2 : 1,\n      isNonSync: isKeyframe ? 0 : 1\n    };\n  }\n}\n\nclass PassThroughRemuxer {\n  constructor() {\n    this.emitInitSegment = false;\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this.initData = void 0;\n    this.initPTS = null;\n    this.initTracks = void 0;\n    this.lastEndTime = null;\n  }\n  destroy() {}\n  resetTimeStamp(defaultInitPTS) {\n    this.initPTS = defaultInitPTS;\n    this.lastEndTime = null;\n  }\n  resetNextTimestamp() {\n    this.lastEndTime = null;\n  }\n  resetInitSegment(initSegment, audioCodec, videoCodec, decryptdata) {\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this.generateInitSegment(patchEncyptionData(initSegment, decryptdata));\n    this.emitInitSegment = true;\n  }\n  generateInitSegment(initSegment) {\n    let {\n      audioCodec,\n      videoCodec\n    } = this;\n    if (!(initSegment != null && initSegment.byteLength)) {\n      this.initTracks = undefined;\n      this.initData = undefined;\n      return;\n    }\n    const initData = this.initData = parseInitSegment(initSegment);\n\n    // Get codec from initSegment or fallback to default\n    if (initData.audio) {\n      audioCodec = getParsedTrackCodec(initData.audio, ElementaryStreamTypes.AUDIO);\n    }\n    if (initData.video) {\n      videoCodec = getParsedTrackCodec(initData.video, ElementaryStreamTypes.VIDEO);\n    }\n    const tracks = {};\n    if (initData.audio && initData.video) {\n      tracks.audiovideo = {\n        container: 'video/mp4',\n        codec: audioCodec + ',' + videoCodec,\n        initSegment,\n        id: 'main'\n      };\n    } else if (initData.audio) {\n      tracks.audio = {\n        container: 'audio/mp4',\n        codec: audioCodec,\n        initSegment,\n        id: 'audio'\n      };\n    } else if (initData.video) {\n      tracks.video = {\n        container: 'video/mp4',\n        codec: videoCodec,\n        initSegment,\n        id: 'main'\n      };\n    } else {\n      logger.warn('[passthrough-remuxer.ts]: initSegment does not contain moov or trak boxes.');\n    }\n    this.initTracks = tracks;\n  }\n  remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset) {\n    var _initData, _initData2;\n    let {\n      initPTS,\n      lastEndTime\n    } = this;\n    const result = {\n      audio: undefined,\n      video: undefined,\n      text: textTrack,\n      id3: id3Track,\n      initSegment: undefined\n    };\n\n    // If we haven't yet set a lastEndDTS, or it was reset, set it to the provided timeOffset. We want to use the\n    // lastEndDTS over timeOffset whenever possible; during progressive playback, the media source will not update\n    // the media duration (which is what timeOffset is provided as) before we need to process the next chunk.\n    if (!isFiniteNumber(lastEndTime)) {\n      lastEndTime = this.lastEndTime = timeOffset || 0;\n    }\n\n    // The binary segment data is added to the videoTrack in the mp4demuxer. We don't check to see if the data is only\n    // audio or video (or both); adding it to video was an arbitrary choice.\n    const data = videoTrack.samples;\n    if (!(data != null && data.length)) {\n      return result;\n    }\n    const initSegment = {\n      initPTS: undefined,\n      timescale: 1\n    };\n    let initData = this.initData;\n    if (!((_initData = initData) != null && _initData.length)) {\n      this.generateInitSegment(data);\n      initData = this.initData;\n    }\n    if (!((_initData2 = initData) != null && _initData2.length)) {\n      // We can't remux if the initSegment could not be generated\n      logger.warn('[passthrough-remuxer.ts]: Failed to generate initSegment.');\n      return result;\n    }\n    if (this.emitInitSegment) {\n      initSegment.tracks = this.initTracks;\n      this.emitInitSegment = false;\n    }\n    const duration = getDuration(data, initData);\n    const startDTS = getStartDTS(initData, data);\n    const decodeTime = startDTS === null ? timeOffset : startDTS;\n    if (isInvalidInitPts(initPTS, decodeTime, timeOffset, duration) || initSegment.timescale !== initPTS.timescale && accurateTimeOffset) {\n      initSegment.initPTS = decodeTime - timeOffset;\n      if (initPTS && initPTS.timescale === 1) {\n        logger.warn(`Adjusting initPTS by ${initSegment.initPTS - initPTS.baseTime}`);\n      }\n      this.initPTS = initPTS = {\n        baseTime: initSegment.initPTS,\n        timescale: 1\n      };\n    }\n    const startTime = audioTrack ? decodeTime - initPTS.baseTime / initPTS.timescale : lastEndTime;\n    const endTime = startTime + duration;\n    offsetStartDTS(initData, data, initPTS.baseTime / initPTS.timescale);\n    if (duration > 0) {\n      this.lastEndTime = endTime;\n    } else {\n      logger.warn('Duration parsed from mp4 should be greater than zero');\n      this.resetNextTimestamp();\n    }\n    const hasAudio = !!initData.audio;\n    const hasVideo = !!initData.video;\n    let type = '';\n    if (hasAudio) {\n      type += 'audio';\n    }\n    if (hasVideo) {\n      type += 'video';\n    }\n    const track = {\n      data1: data,\n      startPTS: startTime,\n      startDTS: startTime,\n      endPTS: endTime,\n      endDTS: endTime,\n      type,\n      hasAudio,\n      hasVideo,\n      nb: 1,\n      dropped: 0\n    };\n    result.audio = track.type === 'audio' ? track : undefined;\n    result.video = track.type !== 'audio' ? track : undefined;\n    result.initSegment = initSegment;\n    result.id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, initPTS, initPTS);\n    if (textTrack.samples.length) {\n      result.text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, initPTS);\n    }\n    return result;\n  }\n}\nfunction isInvalidInitPts(initPTS, startDTS, timeOffset, duration) {\n  if (initPTS === null) {\n    return true;\n  }\n  // InitPTS is invalid when distance from program would be more than segment duration or a minimum of one second\n  const minDuration = Math.max(duration, 1);\n  const startTime = startDTS - initPTS.baseTime / initPTS.timescale;\n  return Math.abs(startTime - timeOffset) > minDuration;\n}\nfunction getParsedTrackCodec(track, type) {\n  const parsedCodec = track == null ? void 0 : track.codec;\n  if (parsedCodec && parsedCodec.length > 4) {\n    return parsedCodec;\n  }\n  if (type === ElementaryStreamTypes.AUDIO) {\n    if (parsedCodec === 'ec-3' || parsedCodec === 'ac-3' || parsedCodec === 'alac') {\n      return parsedCodec;\n    }\n    if (parsedCodec === 'fLaC' || parsedCodec === 'Opus') {\n      // Opting not to get `preferManagedMediaSource` from player config for isSupported() check for simplicity\n      const preferManagedMediaSource = false;\n      return getCodecCompatibleName(parsedCodec, preferManagedMediaSource);\n    }\n    const result = 'mp4a.40.5';\n    logger.info(`Parsed audio codec \"${parsedCodec}\" or audio object type not handled. Using \"${result}\"`);\n    return result;\n  }\n  // Provide defaults based on codec type\n  // This allows for some playback of some fmp4 playlists without CODECS defined in manifest\n  logger.warn(`Unhandled video codec \"${parsedCodec}\"`);\n  if (parsedCodec === 'hvc1' || parsedCodec === 'hev1') {\n    return 'hvc1.1.6.L120.90';\n  }\n  if (parsedCodec === 'av01') {\n    return 'av01.0.04M.08';\n  }\n  return 'avc1.42e01e';\n}\n\nlet now;\n// performance.now() not available on WebWorker, at least on Safari Desktop\ntry {\n  now = self.performance.now.bind(self.performance);\n} catch (err) {\n  logger.debug('Unable to use Performance API on this environment');\n  now = optionalSelf == null ? void 0 : optionalSelf.Date.now;\n}\nconst muxConfig = [{\n  demux: MP4Demuxer,\n  remux: PassThroughRemuxer\n}, {\n  demux: TSDemuxer,\n  remux: MP4Remuxer\n}, {\n  demux: AACDemuxer,\n  remux: MP4Remuxer\n}, {\n  demux: MP3Demuxer,\n  remux: MP4Remuxer\n}];\n{\n  muxConfig.splice(2, 0, {\n    demux: AC3Demuxer,\n    remux: MP4Remuxer\n  });\n}\nclass Transmuxer {\n  constructor(observer, typeSupported, config, vendor, id) {\n    this.async = false;\n    this.observer = void 0;\n    this.typeSupported = void 0;\n    this.config = void 0;\n    this.vendor = void 0;\n    this.id = void 0;\n    this.demuxer = void 0;\n    this.remuxer = void 0;\n    this.decrypter = void 0;\n    this.probe = void 0;\n    this.decryptionPromise = null;\n    this.transmuxConfig = void 0;\n    this.currentTransmuxState = void 0;\n    this.observer = observer;\n    this.typeSupported = typeSupported;\n    this.config = config;\n    this.vendor = vendor;\n    this.id = id;\n  }\n  configure(transmuxConfig) {\n    this.transmuxConfig = transmuxConfig;\n    if (this.decrypter) {\n      this.decrypter.reset();\n    }\n  }\n  push(data, decryptdata, chunkMeta, state) {\n    const stats = chunkMeta.transmuxing;\n    stats.executeStart = now();\n    let uintData = new Uint8Array(data);\n    const {\n      currentTransmuxState,\n      transmuxConfig\n    } = this;\n    if (state) {\n      this.currentTransmuxState = state;\n    }\n    const {\n      contiguous,\n      discontinuity,\n      trackSwitch,\n      accurateTimeOffset,\n      timeOffset,\n      initSegmentChange\n    } = state || currentTransmuxState;\n    const {\n      audioCodec,\n      videoCodec,\n      defaultInitPts,\n      duration,\n      initSegmentData\n    } = transmuxConfig;\n    const keyData = getEncryptionType(uintData, decryptdata);\n    if (keyData && keyData.method === 'AES-128') {\n      const decrypter = this.getDecrypter();\n      // Software decryption is synchronous; webCrypto is not\n      if (decrypter.isSync()) {\n        // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached\n        // data is handled in the flush() call\n        let decryptedData = decrypter.softwareDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer);\n        // For Low-Latency HLS Parts, decrypt in place, since part parsing is expected on push progress\n        const loadingParts = chunkMeta.part > -1;\n        if (loadingParts) {\n          decryptedData = decrypter.flush();\n        }\n        if (!decryptedData) {\n          stats.executeEnd = now();\n          return emptyResult(chunkMeta);\n        }\n        uintData = new Uint8Array(decryptedData);\n      } else {\n        this.decryptionPromise = decrypter.webCryptoDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer).then(decryptedData => {\n          // Calling push here is important; if flush() is called while this is still resolving, this ensures that\n          // the decrypted data has been transmuxed\n          const result = this.push(decryptedData, null, chunkMeta);\n          this.decryptionPromise = null;\n          return result;\n        });\n        return this.decryptionPromise;\n      }\n    }\n    const resetMuxers = this.needsProbing(discontinuity, trackSwitch);\n    if (resetMuxers) {\n      const error = this.configureTransmuxer(uintData);\n      if (error) {\n        logger.warn(`[transmuxer] ${error.message}`);\n        this.observer.emit(Events.ERROR, Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.FRAG_PARSING_ERROR,\n          fatal: false,\n          error,\n          reason: error.message\n        });\n        stats.executeEnd = now();\n        return emptyResult(chunkMeta);\n      }\n    }\n    if (discontinuity || trackSwitch || initSegmentChange || resetMuxers) {\n      this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration, decryptdata);\n    }\n    if (discontinuity || initSegmentChange || resetMuxers) {\n      this.resetInitialTimestamp(defaultInitPts);\n    }\n    if (!contiguous) {\n      this.resetContiguity();\n    }\n    const result = this.transmux(uintData, keyData, timeOffset, accurateTimeOffset, chunkMeta);\n    const currentState = this.currentTransmuxState;\n    currentState.contiguous = true;\n    currentState.discontinuity = false;\n    currentState.trackSwitch = false;\n    stats.executeEnd = now();\n    return result;\n  }\n\n  // Due to data caching, flush calls can produce more than one TransmuxerResult (hence the Array type)\n  flush(chunkMeta) {\n    const stats = chunkMeta.transmuxing;\n    stats.executeStart = now();\n    const {\n      decrypter,\n      currentTransmuxState,\n      decryptionPromise\n    } = this;\n    if (decryptionPromise) {\n      // Upon resolution, the decryption promise calls push() and returns its TransmuxerResult up the stack. Therefore\n      // only flushing is required for async decryption\n      return decryptionPromise.then(() => {\n        return this.flush(chunkMeta);\n      });\n    }\n    const transmuxResults = [];\n    const {\n      timeOffset\n    } = currentTransmuxState;\n    if (decrypter) {\n      // The decrypter may have data cached, which needs to be demuxed. In this case we'll have two TransmuxResults\n      // This happens in the case that we receive only 1 push call for a segment (either for non-progressive downloads,\n      // or for progressive downloads with small segments)\n      const decryptedData = decrypter.flush();\n      if (decryptedData) {\n        // Push always returns a TransmuxerResult if decryptdata is null\n        transmuxResults.push(this.push(decryptedData, null, chunkMeta));\n      }\n    }\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      // If probing failed, then Hls.js has been given content its not able to handle\n      stats.executeEnd = now();\n      return [emptyResult(chunkMeta)];\n    }\n    const demuxResultOrPromise = demuxer.flush(timeOffset);\n    if (isPromise(demuxResultOrPromise)) {\n      // Decrypt final SAMPLE-AES samples\n      return demuxResultOrPromise.then(demuxResult => {\n        this.flushRemux(transmuxResults, demuxResult, chunkMeta);\n        return transmuxResults;\n      });\n    }\n    this.flushRemux(transmuxResults, demuxResultOrPromise, chunkMeta);\n    return transmuxResults;\n  }\n  flushRemux(transmuxResults, demuxResult, chunkMeta) {\n    const {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    } = demuxResult;\n    const {\n      accurateTimeOffset,\n      timeOffset\n    } = this.currentTransmuxState;\n    logger.log(`[transmuxer.ts]: Flushed fragment ${chunkMeta.sn}${chunkMeta.part > -1 ? ' p: ' + chunkMeta.part : ''} of level ${chunkMeta.level}`);\n    const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, true, this.id);\n    transmuxResults.push({\n      remuxResult,\n      chunkMeta\n    });\n    chunkMeta.transmuxing.executeEnd = now();\n  }\n  resetInitialTimestamp(defaultInitPts) {\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      return;\n    }\n    demuxer.resetTimeStamp(defaultInitPts);\n    remuxer.resetTimeStamp(defaultInitPts);\n  }\n  resetContiguity() {\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      return;\n    }\n    demuxer.resetContiguity();\n    remuxer.resetNextTimestamp();\n  }\n  resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration, decryptdata) {\n    const {\n      demuxer,\n      remuxer\n    } = this;\n    if (!demuxer || !remuxer) {\n      return;\n    }\n    demuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration);\n    remuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, decryptdata);\n  }\n  destroy() {\n    if (this.demuxer) {\n      this.demuxer.destroy();\n      this.demuxer = undefined;\n    }\n    if (this.remuxer) {\n      this.remuxer.destroy();\n      this.remuxer = undefined;\n    }\n  }\n  transmux(data, keyData, timeOffset, accurateTimeOffset, chunkMeta) {\n    let result;\n    if (keyData && keyData.method === 'SAMPLE-AES') {\n      result = this.transmuxSampleAes(data, keyData, timeOffset, accurateTimeOffset, chunkMeta);\n    } else {\n      result = this.transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta);\n    }\n    return result;\n  }\n  transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta) {\n    const {\n      audioTrack,\n      videoTrack,\n      id3Track,\n      textTrack\n    } = this.demuxer.demux(data, timeOffset, false, !this.config.progressive);\n    const remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, false, this.id);\n    return {\n      remuxResult,\n      chunkMeta\n    };\n  }\n  transmuxSampleAes(data, decryptData, timeOffset, accurateTimeOffset, chunkMeta) {\n    return this.demuxer.demuxSampleAes(data, decryptData, timeOffset).then(demuxResult => {\n      const remuxResult = this.remuxer.remux(demuxResult.audioTrack, demuxResult.videoTrack, demuxResult.id3Track, demuxResult.textTrack, timeOffset, accurateTimeOffset, false, this.id);\n      return {\n        remuxResult,\n        chunkMeta\n      };\n    });\n  }\n  configureTransmuxer(data) {\n    const {\n      config,\n      observer,\n      typeSupported,\n      vendor\n    } = this;\n    // probe for content type\n    let mux;\n    for (let i = 0, len = muxConfig.length; i < len; i++) {\n      var _muxConfig$i$demux;\n      if ((_muxConfig$i$demux = muxConfig[i].demux) != null && _muxConfig$i$demux.probe(data)) {\n        mux = muxConfig[i];\n        break;\n      }\n    }\n    if (!mux) {\n      return new Error('Failed to find demuxer by probing fragment data');\n    }\n    // so let's check that current remuxer and demuxer are still valid\n    const demuxer = this.demuxer;\n    const remuxer = this.remuxer;\n    const Remuxer = mux.remux;\n    const Demuxer = mux.demux;\n    if (!remuxer || !(remuxer instanceof Remuxer)) {\n      this.remuxer = new Remuxer(observer, config, typeSupported, vendor);\n    }\n    if (!demuxer || !(demuxer instanceof Demuxer)) {\n      this.demuxer = new Demuxer(observer, config, typeSupported);\n      this.probe = Demuxer.probe;\n    }\n  }\n  needsProbing(discontinuity, trackSwitch) {\n    // in case of continuity change, or track switch\n    // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)\n    return !this.demuxer || !this.remuxer || discontinuity || trackSwitch;\n  }\n  getDecrypter() {\n    let decrypter = this.decrypter;\n    if (!decrypter) {\n      decrypter = this.decrypter = new Decrypter(this.config);\n    }\n    return decrypter;\n  }\n}\nfunction getEncryptionType(data, decryptData) {\n  let encryptionType = null;\n  if (data.byteLength > 0 && (decryptData == null ? void 0 : decryptData.key) != null && decryptData.iv !== null && decryptData.method != null) {\n    encryptionType = decryptData;\n  }\n  return encryptionType;\n}\nconst emptyResult = chunkMeta => ({\n  remuxResult: {},\n  chunkMeta\n});\nfunction isPromise(p) {\n  return 'then' in p && p.then instanceof Function;\n}\nclass TransmuxConfig {\n  constructor(audioCodec, videoCodec, initSegmentData, duration, defaultInitPts) {\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this.initSegmentData = void 0;\n    this.duration = void 0;\n    this.defaultInitPts = void 0;\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this.initSegmentData = initSegmentData;\n    this.duration = duration;\n    this.defaultInitPts = defaultInitPts || null;\n  }\n}\nclass TransmuxState {\n  constructor(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange) {\n    this.discontinuity = void 0;\n    this.contiguous = void 0;\n    this.accurateTimeOffset = void 0;\n    this.trackSwitch = void 0;\n    this.timeOffset = void 0;\n    this.initSegmentChange = void 0;\n    this.discontinuity = discontinuity;\n    this.contiguous = contiguous;\n    this.accurateTimeOffset = accurateTimeOffset;\n    this.trackSwitch = trackSwitch;\n    this.timeOffset = timeOffset;\n    this.initSegmentChange = initSegmentChange;\n  }\n}\n\nvar eventemitter3 = {exports: {}};\n\n(function (module) {\n\n\tvar has = Object.prototype.hasOwnProperty\n\t  , prefix = '~';\n\n\t/**\n\t * Constructor to create a storage for our `EE` objects.\n\t * An `Events` instance is a plain object whose properties are event names.\n\t *\n\t * @constructor\n\t * @private\n\t */\n\tfunction Events() {}\n\n\t//\n\t// We try to not inherit from `Object.prototype`. In some engines creating an\n\t// instance in this way is faster than calling `Object.create(null)` directly.\n\t// If `Object.create(null)` is not supported we prefix the event names with a\n\t// character to make sure that the built-in object properties are not\n\t// overridden or used as an attack vector.\n\t//\n\tif (Object.create) {\n\t  Events.prototype = Object.create(null);\n\n\t  //\n\t  // This hack is needed because the `__proto__` property is still inherited in\n\t  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\n\t  //\n\t  if (!new Events().__proto__) prefix = false;\n\t}\n\n\t/**\n\t * Representation of a single event listener.\n\t *\n\t * @param {Function} fn The listener function.\n\t * @param {*} context The context to invoke the listener with.\n\t * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\n\t * @constructor\n\t * @private\n\t */\n\tfunction EE(fn, context, once) {\n\t  this.fn = fn;\n\t  this.context = context;\n\t  this.once = once || false;\n\t}\n\n\t/**\n\t * Add a listener for a given event.\n\t *\n\t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn The listener function.\n\t * @param {*} context The context to invoke the listener with.\n\t * @param {Boolean} once Specify if the listener is a one-time listener.\n\t * @returns {EventEmitter}\n\t * @private\n\t */\n\tfunction addListener(emitter, event, fn, context, once) {\n\t  if (typeof fn !== 'function') {\n\t    throw new TypeError('The listener must be a function');\n\t  }\n\n\t  var listener = new EE(fn, context || emitter, once)\n\t    , evt = prefix ? prefix + event : event;\n\n\t  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\n\t  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\n\t  else emitter._events[evt] = [emitter._events[evt], listener];\n\n\t  return emitter;\n\t}\n\n\t/**\n\t * Clear event by name.\n\t *\n\t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n\t * @param {(String|Symbol)} evt The Event name.\n\t * @private\n\t */\n\tfunction clearEvent(emitter, evt) {\n\t  if (--emitter._eventsCount === 0) emitter._events = new Events();\n\t  else delete emitter._events[evt];\n\t}\n\n\t/**\n\t * Minimal `EventEmitter` interface that is molded against the Node.js\n\t * `EventEmitter` interface.\n\t *\n\t * @constructor\n\t * @public\n\t */\n\tfunction EventEmitter() {\n\t  this._events = new Events();\n\t  this._eventsCount = 0;\n\t}\n\n\t/**\n\t * Return an array listing the events for which the emitter has registered\n\t * listeners.\n\t *\n\t * @returns {Array}\n\t * @public\n\t */\n\tEventEmitter.prototype.eventNames = function eventNames() {\n\t  var names = []\n\t    , events\n\t    , name;\n\n\t  if (this._eventsCount === 0) return names;\n\n\t  for (name in (events = this._events)) {\n\t    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);\n\t  }\n\n\t  if (Object.getOwnPropertySymbols) {\n\t    return names.concat(Object.getOwnPropertySymbols(events));\n\t  }\n\n\t  return names;\n\t};\n\n\t/**\n\t * Return the listeners registered for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @returns {Array} The registered listeners.\n\t * @public\n\t */\n\tEventEmitter.prototype.listeners = function listeners(event) {\n\t  var evt = prefix ? prefix + event : event\n\t    , handlers = this._events[evt];\n\n\t  if (!handlers) return [];\n\t  if (handlers.fn) return [handlers.fn];\n\n\t  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {\n\t    ee[i] = handlers[i].fn;\n\t  }\n\n\t  return ee;\n\t};\n\n\t/**\n\t * Return the number of listeners listening to a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @returns {Number} The number of listeners.\n\t * @public\n\t */\n\tEventEmitter.prototype.listenerCount = function listenerCount(event) {\n\t  var evt = prefix ? prefix + event : event\n\t    , listeners = this._events[evt];\n\n\t  if (!listeners) return 0;\n\t  if (listeners.fn) return 1;\n\t  return listeners.length;\n\t};\n\n\t/**\n\t * Calls each of the listeners registered for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @returns {Boolean} `true` if the event had listeners, else `false`.\n\t * @public\n\t */\n\tEventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\n\t  var evt = prefix ? prefix + event : event;\n\n\t  if (!this._events[evt]) return false;\n\n\t  var listeners = this._events[evt]\n\t    , len = arguments.length\n\t    , args\n\t    , i;\n\n\t  if (listeners.fn) {\n\t    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\n\n\t    switch (len) {\n\t      case 1: return listeners.fn.call(listeners.context), true;\n\t      case 2: return listeners.fn.call(listeners.context, a1), true;\n\t      case 3: return listeners.fn.call(listeners.context, a1, a2), true;\n\t      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;\n\t      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\n\t      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\n\t    }\n\n\t    for (i = 1, args = new Array(len -1); i < len; i++) {\n\t      args[i - 1] = arguments[i];\n\t    }\n\n\t    listeners.fn.apply(listeners.context, args);\n\t  } else {\n\t    var length = listeners.length\n\t      , j;\n\n\t    for (i = 0; i < length; i++) {\n\t      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\n\n\t      switch (len) {\n\t        case 1: listeners[i].fn.call(listeners[i].context); break;\n\t        case 2: listeners[i].fn.call(listeners[i].context, a1); break;\n\t        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;\n\t        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;\n\t        default:\n\t          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {\n\t            args[j - 1] = arguments[j];\n\t          }\n\n\t          listeners[i].fn.apply(listeners[i].context, args);\n\t      }\n\t    }\n\t  }\n\n\t  return true;\n\t};\n\n\t/**\n\t * Add a listener for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn The listener function.\n\t * @param {*} [context=this] The context to invoke the listener with.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.on = function on(event, fn, context) {\n\t  return addListener(this, event, fn, context, false);\n\t};\n\n\t/**\n\t * Add a one-time listener for a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn The listener function.\n\t * @param {*} [context=this] The context to invoke the listener with.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.once = function once(event, fn, context) {\n\t  return addListener(this, event, fn, context, true);\n\t};\n\n\t/**\n\t * Remove the listeners of a given event.\n\t *\n\t * @param {(String|Symbol)} event The event name.\n\t * @param {Function} fn Only remove the listeners that match this function.\n\t * @param {*} context Only remove the listeners that have this context.\n\t * @param {Boolean} once Only remove one-time listeners.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\n\t  var evt = prefix ? prefix + event : event;\n\n\t  if (!this._events[evt]) return this;\n\t  if (!fn) {\n\t    clearEvent(this, evt);\n\t    return this;\n\t  }\n\n\t  var listeners = this._events[evt];\n\n\t  if (listeners.fn) {\n\t    if (\n\t      listeners.fn === fn &&\n\t      (!once || listeners.once) &&\n\t      (!context || listeners.context === context)\n\t    ) {\n\t      clearEvent(this, evt);\n\t    }\n\t  } else {\n\t    for (var i = 0, events = [], length = listeners.length; i < length; i++) {\n\t      if (\n\t        listeners[i].fn !== fn ||\n\t        (once && !listeners[i].once) ||\n\t        (context && listeners[i].context !== context)\n\t      ) {\n\t        events.push(listeners[i]);\n\t      }\n\t    }\n\n\t    //\n\t    // Reset the array, or remove it completely if we have no more listeners.\n\t    //\n\t    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\n\t    else clearEvent(this, evt);\n\t  }\n\n\t  return this;\n\t};\n\n\t/**\n\t * Remove all listeners, or those of the specified event.\n\t *\n\t * @param {(String|Symbol)} [event] The event name.\n\t * @returns {EventEmitter} `this`.\n\t * @public\n\t */\n\tEventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\n\t  var evt;\n\n\t  if (event) {\n\t    evt = prefix ? prefix + event : event;\n\t    if (this._events[evt]) clearEvent(this, evt);\n\t  } else {\n\t    this._events = new Events();\n\t    this._eventsCount = 0;\n\t  }\n\n\t  return this;\n\t};\n\n\t//\n\t// Alias methods names because people roll like that.\n\t//\n\tEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\tEventEmitter.prototype.addListener = EventEmitter.prototype.on;\n\n\t//\n\t// Expose the prefix.\n\t//\n\tEventEmitter.prefixed = prefix;\n\n\t//\n\t// Allow `EventEmitter` to be imported as module namespace.\n\t//\n\tEventEmitter.EventEmitter = EventEmitter;\n\n\t//\n\t// Expose the module.\n\t//\n\t{\n\t  module.exports = EventEmitter;\n\t} \n} (eventemitter3));\n\nvar eventemitter3Exports = eventemitter3.exports;\nvar EventEmitter = /*@__PURE__*/getDefaultExportFromCjs(eventemitter3Exports);\n\nclass TransmuxerInterface {\n  constructor(hls, id, onTransmuxComplete, onFlush) {\n    this.error = null;\n    this.hls = void 0;\n    this.id = void 0;\n    this.observer = void 0;\n    this.frag = null;\n    this.part = null;\n    this.useWorker = void 0;\n    this.workerContext = null;\n    this.onwmsg = void 0;\n    this.transmuxer = null;\n    this.onTransmuxComplete = void 0;\n    this.onFlush = void 0;\n    const config = hls.config;\n    this.hls = hls;\n    this.id = id;\n    this.useWorker = !!config.enableWorker;\n    this.onTransmuxComplete = onTransmuxComplete;\n    this.onFlush = onFlush;\n    const forwardMessage = (ev, data) => {\n      data = data || {};\n      data.frag = this.frag;\n      data.id = this.id;\n      if (ev === Events.ERROR) {\n        this.error = data.error;\n      }\n      this.hls.trigger(ev, data);\n    };\n\n    // forward events to main thread\n    this.observer = new EventEmitter();\n    this.observer.on(Events.FRAG_DECRYPTED, forwardMessage);\n    this.observer.on(Events.ERROR, forwardMessage);\n    const MediaSource = getMediaSource(config.preferManagedMediaSource) || {\n      isTypeSupported: () => false\n    };\n    const m2tsTypeSupported = {\n      mpeg: MediaSource.isTypeSupported('audio/mpeg'),\n      mp3: MediaSource.isTypeSupported('audio/mp4; codecs=\"mp3\"'),\n      ac3: MediaSource.isTypeSupported('audio/mp4; codecs=\"ac-3\"') \n    };\n    if (this.useWorker && typeof Worker !== 'undefined') {\n      const canCreateWorker = config.workerPath || hasUMDWorker();\n      if (canCreateWorker) {\n        try {\n          if (config.workerPath) {\n            logger.log(`loading Web Worker ${config.workerPath} for \"${id}\"`);\n            this.workerContext = loadWorker(config.workerPath);\n          } else {\n            logger.log(`injecting Web Worker for \"${id}\"`);\n            this.workerContext = injectWorker();\n          }\n          this.onwmsg = event => this.onWorkerMessage(event);\n          const {\n            worker\n          } = this.workerContext;\n          worker.addEventListener('message', this.onwmsg);\n          worker.onerror = event => {\n            const error = new Error(`${event.message}  (${event.filename}:${event.lineno})`);\n            config.enableWorker = false;\n            logger.warn(`Error in \"${id}\" Web Worker, fallback to inline`);\n            this.hls.trigger(Events.ERROR, {\n              type: ErrorTypes.OTHER_ERROR,\n              details: ErrorDetails.INTERNAL_EXCEPTION,\n              fatal: false,\n              event: 'demuxerWorker',\n              error\n            });\n          };\n          worker.postMessage({\n            cmd: 'init',\n            typeSupported: m2tsTypeSupported,\n            vendor: '',\n            id: id,\n            config: JSON.stringify(config)\n          });\n        } catch (err) {\n          logger.warn(`Error setting up \"${id}\" Web Worker, fallback to inline`, err);\n          this.resetWorker();\n          this.error = null;\n          this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id);\n        }\n        return;\n      }\n    }\n    this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id);\n  }\n  resetWorker() {\n    if (this.workerContext) {\n      const {\n        worker,\n        objectURL\n      } = this.workerContext;\n      if (objectURL) {\n        // revoke the Object URL that was used to create transmuxer worker, so as not to leak it\n        self.URL.revokeObjectURL(objectURL);\n      }\n      worker.removeEventListener('message', this.onwmsg);\n      worker.onerror = null;\n      worker.terminate();\n      this.workerContext = null;\n    }\n  }\n  destroy() {\n    if (this.workerContext) {\n      this.resetWorker();\n      this.onwmsg = undefined;\n    } else {\n      const transmuxer = this.transmuxer;\n      if (transmuxer) {\n        transmuxer.destroy();\n        this.transmuxer = null;\n      }\n    }\n    const observer = this.observer;\n    if (observer) {\n      observer.removeAllListeners();\n    }\n    this.frag = null;\n    // @ts-ignore\n    this.observer = null;\n    // @ts-ignore\n    this.hls = null;\n  }\n  push(data, initSegmentData, audioCodec, videoCodec, frag, part, duration, accurateTimeOffset, chunkMeta, defaultInitPTS) {\n    var _frag$initSegment, _lastFrag$initSegment;\n    chunkMeta.transmuxing.start = self.performance.now();\n    const {\n      transmuxer\n    } = this;\n    const timeOffset = part ? part.start : frag.start;\n    // TODO: push \"clear-lead\" decrypt data for unencrypted fragments in streams with encrypted ones\n    const decryptdata = frag.decryptdata;\n    const lastFrag = this.frag;\n    const discontinuity = !(lastFrag && frag.cc === lastFrag.cc);\n    const trackSwitch = !(lastFrag && chunkMeta.level === lastFrag.level);\n    const snDiff = lastFrag ? chunkMeta.sn - lastFrag.sn : -1;\n    const partDiff = this.part ? chunkMeta.part - this.part.index : -1;\n    const progressive = snDiff === 0 && chunkMeta.id > 1 && chunkMeta.id === (lastFrag == null ? void 0 : lastFrag.stats.chunkCount);\n    const contiguous = !trackSwitch && (snDiff === 1 || snDiff === 0 && (partDiff === 1 || progressive && partDiff <= 0));\n    const now = self.performance.now();\n    if (trackSwitch || snDiff || frag.stats.parsing.start === 0) {\n      frag.stats.parsing.start = now;\n    }\n    if (part && (partDiff || !contiguous)) {\n      part.stats.parsing.start = now;\n    }\n    const initSegmentChange = !(lastFrag && ((_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.url) === ((_lastFrag$initSegment = lastFrag.initSegment) == null ? void 0 : _lastFrag$initSegment.url));\n    const state = new TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange);\n    if (!contiguous || discontinuity || initSegmentChange) {\n      logger.log(`[transmuxer-interface, ${frag.type}]: Starting new transmux session for sn: ${chunkMeta.sn} p: ${chunkMeta.part} level: ${chunkMeta.level} id: ${chunkMeta.id}\n        discontinuity: ${discontinuity}\n        trackSwitch: ${trackSwitch}\n        contiguous: ${contiguous}\n        accurateTimeOffset: ${accurateTimeOffset}\n        timeOffset: ${timeOffset}\n        initSegmentChange: ${initSegmentChange}`);\n      const config = new TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPTS);\n      this.configureTransmuxer(config);\n    }\n    this.frag = frag;\n    this.part = part;\n\n    // Frags with sn of 'initSegment' are not transmuxed\n    if (this.workerContext) {\n      // post fragment payload as transferable objects for ArrayBuffer (no copy)\n      this.workerContext.worker.postMessage({\n        cmd: 'demux',\n        data,\n        decryptdata,\n        chunkMeta,\n        state\n      }, data instanceof ArrayBuffer ? [data] : []);\n    } else if (transmuxer) {\n      const transmuxResult = transmuxer.push(data, decryptdata, chunkMeta, state);\n      if (isPromise(transmuxResult)) {\n        transmuxer.async = true;\n        transmuxResult.then(data => {\n          this.handleTransmuxComplete(data);\n        }).catch(error => {\n          this.transmuxerError(error, chunkMeta, 'transmuxer-interface push error');\n        });\n      } else {\n        transmuxer.async = false;\n        this.handleTransmuxComplete(transmuxResult);\n      }\n    }\n  }\n  flush(chunkMeta) {\n    chunkMeta.transmuxing.start = self.performance.now();\n    const {\n      transmuxer\n    } = this;\n    if (this.workerContext) {\n      this.workerContext.worker.postMessage({\n        cmd: 'flush',\n        chunkMeta\n      });\n    } else if (transmuxer) {\n      let transmuxResult = transmuxer.flush(chunkMeta);\n      const asyncFlush = isPromise(transmuxResult);\n      if (asyncFlush || transmuxer.async) {\n        if (!isPromise(transmuxResult)) {\n          transmuxResult = Promise.resolve(transmuxResult);\n        }\n        transmuxResult.then(data => {\n          this.handleFlushResult(data, chunkMeta);\n        }).catch(error => {\n          this.transmuxerError(error, chunkMeta, 'transmuxer-interface flush error');\n        });\n      } else {\n        this.handleFlushResult(transmuxResult, chunkMeta);\n      }\n    }\n  }\n  transmuxerError(error, chunkMeta, reason) {\n    if (!this.hls) {\n      return;\n    }\n    this.error = error;\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.FRAG_PARSING_ERROR,\n      chunkMeta,\n      frag: this.frag || undefined,\n      fatal: false,\n      error,\n      err: error,\n      reason\n    });\n  }\n  handleFlushResult(results, chunkMeta) {\n    results.forEach(result => {\n      this.handleTransmuxComplete(result);\n    });\n    this.onFlush(chunkMeta);\n  }\n  onWorkerMessage(event) {\n    const data = event.data;\n    if (!(data != null && data.event)) {\n      logger.warn(`worker message received with no ${data ? 'event name' : 'data'}`);\n      return;\n    }\n    const hls = this.hls;\n    if (!this.hls) {\n      return;\n    }\n    switch (data.event) {\n      case 'init':\n        {\n          var _this$workerContext;\n          const objectURL = (_this$workerContext = this.workerContext) == null ? void 0 : _this$workerContext.objectURL;\n          if (objectURL) {\n            // revoke the Object URL that was used to create transmuxer worker, so as not to leak it\n            self.URL.revokeObjectURL(objectURL);\n          }\n          break;\n        }\n      case 'transmuxComplete':\n        {\n          this.handleTransmuxComplete(data.data);\n          break;\n        }\n      case 'flush':\n        {\n          this.onFlush(data.data);\n          break;\n        }\n\n      // pass logs from the worker thread to the main logger\n      case 'workerLog':\n        if (logger[data.data.logType]) {\n          logger[data.data.logType](data.data.message);\n        }\n        break;\n      default:\n        {\n          data.data = data.data || {};\n          data.data.frag = this.frag;\n          data.data.id = this.id;\n          hls.trigger(data.event, data.data);\n          break;\n        }\n    }\n  }\n  configureTransmuxer(config) {\n    const {\n      transmuxer\n    } = this;\n    if (this.workerContext) {\n      this.workerContext.worker.postMessage({\n        cmd: 'configure',\n        config\n      });\n    } else if (transmuxer) {\n      transmuxer.configure(config);\n    }\n  }\n  handleTransmuxComplete(result) {\n    result.chunkMeta.transmuxing.end = self.performance.now();\n    this.onTransmuxComplete(result);\n  }\n}\n\nfunction subtitleOptionsIdentical(trackList1, trackList2) {\n  if (trackList1.length !== trackList2.length) {\n    return false;\n  }\n  for (let i = 0; i < trackList1.length; i++) {\n    if (!mediaAttributesIdentical(trackList1[i].attrs, trackList2[i].attrs)) {\n      return false;\n    }\n  }\n  return true;\n}\nfunction mediaAttributesIdentical(attrs1, attrs2, customAttributes) {\n  // Media options with the same rendition ID must be bit identical\n  const stableRenditionId = attrs1['STABLE-RENDITION-ID'];\n  if (stableRenditionId && !customAttributes) {\n    return stableRenditionId === attrs2['STABLE-RENDITION-ID'];\n  }\n  // When rendition ID is not present, compare attributes\n  return !(customAttributes || ['LANGUAGE', 'NAME', 'CHARACTERISTICS', 'AUTOSELECT', 'DEFAULT', 'FORCED', 'ASSOC-LANGUAGE']).some(subtitleAttribute => attrs1[subtitleAttribute] !== attrs2[subtitleAttribute]);\n}\nfunction subtitleTrackMatchesTextTrack(subtitleTrack, textTrack) {\n  return textTrack.label.toLowerCase() === subtitleTrack.name.toLowerCase() && (!textTrack.language || textTrack.language.toLowerCase() === (subtitleTrack.lang || '').toLowerCase());\n}\n\nconst TICK_INTERVAL$2 = 100; // how often to tick in ms\n\nclass AudioStreamController extends BaseStreamController {\n  constructor(hls, fragmentTracker, keyLoader) {\n    super(hls, fragmentTracker, keyLoader, '[audio-stream-controller]', PlaylistLevelType.AUDIO);\n    this.videoBuffer = null;\n    this.videoTrackCC = -1;\n    this.waitingVideoCC = -1;\n    this.bufferedTrack = null;\n    this.switchingTrack = null;\n    this.trackId = -1;\n    this.waitingData = null;\n    this.mainDetails = null;\n    this.flushing = false;\n    this.bufferFlushed = false;\n    this.cachedTrackLoadedData = null;\n    this._registerListeners();\n  }\n  onHandlerDestroying() {\n    this._unregisterListeners();\n    super.onHandlerDestroying();\n    this.mainDetails = null;\n    this.bufferedTrack = null;\n    this.switchingTrack = null;\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);\n    hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n    hls.on(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);\n    hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n    hls.off(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n\n  // INIT_PTS_FOUND is triggered when the video track parsed in the stream-controller has a new PTS value\n  onInitPtsFound(event, {\n    frag,\n    id,\n    initPTS,\n    timescale\n  }) {\n    // Always update the new INIT PTS\n    // Can change due level switch\n    if (id === 'main') {\n      const cc = frag.cc;\n      this.initPTS[frag.cc] = {\n        baseTime: initPTS,\n        timescale\n      };\n      this.log(`InitPTS for cc: ${cc} found from main: ${initPTS}`);\n      this.videoTrackCC = cc;\n      // If we are waiting, tick immediately to unblock audio fragment transmuxing\n      if (this.state === State.WAITING_INIT_PTS) {\n        this.tick();\n      }\n    }\n  }\n  startLoad(startPosition) {\n    if (!this.levels) {\n      this.startPosition = startPosition;\n      this.state = State.STOPPED;\n      return;\n    }\n    const lastCurrentTime = this.lastCurrentTime;\n    this.stopLoad();\n    this.setInterval(TICK_INTERVAL$2);\n    if (lastCurrentTime > 0 && startPosition === -1) {\n      this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);\n      startPosition = lastCurrentTime;\n      this.state = State.IDLE;\n    } else {\n      this.loadedmetadata = false;\n      this.state = State.WAITING_TRACK;\n    }\n    this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n    this.tick();\n  }\n  doTick() {\n    switch (this.state) {\n      case State.IDLE:\n        this.doTickIdle();\n        break;\n      case State.WAITING_TRACK:\n        {\n          var _levels$trackId;\n          const {\n            levels,\n            trackId\n          } = this;\n          const details = levels == null ? void 0 : (_levels$trackId = levels[trackId]) == null ? void 0 : _levels$trackId.details;\n          if (details) {\n            if (this.waitForCdnTuneIn(details)) {\n              break;\n            }\n            this.state = State.WAITING_INIT_PTS;\n          }\n          break;\n        }\n      case State.FRAG_LOADING_WAITING_RETRY:\n        {\n          var _this$media;\n          const now = performance.now();\n          const retryDate = this.retryDate;\n          // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n          if (!retryDate || now >= retryDate || (_this$media = this.media) != null && _this$media.seeking) {\n            const {\n              levels,\n              trackId\n            } = this;\n            this.log('RetryDate reached, switch back to IDLE state');\n            this.resetStartWhenNotLoaded((levels == null ? void 0 : levels[trackId]) || null);\n            this.state = State.IDLE;\n          }\n          break;\n        }\n      case State.WAITING_INIT_PTS:\n        {\n          // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS\n          const waitingData = this.waitingData;\n          if (waitingData) {\n            const {\n              frag,\n              part,\n              cache,\n              complete\n            } = waitingData;\n            if (this.initPTS[frag.cc] !== undefined) {\n              this.waitingData = null;\n              this.waitingVideoCC = -1;\n              this.state = State.FRAG_LOADING;\n              const payload = cache.flush();\n              const data = {\n                frag,\n                part,\n                payload,\n                networkDetails: null\n              };\n              this._handleFragmentLoadProgress(data);\n              if (complete) {\n                super._handleFragmentLoadComplete(data);\n              }\n            } else if (this.videoTrackCC !== this.waitingVideoCC) {\n              // Drop waiting fragment if videoTrackCC has changed since waitingFragment was set and initPTS was not found\n              this.log(`Waiting fragment cc (${frag.cc}) cancelled because video is at cc ${this.videoTrackCC}`);\n              this.clearWaitingFragment();\n            } else {\n              // Drop waiting fragment if an earlier fragment is needed\n              const pos = this.getLoadPosition();\n              const bufferInfo = BufferHelper.bufferInfo(this.mediaBuffer, pos, this.config.maxBufferHole);\n              const waitingFragmentAtPosition = fragmentWithinToleranceTest(bufferInfo.end, this.config.maxFragLookUpTolerance, frag);\n              if (waitingFragmentAtPosition < 0) {\n                this.log(`Waiting fragment cc (${frag.cc}) @ ${frag.start} cancelled because another fragment at ${bufferInfo.end} is needed`);\n                this.clearWaitingFragment();\n              }\n            }\n          } else {\n            this.state = State.IDLE;\n          }\n        }\n    }\n    this.onTickEnd();\n  }\n  clearWaitingFragment() {\n    const waitingData = this.waitingData;\n    if (waitingData) {\n      this.fragmentTracker.removeFragment(waitingData.frag);\n      this.waitingData = null;\n      this.waitingVideoCC = -1;\n      this.state = State.IDLE;\n    }\n  }\n  resetLoadingState() {\n    this.clearWaitingFragment();\n    super.resetLoadingState();\n  }\n  onTickEnd() {\n    const {\n      media\n    } = this;\n    if (!(media != null && media.readyState)) {\n      // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)\n      return;\n    }\n    this.lastCurrentTime = media.currentTime;\n  }\n  doTickIdle() {\n    const {\n      hls,\n      levels,\n      media,\n      trackId\n    } = this;\n    const config = hls.config;\n\n    // 1. if video not attached AND\n    //    start fragment already requested OR start frag prefetch not enabled\n    // 2. if tracks or track not loaded and selected\n    // then exit loop\n    // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop\n    if (!media && (this.startFragRequested || !config.startFragPrefetch) || !(levels != null && levels[trackId])) {\n      return;\n    }\n    const levelInfo = levels[trackId];\n    const trackDetails = levelInfo.details;\n    if (!trackDetails || trackDetails.live && this.levelLastLoaded !== levelInfo || this.waitForCdnTuneIn(trackDetails)) {\n      this.state = State.WAITING_TRACK;\n      return;\n    }\n    const bufferable = this.mediaBuffer ? this.mediaBuffer : this.media;\n    if (this.bufferFlushed && bufferable) {\n      this.bufferFlushed = false;\n      this.afterBufferFlushed(bufferable, ElementaryStreamTypes.AUDIO, PlaylistLevelType.AUDIO);\n    }\n    const bufferInfo = this.getFwdBufferInfo(bufferable, PlaylistLevelType.AUDIO);\n    if (bufferInfo === null) {\n      return;\n    }\n    const {\n      bufferedTrack,\n      switchingTrack\n    } = this;\n    if (!switchingTrack && this._streamEnded(bufferInfo, trackDetails)) {\n      hls.trigger(Events.BUFFER_EOS, {\n        type: 'audio'\n      });\n      this.state = State.ENDED;\n      return;\n    }\n    const mainBufferInfo = this.getFwdBufferInfo(this.videoBuffer ? this.videoBuffer : this.media, PlaylistLevelType.MAIN);\n    const bufferLen = bufferInfo.len;\n    const maxBufLen = this.getMaxBufferLength(mainBufferInfo == null ? void 0 : mainBufferInfo.len);\n    const fragments = trackDetails.fragments;\n    const start = fragments[0].start;\n    let targetBufferTime = this.flushing ? this.getLoadPosition() : bufferInfo.end;\n    if (switchingTrack && media) {\n      const pos = this.getLoadPosition();\n      // STABLE\n      if (bufferedTrack && !mediaAttributesIdentical(switchingTrack.attrs, bufferedTrack.attrs)) {\n        targetBufferTime = pos;\n      }\n      // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime\n      if (trackDetails.PTSKnown && pos < start) {\n        // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start\n        if (bufferInfo.end > start || bufferInfo.nextStart) {\n          this.log('Alt audio track ahead of main track, seek to start of alt audio track');\n          media.currentTime = start + 0.05;\n        }\n      }\n    }\n\n    // if buffer length is less than maxBufLen, or near the end, find a fragment to load\n    if (bufferLen >= maxBufLen && !switchingTrack && targetBufferTime < fragments[fragments.length - 1].start) {\n      return;\n    }\n    let frag = this.getNextFragment(targetBufferTime, trackDetails);\n    let atGap = false;\n    // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags\n    if (frag && this.isLoopLoading(frag, targetBufferTime)) {\n      atGap = !!frag.gap;\n      frag = this.getNextFragmentLoopLoading(frag, trackDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);\n    }\n    if (!frag) {\n      this.bufferFlushed = true;\n      return;\n    }\n\n    // Buffer audio up to one target duration ahead of main buffer\n    const atBufferSyncLimit = mainBufferInfo && frag.start > mainBufferInfo.end + trackDetails.targetduration;\n    if (atBufferSyncLimit ||\n    // Or wait for main buffer after buffing some audio\n    !(mainBufferInfo != null && mainBufferInfo.len) && bufferInfo.len) {\n      // Check fragment-tracker for main fragments since GAP segments do not show up in bufferInfo\n      const mainFrag = this.getAppendedFrag(frag.start, PlaylistLevelType.MAIN);\n      if (mainFrag === null) {\n        return;\n      }\n      // Bridge gaps in main buffer\n      atGap || (atGap = !!mainFrag.gap || !!atBufferSyncLimit && mainBufferInfo.len === 0);\n      if (atBufferSyncLimit && !atGap || atGap && bufferInfo.nextStart && bufferInfo.nextStart < mainFrag.end) {\n        return;\n      }\n    }\n    this.loadFragment(frag, levelInfo, targetBufferTime);\n  }\n  getMaxBufferLength(mainBufferLength) {\n    const maxConfigBuffer = super.getMaxBufferLength();\n    if (!mainBufferLength) {\n      return maxConfigBuffer;\n    }\n    return Math.min(Math.max(maxConfigBuffer, mainBufferLength), this.config.maxMaxBufferLength);\n  }\n  onMediaDetaching() {\n    this.videoBuffer = null;\n    this.bufferFlushed = this.flushing = false;\n    super.onMediaDetaching();\n  }\n  onAudioTracksUpdated(event, {\n    audioTracks\n  }) {\n    // Reset tranxmuxer is essential for large context switches (Content Steering)\n    this.resetTransmuxer();\n    this.levels = audioTracks.map(mediaPlaylist => new Level(mediaPlaylist));\n  }\n  onAudioTrackSwitching(event, data) {\n    // if any URL found on new audio track, it is an alternate audio track\n    const altAudio = !!data.url;\n    this.trackId = data.id;\n    const {\n      fragCurrent\n    } = this;\n    if (fragCurrent) {\n      fragCurrent.abortRequests();\n      this.removeUnbufferedFrags(fragCurrent.start);\n    }\n    this.resetLoadingState();\n    // destroy useless transmuxer when switching audio to main\n    if (!altAudio) {\n      this.resetTransmuxer();\n    } else {\n      // switching to audio track, start timer if not already started\n      this.setInterval(TICK_INTERVAL$2);\n    }\n\n    // should we switch tracks ?\n    if (altAudio) {\n      this.switchingTrack = data;\n      // main audio track are handled by stream-controller, just do something if switching to alt audio track\n      this.state = State.IDLE;\n      this.flushAudioIfNeeded(data);\n    } else {\n      this.switchingTrack = null;\n      this.bufferedTrack = data;\n      this.state = State.STOPPED;\n    }\n    this.tick();\n  }\n  onManifestLoading() {\n    this.fragmentTracker.removeAllFragments();\n    this.startPosition = this.lastCurrentTime = 0;\n    this.bufferFlushed = this.flushing = false;\n    this.levels = this.mainDetails = this.waitingData = this.bufferedTrack = this.cachedTrackLoadedData = this.switchingTrack = null;\n    this.startFragRequested = false;\n    this.trackId = this.videoTrackCC = this.waitingVideoCC = -1;\n  }\n  onLevelLoaded(event, data) {\n    this.mainDetails = data.details;\n    if (this.cachedTrackLoadedData !== null) {\n      this.hls.trigger(Events.AUDIO_TRACK_LOADED, this.cachedTrackLoadedData);\n      this.cachedTrackLoadedData = null;\n    }\n  }\n  onAudioTrackLoaded(event, data) {\n    var _track$details;\n    if (this.mainDetails == null) {\n      this.cachedTrackLoadedData = data;\n      return;\n    }\n    const {\n      levels\n    } = this;\n    const {\n      details: newDetails,\n      id: trackId\n    } = data;\n    if (!levels) {\n      this.warn(`Audio tracks were reset while loading level ${trackId}`);\n      return;\n    }\n    this.log(`Audio track ${trackId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''},duration:${newDetails.totalduration}`);\n    const track = levels[trackId];\n    let sliding = 0;\n    if (newDetails.live || (_track$details = track.details) != null && _track$details.live) {\n      this.checkLiveUpdate(newDetails);\n      const mainDetails = this.mainDetails;\n      if (newDetails.deltaUpdateFailed || !mainDetails) {\n        return;\n      }\n      if (!track.details && newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {\n        // Make sure our audio rendition is aligned with the \"main\" rendition, using\n        // pdt as our reference times.\n        alignMediaPlaylistByPDT(newDetails, mainDetails);\n        sliding = newDetails.fragments[0].start;\n      } else {\n        var _this$levelLastLoaded;\n        sliding = this.alignPlaylists(newDetails, track.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n      }\n    }\n    track.details = newDetails;\n    this.levelLastLoaded = track;\n\n    // compute start position if we are aligned with the main playlist\n    if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {\n      this.setStartPosition(this.mainDetails || newDetails, sliding);\n    }\n    // only switch back to IDLE state if we were waiting for track to start downloading a new fragment\n    if (this.state === State.WAITING_TRACK && !this.waitForCdnTuneIn(newDetails)) {\n      this.state = State.IDLE;\n    }\n\n    // trigger handler right now\n    this.tick();\n  }\n  _handleFragmentLoadProgress(data) {\n    var _frag$initSegment;\n    const {\n      frag,\n      part,\n      payload\n    } = data;\n    const {\n      config,\n      trackId,\n      levels\n    } = this;\n    if (!levels) {\n      this.warn(`Audio tracks were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);\n      return;\n    }\n    const track = levels[trackId];\n    if (!track) {\n      this.warn('Audio track is undefined on fragment load progress');\n      return;\n    }\n    const details = track.details;\n    if (!details) {\n      this.warn('Audio track details undefined on fragment load progress');\n      this.removeUnbufferedFrags(frag.start);\n      return;\n    }\n    const audioCodec = config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2';\n    let transmuxer = this.transmuxer;\n    if (!transmuxer) {\n      transmuxer = this.transmuxer = new TransmuxerInterface(this.hls, PlaylistLevelType.AUDIO, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));\n    }\n\n    // Check if we have video initPTS\n    // If not we need to wait for it\n    const initPTS = this.initPTS[frag.cc];\n    const initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;\n    if (initPTS !== undefined) {\n      // this.log(`Transmuxing ${sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);\n      // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n      const accurateTimeOffset = false; // details.PTSKnown || !details.live;\n      const partIndex = part ? part.index : -1;\n      const partial = partIndex !== -1;\n      const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);\n      transmuxer.push(payload, initSegmentData, audioCodec, '', frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);\n    } else {\n      this.log(`Unknown video PTS for cc ${frag.cc}, waiting for video PTS before demuxing audio frag ${frag.sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);\n      const {\n        cache\n      } = this.waitingData = this.waitingData || {\n        frag,\n        part,\n        cache: new ChunkCache(),\n        complete: false\n      };\n      cache.push(new Uint8Array(payload));\n      this.waitingVideoCC = this.videoTrackCC;\n      this.state = State.WAITING_INIT_PTS;\n    }\n  }\n  _handleFragmentLoadComplete(fragLoadedData) {\n    if (this.waitingData) {\n      this.waitingData.complete = true;\n      return;\n    }\n    super._handleFragmentLoadComplete(fragLoadedData);\n  }\n  onBufferReset( /* event: Events.BUFFER_RESET */\n  ) {\n    // reset reference to sourcebuffers\n    this.mediaBuffer = this.videoBuffer = null;\n    this.loadedmetadata = false;\n  }\n  onBufferCreated(event, data) {\n    const audioTrack = data.tracks.audio;\n    if (audioTrack) {\n      this.mediaBuffer = audioTrack.buffer || null;\n    }\n    if (data.tracks.video) {\n      this.videoBuffer = data.tracks.video.buffer || null;\n    }\n  }\n  onFragBuffered(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    if (frag.type !== PlaylistLevelType.AUDIO) {\n      if (!this.loadedmetadata && frag.type === PlaylistLevelType.MAIN) {\n        const bufferable = this.videoBuffer || this.media;\n        if (bufferable) {\n          const bufferedTimeRanges = BufferHelper.getBuffered(bufferable);\n          if (bufferedTimeRanges.length) {\n            this.loadedmetadata = true;\n          }\n        }\n      }\n      return;\n    }\n    if (this.fragContextChanged(frag)) {\n      // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion\n      // Avoid setting state back to IDLE or concluding the audio switch; otherwise, the switched-to track will not buffer\n      this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}, audioSwitch: ${this.switchingTrack ? this.switchingTrack.name : 'false'}`);\n      return;\n    }\n    if (frag.sn !== 'initSegment') {\n      this.fragPrevious = frag;\n      const track = this.switchingTrack;\n      if (track) {\n        this.bufferedTrack = track;\n        this.switchingTrack = null;\n        this.hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, track));\n      }\n    }\n    this.fragBufferedComplete(frag, part);\n  }\n  onError(event, data) {\n    var _data$context;\n    if (data.fatal) {\n      this.state = State.ERROR;\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_PARSING_ERROR:\n      case ErrorDetails.FRAG_DECRYPT_ERROR:\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        this.onFragmentOrKeyLoadError(PlaylistLevelType.AUDIO, data);\n        break;\n      case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n      case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        // in case of non fatal error while loading track, if not retrying to load track, switch back to IDLE\n        if (!data.levelRetry && this.state === State.WAITING_TRACK && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.AUDIO_TRACK) {\n          this.state = State.IDLE;\n        }\n        break;\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n      case ErrorDetails.BUFFER_FULL_ERROR:\n        if (!data.parent || data.parent !== 'audio') {\n          return;\n        }\n        if (data.details === ErrorDetails.BUFFER_APPEND_ERROR) {\n          this.resetLoadingState();\n          return;\n        }\n        if (this.reduceLengthAndFlushBuffer(data)) {\n          this.bufferedTrack = null;\n          super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');\n        }\n        break;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n        this.recoverWorkerError(data);\n        break;\n    }\n  }\n  onBufferFlushing(event, {\n    type\n  }) {\n    if (type !== ElementaryStreamTypes.VIDEO) {\n      this.flushing = true;\n    }\n  }\n  onBufferFlushed(event, {\n    type\n  }) {\n    if (type !== ElementaryStreamTypes.VIDEO) {\n      this.flushing = false;\n      this.bufferFlushed = true;\n      if (this.state === State.ENDED) {\n        this.state = State.IDLE;\n      }\n      const mediaBuffer = this.mediaBuffer || this.media;\n      if (mediaBuffer) {\n        this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.AUDIO);\n        this.tick();\n      }\n    }\n  }\n  _handleTransmuxComplete(transmuxResult) {\n    var _id3$samples;\n    const id = 'audio';\n    const {\n      hls\n    } = this;\n    const {\n      remuxResult,\n      chunkMeta\n    } = transmuxResult;\n    const context = this.getCurrentContext(chunkMeta);\n    if (!context) {\n      this.resetWhenMissingContext(chunkMeta);\n      return;\n    }\n    const {\n      frag,\n      part,\n      level\n    } = context;\n    const {\n      details\n    } = level;\n    const {\n      audio,\n      text,\n      id3,\n      initSegment\n    } = remuxResult;\n\n    // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.\n    // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.\n    if (this.fragContextChanged(frag) || !details) {\n      this.fragmentTracker.removeFragment(frag);\n      return;\n    }\n    this.state = State.PARSING;\n    if (this.switchingTrack && audio) {\n      this.completeAudioSwitch(this.switchingTrack);\n    }\n    if (initSegment != null && initSegment.tracks) {\n      const mapFragment = frag.initSegment || frag;\n      this._bufferInitSegment(level, initSegment.tracks, mapFragment, chunkMeta);\n      hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {\n        frag: mapFragment,\n        id,\n        tracks: initSegment.tracks\n      });\n      // Only flush audio from old audio tracks when PTS is known on new audio track\n    }\n    if (audio) {\n      const {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS\n      } = audio;\n      if (part) {\n        part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {\n          startPTS,\n          endPTS,\n          startDTS,\n          endDTS\n        };\n      }\n      frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);\n      this.bufferFragmentData(audio, frag, part, chunkMeta);\n    }\n    if (id3 != null && (_id3$samples = id3.samples) != null && _id3$samples.length) {\n      const emittedID3 = _extends({\n        id,\n        frag,\n        details\n      }, id3);\n      hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);\n    }\n    if (text) {\n      const emittedText = _extends({\n        id,\n        frag,\n        details\n      }, text);\n      hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);\n    }\n  }\n  _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {\n    if (this.state !== State.PARSING) {\n      return;\n    }\n    // delete any video track found on audio transmuxer\n    if (tracks.video) {\n      delete tracks.video;\n    }\n\n    // include levelCodec in audio and video tracks\n    const track = tracks.audio;\n    if (!track) {\n      return;\n    }\n    track.id = 'audio';\n    const variantAudioCodecs = currentLevel.audioCodec;\n    this.log(`Init audio buffer, container:${track.container}, codecs[level/parsed]=[${variantAudioCodecs}/${track.codec}]`);\n    // SourceBuffer will use track.levelCodec if defined\n    if (variantAudioCodecs && variantAudioCodecs.split(',').length === 1) {\n      track.levelCodec = variantAudioCodecs;\n    }\n    this.hls.trigger(Events.BUFFER_CODECS, tracks);\n    const initSegment = track.initSegment;\n    if (initSegment != null && initSegment.byteLength) {\n      const segment = {\n        type: 'audio',\n        frag,\n        part: null,\n        chunkMeta,\n        parent: frag.type,\n        data: initSegment\n      };\n      this.hls.trigger(Events.BUFFER_APPENDING, segment);\n    }\n    // trigger handler right now\n    this.tickImmediate();\n  }\n  loadFragment(frag, track, targetBufferTime) {\n    // only load if fragment is not loaded or if in audio switch\n    const fragState = this.fragmentTracker.getState(frag);\n    this.fragCurrent = frag;\n\n    // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch\n    if (this.switchingTrack || fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\n      var _track$details2;\n      if (frag.sn === 'initSegment') {\n        this._loadInitSegment(frag, track);\n      } else if ((_track$details2 = track.details) != null && _track$details2.live && !this.initPTS[frag.cc]) {\n        this.log(`Waiting for video PTS in continuity counter ${frag.cc} of live stream before loading audio fragment ${frag.sn} of level ${this.trackId}`);\n        this.state = State.WAITING_INIT_PTS;\n        const mainDetails = this.mainDetails;\n        if (mainDetails && mainDetails.fragments[0].start !== track.details.fragments[0].start) {\n          alignMediaPlaylistByPDT(track.details, mainDetails);\n        }\n      } else {\n        this.startFragRequested = true;\n        super.loadFragment(frag, track, targetBufferTime);\n      }\n    } else {\n      this.clearTrackerIfNeeded(frag);\n    }\n  }\n  flushAudioIfNeeded(switchingTrack) {\n    const {\n      media,\n      bufferedTrack\n    } = this;\n    const bufferedAttributes = bufferedTrack == null ? void 0 : bufferedTrack.attrs;\n    const switchAttributes = switchingTrack.attrs;\n    if (media && bufferedAttributes && (bufferedAttributes.CHANNELS !== switchAttributes.CHANNELS || bufferedTrack.name !== switchingTrack.name || bufferedTrack.lang !== switchingTrack.lang)) {\n      this.log('Switching audio track : flushing all audio');\n      super.flushMainBuffer(0, Number.POSITIVE_INFINITY, 'audio');\n      this.bufferedTrack = null;\n    }\n  }\n  completeAudioSwitch(switchingTrack) {\n    const {\n      hls\n    } = this;\n    this.flushAudioIfNeeded(switchingTrack);\n    this.bufferedTrack = switchingTrack;\n    this.switchingTrack = null;\n    hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, switchingTrack));\n  }\n}\n\nclass AudioTrackController extends BasePlaylistController {\n  constructor(hls) {\n    super(hls, '[audio-track-controller]');\n    this.tracks = [];\n    this.groupIds = null;\n    this.tracksInGroup = [];\n    this.trackId = -1;\n    this.currentTrack = null;\n    this.selectDefaultTrack = true;\n    this.registerListeners();\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.tracks.length = 0;\n    this.tracksInGroup.length = 0;\n    this.currentTrack = null;\n    super.destroy();\n  }\n  onManifestLoading() {\n    this.tracks = [];\n    this.tracksInGroup = [];\n    this.groupIds = null;\n    this.currentTrack = null;\n    this.trackId = -1;\n    this.selectDefaultTrack = true;\n  }\n  onManifestParsed(event, data) {\n    this.tracks = data.audioTracks || [];\n  }\n  onAudioTrackLoaded(event, data) {\n    const {\n      id,\n      groupId,\n      details\n    } = data;\n    const trackInActiveGroup = this.tracksInGroup[id];\n    if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {\n      this.warn(`Audio track with id:${id} and group:${groupId} not found in active group ${trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId}`);\n      return;\n    }\n    const curDetails = trackInActiveGroup.details;\n    trackInActiveGroup.details = data.details;\n    this.log(`Audio track ${id} \"${trackInActiveGroup.name}\" lang:${trackInActiveGroup.lang} group:${groupId} loaded [${details.startSN}-${details.endSN}]`);\n    if (id === this.trackId) {\n      this.playlistLoaded(id, data, curDetails);\n    }\n  }\n  onLevelLoading(event, data) {\n    this.switchLevel(data.level);\n  }\n  onLevelSwitching(event, data) {\n    this.switchLevel(data.level);\n  }\n  switchLevel(levelIndex) {\n    const levelInfo = this.hls.levels[levelIndex];\n    if (!levelInfo) {\n      return;\n    }\n    const audioGroups = levelInfo.audioGroups || null;\n    const currentGroups = this.groupIds;\n    let currentTrack = this.currentTrack;\n    if (!audioGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (audioGroups == null ? void 0 : audioGroups.length) || audioGroups != null && audioGroups.some(groupId => (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1)) {\n      this.groupIds = audioGroups;\n      this.trackId = -1;\n      this.currentTrack = null;\n      const audioTracks = this.tracks.filter(track => !audioGroups || audioGroups.indexOf(track.groupId) !== -1);\n      if (audioTracks.length) {\n        // Disable selectDefaultTrack if there are no default tracks\n        if (this.selectDefaultTrack && !audioTracks.some(track => track.default)) {\n          this.selectDefaultTrack = false;\n        }\n        // track.id should match hls.audioTracks index\n        audioTracks.forEach((track, i) => {\n          track.id = i;\n        });\n      } else if (!currentTrack && !this.tracksInGroup.length) {\n        // Do not dispatch AUDIO_TRACKS_UPDATED when there were and are no tracks\n        return;\n      }\n      this.tracksInGroup = audioTracks;\n\n      // Find preferred track\n      const audioPreference = this.hls.config.audioPreference;\n      if (!currentTrack && audioPreference) {\n        const groupIndex = findMatchingOption(audioPreference, audioTracks, audioMatchPredicate);\n        if (groupIndex > -1) {\n          currentTrack = audioTracks[groupIndex];\n        } else {\n          const allIndex = findMatchingOption(audioPreference, this.tracks);\n          currentTrack = this.tracks[allIndex];\n        }\n      }\n\n      // Select initial track\n      let trackId = this.findTrackId(currentTrack);\n      if (trackId === -1 && currentTrack) {\n        trackId = this.findTrackId(null);\n      }\n\n      // Dispatch events and load track if needed\n      const audioTracksUpdated = {\n        audioTracks\n      };\n      this.log(`Updating audio tracks, ${audioTracks.length} track(s) found in group(s): ${audioGroups == null ? void 0 : audioGroups.join(',')}`);\n      this.hls.trigger(Events.AUDIO_TRACKS_UPDATED, audioTracksUpdated);\n      const selectedTrackId = this.trackId;\n      if (trackId !== -1 && selectedTrackId === -1) {\n        this.setAudioTrack(trackId);\n      } else if (audioTracks.length && selectedTrackId === -1) {\n        var _this$groupIds;\n        const error = new Error(`No audio track selected for current audio group-ID(s): ${(_this$groupIds = this.groupIds) == null ? void 0 : _this$groupIds.join(',')} track count: ${audioTracks.length}`);\n        this.warn(error.message);\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.AUDIO_TRACK_LOAD_ERROR,\n          fatal: true,\n          error\n        });\n      }\n    } else if (this.shouldReloadPlaylist(currentTrack)) {\n      // Retry playlist loading if no playlist is or has been loaded yet\n      this.setAudioTrack(this.trackId);\n    }\n  }\n  onError(event, data) {\n    if (data.fatal || !data.context) {\n      return;\n    }\n    if (data.context.type === PlaylistContextType.AUDIO_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {\n      this.requestScheduled = -1;\n      this.checkRetry(data);\n    }\n  }\n  get allAudioTracks() {\n    return this.tracks;\n  }\n  get audioTracks() {\n    return this.tracksInGroup;\n  }\n  get audioTrack() {\n    return this.trackId;\n  }\n  set audioTrack(newId) {\n    // If audio track is selected from API then don't choose from the manifest default track\n    this.selectDefaultTrack = false;\n    this.setAudioTrack(newId);\n  }\n  setAudioOption(audioOption) {\n    const hls = this.hls;\n    hls.config.audioPreference = audioOption;\n    if (audioOption) {\n      const allAudioTracks = this.allAudioTracks;\n      this.selectDefaultTrack = false;\n      if (allAudioTracks.length) {\n        // First see if current option matches (no switch op)\n        const currentTrack = this.currentTrack;\n        if (currentTrack && matchesOption(audioOption, currentTrack, audioMatchPredicate)) {\n          return currentTrack;\n        }\n        // Find option in available tracks (tracksInGroup)\n        const groupIndex = findMatchingOption(audioOption, this.tracksInGroup, audioMatchPredicate);\n        if (groupIndex > -1) {\n          const track = this.tracksInGroup[groupIndex];\n          this.setAudioTrack(groupIndex);\n          return track;\n        } else if (currentTrack) {\n          // Find option in nearest level audio group\n          let searchIndex = hls.loadLevel;\n          if (searchIndex === -1) {\n            searchIndex = hls.firstAutoLevel;\n          }\n          const switchIndex = findClosestLevelWithAudioGroup(audioOption, hls.levels, allAudioTracks, searchIndex, audioMatchPredicate);\n          if (switchIndex === -1) {\n            // could not find matching variant\n            return null;\n          }\n          // and switch level to acheive the audio group switch\n          hls.nextLoadLevel = switchIndex;\n        }\n        if (audioOption.channels || audioOption.audioCodec) {\n          // Could not find a match with codec / channels predicate\n          // Find a match without channels or codec\n          const withoutCodecAndChannelsMatch = findMatchingOption(audioOption, allAudioTracks);\n          if (withoutCodecAndChannelsMatch > -1) {\n            return allAudioTracks[withoutCodecAndChannelsMatch];\n          }\n        }\n      }\n    }\n    return null;\n  }\n  setAudioTrack(newId) {\n    const tracks = this.tracksInGroup;\n\n    // check if level idx is valid\n    if (newId < 0 || newId >= tracks.length) {\n      this.warn(`Invalid audio track id: ${newId}`);\n      return;\n    }\n\n    // stopping live reloading timer if any\n    this.clearTimer();\n    this.selectDefaultTrack = false;\n    const lastTrack = this.currentTrack;\n    const track = tracks[newId];\n    const trackLoaded = track.details && !track.details.live;\n    if (newId === this.trackId && track === lastTrack && trackLoaded) {\n      return;\n    }\n    this.log(`Switching to audio-track ${newId} \"${track.name}\" lang:${track.lang} group:${track.groupId} channels:${track.channels}`);\n    this.trackId = newId;\n    this.currentTrack = track;\n    this.hls.trigger(Events.AUDIO_TRACK_SWITCHING, _objectSpread2({}, track));\n    // Do not reload track unless live\n    if (trackLoaded) {\n      return;\n    }\n    const hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);\n    this.loadPlaylist(hlsUrlParameters);\n  }\n  findTrackId(currentTrack) {\n    const audioTracks = this.tracksInGroup;\n    for (let i = 0; i < audioTracks.length; i++) {\n      const track = audioTracks[i];\n      if (this.selectDefaultTrack && !track.default) {\n        continue;\n      }\n      if (!currentTrack || matchesOption(currentTrack, track, audioMatchPredicate)) {\n        return i;\n      }\n    }\n    if (currentTrack) {\n      const {\n        name,\n        lang,\n        assocLang,\n        characteristics,\n        audioCodec,\n        channels\n      } = currentTrack;\n      for (let i = 0; i < audioTracks.length; i++) {\n        const track = audioTracks[i];\n        if (matchesOption({\n          name,\n          lang,\n          assocLang,\n          characteristics,\n          audioCodec,\n          channels\n        }, track, audioMatchPredicate)) {\n          return i;\n        }\n      }\n      for (let i = 0; i < audioTracks.length; i++) {\n        const track = audioTracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {\n          return i;\n        }\n      }\n      for (let i = 0; i < audioTracks.length; i++) {\n        const track = audioTracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE'])) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  loadPlaylist(hlsUrlParameters) {\n    const audioTrack = this.currentTrack;\n    if (this.shouldLoadPlaylist(audioTrack) && audioTrack) {\n      super.loadPlaylist();\n      const id = audioTrack.id;\n      const groupId = audioTrack.groupId;\n      let url = audioTrack.url;\n      if (hlsUrlParameters) {\n        try {\n          url = hlsUrlParameters.addDirectives(url);\n        } catch (error) {\n          this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);\n        }\n      }\n      // track not retrieved yet, or live playlist we need to (re)load it\n      this.log(`loading audio-track playlist ${id} \"${audioTrack.name}\" lang:${audioTrack.lang} group:${groupId}`);\n      this.clearTimer();\n      this.hls.trigger(Events.AUDIO_TRACK_LOADING, {\n        url,\n        id,\n        groupId,\n        deliveryDirectives: hlsUrlParameters || null\n      });\n    }\n  }\n}\n\nconst TICK_INTERVAL$1 = 500; // how often to tick in ms\n\nclass SubtitleStreamController extends BaseStreamController {\n  constructor(hls, fragmentTracker, keyLoader) {\n    super(hls, fragmentTracker, keyLoader, '[subtitle-stream-controller]', PlaylistLevelType.SUBTITLE);\n    this.currentTrackId = -1;\n    this.tracksBuffered = [];\n    this.mainDetails = null;\n    this._registerListeners();\n  }\n  onHandlerDestroying() {\n    this._unregisterListeners();\n    super.onHandlerDestroying();\n    this.mainDetails = null;\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n    hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.on(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.on(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n    hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.off(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.off(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  startLoad(startPosition) {\n    this.stopLoad();\n    this.state = State.IDLE;\n    this.setInterval(TICK_INTERVAL$1);\n    this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n    this.tick();\n  }\n  onManifestLoading() {\n    this.mainDetails = null;\n    this.fragmentTracker.removeAllFragments();\n  }\n  onMediaDetaching() {\n    this.tracksBuffered = [];\n    super.onMediaDetaching();\n  }\n  onLevelLoaded(event, data) {\n    this.mainDetails = data.details;\n  }\n  onSubtitleFragProcessed(event, data) {\n    const {\n      frag,\n      success\n    } = data;\n    this.fragPrevious = frag;\n    this.state = State.IDLE;\n    if (!success) {\n      return;\n    }\n    const buffered = this.tracksBuffered[this.currentTrackId];\n    if (!buffered) {\n      return;\n    }\n\n    // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo\n    // so we can re-use the logic used to detect how much has been buffered\n    let timeRange;\n    const fragStart = frag.start;\n    for (let i = 0; i < buffered.length; i++) {\n      if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {\n        timeRange = buffered[i];\n        break;\n      }\n    }\n    const fragEnd = frag.start + frag.duration;\n    if (timeRange) {\n      timeRange.end = fragEnd;\n    } else {\n      timeRange = {\n        start: fragStart,\n        end: fragEnd\n      };\n      buffered.push(timeRange);\n    }\n    this.fragmentTracker.fragBuffered(frag);\n    this.fragBufferedComplete(frag, null);\n  }\n  onBufferFlushing(event, data) {\n    const {\n      startOffset,\n      endOffset\n    } = data;\n    if (startOffset === 0 && endOffset !== Number.POSITIVE_INFINITY) {\n      const endOffsetSubtitles = endOffset - 1;\n      if (endOffsetSubtitles <= 0) {\n        return;\n      }\n      data.endOffsetSubtitles = Math.max(0, endOffsetSubtitles);\n      this.tracksBuffered.forEach(buffered => {\n        for (let i = 0; i < buffered.length;) {\n          if (buffered[i].end <= endOffsetSubtitles) {\n            buffered.shift();\n            continue;\n          } else if (buffered[i].start < endOffsetSubtitles) {\n            buffered[i].start = endOffsetSubtitles;\n          } else {\n            break;\n          }\n          i++;\n        }\n      });\n      this.fragmentTracker.removeFragmentsInRange(startOffset, endOffsetSubtitles, PlaylistLevelType.SUBTITLE);\n    }\n  }\n  onFragBuffered(event, data) {\n    if (!this.loadedmetadata && data.frag.type === PlaylistLevelType.MAIN) {\n      var _this$media;\n      if ((_this$media = this.media) != null && _this$media.buffered.length) {\n        this.loadedmetadata = true;\n      }\n    }\n  }\n\n  // If something goes wrong, proceed to next frag, if we were processing one.\n  onError(event, data) {\n    const frag = data.frag;\n    if ((frag == null ? void 0 : frag.type) === PlaylistLevelType.SUBTITLE) {\n      if (data.details === ErrorDetails.FRAG_GAP) {\n        this.fragmentTracker.fragBuffered(frag, true);\n      }\n      if (this.fragCurrent) {\n        this.fragCurrent.abortRequests();\n      }\n      if (this.state !== State.STOPPED) {\n        this.state = State.IDLE;\n      }\n    }\n  }\n\n  // Got all new subtitle levels.\n  onSubtitleTracksUpdated(event, {\n    subtitleTracks\n  }) {\n    if (this.levels && subtitleOptionsIdentical(this.levels, subtitleTracks)) {\n      this.levels = subtitleTracks.map(mediaPlaylist => new Level(mediaPlaylist));\n      return;\n    }\n    this.tracksBuffered = [];\n    this.levels = subtitleTracks.map(mediaPlaylist => {\n      const level = new Level(mediaPlaylist);\n      this.tracksBuffered[level.id] = [];\n      return level;\n    });\n    this.fragmentTracker.removeFragmentsInRange(0, Number.POSITIVE_INFINITY, PlaylistLevelType.SUBTITLE);\n    this.fragPrevious = null;\n    this.mediaBuffer = null;\n  }\n  onSubtitleTrackSwitch(event, data) {\n    var _this$levels;\n    this.currentTrackId = data.id;\n    if (!((_this$levels = this.levels) != null && _this$levels.length) || this.currentTrackId === -1) {\n      this.clearInterval();\n      return;\n    }\n\n    // Check if track has the necessary details to load fragments\n    const currentTrack = this.levels[this.currentTrackId];\n    if (currentTrack != null && currentTrack.details) {\n      this.mediaBuffer = this.mediaBufferTimeRanges;\n    } else {\n      this.mediaBuffer = null;\n    }\n    if (currentTrack) {\n      this.setInterval(TICK_INTERVAL$1);\n    }\n  }\n\n  // Got a new set of subtitle fragments.\n  onSubtitleTrackLoaded(event, data) {\n    var _track$details;\n    const {\n      currentTrackId,\n      levels\n    } = this;\n    const {\n      details: newDetails,\n      id: trackId\n    } = data;\n    if (!levels) {\n      this.warn(`Subtitle tracks were reset while loading level ${trackId}`);\n      return;\n    }\n    const track = levels[trackId];\n    if (trackId >= levels.length || !track) {\n      return;\n    }\n    this.log(`Subtitle track ${trackId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''},duration:${newDetails.totalduration}`);\n    this.mediaBuffer = this.mediaBufferTimeRanges;\n    let sliding = 0;\n    if (newDetails.live || (_track$details = track.details) != null && _track$details.live) {\n      const mainDetails = this.mainDetails;\n      if (newDetails.deltaUpdateFailed || !mainDetails) {\n        return;\n      }\n      const mainSlidingStartFragment = mainDetails.fragments[0];\n      if (!track.details) {\n        if (newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {\n          alignMediaPlaylistByPDT(newDetails, mainDetails);\n          sliding = newDetails.fragments[0].start;\n        } else if (mainSlidingStartFragment) {\n          // line up live playlist with main so that fragments in range are loaded\n          sliding = mainSlidingStartFragment.start;\n          addSliding(newDetails, sliding);\n        }\n      } else {\n        var _this$levelLastLoaded;\n        sliding = this.alignPlaylists(newDetails, track.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n        if (sliding === 0 && mainSlidingStartFragment) {\n          // realign with main when there is no overlap with last refresh\n          sliding = mainSlidingStartFragment.start;\n          addSliding(newDetails, sliding);\n        }\n      }\n    }\n    track.details = newDetails;\n    this.levelLastLoaded = track;\n    if (trackId !== currentTrackId) {\n      return;\n    }\n    if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {\n      this.setStartPosition(this.mainDetails || newDetails, sliding);\n    }\n\n    // trigger handler right now\n    this.tick();\n\n    // If playlist is misaligned because of bad PDT or drift, delete details to resync with main on reload\n    if (newDetails.live && !this.fragCurrent && this.media && this.state === State.IDLE) {\n      const foundFrag = findFragmentByPTS(null, newDetails.fragments, this.media.currentTime, 0);\n      if (!foundFrag) {\n        this.warn('Subtitle playlist not aligned with playback');\n        track.details = undefined;\n      }\n    }\n  }\n  _handleFragmentLoadComplete(fragLoadedData) {\n    const {\n      frag,\n      payload\n    } = fragLoadedData;\n    const decryptData = frag.decryptdata;\n    const hls = this.hls;\n    if (this.fragContextChanged(frag)) {\n      return;\n    }\n    // check to see if the payload needs to be decrypted\n    if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {\n      const startTime = performance.now();\n      // decrypt the subtitles\n      this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).catch(err => {\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.FRAG_DECRYPT_ERROR,\n          fatal: false,\n          error: err,\n          reason: err.message,\n          frag\n        });\n        throw err;\n      }).then(decryptedData => {\n        const endTime = performance.now();\n        hls.trigger(Events.FRAG_DECRYPTED, {\n          frag,\n          payload: decryptedData,\n          stats: {\n            tstart: startTime,\n            tdecrypt: endTime\n          }\n        });\n      }).catch(err => {\n        this.warn(`${err.name}: ${err.message}`);\n        this.state = State.IDLE;\n      });\n    }\n  }\n  doTick() {\n    if (!this.media) {\n      this.state = State.IDLE;\n      return;\n    }\n    if (this.state === State.IDLE) {\n      const {\n        currentTrackId,\n        levels\n      } = this;\n      const track = levels == null ? void 0 : levels[currentTrackId];\n      if (!track || !levels.length || !track.details) {\n        return;\n      }\n      const {\n        config\n      } = this;\n      const currentTime = this.getLoadPosition();\n      const bufferedInfo = BufferHelper.bufferedInfo(this.tracksBuffered[this.currentTrackId] || [], currentTime, config.maxBufferHole);\n      const {\n        end: targetBufferTime,\n        len: bufferLen\n      } = bufferedInfo;\n      const mainBufferInfo = this.getFwdBufferInfo(this.media, PlaylistLevelType.MAIN);\n      const trackDetails = track.details;\n      const maxBufLen = this.getMaxBufferLength(mainBufferInfo == null ? void 0 : mainBufferInfo.len) + trackDetails.levelTargetDuration;\n      if (bufferLen > maxBufLen) {\n        return;\n      }\n      const fragments = trackDetails.fragments;\n      const fragLen = fragments.length;\n      const end = trackDetails.edge;\n      let foundFrag = null;\n      const fragPrevious = this.fragPrevious;\n      if (targetBufferTime < end) {\n        const tolerance = config.maxFragLookUpTolerance;\n        const lookupTolerance = targetBufferTime > end - tolerance ? 0 : tolerance;\n        foundFrag = findFragmentByPTS(fragPrevious, fragments, Math.max(fragments[0].start, targetBufferTime), lookupTolerance);\n        if (!foundFrag && fragPrevious && fragPrevious.start < fragments[0].start) {\n          foundFrag = fragments[0];\n        }\n      } else {\n        foundFrag = fragments[fragLen - 1];\n      }\n      if (!foundFrag) {\n        return;\n      }\n      foundFrag = this.mapToInitFragWhenRequired(foundFrag);\n      if (foundFrag.sn !== 'initSegment') {\n        // Load earlier fragment in same discontinuity to make up for misaligned playlists and cues that extend beyond end of segment\n        const curSNIdx = foundFrag.sn - trackDetails.startSN;\n        const prevFrag = fragments[curSNIdx - 1];\n        if (prevFrag && prevFrag.cc === foundFrag.cc && this.fragmentTracker.getState(prevFrag) === FragmentState.NOT_LOADED) {\n          foundFrag = prevFrag;\n        }\n      }\n      if (this.fragmentTracker.getState(foundFrag) === FragmentState.NOT_LOADED) {\n        // only load if fragment is not loaded\n        this.loadFragment(foundFrag, track, targetBufferTime);\n      }\n    }\n  }\n  getMaxBufferLength(mainBufferLength) {\n    const maxConfigBuffer = super.getMaxBufferLength();\n    if (!mainBufferLength) {\n      return maxConfigBuffer;\n    }\n    return Math.max(maxConfigBuffer, mainBufferLength);\n  }\n  loadFragment(frag, level, targetBufferTime) {\n    this.fragCurrent = frag;\n    if (frag.sn === 'initSegment') {\n      this._loadInitSegment(frag, level);\n    } else {\n      this.startFragRequested = true;\n      super.loadFragment(frag, level, targetBufferTime);\n    }\n  }\n  get mediaBufferTimeRanges() {\n    return new BufferableInstance(this.tracksBuffered[this.currentTrackId] || []);\n  }\n}\nclass BufferableInstance {\n  constructor(timeranges) {\n    this.buffered = void 0;\n    const getRange = (name, index, length) => {\n      index = index >>> 0;\n      if (index > length - 1) {\n        throw new DOMException(`Failed to execute '${name}' on 'TimeRanges': The index provided (${index}) is greater than the maximum bound (${length})`);\n      }\n      return timeranges[index][name];\n    };\n    this.buffered = {\n      get length() {\n        return timeranges.length;\n      },\n      end(index) {\n        return getRange('end', index, timeranges.length);\n      },\n      start(index) {\n        return getRange('start', index, timeranges.length);\n      }\n    };\n  }\n}\n\nclass SubtitleTrackController extends BasePlaylistController {\n  constructor(hls) {\n    super(hls, '[subtitle-track-controller]');\n    this.media = null;\n    this.tracks = [];\n    this.groupIds = null;\n    this.tracksInGroup = [];\n    this.trackId = -1;\n    this.currentTrack = null;\n    this.selectDefaultTrack = true;\n    this.queuedDefaultTrack = -1;\n    this.asyncPollTrackChange = () => this.pollTrackChange(0);\n    this.useTextTrackPolling = false;\n    this.subtitlePollingInterval = -1;\n    this._subtitleDisplay = true;\n    this.onTextTracksChanged = () => {\n      if (!this.useTextTrackPolling) {\n        self.clearInterval(this.subtitlePollingInterval);\n      }\n      // Media is undefined when switching streams via loadSource()\n      if (!this.media || !this.hls.config.renderTextTracksNatively) {\n        return;\n      }\n      let textTrack = null;\n      const tracks = filterSubtitleTracks(this.media.textTracks);\n      for (let i = 0; i < tracks.length; i++) {\n        if (tracks[i].mode === 'hidden') {\n          // Do not break in case there is a following track with showing.\n          textTrack = tracks[i];\n        } else if (tracks[i].mode === 'showing') {\n          textTrack = tracks[i];\n          break;\n        }\n      }\n\n      // Find internal track index for TextTrack\n      const trackId = this.findTrackForTextTrack(textTrack);\n      if (this.subtitleTrack !== trackId) {\n        this.setSubtitleTrack(trackId);\n      }\n    };\n    this.registerListeners();\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.tracks.length = 0;\n    this.tracksInGroup.length = 0;\n    this.currentTrack = null;\n    this.onTextTracksChanged = this.asyncPollTrackChange = null;\n    super.destroy();\n  }\n  get subtitleDisplay() {\n    return this._subtitleDisplay;\n  }\n  set subtitleDisplay(value) {\n    this._subtitleDisplay = value;\n    if (this.trackId > -1) {\n      this.toggleTrackModes();\n    }\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n    hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n\n  // Listen for subtitle track change, then extract the current track ID.\n  onMediaAttached(event, data) {\n    this.media = data.media;\n    if (!this.media) {\n      return;\n    }\n    if (this.queuedDefaultTrack > -1) {\n      this.subtitleTrack = this.queuedDefaultTrack;\n      this.queuedDefaultTrack = -1;\n    }\n    this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);\n    if (this.useTextTrackPolling) {\n      this.pollTrackChange(500);\n    } else {\n      this.media.textTracks.addEventListener('change', this.asyncPollTrackChange);\n    }\n  }\n  pollTrackChange(timeout) {\n    self.clearInterval(this.subtitlePollingInterval);\n    this.subtitlePollingInterval = self.setInterval(this.onTextTracksChanged, timeout);\n  }\n  onMediaDetaching() {\n    if (!this.media) {\n      return;\n    }\n    self.clearInterval(this.subtitlePollingInterval);\n    if (!this.useTextTrackPolling) {\n      this.media.textTracks.removeEventListener('change', this.asyncPollTrackChange);\n    }\n    if (this.trackId > -1) {\n      this.queuedDefaultTrack = this.trackId;\n    }\n    const textTracks = filterSubtitleTracks(this.media.textTracks);\n    // Clear loaded cues on media detachment from tracks\n    textTracks.forEach(track => {\n      clearCurrentCues(track);\n    });\n    // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.\n    this.subtitleTrack = -1;\n    this.media = null;\n  }\n  onManifestLoading() {\n    this.tracks = [];\n    this.groupIds = null;\n    this.tracksInGroup = [];\n    this.trackId = -1;\n    this.currentTrack = null;\n    this.selectDefaultTrack = true;\n  }\n\n  // Fired whenever a new manifest is loaded.\n  onManifestParsed(event, data) {\n    this.tracks = data.subtitleTracks;\n  }\n  onSubtitleTrackLoaded(event, data) {\n    const {\n      id,\n      groupId,\n      details\n    } = data;\n    const trackInActiveGroup = this.tracksInGroup[id];\n    if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {\n      this.warn(`Subtitle track with id:${id} and group:${groupId} not found in active group ${trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId}`);\n      return;\n    }\n    const curDetails = trackInActiveGroup.details;\n    trackInActiveGroup.details = data.details;\n    this.log(`Subtitle track ${id} \"${trackInActiveGroup.name}\" lang:${trackInActiveGroup.lang} group:${groupId} loaded [${details.startSN}-${details.endSN}]`);\n    if (id === this.trackId) {\n      this.playlistLoaded(id, data, curDetails);\n    }\n  }\n  onLevelLoading(event, data) {\n    this.switchLevel(data.level);\n  }\n  onLevelSwitching(event, data) {\n    this.switchLevel(data.level);\n  }\n  switchLevel(levelIndex) {\n    const levelInfo = this.hls.levels[levelIndex];\n    if (!levelInfo) {\n      return;\n    }\n    const subtitleGroups = levelInfo.subtitleGroups || null;\n    const currentGroups = this.groupIds;\n    let currentTrack = this.currentTrack;\n    if (!subtitleGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (subtitleGroups == null ? void 0 : subtitleGroups.length) || subtitleGroups != null && subtitleGroups.some(groupId => (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1)) {\n      this.groupIds = subtitleGroups;\n      this.trackId = -1;\n      this.currentTrack = null;\n      const subtitleTracks = this.tracks.filter(track => !subtitleGroups || subtitleGroups.indexOf(track.groupId) !== -1);\n      if (subtitleTracks.length) {\n        // Disable selectDefaultTrack if there are no default tracks\n        if (this.selectDefaultTrack && !subtitleTracks.some(track => track.default)) {\n          this.selectDefaultTrack = false;\n        }\n        // track.id should match hls.audioTracks index\n        subtitleTracks.forEach((track, i) => {\n          track.id = i;\n        });\n      } else if (!currentTrack && !this.tracksInGroup.length) {\n        // Do not dispatch SUBTITLE_TRACKS_UPDATED when there were and are no tracks\n        return;\n      }\n      this.tracksInGroup = subtitleTracks;\n\n      // Find preferred track\n      const subtitlePreference = this.hls.config.subtitlePreference;\n      if (!currentTrack && subtitlePreference) {\n        this.selectDefaultTrack = false;\n        const groupIndex = findMatchingOption(subtitlePreference, subtitleTracks);\n        if (groupIndex > -1) {\n          currentTrack = subtitleTracks[groupIndex];\n        } else {\n          const allIndex = findMatchingOption(subtitlePreference, this.tracks);\n          currentTrack = this.tracks[allIndex];\n        }\n      }\n\n      // Select initial track\n      let trackId = this.findTrackId(currentTrack);\n      if (trackId === -1 && currentTrack) {\n        trackId = this.findTrackId(null);\n      }\n\n      // Dispatch events and load track if needed\n      const subtitleTracksUpdated = {\n        subtitleTracks\n      };\n      this.log(`Updating subtitle tracks, ${subtitleTracks.length} track(s) found in \"${subtitleGroups == null ? void 0 : subtitleGroups.join(',')}\" group-id`);\n      this.hls.trigger(Events.SUBTITLE_TRACKS_UPDATED, subtitleTracksUpdated);\n      if (trackId !== -1 && this.trackId === -1) {\n        this.setSubtitleTrack(trackId);\n      }\n    } else if (this.shouldReloadPlaylist(currentTrack)) {\n      // Retry playlist loading if no playlist is or has been loaded yet\n      this.setSubtitleTrack(this.trackId);\n    }\n  }\n  findTrackId(currentTrack) {\n    const tracks = this.tracksInGroup;\n    const selectDefault = this.selectDefaultTrack;\n    for (let i = 0; i < tracks.length; i++) {\n      const track = tracks[i];\n      if (selectDefault && !track.default || !selectDefault && !currentTrack) {\n        continue;\n      }\n      if (!currentTrack || matchesOption(track, currentTrack)) {\n        return i;\n      }\n    }\n    if (currentTrack) {\n      for (let i = 0; i < tracks.length; i++) {\n        const track = tracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {\n          return i;\n        }\n      }\n      for (let i = 0; i < tracks.length; i++) {\n        const track = tracks[i];\n        if (mediaAttributesIdentical(currentTrack.attrs, track.attrs, ['LANGUAGE'])) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  findTrackForTextTrack(textTrack) {\n    if (textTrack) {\n      const tracks = this.tracksInGroup;\n      for (let i = 0; i < tracks.length; i++) {\n        const track = tracks[i];\n        if (subtitleTrackMatchesTextTrack(track, textTrack)) {\n          return i;\n        }\n      }\n    }\n    return -1;\n  }\n  onError(event, data) {\n    if (data.fatal || !data.context) {\n      return;\n    }\n    if (data.context.type === PlaylistContextType.SUBTITLE_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {\n      this.checkRetry(data);\n    }\n  }\n  get allSubtitleTracks() {\n    return this.tracks;\n  }\n\n  /** get alternate subtitle tracks list from playlist **/\n  get subtitleTracks() {\n    return this.tracksInGroup;\n  }\n\n  /** get/set index of the selected subtitle track (based on index in subtitle track lists) **/\n  get subtitleTrack() {\n    return this.trackId;\n  }\n  set subtitleTrack(newId) {\n    this.selectDefaultTrack = false;\n    this.setSubtitleTrack(newId);\n  }\n  setSubtitleOption(subtitleOption) {\n    this.hls.config.subtitlePreference = subtitleOption;\n    if (subtitleOption) {\n      const allSubtitleTracks = this.allSubtitleTracks;\n      this.selectDefaultTrack = false;\n      if (allSubtitleTracks.length) {\n        // First see if current option matches (no switch op)\n        const currentTrack = this.currentTrack;\n        if (currentTrack && matchesOption(subtitleOption, currentTrack)) {\n          return currentTrack;\n        }\n        // Find option in current group\n        const groupIndex = findMatchingOption(subtitleOption, this.tracksInGroup);\n        if (groupIndex > -1) {\n          const track = this.tracksInGroup[groupIndex];\n          this.setSubtitleTrack(groupIndex);\n          return track;\n        } else if (currentTrack) {\n          // If this is not the initial selection return null\n          // option should have matched one in active group\n          return null;\n        } else {\n          // Find the option in all tracks for initial selection\n          const allIndex = findMatchingOption(subtitleOption, allSubtitleTracks);\n          if (allIndex > -1) {\n            return allSubtitleTracks[allIndex];\n          }\n        }\n      }\n    }\n    return null;\n  }\n  loadPlaylist(hlsUrlParameters) {\n    super.loadPlaylist();\n    const currentTrack = this.currentTrack;\n    if (this.shouldLoadPlaylist(currentTrack) && currentTrack) {\n      const id = currentTrack.id;\n      const groupId = currentTrack.groupId;\n      let url = currentTrack.url;\n      if (hlsUrlParameters) {\n        try {\n          url = hlsUrlParameters.addDirectives(url);\n        } catch (error) {\n          this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);\n        }\n      }\n      this.log(`Loading subtitle playlist for id ${id}`);\n      this.hls.trigger(Events.SUBTITLE_TRACK_LOADING, {\n        url,\n        id,\n        groupId,\n        deliveryDirectives: hlsUrlParameters || null\n      });\n    }\n  }\n\n  /**\n   * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.\n   * This operates on the DOM textTracks.\n   * A value of -1 will disable all subtitle tracks.\n   */\n  toggleTrackModes() {\n    const {\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const textTracks = filterSubtitleTracks(media.textTracks);\n    const currentTrack = this.currentTrack;\n    let nextTrack;\n    if (currentTrack) {\n      nextTrack = textTracks.filter(textTrack => subtitleTrackMatchesTextTrack(currentTrack, textTrack))[0];\n      if (!nextTrack) {\n        this.warn(`Unable to find subtitle TextTrack with name \"${currentTrack.name}\" and language \"${currentTrack.lang}\"`);\n      }\n    }\n    [].slice.call(textTracks).forEach(track => {\n      if (track.mode !== 'disabled' && track !== nextTrack) {\n        track.mode = 'disabled';\n      }\n    });\n    if (nextTrack) {\n      const mode = this.subtitleDisplay ? 'showing' : 'hidden';\n      if (nextTrack.mode !== mode) {\n        nextTrack.mode = mode;\n      }\n    }\n  }\n\n  /**\n   * This method is responsible for validating the subtitle index and periodically reloading if live.\n   * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.\n   */\n  setSubtitleTrack(newId) {\n    const tracks = this.tracksInGroup;\n\n    // setting this.subtitleTrack will trigger internal logic\n    // if media has not been attached yet, it will fail\n    // we keep a reference to the default track id\n    // and we'll set subtitleTrack when onMediaAttached is triggered\n    if (!this.media) {\n      this.queuedDefaultTrack = newId;\n      return;\n    }\n\n    // exit if track id as already set or invalid\n    if (newId < -1 || newId >= tracks.length || !isFiniteNumber(newId)) {\n      this.warn(`Invalid subtitle track id: ${newId}`);\n      return;\n    }\n\n    // stopping live reloading timer if any\n    this.clearTimer();\n    this.selectDefaultTrack = false;\n    const lastTrack = this.currentTrack;\n    const track = tracks[newId] || null;\n    this.trackId = newId;\n    this.currentTrack = track;\n    this.toggleTrackModes();\n    if (!track) {\n      // switch to -1\n      this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {\n        id: newId\n      });\n      return;\n    }\n    const trackLoaded = !!track.details && !track.details.live;\n    if (newId === this.trackId && track === lastTrack && trackLoaded) {\n      return;\n    }\n    this.log(`Switching to subtitle-track ${newId}` + (track ? ` \"${track.name}\" lang:${track.lang} group:${track.groupId}` : ''));\n    const {\n      id,\n      groupId = '',\n      name,\n      type,\n      url\n    } = track;\n    this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {\n      id,\n      groupId,\n      name,\n      type,\n      url\n    });\n    const hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);\n    this.loadPlaylist(hlsUrlParameters);\n  }\n}\n\nclass BufferOperationQueue {\n  constructor(sourceBufferReference) {\n    this.buffers = void 0;\n    this.queues = {\n      video: [],\n      audio: [],\n      audiovideo: []\n    };\n    this.buffers = sourceBufferReference;\n  }\n  append(operation, type, pending) {\n    const queue = this.queues[type];\n    queue.push(operation);\n    if (queue.length === 1 && !pending) {\n      this.executeNext(type);\n    }\n  }\n  insertAbort(operation, type) {\n    const queue = this.queues[type];\n    queue.unshift(operation);\n    this.executeNext(type);\n  }\n  appendBlocker(type) {\n    let execute;\n    const promise = new Promise(resolve => {\n      execute = resolve;\n    });\n    const operation = {\n      execute,\n      onStart: () => {},\n      onComplete: () => {},\n      onError: () => {}\n    };\n    this.append(operation, type);\n    return promise;\n  }\n  executeNext(type) {\n    const queue = this.queues[type];\n    if (queue.length) {\n      const operation = queue[0];\n      try {\n        // Operations are expected to result in an 'updateend' event being fired. If not, the queue will lock. Operations\n        // which do not end with this event must call _onSBUpdateEnd manually\n        operation.execute();\n      } catch (error) {\n        logger.warn(`[buffer-operation-queue]: Exception executing \"${type}\" SourceBuffer operation: ${error}`);\n        operation.onError(error);\n\n        // Only shift the current operation off, otherwise the updateend handler will do this for us\n        const sb = this.buffers[type];\n        if (!(sb != null && sb.updating)) {\n          this.shiftAndExecuteNext(type);\n        }\n      }\n    }\n  }\n  shiftAndExecuteNext(type) {\n    this.queues[type].shift();\n    this.executeNext(type);\n  }\n  current(type) {\n    return this.queues[type][0];\n  }\n}\n\nconst VIDEO_CODEC_PROFILE_REPLACE = /(avc[1234]|hvc1|hev1|dvh[1e]|vp09|av01)(?:\\.[^.,]+)+/;\nclass BufferController {\n  constructor(hls) {\n    // The level details used to determine duration, target-duration and live\n    this.details = null;\n    // cache the self generated object url to detect hijack of video tag\n    this._objectUrl = null;\n    // A queue of buffer operations which require the SourceBuffer to not be updating upon execution\n    this.operationQueue = void 0;\n    // References to event listeners for each SourceBuffer, so that they can be referenced for event removal\n    this.listeners = void 0;\n    this.hls = void 0;\n    // The number of BUFFER_CODEC events received before any sourceBuffers are created\n    this.bufferCodecEventsExpected = 0;\n    // The total number of BUFFER_CODEC events received\n    this._bufferCodecEventsTotal = 0;\n    // A reference to the attached media element\n    this.media = null;\n    // A reference to the active media source\n    this.mediaSource = null;\n    // Last MP3 audio chunk appended\n    this.lastMpegAudioChunk = null;\n    this.appendSource = void 0;\n    // counters\n    this.appendErrors = {\n      audio: 0,\n      video: 0,\n      audiovideo: 0\n    };\n    this.tracks = {};\n    this.pendingTracks = {};\n    this.sourceBuffer = void 0;\n    this.log = void 0;\n    this.warn = void 0;\n    this.error = void 0;\n    this._onEndStreaming = event => {\n      if (!this.hls) {\n        return;\n      }\n      this.hls.pauseBuffering();\n    };\n    this._onStartStreaming = event => {\n      if (!this.hls) {\n        return;\n      }\n      this.hls.resumeBuffering();\n    };\n    // Keep as arrow functions so that we can directly reference these functions directly as event listeners\n    this._onMediaSourceOpen = () => {\n      const {\n        media,\n        mediaSource\n      } = this;\n      this.log('Media source opened');\n      if (media) {\n        media.removeEventListener('emptied', this._onMediaEmptied);\n        this.updateMediaElementDuration();\n        this.hls.trigger(Events.MEDIA_ATTACHED, {\n          media,\n          mediaSource: mediaSource\n        });\n      }\n      if (mediaSource) {\n        // once received, don't listen anymore to sourceopen event\n        mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);\n      }\n      this.checkPendingTracks();\n    };\n    this._onMediaSourceClose = () => {\n      this.log('Media source closed');\n    };\n    this._onMediaSourceEnded = () => {\n      this.log('Media source ended');\n    };\n    this._onMediaEmptied = () => {\n      const {\n        mediaSrc,\n        _objectUrl\n      } = this;\n      if (mediaSrc !== _objectUrl) {\n        logger.error(`Media element src was set while attaching MediaSource (${_objectUrl} > ${mediaSrc})`);\n      }\n    };\n    this.hls = hls;\n    const logPrefix = '[buffer-controller]';\n    this.appendSource = isManagedMediaSource(getMediaSource(hls.config.preferManagedMediaSource));\n    this.log = logger.log.bind(logger, logPrefix);\n    this.warn = logger.warn.bind(logger, logPrefix);\n    this.error = logger.error.bind(logger, logPrefix);\n    this._initSourceBuffer();\n    this.registerListeners();\n  }\n  hasSourceTypes() {\n    return this.getSourceBufferTypes().length > 0 || Object.keys(this.pendingTracks).length > 0;\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.details = null;\n    this.lastMpegAudioChunk = null;\n    // @ts-ignore\n    this.hls = null;\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.on(Events.BUFFER_APPENDING, this.onBufferAppending, this);\n    hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.on(Events.BUFFER_EOS, this.onBufferEos, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    hls.on(Events.FRAG_PARSED, this.onFragParsed, this);\n    hls.on(Events.FRAG_CHANGED, this.onFragChanged, this);\n  }\n  unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.BUFFER_RESET, this.onBufferReset, this);\n    hls.off(Events.BUFFER_APPENDING, this.onBufferAppending, this);\n    hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.off(Events.BUFFER_EOS, this.onBufferEos, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    hls.off(Events.FRAG_PARSED, this.onFragParsed, this);\n    hls.off(Events.FRAG_CHANGED, this.onFragChanged, this);\n  }\n  _initSourceBuffer() {\n    this.sourceBuffer = {};\n    this.operationQueue = new BufferOperationQueue(this.sourceBuffer);\n    this.listeners = {\n      audio: [],\n      video: [],\n      audiovideo: []\n    };\n    this.appendErrors = {\n      audio: 0,\n      video: 0,\n      audiovideo: 0\n    };\n    this.lastMpegAudioChunk = null;\n  }\n  onManifestLoading() {\n    this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = 0;\n    this.details = null;\n  }\n  onManifestParsed(event, data) {\n    // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller\n    // sourcebuffers will be created all at once when the expected nb of tracks will be reached\n    // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller\n    // it will contain the expected nb of source buffers, no need to compute it\n    let codecEvents = 2;\n    if (data.audio && !data.video || !data.altAudio || !true) {\n      codecEvents = 1;\n    }\n    this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = codecEvents;\n    this.log(`${this.bufferCodecEventsExpected} bufferCodec event(s) expected`);\n  }\n  onMediaAttaching(event, data) {\n    const media = this.media = data.media;\n    const MediaSource = getMediaSource(this.appendSource);\n    if (media && MediaSource) {\n      var _ms$constructor;\n      const ms = this.mediaSource = new MediaSource();\n      this.log(`created media source: ${(_ms$constructor = ms.constructor) == null ? void 0 : _ms$constructor.name}`);\n      // MediaSource listeners are arrow functions with a lexical scope, and do not need to be bound\n      ms.addEventListener('sourceopen', this._onMediaSourceOpen);\n      ms.addEventListener('sourceended', this._onMediaSourceEnded);\n      ms.addEventListener('sourceclose', this._onMediaSourceClose);\n      if (this.appendSource) {\n        ms.addEventListener('startstreaming', this._onStartStreaming);\n        ms.addEventListener('endstreaming', this._onEndStreaming);\n      }\n\n      // cache the locally generated object url\n      const objectUrl = this._objectUrl = self.URL.createObjectURL(ms);\n      // link video and media Source\n      if (this.appendSource) {\n        try {\n          media.removeAttribute('src');\n          // ManagedMediaSource will not open without disableRemotePlayback set to false or source alternatives\n          const MMS = self.ManagedMediaSource;\n          media.disableRemotePlayback = media.disableRemotePlayback || MMS && ms instanceof MMS;\n          removeSourceChildren(media);\n          addSource(media, objectUrl);\n          media.load();\n        } catch (error) {\n          media.src = objectUrl;\n        }\n      } else {\n        media.src = objectUrl;\n      }\n      media.addEventListener('emptied', this._onMediaEmptied);\n    }\n  }\n  onMediaDetaching() {\n    const {\n      media,\n      mediaSource,\n      _objectUrl\n    } = this;\n    if (mediaSource) {\n      this.log('media source detaching');\n      if (mediaSource.readyState === 'open') {\n        try {\n          // endOfStream could trigger exception if any sourcebuffer is in updating state\n          // we don't really care about checking sourcebuffer state here,\n          // as we are anyway detaching the MediaSource\n          // let's just avoid this exception to propagate\n          mediaSource.endOfStream();\n        } catch (err) {\n          this.warn(`onMediaDetaching: ${err.message} while calling endOfStream`);\n        }\n      }\n      // Clean up the SourceBuffers by invoking onBufferReset\n      this.onBufferReset();\n      mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);\n      mediaSource.removeEventListener('sourceended', this._onMediaSourceEnded);\n      mediaSource.removeEventListener('sourceclose', this._onMediaSourceClose);\n      if (this.appendSource) {\n        mediaSource.removeEventListener('startstreaming', this._onStartStreaming);\n        mediaSource.removeEventListener('endstreaming', this._onEndStreaming);\n      }\n\n      // Detach properly the MediaSource from the HTMLMediaElement as\n      // suggested in https://github.com/w3c/media-source/issues/53.\n      if (media) {\n        media.removeEventListener('emptied', this._onMediaEmptied);\n        if (_objectUrl) {\n          self.URL.revokeObjectURL(_objectUrl);\n        }\n\n        // clean up video tag src only if it's our own url. some external libraries might\n        // hijack the video tag and change its 'src' without destroying the Hls instance first\n        if (this.mediaSrc === _objectUrl) {\n          media.removeAttribute('src');\n          if (this.appendSource) {\n            removeSourceChildren(media);\n          }\n          media.load();\n        } else {\n          this.warn('media|source.src was changed by a third party - skip cleanup');\n        }\n      }\n      this.mediaSource = null;\n      this.media = null;\n      this._objectUrl = null;\n      this.bufferCodecEventsExpected = this._bufferCodecEventsTotal;\n      this.pendingTracks = {};\n      this.tracks = {};\n    }\n    this.hls.trigger(Events.MEDIA_DETACHED, undefined);\n  }\n  onBufferReset() {\n    this.getSourceBufferTypes().forEach(type => {\n      this.resetBuffer(type);\n    });\n    this._initSourceBuffer();\n  }\n  resetBuffer(type) {\n    const sb = this.sourceBuffer[type];\n    try {\n      if (sb) {\n        var _this$mediaSource;\n        this.removeBufferListeners(type);\n        // Synchronously remove the SB from the map before the next call in order to prevent an async function from\n        // accessing it\n        this.sourceBuffer[type] = undefined;\n        if ((_this$mediaSource = this.mediaSource) != null && _this$mediaSource.sourceBuffers.length) {\n          this.mediaSource.removeSourceBuffer(sb);\n        }\n      }\n    } catch (err) {\n      this.warn(`onBufferReset ${type}`, err);\n    }\n  }\n  onBufferCodecs(event, data) {\n    const sourceBufferCount = this.getSourceBufferTypes().length;\n    const trackNames = Object.keys(data);\n    trackNames.forEach(trackName => {\n      if (sourceBufferCount) {\n        // check if SourceBuffer codec needs to change\n        const track = this.tracks[trackName];\n        if (track && typeof track.buffer.changeType === 'function') {\n          var _trackCodec;\n          const {\n            id,\n            codec,\n            levelCodec,\n            container,\n            metadata\n          } = data[trackName];\n          const currentCodecFull = pickMostCompleteCodecName(track.codec, track.levelCodec);\n          const currentCodec = currentCodecFull == null ? void 0 : currentCodecFull.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');\n          let trackCodec = pickMostCompleteCodecName(codec, levelCodec);\n          const nextCodec = (_trackCodec = trackCodec) == null ? void 0 : _trackCodec.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');\n          if (trackCodec && currentCodec !== nextCodec) {\n            if (trackName.slice(0, 5) === 'audio') {\n              trackCodec = getCodecCompatibleName(trackCodec, this.appendSource);\n            }\n            const mimeType = `${container};codecs=${trackCodec}`;\n            this.appendChangeType(trackName, mimeType);\n            this.log(`switching codec ${currentCodecFull} to ${trackCodec}`);\n            this.tracks[trackName] = {\n              buffer: track.buffer,\n              codec,\n              container,\n              levelCodec,\n              metadata,\n              id\n            };\n          }\n        }\n      } else {\n        // if source buffer(s) not created yet, appended buffer tracks in this.pendingTracks\n        this.pendingTracks[trackName] = data[trackName];\n      }\n    });\n\n    // if sourcebuffers already created, do nothing ...\n    if (sourceBufferCount) {\n      return;\n    }\n    const bufferCodecEventsExpected = Math.max(this.bufferCodecEventsExpected - 1, 0);\n    if (this.bufferCodecEventsExpected !== bufferCodecEventsExpected) {\n      this.log(`${bufferCodecEventsExpected} bufferCodec event(s) expected ${trackNames.join(',')}`);\n      this.bufferCodecEventsExpected = bufferCodecEventsExpected;\n    }\n    if (this.mediaSource && this.mediaSource.readyState === 'open') {\n      this.checkPendingTracks();\n    }\n  }\n  appendChangeType(type, mimeType) {\n    const {\n      operationQueue\n    } = this;\n    const operation = {\n      execute: () => {\n        const sb = this.sourceBuffer[type];\n        if (sb) {\n          this.log(`changing ${type} sourceBuffer type to ${mimeType}`);\n          sb.changeType(mimeType);\n        }\n        operationQueue.shiftAndExecuteNext(type);\n      },\n      onStart: () => {},\n      onComplete: () => {},\n      onError: error => {\n        this.warn(`Failed to change ${type} SourceBuffer type`, error);\n      }\n    };\n    operationQueue.append(operation, type, !!this.pendingTracks[type]);\n  }\n  onBufferAppending(event, eventData) {\n    const {\n      hls,\n      operationQueue,\n      tracks\n    } = this;\n    const {\n      data,\n      type,\n      frag,\n      part,\n      chunkMeta\n    } = eventData;\n    const chunkStats = chunkMeta.buffering[type];\n    const bufferAppendingStart = self.performance.now();\n    chunkStats.start = bufferAppendingStart;\n    const fragBuffering = frag.stats.buffering;\n    const partBuffering = part ? part.stats.buffering : null;\n    if (fragBuffering.start === 0) {\n      fragBuffering.start = bufferAppendingStart;\n    }\n    if (partBuffering && partBuffering.start === 0) {\n      partBuffering.start = bufferAppendingStart;\n    }\n\n    // TODO: Only update timestampOffset when audio/mpeg fragment or part is not contiguous with previously appended\n    // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)\n    // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`\n    // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos).\n    // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486\n    const audioTrack = tracks.audio;\n    let checkTimestampOffset = false;\n    if (type === 'audio' && (audioTrack == null ? void 0 : audioTrack.container) === 'audio/mpeg') {\n      checkTimestampOffset = !this.lastMpegAudioChunk || chunkMeta.id === 1 || this.lastMpegAudioChunk.sn !== chunkMeta.sn;\n      this.lastMpegAudioChunk = chunkMeta;\n    }\n    const fragStart = frag.start;\n    const operation = {\n      execute: () => {\n        chunkStats.executeStart = self.performance.now();\n        if (checkTimestampOffset) {\n          const sb = this.sourceBuffer[type];\n          if (sb) {\n            const delta = fragStart - sb.timestampOffset;\n            if (Math.abs(delta) >= 0.1) {\n              this.log(`Updating audio SourceBuffer timestampOffset to ${fragStart} (delta: ${delta}) sn: ${frag.sn})`);\n              sb.timestampOffset = fragStart;\n            }\n          }\n        }\n        this.appendExecutor(data, type);\n      },\n      onStart: () => {\n        // logger.debug(`[buffer-controller]: ${type} SourceBuffer updatestart`);\n      },\n      onComplete: () => {\n        // logger.debug(`[buffer-controller]: ${type} SourceBuffer updateend`);\n        const end = self.performance.now();\n        chunkStats.executeEnd = chunkStats.end = end;\n        if (fragBuffering.first === 0) {\n          fragBuffering.first = end;\n        }\n        if (partBuffering && partBuffering.first === 0) {\n          partBuffering.first = end;\n        }\n        const {\n          sourceBuffer\n        } = this;\n        const timeRanges = {};\n        for (const type in sourceBuffer) {\n          timeRanges[type] = BufferHelper.getBuffered(sourceBuffer[type]);\n        }\n        this.appendErrors[type] = 0;\n        if (type === 'audio' || type === 'video') {\n          this.appendErrors.audiovideo = 0;\n        } else {\n          this.appendErrors.audio = 0;\n          this.appendErrors.video = 0;\n        }\n        this.hls.trigger(Events.BUFFER_APPENDED, {\n          type,\n          frag,\n          part,\n          chunkMeta,\n          parent: frag.type,\n          timeRanges\n        });\n      },\n      onError: error => {\n        // in case any error occured while appending, put back segment in segments table\n        const event = {\n          type: ErrorTypes.MEDIA_ERROR,\n          parent: frag.type,\n          details: ErrorDetails.BUFFER_APPEND_ERROR,\n          sourceBufferName: type,\n          frag,\n          part,\n          chunkMeta,\n          error,\n          err: error,\n          fatal: false\n        };\n        if (error.code === DOMException.QUOTA_EXCEEDED_ERR) {\n          // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror\n          // let's stop appending any segments, and report BUFFER_FULL_ERROR error\n          event.details = ErrorDetails.BUFFER_FULL_ERROR;\n        } else {\n          const appendErrorCount = ++this.appendErrors[type];\n          event.details = ErrorDetails.BUFFER_APPEND_ERROR;\n          /* with UHD content, we could get loop of quota exceeded error until\n            browser is able to evict some data from sourcebuffer. Retrying can help recover.\n          */\n          this.warn(`Failed ${appendErrorCount}/${hls.config.appendErrorMaxRetry} times to append segment in \"${type}\" sourceBuffer`);\n          if (appendErrorCount >= hls.config.appendErrorMaxRetry) {\n            event.fatal = true;\n          }\n        }\n        hls.trigger(Events.ERROR, event);\n      }\n    };\n    operationQueue.append(operation, type, !!this.pendingTracks[type]);\n  }\n  onBufferFlushing(event, data) {\n    const {\n      operationQueue\n    } = this;\n    const flushOperation = type => ({\n      execute: this.removeExecutor.bind(this, type, data.startOffset, data.endOffset),\n      onStart: () => {\n        // logger.debug(`[buffer-controller]: Started flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);\n      },\n      onComplete: () => {\n        // logger.debug(`[buffer-controller]: Finished flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);\n        this.hls.trigger(Events.BUFFER_FLUSHED, {\n          type\n        });\n      },\n      onError: error => {\n        this.warn(`Failed to remove from ${type} SourceBuffer`, error);\n      }\n    });\n    if (data.type) {\n      operationQueue.append(flushOperation(data.type), data.type);\n    } else {\n      this.getSourceBufferTypes().forEach(type => {\n        operationQueue.append(flushOperation(type), type);\n      });\n    }\n  }\n  onFragParsed(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    const buffersAppendedTo = [];\n    const elementaryStreams = part ? part.elementaryStreams : frag.elementaryStreams;\n    if (elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO]) {\n      buffersAppendedTo.push('audiovideo');\n    } else {\n      if (elementaryStreams[ElementaryStreamTypes.AUDIO]) {\n        buffersAppendedTo.push('audio');\n      }\n      if (elementaryStreams[ElementaryStreamTypes.VIDEO]) {\n        buffersAppendedTo.push('video');\n      }\n    }\n    const onUnblocked = () => {\n      const now = self.performance.now();\n      frag.stats.buffering.end = now;\n      if (part) {\n        part.stats.buffering.end = now;\n      }\n      const stats = part ? part.stats : frag.stats;\n      this.hls.trigger(Events.FRAG_BUFFERED, {\n        frag,\n        part,\n        stats,\n        id: frag.type\n      });\n    };\n    if (buffersAppendedTo.length === 0) {\n      this.warn(`Fragments must have at least one ElementaryStreamType set. type: ${frag.type} level: ${frag.level} sn: ${frag.sn}`);\n    }\n    this.blockBuffers(onUnblocked, buffersAppendedTo);\n  }\n  onFragChanged(event, data) {\n    this.trimBuffers();\n  }\n\n  // on BUFFER_EOS mark matching sourcebuffer(s) as ended and trigger checkEos()\n  // an undefined data.type will mark all buffers as EOS.\n  onBufferEos(event, data) {\n    const ended = this.getSourceBufferTypes().reduce((acc, type) => {\n      const sb = this.sourceBuffer[type];\n      if (sb && (!data.type || data.type === type)) {\n        sb.ending = true;\n        if (!sb.ended) {\n          sb.ended = true;\n          this.log(`${type} sourceBuffer now EOS`);\n        }\n      }\n      return acc && !!(!sb || sb.ended);\n    }, true);\n    if (ended) {\n      this.log(`Queueing mediaSource.endOfStream()`);\n      this.blockBuffers(() => {\n        this.getSourceBufferTypes().forEach(type => {\n          const sb = this.sourceBuffer[type];\n          if (sb) {\n            sb.ending = false;\n          }\n        });\n        const {\n          mediaSource\n        } = this;\n        if (!mediaSource || mediaSource.readyState !== 'open') {\n          if (mediaSource) {\n            this.log(`Could not call mediaSource.endOfStream(). mediaSource.readyState: ${mediaSource.readyState}`);\n          }\n          return;\n        }\n        this.log(`Calling mediaSource.endOfStream()`);\n        // Allow this to throw and be caught by the enqueueing function\n        mediaSource.endOfStream();\n      });\n    }\n  }\n  onLevelUpdated(event, {\n    details\n  }) {\n    if (!details.fragments.length) {\n      return;\n    }\n    this.details = details;\n    if (this.getSourceBufferTypes().length) {\n      this.blockBuffers(this.updateMediaElementDuration.bind(this));\n    } else {\n      this.updateMediaElementDuration();\n    }\n  }\n  trimBuffers() {\n    const {\n      hls,\n      details,\n      media\n    } = this;\n    if (!media || details === null) {\n      return;\n    }\n    const sourceBufferTypes = this.getSourceBufferTypes();\n    if (!sourceBufferTypes.length) {\n      return;\n    }\n    const config = hls.config;\n    const currentTime = media.currentTime;\n    const targetDuration = details.levelTargetDuration;\n\n    // Support for deprecated liveBackBufferLength\n    const backBufferLength = details.live && config.liveBackBufferLength !== null ? config.liveBackBufferLength : config.backBufferLength;\n    if (isFiniteNumber(backBufferLength) && backBufferLength > 0) {\n      const maxBackBufferLength = Math.max(backBufferLength, targetDuration);\n      const targetBackBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration - maxBackBufferLength;\n      this.flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition);\n    }\n    if (isFiniteNumber(config.frontBufferFlushThreshold) && config.frontBufferFlushThreshold > 0) {\n      const frontBufferLength = Math.max(config.maxBufferLength, config.frontBufferFlushThreshold);\n      const maxFrontBufferLength = Math.max(frontBufferLength, targetDuration);\n      const targetFrontBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration + maxFrontBufferLength;\n      this.flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition);\n    }\n  }\n  flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition) {\n    const {\n      details,\n      sourceBuffer\n    } = this;\n    const sourceBufferTypes = this.getSourceBufferTypes();\n    sourceBufferTypes.forEach(type => {\n      const sb = sourceBuffer[type];\n      if (sb) {\n        const buffered = BufferHelper.getBuffered(sb);\n        // when target buffer start exceeds actual buffer start\n        if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {\n          this.hls.trigger(Events.BACK_BUFFER_REACHED, {\n            bufferEnd: targetBackBufferPosition\n          });\n\n          // Support for deprecated event:\n          if (details != null && details.live) {\n            this.hls.trigger(Events.LIVE_BACK_BUFFER_REACHED, {\n              bufferEnd: targetBackBufferPosition\n            });\n          } else if (sb.ended && buffered.end(buffered.length - 1) - currentTime < targetDuration * 2) {\n            this.log(`Cannot flush ${type} back buffer while SourceBuffer is in ended state`);\n            return;\n          }\n          this.hls.trigger(Events.BUFFER_FLUSHING, {\n            startOffset: 0,\n            endOffset: targetBackBufferPosition,\n            type\n          });\n        }\n      }\n    });\n  }\n  flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition) {\n    const {\n      sourceBuffer\n    } = this;\n    const sourceBufferTypes = this.getSourceBufferTypes();\n    sourceBufferTypes.forEach(type => {\n      const sb = sourceBuffer[type];\n      if (sb) {\n        const buffered = BufferHelper.getBuffered(sb);\n        const numBufferedRanges = buffered.length;\n        // The buffer is either empty or contiguous\n        if (numBufferedRanges < 2) {\n          return;\n        }\n        const bufferStart = buffered.start(numBufferedRanges - 1);\n        const bufferEnd = buffered.end(numBufferedRanges - 1);\n        // No flush if we can tolerate the current buffer length or the current buffer range we would flush is contiguous with current position\n        if (targetFrontBufferPosition > bufferStart || currentTime >= bufferStart && currentTime <= bufferEnd) {\n          return;\n        } else if (sb.ended && currentTime - bufferEnd < 2 * targetDuration) {\n          this.log(`Cannot flush ${type} front buffer while SourceBuffer is in ended state`);\n          return;\n        }\n        this.hls.trigger(Events.BUFFER_FLUSHING, {\n          startOffset: bufferStart,\n          endOffset: Infinity,\n          type\n        });\n      }\n    });\n  }\n\n  /**\n   * Update Media Source duration to current level duration or override to Infinity if configuration parameter\n   * 'liveDurationInfinity` is set to `true`\n   * More details: https://github.com/video-dev/hls.js/issues/355\n   */\n  updateMediaElementDuration() {\n    if (!this.details || !this.media || !this.mediaSource || this.mediaSource.readyState !== 'open') {\n      return;\n    }\n    const {\n      details,\n      hls,\n      media,\n      mediaSource\n    } = this;\n    const levelDuration = details.fragments[0].start + details.totalduration;\n    const mediaDuration = media.duration;\n    const msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : 0;\n    if (details.live && hls.config.liveDurationInfinity) {\n      // Override duration to Infinity\n      mediaSource.duration = Infinity;\n      this.updateSeekableRange(details);\n    } else if (levelDuration > msDuration && levelDuration > mediaDuration || !isFiniteNumber(mediaDuration)) {\n      // levelDuration was the last value we set.\n      // not using mediaSource.duration as the browser may tweak this value\n      // only update Media Source duration if its value increase, this is to avoid\n      // flushing already buffered portion when switching between quality level\n      this.log(`Updating Media Source duration to ${levelDuration.toFixed(3)}`);\n      mediaSource.duration = levelDuration;\n    }\n  }\n  updateSeekableRange(levelDetails) {\n    const mediaSource = this.mediaSource;\n    const fragments = levelDetails.fragments;\n    const len = fragments.length;\n    if (len && levelDetails.live && mediaSource != null && mediaSource.setLiveSeekableRange) {\n      const start = Math.max(0, fragments[0].start);\n      const end = Math.max(start, start + levelDetails.totalduration);\n      this.log(`Media Source duration is set to ${mediaSource.duration}. Setting seekable range to ${start}-${end}.`);\n      mediaSource.setLiveSeekableRange(start, end);\n    }\n  }\n  checkPendingTracks() {\n    const {\n      bufferCodecEventsExpected,\n      operationQueue,\n      pendingTracks\n    } = this;\n\n    // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.\n    // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after\n    // data has been appended to existing ones.\n    // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.\n    const pendingTracksCount = Object.keys(pendingTracks).length;\n    if (pendingTracksCount && (!bufferCodecEventsExpected || pendingTracksCount === 2 || 'audiovideo' in pendingTracks)) {\n      // ok, let's create them now !\n      this.createSourceBuffers(pendingTracks);\n      this.pendingTracks = {};\n      // append any pending segments now !\n      const buffers = this.getSourceBufferTypes();\n      if (buffers.length) {\n        this.hls.trigger(Events.BUFFER_CREATED, {\n          tracks: this.tracks\n        });\n        buffers.forEach(type => {\n          operationQueue.executeNext(type);\n        });\n      } else {\n        const error = new Error('could not create source buffer for media codec(s)');\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.BUFFER_INCOMPATIBLE_CODECS_ERROR,\n          fatal: true,\n          error,\n          reason: error.message\n        });\n      }\n    }\n  }\n  createSourceBuffers(tracks) {\n    const {\n      sourceBuffer,\n      mediaSource\n    } = this;\n    if (!mediaSource) {\n      throw Error('createSourceBuffers called when mediaSource was null');\n    }\n    for (const trackName in tracks) {\n      if (!sourceBuffer[trackName]) {\n        var _track$levelCodec;\n        const track = tracks[trackName];\n        if (!track) {\n          throw Error(`source buffer exists for track ${trackName}, however track does not`);\n        }\n        // use levelCodec as first priority unless it contains multiple comma-separated codec values\n        let codec = ((_track$levelCodec = track.levelCodec) == null ? void 0 : _track$levelCodec.indexOf(',')) === -1 ? track.levelCodec : track.codec;\n        if (codec) {\n          if (trackName.slice(0, 5) === 'audio') {\n            codec = getCodecCompatibleName(codec, this.appendSource);\n          }\n        }\n        const mimeType = `${track.container};codecs=${codec}`;\n        this.log(`creating sourceBuffer(${mimeType})`);\n        try {\n          const sb = sourceBuffer[trackName] = mediaSource.addSourceBuffer(mimeType);\n          const sbName = trackName;\n          this.addBufferListener(sbName, 'updatestart', this._onSBUpdateStart);\n          this.addBufferListener(sbName, 'updateend', this._onSBUpdateEnd);\n          this.addBufferListener(sbName, 'error', this._onSBUpdateError);\n          // ManagedSourceBuffer bufferedchange event\n          if (this.appendSource) {\n            this.addBufferListener(sbName, 'bufferedchange', (type, event) => {\n              // If media was ejected check for a change. Added ranges are redundant with changes on 'updateend' event.\n              const removedRanges = event.removedRanges;\n              if (removedRanges != null && removedRanges.length) {\n                this.hls.trigger(Events.BUFFER_FLUSHED, {\n                  type: trackName\n                });\n              }\n            });\n          }\n          this.tracks[trackName] = {\n            buffer: sb,\n            codec: codec,\n            container: track.container,\n            levelCodec: track.levelCodec,\n            metadata: track.metadata,\n            id: track.id\n          };\n        } catch (err) {\n          this.error(`error while trying to add sourceBuffer: ${err.message}`);\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.BUFFER_ADD_CODEC_ERROR,\n            fatal: false,\n            error: err,\n            sourceBufferName: trackName,\n            mimeType: mimeType\n          });\n        }\n      }\n    }\n  }\n  get mediaSrc() {\n    var _this$media;\n    const media = ((_this$media = this.media) == null ? void 0 : _this$media.firstChild) || this.media;\n    return media == null ? void 0 : media.src;\n  }\n  _onSBUpdateStart(type) {\n    const {\n      operationQueue\n    } = this;\n    const operation = operationQueue.current(type);\n    operation.onStart();\n  }\n  _onSBUpdateEnd(type) {\n    var _this$mediaSource2;\n    if (((_this$mediaSource2 = this.mediaSource) == null ? void 0 : _this$mediaSource2.readyState) === 'closed') {\n      this.resetBuffer(type);\n      return;\n    }\n    const {\n      operationQueue\n    } = this;\n    const operation = operationQueue.current(type);\n    operation.onComplete();\n    operationQueue.shiftAndExecuteNext(type);\n  }\n  _onSBUpdateError(type, event) {\n    var _this$mediaSource3;\n    const error = new Error(`${type} SourceBuffer error. MediaSource readyState: ${(_this$mediaSource3 = this.mediaSource) == null ? void 0 : _this$mediaSource3.readyState}`);\n    this.error(`${error}`, event);\n    // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error\n    // SourceBuffer errors are not necessarily fatal; if so, the HTMLMediaElement will fire an error event\n    this.hls.trigger(Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.BUFFER_APPENDING_ERROR,\n      sourceBufferName: type,\n      error,\n      fatal: false\n    });\n    // updateend is always fired after error, so we'll allow that to shift the current operation off of the queue\n    const operation = this.operationQueue.current(type);\n    if (operation) {\n      operation.onError(error);\n    }\n  }\n\n  // This method must result in an updateend event; if remove is not called, _onSBUpdateEnd must be called manually\n  removeExecutor(type, startOffset, endOffset) {\n    const {\n      media,\n      mediaSource,\n      operationQueue,\n      sourceBuffer\n    } = this;\n    const sb = sourceBuffer[type];\n    if (!media || !mediaSource || !sb) {\n      this.warn(`Attempting to remove from the ${type} SourceBuffer, but it does not exist`);\n      operationQueue.shiftAndExecuteNext(type);\n      return;\n    }\n    const mediaDuration = isFiniteNumber(media.duration) ? media.duration : Infinity;\n    const msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : Infinity;\n    const removeStart = Math.max(0, startOffset);\n    const removeEnd = Math.min(endOffset, mediaDuration, msDuration);\n    if (removeEnd > removeStart && (!sb.ending || sb.ended)) {\n      sb.ended = false;\n      this.log(`Removing [${removeStart},${removeEnd}] from the ${type} SourceBuffer`);\n      sb.remove(removeStart, removeEnd);\n    } else {\n      // Cycle the queue\n      operationQueue.shiftAndExecuteNext(type);\n    }\n  }\n\n  // This method must result in an updateend event; if append is not called, _onSBUpdateEnd must be called manually\n  appendExecutor(data, type) {\n    const sb = this.sourceBuffer[type];\n    if (!sb) {\n      if (!this.pendingTracks[type]) {\n        throw new Error(`Attempting to append to the ${type} SourceBuffer, but it does not exist`);\n      }\n      return;\n    }\n    sb.ended = false;\n    sb.appendBuffer(data);\n  }\n\n  // Enqueues an operation to each SourceBuffer queue which, upon execution, resolves a promise. When all promises\n  // resolve, the onUnblocked function is executed. Functions calling this method do not need to unblock the queue\n  // upon completion, since we already do it here\n  blockBuffers(onUnblocked, buffers = this.getSourceBufferTypes()) {\n    if (!buffers.length) {\n      this.log('Blocking operation requested, but no SourceBuffers exist');\n      Promise.resolve().then(onUnblocked);\n      return;\n    }\n    const {\n      operationQueue\n    } = this;\n\n    // logger.debug(`[buffer-controller]: Blocking ${buffers} SourceBuffer`);\n    const blockingOperations = buffers.map(type => operationQueue.appendBlocker(type));\n    Promise.all(blockingOperations).then(() => {\n      // logger.debug(`[buffer-controller]: Blocking operation resolved; unblocking ${buffers} SourceBuffer`);\n      onUnblocked();\n      buffers.forEach(type => {\n        const sb = this.sourceBuffer[type];\n        // Only cycle the queue if the SB is not updating. There's a bug in Chrome which sets the SB updating flag to\n        // true when changing the MediaSource duration (https://bugs.chromium.org/p/chromium/issues/detail?id=959359&can=2&q=mediasource%20duration)\n        // While this is a workaround, it's probably useful to have around\n        if (!(sb != null && sb.updating)) {\n          operationQueue.shiftAndExecuteNext(type);\n        }\n      });\n    });\n  }\n  getSourceBufferTypes() {\n    return Object.keys(this.sourceBuffer);\n  }\n  addBufferListener(type, event, fn) {\n    const buffer = this.sourceBuffer[type];\n    if (!buffer) {\n      return;\n    }\n    const listener = fn.bind(this, type);\n    this.listeners[type].push({\n      event,\n      listener\n    });\n    buffer.addEventListener(event, listener);\n  }\n  removeBufferListeners(type) {\n    const buffer = this.sourceBuffer[type];\n    if (!buffer) {\n      return;\n    }\n    this.listeners[type].forEach(l => {\n      buffer.removeEventListener(l.event, l.listener);\n    });\n  }\n}\nfunction removeSourceChildren(node) {\n  const sourceChildren = node.querySelectorAll('source');\n  [].slice.call(sourceChildren).forEach(source => {\n    node.removeChild(source);\n  });\n}\nfunction addSource(media, url) {\n  const source = self.document.createElement('source');\n  source.type = 'video/mp4';\n  source.src = url;\n  media.appendChild(source);\n}\n\n/**\n *\n * This code was ported from the dash.js project at:\n *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js\n *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2\n *\n * The original copyright appears below:\n *\n * The copyright in this software is being made available under the BSD License,\n * included below. This software may be subject to other third party and contributor\n * rights, including patent rights, and no such rights are granted under this license.\n *\n * Copyright (c) 2015-2016, DASH Industry Forum.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without modification,\n * are permitted provided that the following conditions are met:\n *  1. Redistributions of source code must retain the above copyright notice, this\n *  list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above copyright notice,\n *  this list of conditions and the following disclaimer in the documentation and/or\n *  other materials provided with the distribution.\n *  2. Neither the name of Dash Industry Forum nor the names of its\n *  contributors may be used to endorse or promote products derived from this software\n *  without specific prior written permission.\n *\n *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY\n *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n *  POSSIBILITY OF SUCH DAMAGE.\n */\n/**\n *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes\n */\n\nconst specialCea608CharsCodes = {\n  0x2a: 0xe1,\n  // lowercase a, acute accent\n  0x5c: 0xe9,\n  // lowercase e, acute accent\n  0x5e: 0xed,\n  // lowercase i, acute accent\n  0x5f: 0xf3,\n  // lowercase o, acute accent\n  0x60: 0xfa,\n  // lowercase u, acute accent\n  0x7b: 0xe7,\n  // lowercase c with cedilla\n  0x7c: 0xf7,\n  // division symbol\n  0x7d: 0xd1,\n  // uppercase N tilde\n  0x7e: 0xf1,\n  // lowercase n tilde\n  0x7f: 0x2588,\n  // Full block\n  // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F\n  // THIS MEANS THAT \\x50 MUST BE ADDED TO THE VALUES\n  0x80: 0xae,\n  // Registered symbol (R)\n  0x81: 0xb0,\n  // degree sign\n  0x82: 0xbd,\n  // 1/2 symbol\n  0x83: 0xbf,\n  // Inverted (open) question mark\n  0x84: 0x2122,\n  // Trademark symbol (TM)\n  0x85: 0xa2,\n  // Cents symbol\n  0x86: 0xa3,\n  // Pounds sterling\n  0x87: 0x266a,\n  // Music 8'th note\n  0x88: 0xe0,\n  // lowercase a, grave accent\n  0x89: 0x20,\n  // transparent space (regular)\n  0x8a: 0xe8,\n  // lowercase e, grave accent\n  0x8b: 0xe2,\n  // lowercase a, circumflex accent\n  0x8c: 0xea,\n  // lowercase e, circumflex accent\n  0x8d: 0xee,\n  // lowercase i, circumflex accent\n  0x8e: 0xf4,\n  // lowercase o, circumflex accent\n  0x8f: 0xfb,\n  // lowercase u, circumflex accent\n  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F\n  0x90: 0xc1,\n  // capital letter A with acute\n  0x91: 0xc9,\n  // capital letter E with acute\n  0x92: 0xd3,\n  // capital letter O with acute\n  0x93: 0xda,\n  // capital letter U with acute\n  0x94: 0xdc,\n  // capital letter U with diaresis\n  0x95: 0xfc,\n  // lowercase letter U with diaeresis\n  0x96: 0x2018,\n  // opening single quote\n  0x97: 0xa1,\n  // inverted exclamation mark\n  0x98: 0x2a,\n  // asterisk\n  0x99: 0x2019,\n  // closing single quote\n  0x9a: 0x2501,\n  // box drawings heavy horizontal\n  0x9b: 0xa9,\n  // copyright sign\n  0x9c: 0x2120,\n  // Service mark\n  0x9d: 0x2022,\n  // (round) bullet\n  0x9e: 0x201c,\n  // Left double quotation mark\n  0x9f: 0x201d,\n  // Right double quotation mark\n  0xa0: 0xc0,\n  // uppercase A, grave accent\n  0xa1: 0xc2,\n  // uppercase A, circumflex\n  0xa2: 0xc7,\n  // uppercase C with cedilla\n  0xa3: 0xc8,\n  // uppercase E, grave accent\n  0xa4: 0xca,\n  // uppercase E, circumflex\n  0xa5: 0xcb,\n  // capital letter E with diaresis\n  0xa6: 0xeb,\n  // lowercase letter e with diaresis\n  0xa7: 0xce,\n  // uppercase I, circumflex\n  0xa8: 0xcf,\n  // uppercase I, with diaresis\n  0xa9: 0xef,\n  // lowercase i, with diaresis\n  0xaa: 0xd4,\n  // uppercase O, circumflex\n  0xab: 0xd9,\n  // uppercase U, grave accent\n  0xac: 0xf9,\n  // lowercase u, grave accent\n  0xad: 0xdb,\n  // uppercase U, circumflex\n  0xae: 0xab,\n  // left-pointing double angle quotation mark\n  0xaf: 0xbb,\n  // right-pointing double angle quotation mark\n  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n  // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F\n  0xb0: 0xc3,\n  // Uppercase A, tilde\n  0xb1: 0xe3,\n  // Lowercase a, tilde\n  0xb2: 0xcd,\n  // Uppercase I, acute accent\n  0xb3: 0xcc,\n  // Uppercase I, grave accent\n  0xb4: 0xec,\n  // Lowercase i, grave accent\n  0xb5: 0xd2,\n  // Uppercase O, grave accent\n  0xb6: 0xf2,\n  // Lowercase o, grave accent\n  0xb7: 0xd5,\n  // Uppercase O, tilde\n  0xb8: 0xf5,\n  // Lowercase o, tilde\n  0xb9: 0x7b,\n  // Open curly brace\n  0xba: 0x7d,\n  // Closing curly brace\n  0xbb: 0x5c,\n  // Backslash\n  0xbc: 0x5e,\n  // Caret\n  0xbd: 0x5f,\n  // Underscore\n  0xbe: 0x7c,\n  // Pipe (vertical line)\n  0xbf: 0x223c,\n  // Tilde operator\n  0xc0: 0xc4,\n  // Uppercase A, umlaut\n  0xc1: 0xe4,\n  // Lowercase A, umlaut\n  0xc2: 0xd6,\n  // Uppercase O, umlaut\n  0xc3: 0xf6,\n  // Lowercase o, umlaut\n  0xc4: 0xdf,\n  // Esszett (sharp S)\n  0xc5: 0xa5,\n  // Yen symbol\n  0xc6: 0xa4,\n  // Generic currency sign\n  0xc7: 0x2503,\n  // Box drawings heavy vertical\n  0xc8: 0xc5,\n  // Uppercase A, ring\n  0xc9: 0xe5,\n  // Lowercase A, ring\n  0xca: 0xd8,\n  // Uppercase O, stroke\n  0xcb: 0xf8,\n  // Lowercase o, strok\n  0xcc: 0x250f,\n  // Box drawings heavy down and right\n  0xcd: 0x2513,\n  // Box drawings heavy down and left\n  0xce: 0x2517,\n  // Box drawings heavy up and right\n  0xcf: 0x251b // Box drawings heavy up and left\n};\n\n/**\n * Utils\n */\nconst getCharForByte = byte => String.fromCharCode(specialCea608CharsCodes[byte] || byte);\nconst NR_ROWS = 15;\nconst NR_COLS = 100;\n// Tables to look up row from PAC data\nconst rowsLowCh1 = {\n  0x11: 1,\n  0x12: 3,\n  0x15: 5,\n  0x16: 7,\n  0x17: 9,\n  0x10: 11,\n  0x13: 12,\n  0x14: 14\n};\nconst rowsHighCh1 = {\n  0x11: 2,\n  0x12: 4,\n  0x15: 6,\n  0x16: 8,\n  0x17: 10,\n  0x13: 13,\n  0x14: 15\n};\nconst rowsLowCh2 = {\n  0x19: 1,\n  0x1a: 3,\n  0x1d: 5,\n  0x1e: 7,\n  0x1f: 9,\n  0x18: 11,\n  0x1b: 12,\n  0x1c: 14\n};\nconst rowsHighCh2 = {\n  0x19: 2,\n  0x1a: 4,\n  0x1d: 6,\n  0x1e: 8,\n  0x1f: 10,\n  0x1b: 13,\n  0x1c: 15\n};\nconst backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];\nclass CaptionsLogger {\n  constructor() {\n    this.time = null;\n    this.verboseLevel = 0;\n  }\n  log(severity, msg) {\n    if (this.verboseLevel >= severity) {\n      const m = typeof msg === 'function' ? msg() : msg;\n      logger.log(`${this.time} [${severity}] ${m}`);\n    }\n  }\n}\nconst numArrayToHexArray = function numArrayToHexArray(numArray) {\n  const hexArray = [];\n  for (let j = 0; j < numArray.length; j++) {\n    hexArray.push(numArray[j].toString(16));\n  }\n  return hexArray;\n};\nclass PenState {\n  constructor() {\n    this.foreground = 'white';\n    this.underline = false;\n    this.italics = false;\n    this.background = 'black';\n    this.flash = false;\n  }\n  reset() {\n    this.foreground = 'white';\n    this.underline = false;\n    this.italics = false;\n    this.background = 'black';\n    this.flash = false;\n  }\n  setStyles(styles) {\n    const attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];\n    for (let i = 0; i < attribs.length; i++) {\n      const style = attribs[i];\n      if (styles.hasOwnProperty(style)) {\n        this[style] = styles[style];\n      }\n    }\n  }\n  isDefault() {\n    return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;\n  }\n  equals(other) {\n    return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;\n  }\n  copy(newPenState) {\n    this.foreground = newPenState.foreground;\n    this.underline = newPenState.underline;\n    this.italics = newPenState.italics;\n    this.background = newPenState.background;\n    this.flash = newPenState.flash;\n  }\n  toString() {\n    return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;\n  }\n}\n\n/**\n * Unicode character with styling and background.\n * @constructor\n */\nclass StyledUnicodeChar {\n  constructor() {\n    this.uchar = ' ';\n    this.penState = new PenState();\n  }\n  reset() {\n    this.uchar = ' ';\n    this.penState.reset();\n  }\n  setChar(uchar, newPenState) {\n    this.uchar = uchar;\n    this.penState.copy(newPenState);\n  }\n  setPenState(newPenState) {\n    this.penState.copy(newPenState);\n  }\n  equals(other) {\n    return this.uchar === other.uchar && this.penState.equals(other.penState);\n  }\n  copy(newChar) {\n    this.uchar = newChar.uchar;\n    this.penState.copy(newChar.penState);\n  }\n  isEmpty() {\n    return this.uchar === ' ' && this.penState.isDefault();\n  }\n}\n\n/**\n * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.\n * @constructor\n */\nclass Row {\n  constructor(logger) {\n    this.chars = [];\n    this.pos = 0;\n    this.currPenState = new PenState();\n    this.cueStartTime = null;\n    this.logger = void 0;\n    for (let i = 0; i < NR_COLS; i++) {\n      this.chars.push(new StyledUnicodeChar());\n    }\n    this.logger = logger;\n  }\n  equals(other) {\n    for (let i = 0; i < NR_COLS; i++) {\n      if (!this.chars[i].equals(other.chars[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  copy(other) {\n    for (let i = 0; i < NR_COLS; i++) {\n      this.chars[i].copy(other.chars[i]);\n    }\n  }\n  isEmpty() {\n    let empty = true;\n    for (let i = 0; i < NR_COLS; i++) {\n      if (!this.chars[i].isEmpty()) {\n        empty = false;\n        break;\n      }\n    }\n    return empty;\n  }\n\n  /**\n   *  Set the cursor to a valid column.\n   */\n  setCursor(absPos) {\n    if (this.pos !== absPos) {\n      this.pos = absPos;\n    }\n    if (this.pos < 0) {\n      this.logger.log(3, 'Negative cursor position ' + this.pos);\n      this.pos = 0;\n    } else if (this.pos > NR_COLS) {\n      this.logger.log(3, 'Too large cursor position ' + this.pos);\n      this.pos = NR_COLS;\n    }\n  }\n\n  /**\n   * Move the cursor relative to current position.\n   */\n  moveCursor(relPos) {\n    const newPos = this.pos + relPos;\n    if (relPos > 1) {\n      for (let i = this.pos + 1; i < newPos + 1; i++) {\n        this.chars[i].setPenState(this.currPenState);\n      }\n    }\n    this.setCursor(newPos);\n  }\n\n  /**\n   * Backspace, move one step back and clear character.\n   */\n  backSpace() {\n    this.moveCursor(-1);\n    this.chars[this.pos].setChar(' ', this.currPenState);\n  }\n  insertChar(byte) {\n    if (byte >= 0x90) {\n      // Extended char\n      this.backSpace();\n    }\n    const char = getCharForByte(byte);\n    if (this.pos >= NR_COLS) {\n      this.logger.log(0, () => 'Cannot insert ' + byte.toString(16) + ' (' + char + ') at position ' + this.pos + '. Skipping it!');\n      return;\n    }\n    this.chars[this.pos].setChar(char, this.currPenState);\n    this.moveCursor(1);\n  }\n  clearFromPos(startPos) {\n    let i;\n    for (i = startPos; i < NR_COLS; i++) {\n      this.chars[i].reset();\n    }\n  }\n  clear() {\n    this.clearFromPos(0);\n    this.pos = 0;\n    this.currPenState.reset();\n  }\n  clearToEndOfRow() {\n    this.clearFromPos(this.pos);\n  }\n  getTextString() {\n    const chars = [];\n    let empty = true;\n    for (let i = 0; i < NR_COLS; i++) {\n      const char = this.chars[i].uchar;\n      if (char !== ' ') {\n        empty = false;\n      }\n      chars.push(char);\n    }\n    if (empty) {\n      return '';\n    } else {\n      return chars.join('');\n    }\n  }\n  setPenStyles(styles) {\n    this.currPenState.setStyles(styles);\n    const currChar = this.chars[this.pos];\n    currChar.setPenState(this.currPenState);\n  }\n}\n\n/**\n * Keep a CEA-608 screen of 32x15 styled characters\n * @constructor\n */\nclass CaptionScreen {\n  constructor(logger) {\n    this.rows = [];\n    this.currRow = NR_ROWS - 1;\n    this.nrRollUpRows = null;\n    this.lastOutputScreen = null;\n    this.logger = void 0;\n    for (let i = 0; i < NR_ROWS; i++) {\n      this.rows.push(new Row(logger));\n    }\n    this.logger = logger;\n  }\n  reset() {\n    for (let i = 0; i < NR_ROWS; i++) {\n      this.rows[i].clear();\n    }\n    this.currRow = NR_ROWS - 1;\n  }\n  equals(other) {\n    let equal = true;\n    for (let i = 0; i < NR_ROWS; i++) {\n      if (!this.rows[i].equals(other.rows[i])) {\n        equal = false;\n        break;\n      }\n    }\n    return equal;\n  }\n  copy(other) {\n    for (let i = 0; i < NR_ROWS; i++) {\n      this.rows[i].copy(other.rows[i]);\n    }\n  }\n  isEmpty() {\n    let empty = true;\n    for (let i = 0; i < NR_ROWS; i++) {\n      if (!this.rows[i].isEmpty()) {\n        empty = false;\n        break;\n      }\n    }\n    return empty;\n  }\n  backSpace() {\n    const row = this.rows[this.currRow];\n    row.backSpace();\n  }\n  clearToEndOfRow() {\n    const row = this.rows[this.currRow];\n    row.clearToEndOfRow();\n  }\n\n  /**\n   * Insert a character (without styling) in the current row.\n   */\n  insertChar(char) {\n    const row = this.rows[this.currRow];\n    row.insertChar(char);\n  }\n  setPen(styles) {\n    const row = this.rows[this.currRow];\n    row.setPenStyles(styles);\n  }\n  moveCursor(relPos) {\n    const row = this.rows[this.currRow];\n    row.moveCursor(relPos);\n  }\n  setCursor(absPos) {\n    this.logger.log(2, 'setCursor: ' + absPos);\n    const row = this.rows[this.currRow];\n    row.setCursor(absPos);\n  }\n  setPAC(pacData) {\n    this.logger.log(2, () => 'pacData = ' + JSON.stringify(pacData));\n    let newRow = pacData.row - 1;\n    if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {\n      newRow = this.nrRollUpRows - 1;\n    }\n\n    // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows\n    if (this.nrRollUpRows && this.currRow !== newRow) {\n      // clear all rows first\n      for (let i = 0; i < NR_ROWS; i++) {\n        this.rows[i].clear();\n      }\n\n      // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location\n      // topRowIndex - the start of rows to copy (inclusive index)\n      const topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n      // We only copy if the last position was already shown.\n      // We use the cueStartTime value to check this.\n      const lastOutputScreen = this.lastOutputScreen;\n      if (lastOutputScreen) {\n        const prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;\n        const time = this.logger.time;\n        if (prevLineTime !== null && time !== null && prevLineTime < time) {\n          for (let i = 0; i < this.nrRollUpRows; i++) {\n            this.rows[newRow - this.nrRollUpRows + i + 1].copy(lastOutputScreen.rows[topRowIndex + i]);\n          }\n        }\n      }\n    }\n    this.currRow = newRow;\n    const row = this.rows[this.currRow];\n    if (pacData.indent !== null) {\n      const indent = pacData.indent;\n      const prevPos = Math.max(indent - 1, 0);\n      row.setCursor(pacData.indent);\n      pacData.color = row.chars[prevPos].penState.foreground;\n    }\n    const styles = {\n      foreground: pacData.color,\n      underline: pacData.underline,\n      italics: pacData.italics,\n      background: 'black',\n      flash: false\n    };\n    this.setPen(styles);\n  }\n\n  /**\n   * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).\n   */\n  setBkgData(bkgData) {\n    this.logger.log(2, () => 'bkgData = ' + JSON.stringify(bkgData));\n    this.backSpace();\n    this.setPen(bkgData);\n    this.insertChar(0x20); // Space\n  }\n  setRollUpRows(nrRows) {\n    this.nrRollUpRows = nrRows;\n  }\n  rollUp() {\n    if (this.nrRollUpRows === null) {\n      this.logger.log(3, 'roll_up but nrRollUpRows not set yet');\n      return; // Not properly setup\n    }\n    this.logger.log(1, () => this.getDisplayText());\n    const topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n    const topRow = this.rows.splice(topRowIndex, 1)[0];\n    topRow.clear();\n    this.rows.splice(this.currRow, 0, topRow);\n    this.logger.log(2, 'Rolling up');\n    // this.logger.log(VerboseLevel.TEXT, this.get_display_text())\n  }\n\n  /**\n   * Get all non-empty rows with as unicode text.\n   */\n  getDisplayText(asOneRow) {\n    asOneRow = asOneRow || false;\n    const displayText = [];\n    let text = '';\n    let rowNr = -1;\n    for (let i = 0; i < NR_ROWS; i++) {\n      const rowText = this.rows[i].getTextString();\n      if (rowText) {\n        rowNr = i + 1;\n        if (asOneRow) {\n          displayText.push('Row ' + rowNr + \": '\" + rowText + \"'\");\n        } else {\n          displayText.push(rowText.trim());\n        }\n      }\n    }\n    if (displayText.length > 0) {\n      if (asOneRow) {\n        text = '[' + displayText.join(' | ') + ']';\n      } else {\n        text = displayText.join('\\n');\n      }\n    }\n    return text;\n  }\n  getTextAndFormat() {\n    return this.rows;\n  }\n}\n\n// var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];\n\nclass Cea608Channel {\n  constructor(channelNumber, outputFilter, logger) {\n    this.chNr = void 0;\n    this.outputFilter = void 0;\n    this.mode = void 0;\n    this.verbose = void 0;\n    this.displayedMemory = void 0;\n    this.nonDisplayedMemory = void 0;\n    this.lastOutputScreen = void 0;\n    this.currRollUpRow = void 0;\n    this.writeScreen = void 0;\n    this.cueStartTime = void 0;\n    this.logger = void 0;\n    this.chNr = channelNumber;\n    this.outputFilter = outputFilter;\n    this.mode = null;\n    this.verbose = 0;\n    this.displayedMemory = new CaptionScreen(logger);\n    this.nonDisplayedMemory = new CaptionScreen(logger);\n    this.lastOutputScreen = new CaptionScreen(logger);\n    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n    this.writeScreen = this.displayedMemory;\n    this.mode = null;\n    this.cueStartTime = null; // Keeps track of where a cue started.\n    this.logger = logger;\n  }\n  reset() {\n    this.mode = null;\n    this.displayedMemory.reset();\n    this.nonDisplayedMemory.reset();\n    this.lastOutputScreen.reset();\n    this.outputFilter.reset();\n    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n    this.writeScreen = this.displayedMemory;\n    this.mode = null;\n    this.cueStartTime = null;\n  }\n  getHandler() {\n    return this.outputFilter;\n  }\n  setHandler(newHandler) {\n    this.outputFilter = newHandler;\n  }\n  setPAC(pacData) {\n    this.writeScreen.setPAC(pacData);\n  }\n  setBkgData(bkgData) {\n    this.writeScreen.setBkgData(bkgData);\n  }\n  setMode(newMode) {\n    if (newMode === this.mode) {\n      return;\n    }\n    this.mode = newMode;\n    this.logger.log(2, () => 'MODE=' + newMode);\n    if (this.mode === 'MODE_POP-ON') {\n      this.writeScreen = this.nonDisplayedMemory;\n    } else {\n      this.writeScreen = this.displayedMemory;\n      this.writeScreen.reset();\n    }\n    if (this.mode !== 'MODE_ROLL-UP') {\n      this.displayedMemory.nrRollUpRows = null;\n      this.nonDisplayedMemory.nrRollUpRows = null;\n    }\n    this.mode = newMode;\n  }\n  insertChars(chars) {\n    for (let i = 0; i < chars.length; i++) {\n      this.writeScreen.insertChar(chars[i]);\n    }\n    const screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';\n    this.logger.log(2, () => screen + ': ' + this.writeScreen.getDisplayText(true));\n    if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {\n      this.logger.log(1, () => 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));\n      this.outputDataUpdate();\n    }\n  }\n  ccRCL() {\n    // Resume Caption Loading (switch mode to Pop On)\n    this.logger.log(2, 'RCL - Resume Caption Loading');\n    this.setMode('MODE_POP-ON');\n  }\n  ccBS() {\n    // BackSpace\n    this.logger.log(2, 'BS - BackSpace');\n    if (this.mode === 'MODE_TEXT') {\n      return;\n    }\n    this.writeScreen.backSpace();\n    if (this.writeScreen === this.displayedMemory) {\n      this.outputDataUpdate();\n    }\n  }\n  ccAOF() {\n    // Reserved (formerly Alarm Off)\n  }\n  ccAON() {\n    // Reserved (formerly Alarm On)\n  }\n  ccDER() {\n    // Delete to End of Row\n    this.logger.log(2, 'DER- Delete to End of Row');\n    this.writeScreen.clearToEndOfRow();\n    this.outputDataUpdate();\n  }\n  ccRU(nrRows) {\n    // Roll-Up Captions-2,3,or 4 Rows\n    this.logger.log(2, 'RU(' + nrRows + ') - Roll Up');\n    this.writeScreen = this.displayedMemory;\n    this.setMode('MODE_ROLL-UP');\n    this.writeScreen.setRollUpRows(nrRows);\n  }\n  ccFON() {\n    // Flash On\n    this.logger.log(2, 'FON - Flash On');\n    this.writeScreen.setPen({\n      flash: true\n    });\n  }\n  ccRDC() {\n    // Resume Direct Captioning (switch mode to PaintOn)\n    this.logger.log(2, 'RDC - Resume Direct Captioning');\n    this.setMode('MODE_PAINT-ON');\n  }\n  ccTR() {\n    // Text Restart in text mode (not supported, however)\n    this.logger.log(2, 'TR');\n    this.setMode('MODE_TEXT');\n  }\n  ccRTD() {\n    // Resume Text Display in Text mode (not supported, however)\n    this.logger.log(2, 'RTD');\n    this.setMode('MODE_TEXT');\n  }\n  ccEDM() {\n    // Erase Displayed Memory\n    this.logger.log(2, 'EDM - Erase Displayed Memory');\n    this.displayedMemory.reset();\n    this.outputDataUpdate(true);\n  }\n  ccCR() {\n    // Carriage Return\n    this.logger.log(2, 'CR - Carriage Return');\n    this.writeScreen.rollUp();\n    this.outputDataUpdate(true);\n  }\n  ccENM() {\n    // Erase Non-Displayed Memory\n    this.logger.log(2, 'ENM - Erase Non-displayed Memory');\n    this.nonDisplayedMemory.reset();\n  }\n  ccEOC() {\n    // End of Caption (Flip Memories)\n    this.logger.log(2, 'EOC - End Of Caption');\n    if (this.mode === 'MODE_POP-ON') {\n      const tmp = this.displayedMemory;\n      this.displayedMemory = this.nonDisplayedMemory;\n      this.nonDisplayedMemory = tmp;\n      this.writeScreen = this.nonDisplayedMemory;\n      this.logger.log(1, () => 'DISP: ' + this.displayedMemory.getDisplayText());\n    }\n    this.outputDataUpdate(true);\n  }\n  ccTO(nrCols) {\n    // Tab Offset 1,2, or 3 columns\n    this.logger.log(2, 'TO(' + nrCols + ') - Tab Offset');\n    this.writeScreen.moveCursor(nrCols);\n  }\n  ccMIDROW(secondByte) {\n    // Parse MIDROW command\n    const styles = {\n      flash: false\n    };\n    styles.underline = secondByte % 2 === 1;\n    styles.italics = secondByte >= 0x2e;\n    if (!styles.italics) {\n      const colorIndex = Math.floor(secondByte / 2) - 0x10;\n      const colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];\n      styles.foreground = colors[colorIndex];\n    } else {\n      styles.foreground = 'white';\n    }\n    this.logger.log(2, 'MIDROW: ' + JSON.stringify(styles));\n    this.writeScreen.setPen(styles);\n  }\n  outputDataUpdate(dispatch = false) {\n    const time = this.logger.time;\n    if (time === null) {\n      return;\n    }\n    if (this.outputFilter) {\n      if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {\n        // Start of a new cue\n        this.cueStartTime = time;\n      } else {\n        if (!this.displayedMemory.equals(this.lastOutputScreen)) {\n          this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);\n          if (dispatch && this.outputFilter.dispatchCue) {\n            this.outputFilter.dispatchCue();\n          }\n          this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;\n        }\n      }\n      this.lastOutputScreen.copy(this.displayedMemory);\n    }\n  }\n  cueSplitAtTime(t) {\n    if (this.outputFilter) {\n      if (!this.displayedMemory.isEmpty()) {\n        if (this.outputFilter.newCue) {\n          this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);\n        }\n        this.cueStartTime = t;\n      }\n    }\n  }\n}\n\n// Will be 1 or 2 when parsing captions\n\nclass Cea608Parser {\n  constructor(field, out1, out2) {\n    this.channels = void 0;\n    this.currentChannel = 0;\n    this.cmdHistory = createCmdHistory();\n    this.logger = void 0;\n    const logger = this.logger = new CaptionsLogger();\n    this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];\n  }\n  getHandler(channel) {\n    return this.channels[channel].getHandler();\n  }\n  setHandler(channel, newHandler) {\n    this.channels[channel].setHandler(newHandler);\n  }\n\n  /**\n   * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.\n   */\n  addData(time, byteList) {\n    this.logger.time = time;\n    for (let i = 0; i < byteList.length; i += 2) {\n      const a = byteList[i] & 0x7f;\n      const b = byteList[i + 1] & 0x7f;\n      let cmdFound = false;\n      let charsFound = null;\n      if (a === 0 && b === 0) {\n        continue;\n      } else {\n        this.logger.log(3, () => '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');\n      }\n      const cmdHistory = this.cmdHistory;\n      const isControlCode = a >= 0x10 && a <= 0x1f;\n      if (isControlCode) {\n        // Skip redundant control codes\n        if (hasCmdRepeated(a, b, cmdHistory)) {\n          setLastCmd(null, null, cmdHistory);\n          this.logger.log(3, () => 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');\n          continue;\n        }\n        setLastCmd(a, b, this.cmdHistory);\n        cmdFound = this.parseCmd(a, b);\n        if (!cmdFound) {\n          cmdFound = this.parseMidrow(a, b);\n        }\n        if (!cmdFound) {\n          cmdFound = this.parsePAC(a, b);\n        }\n        if (!cmdFound) {\n          cmdFound = this.parseBackgroundAttributes(a, b);\n        }\n      } else {\n        setLastCmd(null, null, cmdHistory);\n      }\n      if (!cmdFound) {\n        charsFound = this.parseChars(a, b);\n        if (charsFound) {\n          const currChNr = this.currentChannel;\n          if (currChNr && currChNr > 0) {\n            const channel = this.channels[currChNr];\n            channel.insertChars(charsFound);\n          } else {\n            this.logger.log(2, 'No channel found yet. TEXT-MODE?');\n          }\n        }\n      }\n      if (!cmdFound && !charsFound) {\n        this.logger.log(2, () => \"Couldn't parse cleaned data \" + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));\n      }\n    }\n  }\n\n  /**\n   * Parse Command.\n   * @returns True if a command was found\n   */\n  parseCmd(a, b) {\n    const cond1 = (a === 0x14 || a === 0x1c || a === 0x15 || a === 0x1d) && b >= 0x20 && b <= 0x2f;\n    const cond2 = (a === 0x17 || a === 0x1f) && b >= 0x21 && b <= 0x23;\n    if (!(cond1 || cond2)) {\n      return false;\n    }\n    const chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;\n    const channel = this.channels[chNr];\n    if (a === 0x14 || a === 0x15 || a === 0x1c || a === 0x1d) {\n      if (b === 0x20) {\n        channel.ccRCL();\n      } else if (b === 0x21) {\n        channel.ccBS();\n      } else if (b === 0x22) {\n        channel.ccAOF();\n      } else if (b === 0x23) {\n        channel.ccAON();\n      } else if (b === 0x24) {\n        channel.ccDER();\n      } else if (b === 0x25) {\n        channel.ccRU(2);\n      } else if (b === 0x26) {\n        channel.ccRU(3);\n      } else if (b === 0x27) {\n        channel.ccRU(4);\n      } else if (b === 0x28) {\n        channel.ccFON();\n      } else if (b === 0x29) {\n        channel.ccRDC();\n      } else if (b === 0x2a) {\n        channel.ccTR();\n      } else if (b === 0x2b) {\n        channel.ccRTD();\n      } else if (b === 0x2c) {\n        channel.ccEDM();\n      } else if (b === 0x2d) {\n        channel.ccCR();\n      } else if (b === 0x2e) {\n        channel.ccENM();\n      } else if (b === 0x2f) {\n        channel.ccEOC();\n      }\n    } else {\n      // a == 0x17 || a == 0x1F\n      channel.ccTO(b - 0x20);\n    }\n    this.currentChannel = chNr;\n    return true;\n  }\n\n  /**\n   * Parse midrow styling command\n   */\n  parseMidrow(a, b) {\n    let chNr = 0;\n    if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {\n      if (a === 0x11) {\n        chNr = 1;\n      } else {\n        chNr = 2;\n      }\n      if (chNr !== this.currentChannel) {\n        this.logger.log(0, 'Mismatch channel in midrow parsing');\n        return false;\n      }\n      const channel = this.channels[chNr];\n      if (!channel) {\n        return false;\n      }\n      channel.ccMIDROW(b);\n      this.logger.log(3, () => 'MIDROW (' + numArrayToHexArray([a, b]) + ')');\n      return true;\n    }\n    return false;\n  }\n\n  /**\n   * Parse Preable Access Codes (Table 53).\n   * @returns {Boolean} Tells if PAC found\n   */\n  parsePAC(a, b) {\n    let row;\n    const case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1f) && b >= 0x40 && b <= 0x7f;\n    const case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5f;\n    if (!(case1 || case2)) {\n      return false;\n    }\n    const chNr = a <= 0x17 ? 1 : 2;\n    if (b >= 0x40 && b <= 0x5f) {\n      row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];\n    } else {\n      // 0x60 <= b <= 0x7F\n      row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];\n    }\n    const channel = this.channels[chNr];\n    if (!channel) {\n      return false;\n    }\n    channel.setPAC(this.interpretPAC(row, b));\n    this.currentChannel = chNr;\n    return true;\n  }\n\n  /**\n   * Interpret the second byte of the pac, and return the information.\n   * @returns pacData with style parameters\n   */\n  interpretPAC(row, byte) {\n    let pacIndex;\n    const pacData = {\n      color: null,\n      italics: false,\n      indent: null,\n      underline: false,\n      row: row\n    };\n    if (byte > 0x5f) {\n      pacIndex = byte - 0x60;\n    } else {\n      pacIndex = byte - 0x40;\n    }\n    pacData.underline = (pacIndex & 1) === 1;\n    if (pacIndex <= 0xd) {\n      pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];\n    } else if (pacIndex <= 0xf) {\n      pacData.italics = true;\n      pacData.color = 'white';\n    } else {\n      pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;\n    }\n    return pacData; // Note that row has zero offset. The spec uses 1.\n  }\n\n  /**\n   * Parse characters.\n   * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.\n   */\n  parseChars(a, b) {\n    let channelNr;\n    let charCodes = null;\n    let charCode1 = null;\n    if (a >= 0x19) {\n      channelNr = 2;\n      charCode1 = a - 8;\n    } else {\n      channelNr = 1;\n      charCode1 = a;\n    }\n    if (charCode1 >= 0x11 && charCode1 <= 0x13) {\n      // Special character\n      let oneCode;\n      if (charCode1 === 0x11) {\n        oneCode = b + 0x50;\n      } else if (charCode1 === 0x12) {\n        oneCode = b + 0x70;\n      } else {\n        oneCode = b + 0x90;\n      }\n      this.logger.log(2, () => \"Special char '\" + getCharForByte(oneCode) + \"' in channel \" + channelNr);\n      charCodes = [oneCode];\n    } else if (a >= 0x20 && a <= 0x7f) {\n      charCodes = b === 0 ? [a] : [a, b];\n    }\n    if (charCodes) {\n      this.logger.log(3, () => 'Char codes =  ' + numArrayToHexArray(charCodes).join(','));\n    }\n    return charCodes;\n  }\n\n  /**\n   * Parse extended background attributes as well as new foreground color black.\n   * @returns True if background attributes are found\n   */\n  parseBackgroundAttributes(a, b) {\n    const case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;\n    const case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;\n    if (!(case1 || case2)) {\n      return false;\n    }\n    let index;\n    const bkgData = {};\n    if (a === 0x10 || a === 0x18) {\n      index = Math.floor((b - 0x20) / 2);\n      bkgData.background = backgroundColors[index];\n      if (b % 2 === 1) {\n        bkgData.background = bkgData.background + '_semi';\n      }\n    } else if (b === 0x2d) {\n      bkgData.background = 'transparent';\n    } else {\n      bkgData.foreground = 'black';\n      if (b === 0x2f) {\n        bkgData.underline = true;\n      }\n    }\n    const chNr = a <= 0x17 ? 1 : 2;\n    const channel = this.channels[chNr];\n    channel.setBkgData(bkgData);\n    return true;\n  }\n\n  /**\n   * Reset state of parser and its channels.\n   */\n  reset() {\n    for (let i = 0; i < Object.keys(this.channels).length; i++) {\n      const channel = this.channels[i];\n      if (channel) {\n        channel.reset();\n      }\n    }\n    setLastCmd(null, null, this.cmdHistory);\n  }\n\n  /**\n   * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.\n   */\n  cueSplitAtTime(t) {\n    for (let i = 0; i < this.channels.length; i++) {\n      const channel = this.channels[i];\n      if (channel) {\n        channel.cueSplitAtTime(t);\n      }\n    }\n  }\n}\nfunction setLastCmd(a, b, cmdHistory) {\n  cmdHistory.a = a;\n  cmdHistory.b = b;\n}\nfunction hasCmdRepeated(a, b, cmdHistory) {\n  return cmdHistory.a === a && cmdHistory.b === b;\n}\nfunction createCmdHistory() {\n  return {\n    a: null,\n    b: null\n  };\n}\n\nclass OutputFilter {\n  constructor(timelineController, trackName) {\n    this.timelineController = void 0;\n    this.cueRanges = [];\n    this.trackName = void 0;\n    this.startTime = null;\n    this.endTime = null;\n    this.screen = null;\n    this.timelineController = timelineController;\n    this.trackName = trackName;\n  }\n  dispatchCue() {\n    if (this.startTime === null) {\n      return;\n    }\n    this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);\n    this.startTime = null;\n  }\n  newCue(startTime, endTime, screen) {\n    if (this.startTime === null || this.startTime > startTime) {\n      this.startTime = startTime;\n    }\n    this.endTime = endTime;\n    this.screen = screen;\n    this.timelineController.createCaptionsTrack(this.trackName);\n  }\n  reset() {\n    this.cueRanges = [];\n    this.startTime = null;\n  }\n}\n\n/**\n * Copyright 2013 vtt.js Contributors\n *\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nvar VTTCue = (function () {\n  if (optionalSelf != null && optionalSelf.VTTCue) {\n    return self.VTTCue;\n  }\n  const AllowedDirections = ['', 'lr', 'rl'];\n  const AllowedAlignments = ['start', 'middle', 'end', 'left', 'right'];\n  function isAllowedValue(allowed, value) {\n    if (typeof value !== 'string') {\n      return false;\n    }\n    // necessary for assuring the generic conforms to the Array interface\n    if (!Array.isArray(allowed)) {\n      return false;\n    }\n    // reset the type so that the next narrowing works well\n    const lcValue = value.toLowerCase();\n    // use the allow list to narrow the type to a specific subset of strings\n    if (~allowed.indexOf(lcValue)) {\n      return lcValue;\n    }\n    return false;\n  }\n  function findDirectionSetting(value) {\n    return isAllowedValue(AllowedDirections, value);\n  }\n  function findAlignSetting(value) {\n    return isAllowedValue(AllowedAlignments, value);\n  }\n  function extend(obj, ...rest) {\n    let i = 1;\n    for (; i < arguments.length; i++) {\n      const cobj = arguments[i];\n      for (const p in cobj) {\n        obj[p] = cobj[p];\n      }\n    }\n    return obj;\n  }\n  function VTTCue(startTime, endTime, text) {\n    const cue = this;\n    const baseObj = {\n      enumerable: true\n    };\n    /**\n     * Shim implementation specific properties. These properties are not in\n     * the spec.\n     */\n\n    // Lets us know when the VTTCue's data has changed in such a way that we need\n    // to recompute its display state. This lets us compute its display state\n    // lazily.\n    cue.hasBeenReset = false;\n\n    /**\n     * VTTCue and TextTrackCue properties\n     * http://dev.w3.org/html5/webvtt/#vttcue-interface\n     */\n\n    let _id = '';\n    let _pauseOnExit = false;\n    let _startTime = startTime;\n    let _endTime = endTime;\n    let _text = text;\n    let _region = null;\n    let _vertical = '';\n    let _snapToLines = true;\n    let _line = 'auto';\n    let _lineAlign = 'start';\n    let _position = 50;\n    let _positionAlign = 'middle';\n    let _size = 50;\n    let _align = 'middle';\n    Object.defineProperty(cue, 'id', extend({}, baseObj, {\n      get: function () {\n        return _id;\n      },\n      set: function (value) {\n        _id = '' + value;\n      }\n    }));\n    Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {\n      get: function () {\n        return _pauseOnExit;\n      },\n      set: function (value) {\n        _pauseOnExit = !!value;\n      }\n    }));\n    Object.defineProperty(cue, 'startTime', extend({}, baseObj, {\n      get: function () {\n        return _startTime;\n      },\n      set: function (value) {\n        if (typeof value !== 'number') {\n          throw new TypeError('Start time must be set to a number.');\n        }\n        _startTime = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'endTime', extend({}, baseObj, {\n      get: function () {\n        return _endTime;\n      },\n      set: function (value) {\n        if (typeof value !== 'number') {\n          throw new TypeError('End time must be set to a number.');\n        }\n        _endTime = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'text', extend({}, baseObj, {\n      get: function () {\n        return _text;\n      },\n      set: function (value) {\n        _text = '' + value;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    // todo: implement VTTRegion polyfill?\n    Object.defineProperty(cue, 'region', extend({}, baseObj, {\n      get: function () {\n        return _region;\n      },\n      set: function (value) {\n        _region = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'vertical', extend({}, baseObj, {\n      get: function () {\n        return _vertical;\n      },\n      set: function (value) {\n        const setting = findDirectionSetting(value);\n        // Have to check for false because the setting an be an empty string.\n        if (setting === false) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _vertical = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {\n      get: function () {\n        return _snapToLines;\n      },\n      set: function (value) {\n        _snapToLines = !!value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'line', extend({}, baseObj, {\n      get: function () {\n        return _line;\n      },\n      set: function (value) {\n        if (typeof value !== 'number' && value !== 'auto') {\n          throw new SyntaxError('An invalid number or illegal string was specified.');\n        }\n        _line = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {\n      get: function () {\n        return _lineAlign;\n      },\n      set: function (value) {\n        const setting = findAlignSetting(value);\n        if (!setting) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _lineAlign = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'position', extend({}, baseObj, {\n      get: function () {\n        return _position;\n      },\n      set: function (value) {\n        if (value < 0 || value > 100) {\n          throw new Error('Position must be between 0 and 100.');\n        }\n        _position = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {\n      get: function () {\n        return _positionAlign;\n      },\n      set: function (value) {\n        const setting = findAlignSetting(value);\n        if (!setting) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _positionAlign = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'size', extend({}, baseObj, {\n      get: function () {\n        return _size;\n      },\n      set: function (value) {\n        if (value < 0 || value > 100) {\n          throw new Error('Size must be between 0 and 100.');\n        }\n        _size = value;\n        this.hasBeenReset = true;\n      }\n    }));\n    Object.defineProperty(cue, 'align', extend({}, baseObj, {\n      get: function () {\n        return _align;\n      },\n      set: function (value) {\n        const setting = findAlignSetting(value);\n        if (!setting) {\n          throw new SyntaxError('An invalid or illegal string was specified.');\n        }\n        _align = setting;\n        this.hasBeenReset = true;\n      }\n    }));\n\n    /**\n     * Other <track> spec defined properties\n     */\n\n    // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state\n    cue.displayState = undefined;\n  }\n\n  /**\n   * VTTCue methods\n   */\n\n  VTTCue.prototype.getCueAsHTML = function () {\n    // Assume WebVTT.convertCueToDOMTree is on the global.\n    const WebVTT = self.WebVTT;\n    return WebVTT.convertCueToDOMTree(self, this.text);\n  };\n  // this is a polyfill hack\n  return VTTCue;\n})();\n\n/*\n * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js\n */\n\nclass StringDecoder {\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  decode(data, options) {\n    if (!data) {\n      return '';\n    }\n    if (typeof data !== 'string') {\n      throw new Error('Error - expected string data.');\n    }\n    return decodeURIComponent(encodeURIComponent(data));\n  }\n}\n\n// Try to parse input as a time stamp.\nfunction parseTimeStamp(input) {\n  function computeSeconds(h, m, s, f) {\n    return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + parseFloat(f || 0);\n  }\n  const m = input.match(/^(?:(\\d+):)?(\\d{2}):(\\d{2})(\\.\\d+)?/);\n  if (!m) {\n    return null;\n  }\n  if (parseFloat(m[2]) > 59) {\n    // Timestamp takes the form of [hours]:[minutes].[milliseconds]\n    // First position is hours as it's over 59.\n    return computeSeconds(m[2], m[3], 0, m[4]);\n  }\n  // Timestamp takes the form of [hours (optional)]:[minutes]:[seconds].[milliseconds]\n  return computeSeconds(m[1], m[2], m[3], m[4]);\n}\n\n// A settings object holds key/value pairs and will ignore anything but the first\n// assignment to a specific key.\nclass Settings {\n  constructor() {\n    this.values = Object.create(null);\n  }\n  // Only accept the first assignment to any key.\n  set(k, v) {\n    if (!this.get(k) && v !== '') {\n      this.values[k] = v;\n    }\n  }\n  // Return the value for a key, or a default value.\n  // If 'defaultKey' is passed then 'dflt' is assumed to be an object with\n  // a number of possible default values as properties where 'defaultKey' is\n  // the key of the property that will be chosen; otherwise it's assumed to be\n  // a single value.\n  get(k, dflt, defaultKey) {\n    if (defaultKey) {\n      return this.has(k) ? this.values[k] : dflt[defaultKey];\n    }\n    return this.has(k) ? this.values[k] : dflt;\n  }\n  // Check whether we have a value for a key.\n  has(k) {\n    return k in this.values;\n  }\n  // Accept a setting if its one of the given alternatives.\n  alt(k, v, a) {\n    for (let n = 0; n < a.length; ++n) {\n      if (v === a[n]) {\n        this.set(k, v);\n        break;\n      }\n    }\n  }\n  // Accept a setting if its a valid (signed) integer.\n  integer(k, v) {\n    if (/^-?\\d+$/.test(v)) {\n      // integer\n      this.set(k, parseInt(v, 10));\n    }\n  }\n  // Accept a setting if its a valid percentage.\n  percent(k, v) {\n    if (/^([\\d]{1,3})(\\.[\\d]*)?%$/.test(v)) {\n      const percent = parseFloat(v);\n      if (percent >= 0 && percent <= 100) {\n        this.set(k, percent);\n        return true;\n      }\n    }\n    return false;\n  }\n}\n\n// Helper function to parse input into groups separated by 'groupDelim', and\n// interpret each group as a key/value pair separated by 'keyValueDelim'.\nfunction parseOptions(input, callback, keyValueDelim, groupDelim) {\n  const groups = groupDelim ? input.split(groupDelim) : [input];\n  for (const i in groups) {\n    if (typeof groups[i] !== 'string') {\n      continue;\n    }\n    const kv = groups[i].split(keyValueDelim);\n    if (kv.length !== 2) {\n      continue;\n    }\n    const k = kv[0];\n    const v = kv[1];\n    callback(k, v);\n  }\n}\nconst defaults = new VTTCue(0, 0, '');\n// 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244\n//  Safari doesn't yet support this change, but FF and Chrome do.\nconst center = defaults.align === 'middle' ? 'middle' : 'center';\nfunction parseCue(input, cue, regionList) {\n  // Remember the original input if we need to throw an error.\n  const oInput = input;\n  // 4.1 WebVTT timestamp\n  function consumeTimeStamp() {\n    const ts = parseTimeStamp(input);\n    if (ts === null) {\n      throw new Error('Malformed timestamp: ' + oInput);\n    }\n\n    // Remove time stamp from input.\n    input = input.replace(/^[^\\sa-zA-Z-]+/, '');\n    return ts;\n  }\n\n  // 4.4.2 WebVTT cue settings\n  function consumeCueSettings(input, cue) {\n    const settings = new Settings();\n    parseOptions(input, function (k, v) {\n      let vals;\n      switch (k) {\n        case 'region':\n          // Find the last region we parsed with the same region id.\n          for (let i = regionList.length - 1; i >= 0; i--) {\n            if (regionList[i].id === v) {\n              settings.set(k, regionList[i].region);\n              break;\n            }\n          }\n          break;\n        case 'vertical':\n          settings.alt(k, v, ['rl', 'lr']);\n          break;\n        case 'line':\n          vals = v.split(',');\n          settings.integer(k, vals[0]);\n          if (settings.percent(k, vals[0])) {\n            settings.set('snapToLines', false);\n          }\n          settings.alt(k, vals[0], ['auto']);\n          if (vals.length === 2) {\n            settings.alt('lineAlign', vals[1], ['start', center, 'end']);\n          }\n          break;\n        case 'position':\n          vals = v.split(',');\n          settings.percent(k, vals[0]);\n          if (vals.length === 2) {\n            settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);\n          }\n          break;\n        case 'size':\n          settings.percent(k, v);\n          break;\n        case 'align':\n          settings.alt(k, v, ['start', center, 'end', 'left', 'right']);\n          break;\n      }\n    }, /:/, /\\s/);\n\n    // Apply default values for any missing fields.\n    cue.region = settings.get('region', null);\n    cue.vertical = settings.get('vertical', '');\n    let line = settings.get('line', 'auto');\n    if (line === 'auto' && defaults.line === -1) {\n      // set numeric line number for Safari\n      line = -1;\n    }\n    cue.line = line;\n    cue.lineAlign = settings.get('lineAlign', 'start');\n    cue.snapToLines = settings.get('snapToLines', true);\n    cue.size = settings.get('size', 100);\n    cue.align = settings.get('align', center);\n    let position = settings.get('position', 'auto');\n    if (position === 'auto' && defaults.position === 50) {\n      // set numeric position for Safari\n      position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;\n    }\n    cue.position = position;\n  }\n  function skipWhitespace() {\n    input = input.replace(/^\\s+/, '');\n  }\n\n  // 4.1 WebVTT cue timings.\n  skipWhitespace();\n  cue.startTime = consumeTimeStamp(); // (1) collect cue start time\n  skipWhitespace();\n  if (input.slice(0, 3) !== '-->') {\n    // (3) next characters must match '-->'\n    throw new Error(\"Malformed time stamp (time stamps must be separated by '-->'): \" + oInput);\n  }\n  input = input.slice(3);\n  skipWhitespace();\n  cue.endTime = consumeTimeStamp(); // (5) collect cue end time\n\n  // 4.1 WebVTT cue settings list.\n  skipWhitespace();\n  consumeCueSettings(input, cue);\n}\nfunction fixLineBreaks(input) {\n  return input.replace(/<br(?: \\/)?>/gi, '\\n');\n}\nclass VTTParser {\n  constructor() {\n    this.state = 'INITIAL';\n    this.buffer = '';\n    this.decoder = new StringDecoder();\n    this.regionList = [];\n    this.cue = null;\n    this.oncue = void 0;\n    this.onparsingerror = void 0;\n    this.onflush = void 0;\n  }\n  parse(data) {\n    const _this = this;\n\n    // If there is no data then we won't decode it, but will just try to parse\n    // whatever is in buffer already. This may occur in circumstances, for\n    // example when flush() is called.\n    if (data) {\n      // Try to decode the data that we received.\n      _this.buffer += _this.decoder.decode(data, {\n        stream: true\n      });\n    }\n    function collectNextLine() {\n      let buffer = _this.buffer;\n      let pos = 0;\n      buffer = fixLineBreaks(buffer);\n      while (pos < buffer.length && buffer[pos] !== '\\r' && buffer[pos] !== '\\n') {\n        ++pos;\n      }\n      const line = buffer.slice(0, pos);\n      // Advance the buffer early in case we fail below.\n      if (buffer[pos] === '\\r') {\n        ++pos;\n      }\n      if (buffer[pos] === '\\n') {\n        ++pos;\n      }\n      _this.buffer = buffer.slice(pos);\n      return line;\n    }\n\n    // 3.2 WebVTT metadata header syntax\n    function parseHeader(input) {\n      parseOptions(input, function (k, v) {\n        // switch (k) {\n        // case 'region':\n        // 3.3 WebVTT region metadata header syntax\n        // console.log('parse region', v);\n        // parseRegion(v);\n        // break;\n        // }\n      }, /:/);\n    }\n\n    // 5.1 WebVTT file parsing.\n    try {\n      let line = '';\n      if (_this.state === 'INITIAL') {\n        // We can't start parsing until we have the first line.\n        if (!/\\r\\n|\\n/.test(_this.buffer)) {\n          return this;\n        }\n        line = collectNextLine();\n        // strip of UTF-8 BOM if any\n        // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8\n        const m = line.match(/^()?WEBVTT([ \\t].*)?$/);\n        if (!(m != null && m[0])) {\n          throw new Error('Malformed WebVTT signature.');\n        }\n        _this.state = 'HEADER';\n      }\n      let alreadyCollectedLine = false;\n      while (_this.buffer) {\n        // We can't parse a line until we have the full line.\n        if (!/\\r\\n|\\n/.test(_this.buffer)) {\n          return this;\n        }\n        if (!alreadyCollectedLine) {\n          line = collectNextLine();\n        } else {\n          alreadyCollectedLine = false;\n        }\n        switch (_this.state) {\n          case 'HEADER':\n            // 13-18 - Allow a header (metadata) under the WEBVTT line.\n            if (/:/.test(line)) {\n              parseHeader(line);\n            } else if (!line) {\n              // An empty line terminates the header and starts the body (cues).\n              _this.state = 'ID';\n            }\n            continue;\n          case 'NOTE':\n            // Ignore NOTE blocks.\n            if (!line) {\n              _this.state = 'ID';\n            }\n            continue;\n          case 'ID':\n            // Check for the start of NOTE blocks.\n            if (/^NOTE($|[ \\t])/.test(line)) {\n              _this.state = 'NOTE';\n              break;\n            }\n            // 19-29 - Allow any number of line terminators, then initialize new cue values.\n            if (!line) {\n              continue;\n            }\n            _this.cue = new VTTCue(0, 0, '');\n            _this.state = 'CUE';\n            // 30-39 - Check if self line contains an optional identifier or timing data.\n            if (line.indexOf('-->') === -1) {\n              _this.cue.id = line;\n              continue;\n            }\n          // Process line as start of a cue.\n          /* falls through */\n          case 'CUE':\n            // 40 - Collect cue timings and settings.\n            if (!_this.cue) {\n              _this.state = 'BADCUE';\n              continue;\n            }\n            try {\n              parseCue(line, _this.cue, _this.regionList);\n            } catch (e) {\n              // In case of an error ignore rest of the cue.\n              _this.cue = null;\n              _this.state = 'BADCUE';\n              continue;\n            }\n            _this.state = 'CUETEXT';\n            continue;\n          case 'CUETEXT':\n            {\n              const hasSubstring = line.indexOf('-->') !== -1;\n              // 34 - If we have an empty line then report the cue.\n              // 35 - If we have the special substring '-->' then report the cue,\n              // but do not collect the line as we need to process the current\n              // one as a new cue.\n              if (!line || hasSubstring && (alreadyCollectedLine = true)) {\n                // We are done parsing self cue.\n                if (_this.oncue && _this.cue) {\n                  _this.oncue(_this.cue);\n                }\n                _this.cue = null;\n                _this.state = 'ID';\n                continue;\n              }\n              if (_this.cue === null) {\n                continue;\n              }\n              if (_this.cue.text) {\n                _this.cue.text += '\\n';\n              }\n              _this.cue.text += line;\n            }\n            continue;\n          case 'BADCUE':\n            // 54-62 - Collect and discard the remaining cue.\n            if (!line) {\n              _this.state = 'ID';\n            }\n        }\n      }\n    } catch (e) {\n      // If we are currently parsing a cue, report what we have.\n      if (_this.state === 'CUETEXT' && _this.cue && _this.oncue) {\n        _this.oncue(_this.cue);\n      }\n      _this.cue = null;\n      // Enter BADWEBVTT state if header was not parsed correctly otherwise\n      // another exception occurred so enter BADCUE state.\n      _this.state = _this.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';\n    }\n    return this;\n  }\n  flush() {\n    const _this = this;\n    try {\n      // Finish decoding the stream.\n      // _this.buffer += _this.decoder.decode();\n      // Synthesize the end of the current cue or region.\n      if (_this.cue || _this.state === 'HEADER') {\n        _this.buffer += '\\n\\n';\n        _this.parse();\n      }\n      // If we've flushed, parsed, and we're still on the INITIAL state then\n      // that means we don't have enough of the stream to parse the first\n      // line.\n      if (_this.state === 'INITIAL' || _this.state === 'BADWEBVTT') {\n        throw new Error('Malformed WebVTT signature.');\n      }\n    } catch (e) {\n      if (_this.onparsingerror) {\n        _this.onparsingerror(e);\n      }\n    }\n    if (_this.onflush) {\n      _this.onflush();\n    }\n    return this;\n  }\n}\n\nconst LINEBREAKS = /\\r\\n|\\n\\r|\\n|\\r/g;\n\n// String.prototype.startsWith is not supported in IE11\nconst startsWith = function startsWith(inputString, searchString, position = 0) {\n  return inputString.slice(position, position + searchString.length) === searchString;\n};\nconst cueString2millis = function cueString2millis(timeString) {\n  let ts = parseInt(timeString.slice(-3));\n  const secs = parseInt(timeString.slice(-6, -4));\n  const mins = parseInt(timeString.slice(-9, -7));\n  const hours = timeString.length > 9 ? parseInt(timeString.substring(0, timeString.indexOf(':'))) : 0;\n  if (!isFiniteNumber(ts) || !isFiniteNumber(secs) || !isFiniteNumber(mins) || !isFiniteNumber(hours)) {\n    throw Error(`Malformed X-TIMESTAMP-MAP: Local:${timeString}`);\n  }\n  ts += 1000 * secs;\n  ts += 60 * 1000 * mins;\n  ts += 60 * 60 * 1000 * hours;\n  return ts;\n};\n\n// From https://github.com/darkskyapp/string-hash\nconst hash = function hash(text) {\n  let _hash = 5381;\n  let i = text.length;\n  while (i) {\n    _hash = _hash * 33 ^ text.charCodeAt(--i);\n  }\n  return (_hash >>> 0).toString();\n};\n\n// Create a unique hash id for a cue based on start/end times and text.\n// This helps timeline-controller to avoid showing repeated captions.\nfunction generateCueId(startTime, endTime, text) {\n  return hash(startTime.toString()) + hash(endTime.toString()) + hash(text);\n}\nconst calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {\n  let currCC = vttCCs[cc];\n  let prevCC = vttCCs[currCC.prevCC];\n\n  // This is the first discontinuity or cues have been processed since the last discontinuity\n  // Offset = current discontinuity time\n  if (!prevCC || !prevCC.new && currCC.new) {\n    vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;\n    currCC.new = false;\n    return;\n  }\n\n  // There have been discontinuities since cues were last parsed.\n  // Offset = time elapsed\n  while ((_prevCC = prevCC) != null && _prevCC.new) {\n    var _prevCC;\n    vttCCs.ccOffset += currCC.start - prevCC.start;\n    currCC.new = false;\n    currCC = prevCC;\n    prevCC = vttCCs[currCC.prevCC];\n  }\n  vttCCs.presentationOffset = presentationTime;\n};\nfunction parseWebVTT(vttByteArray, initPTS, vttCCs, cc, timeOffset, callBack, errorCallBack) {\n  const parser = new VTTParser();\n  // Convert byteArray into string, replacing any somewhat exotic linefeeds with \"\\n\", then split on that character.\n  // Uint8Array.prototype.reduce is not implemented in IE11\n  const vttLines = utf8ArrayToStr(new Uint8Array(vttByteArray)).trim().replace(LINEBREAKS, '\\n').split('\\n');\n  const cues = [];\n  const init90kHz = initPTS ? toMpegTsClockFromTimescale(initPTS.baseTime, initPTS.timescale) : 0;\n  let cueTime = '00:00.000';\n  let timestampMapMPEGTS = 0;\n  let timestampMapLOCAL = 0;\n  let parsingError;\n  let inHeader = true;\n  parser.oncue = function (cue) {\n    // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.\n    const currCC = vttCCs[cc];\n    let cueOffset = vttCCs.ccOffset;\n\n    // Calculate subtitle PTS offset\n    const webVttMpegTsMapOffset = (timestampMapMPEGTS - init90kHz) / 90000;\n\n    // Update offsets for new discontinuities\n    if (currCC != null && currCC.new) {\n      if (timestampMapLOCAL !== undefined) {\n        // When local time is provided, offset = discontinuity start time - local time\n        cueOffset = vttCCs.ccOffset = currCC.start;\n      } else {\n        calculateOffset(vttCCs, cc, webVttMpegTsMapOffset);\n      }\n    }\n    if (webVttMpegTsMapOffset) {\n      if (!initPTS) {\n        parsingError = new Error('Missing initPTS for VTT MPEGTS');\n        return;\n      }\n      // If we have MPEGTS, offset = presentation time + discontinuity offset\n      cueOffset = webVttMpegTsMapOffset - vttCCs.presentationOffset;\n    }\n    const duration = cue.endTime - cue.startTime;\n    const startTime = normalizePts((cue.startTime + cueOffset - timestampMapLOCAL) * 90000, timeOffset * 90000) / 90000;\n    cue.startTime = Math.max(startTime, 0);\n    cue.endTime = Math.max(startTime + duration, 0);\n\n    //trim trailing webvtt block whitespaces\n    const text = cue.text.trim();\n\n    // Fix encoding of special characters\n    cue.text = decodeURIComponent(encodeURIComponent(text));\n\n    // If the cue was not assigned an id from the VTT file (line above the content), create one.\n    if (!cue.id) {\n      cue.id = generateCueId(cue.startTime, cue.endTime, text);\n    }\n    if (cue.endTime > 0) {\n      cues.push(cue);\n    }\n  };\n  parser.onparsingerror = function (error) {\n    parsingError = error;\n  };\n  parser.onflush = function () {\n    if (parsingError) {\n      errorCallBack(parsingError);\n      return;\n    }\n    callBack(cues);\n  };\n\n  // Go through contents line by line.\n  vttLines.forEach(line => {\n    if (inHeader) {\n      // Look for X-TIMESTAMP-MAP in header.\n      if (startsWith(line, 'X-TIMESTAMP-MAP=')) {\n        // Once found, no more are allowed anyway, so stop searching.\n        inHeader = false;\n        // Extract LOCAL and MPEGTS.\n        line.slice(16).split(',').forEach(timestamp => {\n          if (startsWith(timestamp, 'LOCAL:')) {\n            cueTime = timestamp.slice(6);\n          } else if (startsWith(timestamp, 'MPEGTS:')) {\n            timestampMapMPEGTS = parseInt(timestamp.slice(7));\n          }\n        });\n        try {\n          // Convert cue time to seconds\n          timestampMapLOCAL = cueString2millis(cueTime) / 1000;\n        } catch (error) {\n          parsingError = error;\n        }\n        // Return without parsing X-TIMESTAMP-MAP line.\n        return;\n      } else if (line === '') {\n        inHeader = false;\n      }\n    }\n    // Parse line by default.\n    parser.parse(line + '\\n');\n  });\n  parser.flush();\n}\n\nconst IMSC1_CODEC = 'stpp.ttml.im1t';\n\n// Time format: h:m:s:frames(.subframes)\nconst HMSF_REGEX = /^(\\d{2,}):(\\d{2}):(\\d{2}):(\\d{2})\\.?(\\d+)?$/;\n\n// Time format: hours, minutes, seconds, milliseconds, frames, ticks\nconst TIME_UNIT_REGEX = /^(\\d*(?:\\.\\d*)?)(h|m|s|ms|f|t)$/;\nconst textAlignToLineAlign = {\n  left: 'start',\n  center: 'center',\n  right: 'end',\n  start: 'start',\n  end: 'end'\n};\nfunction parseIMSC1(payload, initPTS, callBack, errorCallBack) {\n  const results = findBox(new Uint8Array(payload), ['mdat']);\n  if (results.length === 0) {\n    errorCallBack(new Error('Could not parse IMSC1 mdat'));\n    return;\n  }\n  const ttmlList = results.map(mdat => utf8ArrayToStr(mdat));\n  const syncTime = toTimescaleFromScale(initPTS.baseTime, 1, initPTS.timescale);\n  try {\n    ttmlList.forEach(ttml => callBack(parseTTML(ttml, syncTime)));\n  } catch (error) {\n    errorCallBack(error);\n  }\n}\nfunction parseTTML(ttml, syncTime) {\n  const parser = new DOMParser();\n  const xmlDoc = parser.parseFromString(ttml, 'text/xml');\n  const tt = xmlDoc.getElementsByTagName('tt')[0];\n  if (!tt) {\n    throw new Error('Invalid ttml');\n  }\n  const defaultRateInfo = {\n    frameRate: 30,\n    subFrameRate: 1,\n    frameRateMultiplier: 0,\n    tickRate: 0\n  };\n  const rateInfo = Object.keys(defaultRateInfo).reduce((result, key) => {\n    result[key] = tt.getAttribute(`ttp:${key}`) || defaultRateInfo[key];\n    return result;\n  }, {});\n  const trim = tt.getAttribute('xml:space') !== 'preserve';\n  const styleElements = collectionToDictionary(getElementCollection(tt, 'styling', 'style'));\n  const regionElements = collectionToDictionary(getElementCollection(tt, 'layout', 'region'));\n  const cueElements = getElementCollection(tt, 'body', '[begin]');\n  return [].map.call(cueElements, cueElement => {\n    const cueText = getTextContent(cueElement, trim);\n    if (!cueText || !cueElement.hasAttribute('begin')) {\n      return null;\n    }\n    const startTime = parseTtmlTime(cueElement.getAttribute('begin'), rateInfo);\n    const duration = parseTtmlTime(cueElement.getAttribute('dur'), rateInfo);\n    let endTime = parseTtmlTime(cueElement.getAttribute('end'), rateInfo);\n    if (startTime === null) {\n      throw timestampParsingError(cueElement);\n    }\n    if (endTime === null) {\n      if (duration === null) {\n        throw timestampParsingError(cueElement);\n      }\n      endTime = startTime + duration;\n    }\n    const cue = new VTTCue(startTime - syncTime, endTime - syncTime, cueText);\n    cue.id = generateCueId(cue.startTime, cue.endTime, cue.text);\n    const region = regionElements[cueElement.getAttribute('region')];\n    const style = styleElements[cueElement.getAttribute('style')];\n\n    // Apply styles to cue\n    const styles = getTtmlStyles(region, style, styleElements);\n    const {\n      textAlign\n    } = styles;\n    if (textAlign) {\n      // cue.positionAlign not settable in FF~2016\n      const lineAlign = textAlignToLineAlign[textAlign];\n      if (lineAlign) {\n        cue.lineAlign = lineAlign;\n      }\n      cue.align = textAlign;\n    }\n    _extends(cue, styles);\n    return cue;\n  }).filter(cue => cue !== null);\n}\nfunction getElementCollection(fromElement, parentName, childName) {\n  const parent = fromElement.getElementsByTagName(parentName)[0];\n  if (parent) {\n    return [].slice.call(parent.querySelectorAll(childName));\n  }\n  return [];\n}\nfunction collectionToDictionary(elementsWithId) {\n  return elementsWithId.reduce((dict, element) => {\n    const id = element.getAttribute('xml:id');\n    if (id) {\n      dict[id] = element;\n    }\n    return dict;\n  }, {});\n}\nfunction getTextContent(element, trim) {\n  return [].slice.call(element.childNodes).reduce((str, node, i) => {\n    var _node$childNodes;\n    if (node.nodeName === 'br' && i) {\n      return str + '\\n';\n    }\n    if ((_node$childNodes = node.childNodes) != null && _node$childNodes.length) {\n      return getTextContent(node, trim);\n    } else if (trim) {\n      return str + node.textContent.trim().replace(/\\s+/g, ' ');\n    }\n    return str + node.textContent;\n  }, '');\n}\nfunction getTtmlStyles(region, style, styleElements) {\n  const ttsNs = 'http://www.w3.org/ns/ttml#styling';\n  let regionStyle = null;\n  const styleAttributes = ['displayAlign', 'textAlign', 'color', 'backgroundColor', 'fontSize', 'fontFamily'\n  // 'fontWeight',\n  // 'lineHeight',\n  // 'wrapOption',\n  // 'fontStyle',\n  // 'direction',\n  // 'writingMode'\n  ];\n  const regionStyleName = region != null && region.hasAttribute('style') ? region.getAttribute('style') : null;\n  if (regionStyleName && styleElements.hasOwnProperty(regionStyleName)) {\n    regionStyle = styleElements[regionStyleName];\n  }\n  return styleAttributes.reduce((styles, name) => {\n    const value = getAttributeNS(style, ttsNs, name) || getAttributeNS(region, ttsNs, name) || getAttributeNS(regionStyle, ttsNs, name);\n    if (value) {\n      styles[name] = value;\n    }\n    return styles;\n  }, {});\n}\nfunction getAttributeNS(element, ns, name) {\n  if (!element) {\n    return null;\n  }\n  return element.hasAttributeNS(ns, name) ? element.getAttributeNS(ns, name) : null;\n}\nfunction timestampParsingError(node) {\n  return new Error(`Could not parse ttml timestamp ${node}`);\n}\nfunction parseTtmlTime(timeAttributeValue, rateInfo) {\n  if (!timeAttributeValue) {\n    return null;\n  }\n  let seconds = parseTimeStamp(timeAttributeValue);\n  if (seconds === null) {\n    if (HMSF_REGEX.test(timeAttributeValue)) {\n      seconds = parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo);\n    } else if (TIME_UNIT_REGEX.test(timeAttributeValue)) {\n      seconds = parseTimeUnits(timeAttributeValue, rateInfo);\n    }\n  }\n  return seconds;\n}\nfunction parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo) {\n  const m = HMSF_REGEX.exec(timeAttributeValue);\n  const frames = (m[4] | 0) + (m[5] | 0) / rateInfo.subFrameRate;\n  return (m[1] | 0) * 3600 + (m[2] | 0) * 60 + (m[3] | 0) + frames / rateInfo.frameRate;\n}\nfunction parseTimeUnits(timeAttributeValue, rateInfo) {\n  const m = TIME_UNIT_REGEX.exec(timeAttributeValue);\n  const value = Number(m[1]);\n  const unit = m[2];\n  switch (unit) {\n    case 'h':\n      return value * 3600;\n    case 'm':\n      return value * 60;\n    case 'ms':\n      return value * 1000;\n    case 'f':\n      return value / rateInfo.frameRate;\n    case 't':\n      return value / rateInfo.tickRate;\n  }\n  return value;\n}\n\nclass TimelineController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.media = null;\n    this.config = void 0;\n    this.enabled = true;\n    this.Cues = void 0;\n    this.textTracks = [];\n    this.tracks = [];\n    this.initPTS = [];\n    this.unparsedVttFrags = [];\n    this.captionsTracks = {};\n    this.nonNativeCaptionsTracks = {};\n    this.cea608Parser1 = void 0;\n    this.cea608Parser2 = void 0;\n    this.lastCc = -1;\n    // Last video (CEA-608) fragment CC\n    this.lastSn = -1;\n    // Last video (CEA-608) fragment MSN\n    this.lastPartIndex = -1;\n    // Last video (CEA-608) fragment Part Index\n    this.prevCC = -1;\n    // Last subtitle fragment CC\n    this.vttCCs = newVTTCCs();\n    this.captionsProperties = void 0;\n    this.hls = hls;\n    this.config = hls.config;\n    this.Cues = hls.config.cueHandler;\n    this.captionsProperties = {\n      textTrack1: {\n        label: this.config.captionsTextTrack1Label,\n        languageCode: this.config.captionsTextTrack1LanguageCode\n      },\n      textTrack2: {\n        label: this.config.captionsTextTrack2Label,\n        languageCode: this.config.captionsTextTrack2LanguageCode\n      },\n      textTrack3: {\n        label: this.config.captionsTextTrack3Label,\n        languageCode: this.config.captionsTextTrack3LanguageCode\n      },\n      textTrack4: {\n        label: this.config.captionsTextTrack4Label,\n        languageCode: this.config.captionsTextTrack4LanguageCode\n      }\n    };\n    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.on(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);\n    hls.on(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);\n    hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.on(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);\n    hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n  }\n  destroy() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n    hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n    hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    hls.off(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);\n    hls.off(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);\n    hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n    hls.off(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);\n    hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    // @ts-ignore\n    this.hls = this.config = null;\n    this.cea608Parser1 = this.cea608Parser2 = undefined;\n  }\n  initCea608Parsers() {\n    if (this.config.enableCEA708Captions && (!this.cea608Parser1 || !this.cea608Parser2)) {\n      const channel1 = new OutputFilter(this, 'textTrack1');\n      const channel2 = new OutputFilter(this, 'textTrack2');\n      const channel3 = new OutputFilter(this, 'textTrack3');\n      const channel4 = new OutputFilter(this, 'textTrack4');\n      this.cea608Parser1 = new Cea608Parser(1, channel1, channel2);\n      this.cea608Parser2 = new Cea608Parser(3, channel3, channel4);\n    }\n  }\n  addCues(trackName, startTime, endTime, screen, cueRanges) {\n    // skip cues which overlap more than 50% with previously parsed time ranges\n    let merged = false;\n    for (let i = cueRanges.length; i--;) {\n      const cueRange = cueRanges[i];\n      const overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);\n      if (overlap >= 0) {\n        cueRange[0] = Math.min(cueRange[0], startTime);\n        cueRange[1] = Math.max(cueRange[1], endTime);\n        merged = true;\n        if (overlap / (endTime - startTime) > 0.5) {\n          return;\n        }\n      }\n    }\n    if (!merged) {\n      cueRanges.push([startTime, endTime]);\n    }\n    if (this.config.renderTextTracksNatively) {\n      const track = this.captionsTracks[trackName];\n      this.Cues.newCue(track, startTime, endTime, screen);\n    } else {\n      const cues = this.Cues.newCue(null, startTime, endTime, screen);\n      this.hls.trigger(Events.CUES_PARSED, {\n        type: 'captions',\n        cues,\n        track: trackName\n      });\n    }\n  }\n\n  // Triggered when an initial PTS is found; used for synchronisation of WebVTT.\n  onInitPtsFound(event, {\n    frag,\n    id,\n    initPTS,\n    timescale\n  }) {\n    const {\n      unparsedVttFrags\n    } = this;\n    if (id === 'main') {\n      this.initPTS[frag.cc] = {\n        baseTime: initPTS,\n        timescale\n      };\n    }\n\n    // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.\n    // Parse any unparsed fragments upon receiving the initial PTS.\n    if (unparsedVttFrags.length) {\n      this.unparsedVttFrags = [];\n      unparsedVttFrags.forEach(frag => {\n        this.onFragLoaded(Events.FRAG_LOADED, frag);\n      });\n    }\n  }\n  getExistingTrack(label, language) {\n    const {\n      media\n    } = this;\n    if (media) {\n      for (let i = 0; i < media.textTracks.length; i++) {\n        const textTrack = media.textTracks[i];\n        if (canReuseVttTextTrack(textTrack, {\n          name: label,\n          lang: language,\n          attrs: {}\n        })) {\n          return textTrack;\n        }\n      }\n    }\n    return null;\n  }\n  createCaptionsTrack(trackName) {\n    if (this.config.renderTextTracksNatively) {\n      this.createNativeTrack(trackName);\n    } else {\n      this.createNonNativeTrack(trackName);\n    }\n  }\n  createNativeTrack(trackName) {\n    if (this.captionsTracks[trackName]) {\n      return;\n    }\n    const {\n      captionsProperties,\n      captionsTracks,\n      media\n    } = this;\n    const {\n      label,\n      languageCode\n    } = captionsProperties[trackName];\n    // Enable reuse of existing text track.\n    const existingTrack = this.getExistingTrack(label, languageCode);\n    if (!existingTrack) {\n      const textTrack = this.createTextTrack('captions', label, languageCode);\n      if (textTrack) {\n        // Set a special property on the track so we know it's managed by Hls.js\n        textTrack[trackName] = true;\n        captionsTracks[trackName] = textTrack;\n      }\n    } else {\n      captionsTracks[trackName] = existingTrack;\n      clearCurrentCues(captionsTracks[trackName]);\n      sendAddTrackEvent(captionsTracks[trackName], media);\n    }\n  }\n  createNonNativeTrack(trackName) {\n    if (this.nonNativeCaptionsTracks[trackName]) {\n      return;\n    }\n    // Create a list of a single track for the provider to consume\n    const trackProperties = this.captionsProperties[trackName];\n    if (!trackProperties) {\n      return;\n    }\n    const label = trackProperties.label;\n    const track = {\n      _id: trackName,\n      label,\n      kind: 'captions',\n      default: trackProperties.media ? !!trackProperties.media.default : false,\n      closedCaptions: trackProperties.media\n    };\n    this.nonNativeCaptionsTracks[trackName] = track;\n    this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {\n      tracks: [track]\n    });\n  }\n  createTextTrack(kind, label, lang) {\n    const media = this.media;\n    if (!media) {\n      return;\n    }\n    return media.addTextTrack(kind, label, lang);\n  }\n  onMediaAttaching(event, data) {\n    this.media = data.media;\n    this._cleanTracks();\n  }\n  onMediaDetaching() {\n    const {\n      captionsTracks\n    } = this;\n    Object.keys(captionsTracks).forEach(trackName => {\n      clearCurrentCues(captionsTracks[trackName]);\n      delete captionsTracks[trackName];\n    });\n    this.nonNativeCaptionsTracks = {};\n  }\n  onManifestLoading() {\n    // Detect discontinuity in video fragment (CEA-608) parsing\n    this.lastCc = -1;\n    this.lastSn = -1;\n    this.lastPartIndex = -1;\n    // Detect discontinuity in subtitle manifests\n    this.prevCC = -1;\n    this.vttCCs = newVTTCCs();\n    // Reset tracks\n    this._cleanTracks();\n    this.tracks = [];\n    this.captionsTracks = {};\n    this.nonNativeCaptionsTracks = {};\n    this.textTracks = [];\n    this.unparsedVttFrags = [];\n    this.initPTS = [];\n    if (this.cea608Parser1 && this.cea608Parser2) {\n      this.cea608Parser1.reset();\n      this.cea608Parser2.reset();\n    }\n  }\n  _cleanTracks() {\n    // clear outdated subtitles\n    const {\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const textTracks = media.textTracks;\n    if (textTracks) {\n      for (let i = 0; i < textTracks.length; i++) {\n        clearCurrentCues(textTracks[i]);\n      }\n    }\n  }\n  onSubtitleTracksUpdated(event, data) {\n    const tracks = data.subtitleTracks || [];\n    const hasIMSC1 = tracks.some(track => track.textCodec === IMSC1_CODEC);\n    if (this.config.enableWebVTT || hasIMSC1 && this.config.enableIMSC1) {\n      const listIsIdentical = subtitleOptionsIdentical(this.tracks, tracks);\n      if (listIsIdentical) {\n        this.tracks = tracks;\n        return;\n      }\n      this.textTracks = [];\n      this.tracks = tracks;\n      if (this.config.renderTextTracksNatively) {\n        const media = this.media;\n        const inUseTracks = media ? filterSubtitleTracks(media.textTracks) : null;\n        this.tracks.forEach((track, index) => {\n          // Reuse tracks with the same label and lang, but do not reuse 608/708 tracks\n          let textTrack;\n          if (inUseTracks) {\n            let inUseTrack = null;\n            for (let i = 0; i < inUseTracks.length; i++) {\n              if (inUseTracks[i] && canReuseVttTextTrack(inUseTracks[i], track)) {\n                inUseTrack = inUseTracks[i];\n                inUseTracks[i] = null;\n                break;\n              }\n            }\n            if (inUseTrack) {\n              textTrack = inUseTrack;\n            }\n          }\n          if (textTrack) {\n            clearCurrentCues(textTrack);\n          } else {\n            const textTrackKind = captionsOrSubtitlesFromCharacteristics(track);\n            textTrack = this.createTextTrack(textTrackKind, track.name, track.lang);\n            if (textTrack) {\n              textTrack.mode = 'disabled';\n            }\n          }\n          if (textTrack) {\n            this.textTracks.push(textTrack);\n          }\n        });\n        // Warn when video element has captions or subtitle TextTracks carried over from another source\n        if (inUseTracks != null && inUseTracks.length) {\n          const unusedTextTracks = inUseTracks.filter(t => t !== null).map(t => t.label);\n          if (unusedTextTracks.length) {\n            logger.warn(`Media element contains unused subtitle tracks: ${unusedTextTracks.join(', ')}. Replace media element for each source to clear TextTracks and captions menu.`);\n          }\n        }\n      } else if (this.tracks.length) {\n        // Create a list of tracks for the provider to consume\n        const tracksList = this.tracks.map(track => {\n          return {\n            label: track.name,\n            kind: track.type.toLowerCase(),\n            default: track.default,\n            subtitleTrack: track\n          };\n        });\n        this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {\n          tracks: tracksList\n        });\n      }\n    }\n  }\n  onManifestLoaded(event, data) {\n    if (this.config.enableCEA708Captions && data.captions) {\n      data.captions.forEach(captionsTrack => {\n        const instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);\n        if (!instreamIdMatch) {\n          return;\n        }\n        const trackName = `textTrack${instreamIdMatch[1]}`;\n        const trackProperties = this.captionsProperties[trackName];\n        if (!trackProperties) {\n          return;\n        }\n        trackProperties.label = captionsTrack.name;\n        if (captionsTrack.lang) {\n          // optional attribute\n          trackProperties.languageCode = captionsTrack.lang;\n        }\n        trackProperties.media = captionsTrack;\n      });\n    }\n  }\n  closedCaptionsForLevel(frag) {\n    const level = this.hls.levels[frag.level];\n    return level == null ? void 0 : level.attrs['CLOSED-CAPTIONS'];\n  }\n  onFragLoading(event, data) {\n    // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack\n    if (this.enabled && data.frag.type === PlaylistLevelType.MAIN) {\n      var _data$part$index, _data$part;\n      const {\n        cea608Parser1,\n        cea608Parser2,\n        lastSn\n      } = this;\n      const {\n        cc,\n        sn\n      } = data.frag;\n      const partIndex = (_data$part$index = (_data$part = data.part) == null ? void 0 : _data$part.index) != null ? _data$part$index : -1;\n      if (cea608Parser1 && cea608Parser2) {\n        if (sn !== lastSn + 1 || sn === lastSn && partIndex !== this.lastPartIndex + 1 || cc !== this.lastCc) {\n          cea608Parser1.reset();\n          cea608Parser2.reset();\n        }\n      }\n      this.lastCc = cc;\n      this.lastSn = sn;\n      this.lastPartIndex = partIndex;\n    }\n  }\n  onFragLoaded(event, data) {\n    const {\n      frag,\n      payload\n    } = data;\n    if (frag.type === PlaylistLevelType.SUBTITLE) {\n      // If fragment is subtitle type, parse as WebVTT.\n      if (payload.byteLength) {\n        const decryptData = frag.decryptdata;\n        // fragment after decryption has a stats object\n        const decrypted = ('stats' in data);\n        // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.\n        if (decryptData == null || !decryptData.encrypted || decrypted) {\n          const trackPlaylistMedia = this.tracks[frag.level];\n          const vttCCs = this.vttCCs;\n          if (!vttCCs[frag.cc]) {\n            vttCCs[frag.cc] = {\n              start: frag.start,\n              prevCC: this.prevCC,\n              new: true\n            };\n            this.prevCC = frag.cc;\n          }\n          if (trackPlaylistMedia && trackPlaylistMedia.textCodec === IMSC1_CODEC) {\n            this._parseIMSC1(frag, payload);\n          } else {\n            this._parseVTTs(data);\n          }\n        }\n      } else {\n        // In case there is no payload, finish unsuccessfully.\n        this.hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n          success: false,\n          frag,\n          error: new Error('Empty subtitle payload')\n        });\n      }\n    }\n  }\n  _parseIMSC1(frag, payload) {\n    const hls = this.hls;\n    parseIMSC1(payload, this.initPTS[frag.cc], cues => {\n      this._appendCues(cues, frag.level);\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: true,\n        frag: frag\n      });\n    }, error => {\n      logger.log(`Failed to parse IMSC1: ${error}`);\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: false,\n        frag: frag,\n        error\n      });\n    });\n  }\n  _parseVTTs(data) {\n    var _frag$initSegment;\n    const {\n      frag,\n      payload\n    } = data;\n    // We need an initial synchronisation PTS. Store fragments as long as none has arrived\n    const {\n      initPTS,\n      unparsedVttFrags\n    } = this;\n    const maxAvCC = initPTS.length - 1;\n    if (!initPTS[frag.cc] && maxAvCC === -1) {\n      unparsedVttFrags.push(data);\n      return;\n    }\n    const hls = this.hls;\n    // Parse the WebVTT file contents.\n    const payloadWebVTT = (_frag$initSegment = frag.initSegment) != null && _frag$initSegment.data ? appendUint8Array(frag.initSegment.data, new Uint8Array(payload)) : payload;\n    parseWebVTT(payloadWebVTT, this.initPTS[frag.cc], this.vttCCs, frag.cc, frag.start, cues => {\n      this._appendCues(cues, frag.level);\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: true,\n        frag: frag\n      });\n    }, error => {\n      const missingInitPTS = error.message === 'Missing initPTS for VTT MPEGTS';\n      if (missingInitPTS) {\n        unparsedVttFrags.push(data);\n      } else {\n        this._fallbackToIMSC1(frag, payload);\n      }\n      // Something went wrong while parsing. Trigger event with success false.\n      logger.log(`Failed to parse VTT cue: ${error}`);\n      if (missingInitPTS && maxAvCC > frag.cc) {\n        return;\n      }\n      hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n        success: false,\n        frag: frag,\n        error\n      });\n    });\n  }\n  _fallbackToIMSC1(frag, payload) {\n    // If textCodec is unknown, try parsing as IMSC1. Set textCodec based on the result\n    const trackPlaylistMedia = this.tracks[frag.level];\n    if (!trackPlaylistMedia.textCodec) {\n      parseIMSC1(payload, this.initPTS[frag.cc], () => {\n        trackPlaylistMedia.textCodec = IMSC1_CODEC;\n        this._parseIMSC1(frag, payload);\n      }, () => {\n        trackPlaylistMedia.textCodec = 'wvtt';\n      });\n    }\n  }\n  _appendCues(cues, fragLevel) {\n    const hls = this.hls;\n    if (this.config.renderTextTracksNatively) {\n      const textTrack = this.textTracks[fragLevel];\n      // WebVTTParser.parse is an async method and if the currently selected text track mode is set to \"disabled\"\n      // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null\n      // and trying to access getCueById method of cues will throw an exception\n      // Because we check if the mode is disabled, we can force check `cues` below. They can't be null.\n      if (!textTrack || textTrack.mode === 'disabled') {\n        return;\n      }\n      cues.forEach(cue => addCueToTrack(textTrack, cue));\n    } else {\n      const currentTrack = this.tracks[fragLevel];\n      if (!currentTrack) {\n        return;\n      }\n      const track = currentTrack.default ? 'default' : 'subtitles' + fragLevel;\n      hls.trigger(Events.CUES_PARSED, {\n        type: 'subtitles',\n        cues,\n        track\n      });\n    }\n  }\n  onFragDecrypted(event, data) {\n    const {\n      frag\n    } = data;\n    if (frag.type === PlaylistLevelType.SUBTITLE) {\n      this.onFragLoaded(Events.FRAG_LOADED, data);\n    }\n  }\n  onSubtitleTracksCleared() {\n    this.tracks = [];\n    this.captionsTracks = {};\n  }\n  onFragParsingUserdata(event, data) {\n    this.initCea608Parsers();\n    const {\n      cea608Parser1,\n      cea608Parser2\n    } = this;\n    if (!this.enabled || !cea608Parser1 || !cea608Parser2) {\n      return;\n    }\n    const {\n      frag,\n      samples\n    } = data;\n    if (frag.type === PlaylistLevelType.MAIN && this.closedCaptionsForLevel(frag) === 'NONE') {\n      return;\n    }\n    // If the event contains captions (found in the bytes property), push all bytes into the parser immediately\n    // It will create the proper timestamps based on the PTS value\n    for (let i = 0; i < samples.length; i++) {\n      const ccBytes = samples[i].bytes;\n      if (ccBytes) {\n        const ccdatas = this.extractCea608Data(ccBytes);\n        cea608Parser1.addData(samples[i].pts, ccdatas[0]);\n        cea608Parser2.addData(samples[i].pts, ccdatas[1]);\n      }\n    }\n  }\n  onBufferFlushing(event, {\n    startOffset,\n    endOffset,\n    endOffsetSubtitles,\n    type\n  }) {\n    const {\n      media\n    } = this;\n    if (!media || media.currentTime < endOffset) {\n      return;\n    }\n    // Clear 608 caption cues from the captions TextTracks when the video back buffer is flushed\n    // Forward cues are never removed because we can loose streamed 608 content from recent fragments\n    if (!type || type === 'video') {\n      const {\n        captionsTracks\n      } = this;\n      Object.keys(captionsTracks).forEach(trackName => removeCuesInRange(captionsTracks[trackName], startOffset, endOffset));\n    }\n    if (this.config.renderTextTracksNatively) {\n      // Clear VTT/IMSC1 subtitle cues from the subtitle TextTracks when the back buffer is flushed\n      if (startOffset === 0 && endOffsetSubtitles !== undefined) {\n        const {\n          textTracks\n        } = this;\n        Object.keys(textTracks).forEach(trackName => removeCuesInRange(textTracks[trackName], startOffset, endOffsetSubtitles));\n      }\n    }\n  }\n  extractCea608Data(byteArray) {\n    const actualCCBytes = [[], []];\n    const count = byteArray[0] & 0x1f;\n    let position = 2;\n    for (let j = 0; j < count; j++) {\n      const tmpByte = byteArray[position++];\n      const ccbyte1 = 0x7f & byteArray[position++];\n      const ccbyte2 = 0x7f & byteArray[position++];\n      if (ccbyte1 === 0 && ccbyte2 === 0) {\n        continue;\n      }\n      const ccValid = (0x04 & tmpByte) !== 0; // Support all four channels\n      if (ccValid) {\n        const ccType = 0x03 & tmpByte;\n        if (0x00 /* CEA608 field1*/ === ccType || 0x01 /* CEA608 field2*/ === ccType) {\n          // Exclude CEA708 CC data.\n          actualCCBytes[ccType].push(ccbyte1);\n          actualCCBytes[ccType].push(ccbyte2);\n        }\n      }\n    }\n    return actualCCBytes;\n  }\n}\nfunction captionsOrSubtitlesFromCharacteristics(track) {\n  if (track.characteristics) {\n    if (/transcribes-spoken-dialog/gi.test(track.characteristics) && /describes-music-and-sound/gi.test(track.characteristics)) {\n      return 'captions';\n    }\n  }\n  return 'subtitles';\n}\nfunction canReuseVttTextTrack(inUseTrack, manifestTrack) {\n  return !!inUseTrack && inUseTrack.kind === captionsOrSubtitlesFromCharacteristics(manifestTrack) && subtitleTrackMatchesTextTrack(manifestTrack, inUseTrack);\n}\nfunction intersection(x1, x2, y1, y2) {\n  return Math.min(x2, y2) - Math.max(x1, y1);\n}\nfunction newVTTCCs() {\n  return {\n    ccOffset: 0,\n    presentationOffset: 0,\n    0: {\n      start: 0,\n      prevCC: -1,\n      new: true\n    }\n  };\n}\n\nclass CapLevelController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.autoLevelCapping = void 0;\n    this.firstLevel = void 0;\n    this.media = void 0;\n    this.restrictedLevels = void 0;\n    this.timer = void 0;\n    this.clientRect = void 0;\n    this.streamController = void 0;\n    this.hls = hls;\n    this.autoLevelCapping = Number.POSITIVE_INFINITY;\n    this.firstLevel = -1;\n    this.media = null;\n    this.restrictedLevels = [];\n    this.timer = undefined;\n    this.clientRect = null;\n    this.registerListeners();\n  }\n  setStreamController(streamController) {\n    this.streamController = streamController;\n  }\n  destroy() {\n    if (this.hls) {\n      this.unregisterListener();\n    }\n    if (this.timer) {\n      this.stopCapping();\n    }\n    this.media = null;\n    this.clientRect = null;\n    // @ts-ignore\n    this.hls = this.streamController = null;\n  }\n  registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);\n    hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n  }\n  unregisterListener() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);\n    hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n  }\n  onFpsDropLevelCapping(event, data) {\n    // Don't add a restricted level more than once\n    const level = this.hls.levels[data.droppedLevel];\n    if (this.isLevelAllowed(level)) {\n      this.restrictedLevels.push({\n        bitrate: level.bitrate,\n        height: level.height,\n        width: level.width\n      });\n    }\n  }\n  onMediaAttaching(event, data) {\n    this.media = data.media instanceof HTMLVideoElement ? data.media : null;\n    this.clientRect = null;\n    if (this.timer && this.hls.levels.length) {\n      this.detectPlayerSize();\n    }\n  }\n  onManifestParsed(event, data) {\n    const hls = this.hls;\n    this.restrictedLevels = [];\n    this.firstLevel = data.firstLevel;\n    if (hls.config.capLevelToPlayerSize && data.video) {\n      // Start capping immediately if the manifest has signaled video codecs\n      this.startCapping();\n    }\n  }\n  onLevelsUpdated(event, data) {\n    if (this.timer && isFiniteNumber(this.autoLevelCapping)) {\n      this.detectPlayerSize();\n    }\n  }\n\n  // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted\n  // to the first level\n  onBufferCodecs(event, data) {\n    const hls = this.hls;\n    if (hls.config.capLevelToPlayerSize && data.video) {\n      // If the manifest did not signal a video codec capping has been deferred until we're certain video is present\n      this.startCapping();\n    }\n  }\n  onMediaDetaching() {\n    this.stopCapping();\n  }\n  detectPlayerSize() {\n    if (this.media) {\n      if (this.mediaHeight <= 0 || this.mediaWidth <= 0) {\n        this.clientRect = null;\n        return;\n      }\n      const levels = this.hls.levels;\n      if (levels.length) {\n        const hls = this.hls;\n        const maxLevel = this.getMaxLevel(levels.length - 1);\n        if (maxLevel !== this.autoLevelCapping) {\n          logger.log(`Setting autoLevelCapping to ${maxLevel}: ${levels[maxLevel].height}p@${levels[maxLevel].bitrate} for media ${this.mediaWidth}x${this.mediaHeight}`);\n        }\n        hls.autoLevelCapping = maxLevel;\n        if (hls.autoLevelCapping > this.autoLevelCapping && this.streamController) {\n          // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch\n          // usually happen when the user go to the fullscreen mode.\n          this.streamController.nextLevelSwitch();\n        }\n        this.autoLevelCapping = hls.autoLevelCapping;\n      }\n    }\n  }\n\n  /*\n   * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)\n   */\n  getMaxLevel(capLevelIndex) {\n    const levels = this.hls.levels;\n    if (!levels.length) {\n      return -1;\n    }\n    const validLevels = levels.filter((level, index) => this.isLevelAllowed(level) && index <= capLevelIndex);\n    this.clientRect = null;\n    return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);\n  }\n  startCapping() {\n    if (this.timer) {\n      // Don't reset capping if started twice; this can happen if the manifest signals a video codec\n      return;\n    }\n    this.autoLevelCapping = Number.POSITIVE_INFINITY;\n    self.clearInterval(this.timer);\n    this.timer = self.setInterval(this.detectPlayerSize.bind(this), 1000);\n    this.detectPlayerSize();\n  }\n  stopCapping() {\n    this.restrictedLevels = [];\n    this.firstLevel = -1;\n    this.autoLevelCapping = Number.POSITIVE_INFINITY;\n    if (this.timer) {\n      self.clearInterval(this.timer);\n      this.timer = undefined;\n    }\n  }\n  getDimensions() {\n    if (this.clientRect) {\n      return this.clientRect;\n    }\n    const media = this.media;\n    const boundsRect = {\n      width: 0,\n      height: 0\n    };\n    if (media) {\n      const clientRect = media.getBoundingClientRect();\n      boundsRect.width = clientRect.width;\n      boundsRect.height = clientRect.height;\n      if (!boundsRect.width && !boundsRect.height) {\n        // When the media element has no width or height (equivalent to not being in the DOM),\n        // then use its width and height attributes (media.width, media.height)\n        boundsRect.width = clientRect.right - clientRect.left || media.width || 0;\n        boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;\n      }\n    }\n    this.clientRect = boundsRect;\n    return boundsRect;\n  }\n  get mediaWidth() {\n    return this.getDimensions().width * this.contentScaleFactor;\n  }\n  get mediaHeight() {\n    return this.getDimensions().height * this.contentScaleFactor;\n  }\n  get contentScaleFactor() {\n    let pixelRatio = 1;\n    if (!this.hls.config.ignoreDevicePixelRatio) {\n      try {\n        pixelRatio = self.devicePixelRatio;\n      } catch (e) {\n        /* no-op */\n      }\n    }\n    return pixelRatio;\n  }\n  isLevelAllowed(level) {\n    const restrictedLevels = this.restrictedLevels;\n    return !restrictedLevels.some(restrictedLevel => {\n      return level.bitrate === restrictedLevel.bitrate && level.width === restrictedLevel.width && level.height === restrictedLevel.height;\n    });\n  }\n  static getMaxLevelByMediaSize(levels, width, height) {\n    if (!(levels != null && levels.length)) {\n      return -1;\n    }\n\n    // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next\n    // to determine whether we've chosen the greatest bandwidth for the media's dimensions\n    const atGreatestBandwidth = (curLevel, nextLevel) => {\n      if (!nextLevel) {\n        return true;\n      }\n      return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;\n    };\n\n    // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to\n    // the max level\n    let maxLevelIndex = levels.length - 1;\n    // Prevent changes in aspect-ratio from causing capping to toggle back and forth\n    const squareSize = Math.max(width, height);\n    for (let i = 0; i < levels.length; i += 1) {\n      const level = levels[i];\n      if ((level.width >= squareSize || level.height >= squareSize) && atGreatestBandwidth(level, levels[i + 1])) {\n        maxLevelIndex = i;\n        break;\n      }\n    }\n    return maxLevelIndex;\n  }\n}\n\nclass FPSController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.isVideoPlaybackQualityAvailable = false;\n    this.timer = void 0;\n    this.media = null;\n    this.lastTime = void 0;\n    this.lastDroppedFrames = 0;\n    this.lastDecodedFrames = 0;\n    // stream controller must be provided as a dependency!\n    this.streamController = void 0;\n    this.hls = hls;\n    this.registerListeners();\n  }\n  setStreamController(streamController) {\n    this.streamController = streamController;\n  }\n  registerListeners() {\n    this.hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n  }\n  unregisterListeners() {\n    this.hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n  }\n  destroy() {\n    if (this.timer) {\n      clearInterval(this.timer);\n    }\n    this.unregisterListeners();\n    this.isVideoPlaybackQualityAvailable = false;\n    this.media = null;\n  }\n  onMediaAttaching(event, data) {\n    const config = this.hls.config;\n    if (config.capLevelOnFPSDrop) {\n      const media = data.media instanceof self.HTMLVideoElement ? data.media : null;\n      this.media = media;\n      if (media && typeof media.getVideoPlaybackQuality === 'function') {\n        this.isVideoPlaybackQualityAvailable = true;\n      }\n      self.clearInterval(this.timer);\n      this.timer = self.setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);\n    }\n  }\n  checkFPS(video, decodedFrames, droppedFrames) {\n    const currentTime = performance.now();\n    if (decodedFrames) {\n      if (this.lastTime) {\n        const currentPeriod = currentTime - this.lastTime;\n        const currentDropped = droppedFrames - this.lastDroppedFrames;\n        const currentDecoded = decodedFrames - this.lastDecodedFrames;\n        const droppedFPS = 1000 * currentDropped / currentPeriod;\n        const hls = this.hls;\n        hls.trigger(Events.FPS_DROP, {\n          currentDropped: currentDropped,\n          currentDecoded: currentDecoded,\n          totalDroppedFrames: droppedFrames\n        });\n        if (droppedFPS > 0) {\n          // logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));\n          if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {\n            let currentLevel = hls.currentLevel;\n            logger.warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);\n            if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {\n              currentLevel = currentLevel - 1;\n              hls.trigger(Events.FPS_DROP_LEVEL_CAPPING, {\n                level: currentLevel,\n                droppedLevel: hls.currentLevel\n              });\n              hls.autoLevelCapping = currentLevel;\n              this.streamController.nextLevelSwitch();\n            }\n          }\n        }\n      }\n      this.lastTime = currentTime;\n      this.lastDroppedFrames = droppedFrames;\n      this.lastDecodedFrames = decodedFrames;\n    }\n  }\n  checkFPSInterval() {\n    const video = this.media;\n    if (video) {\n      if (this.isVideoPlaybackQualityAvailable) {\n        const videoPlaybackQuality = video.getVideoPlaybackQuality();\n        this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);\n      } else {\n        // HTMLVideoElement doesn't include the webkit types\n        this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);\n      }\n    }\n  }\n}\n\nconst LOGGER_PREFIX = '[eme]';\n/**\n * Controller to deal with encrypted media extensions (EME)\n * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API\n *\n * @class\n * @constructor\n */\nclass EMEController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.config = void 0;\n    this.media = null;\n    this.keyFormatPromise = null;\n    this.keySystemAccessPromises = {};\n    this._requestLicenseFailureCount = 0;\n    this.mediaKeySessions = [];\n    this.keyIdToKeySessionPromise = {};\n    this.setMediaKeysQueue = EMEController.CDMCleanupPromise ? [EMEController.CDMCleanupPromise] : [];\n    this.onMediaEncrypted = this._onMediaEncrypted.bind(this);\n    this.onWaitingForKey = this._onWaitingForKey.bind(this);\n    this.debug = logger.debug.bind(logger, LOGGER_PREFIX);\n    this.log = logger.log.bind(logger, LOGGER_PREFIX);\n    this.warn = logger.warn.bind(logger, LOGGER_PREFIX);\n    this.error = logger.error.bind(logger, LOGGER_PREFIX);\n    this.hls = hls;\n    this.config = hls.config;\n    this.registerListeners();\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.onMediaDetached();\n    // Remove any references that could be held in config options or callbacks\n    const config = this.config;\n    config.requestMediaKeySystemAccessFunc = null;\n    config.licenseXhrSetup = config.licenseResponseCallback = undefined;\n    config.drmSystems = config.drmSystemOptions = {};\n    // @ts-ignore\n    this.hls = this.onMediaEncrypted = this.onWaitingForKey = this.keyIdToKeySessionPromise = null;\n    // @ts-ignore\n    this.config = null;\n  }\n  registerListeners() {\n    this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n  }\n  unregisterListeners() {\n    this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    this.hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    this.hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n  }\n  getLicenseServerUrl(keySystem) {\n    const {\n      drmSystems,\n      widevineLicenseUrl\n    } = this.config;\n    const keySystemConfiguration = drmSystems[keySystem];\n    if (keySystemConfiguration) {\n      return keySystemConfiguration.licenseUrl;\n    }\n\n    // For backward compatibility\n    if (keySystem === KeySystems.WIDEVINE && widevineLicenseUrl) {\n      return widevineLicenseUrl;\n    }\n    throw new Error(`no license server URL configured for key-system \"${keySystem}\"`);\n  }\n  getServerCertificateUrl(keySystem) {\n    const {\n      drmSystems\n    } = this.config;\n    const keySystemConfiguration = drmSystems[keySystem];\n    if (keySystemConfiguration) {\n      return keySystemConfiguration.serverCertificateUrl;\n    } else {\n      this.log(`No Server Certificate in config.drmSystems[\"${keySystem}\"]`);\n    }\n  }\n  attemptKeySystemAccess(keySystemsToAttempt) {\n    const levels = this.hls.levels;\n    const uniqueCodec = (value, i, a) => !!value && a.indexOf(value) === i;\n    const audioCodecs = levels.map(level => level.audioCodec).filter(uniqueCodec);\n    const videoCodecs = levels.map(level => level.videoCodec).filter(uniqueCodec);\n    if (audioCodecs.length + videoCodecs.length === 0) {\n      videoCodecs.push('avc1.42e01e');\n    }\n    return new Promise((resolve, reject) => {\n      const attempt = keySystems => {\n        const keySystem = keySystems.shift();\n        this.getMediaKeysPromise(keySystem, audioCodecs, videoCodecs).then(mediaKeys => resolve({\n          keySystem,\n          mediaKeys\n        })).catch(error => {\n          if (keySystems.length) {\n            attempt(keySystems);\n          } else if (error instanceof EMEKeyError) {\n            reject(error);\n          } else {\n            reject(new EMEKeyError({\n              type: ErrorTypes.KEY_SYSTEM_ERROR,\n              details: ErrorDetails.KEY_SYSTEM_NO_ACCESS,\n              error,\n              fatal: true\n            }, error.message));\n          }\n        });\n      };\n      attempt(keySystemsToAttempt);\n    });\n  }\n  requestMediaKeySystemAccess(keySystem, supportedConfigurations) {\n    const {\n      requestMediaKeySystemAccessFunc\n    } = this.config;\n    if (!(typeof requestMediaKeySystemAccessFunc === 'function')) {\n      let errMessage = `Configured requestMediaKeySystemAccess is not a function ${requestMediaKeySystemAccessFunc}`;\n      if (requestMediaKeySystemAccess === null && self.location.protocol === 'http:') {\n        errMessage = `navigator.requestMediaKeySystemAccess is not available over insecure protocol ${location.protocol}`;\n      }\n      return Promise.reject(new Error(errMessage));\n    }\n    return requestMediaKeySystemAccessFunc(keySystem, supportedConfigurations);\n  }\n  getMediaKeysPromise(keySystem, audioCodecs, videoCodecs) {\n    // This can throw, but is caught in event handler callpath\n    const mediaKeySystemConfigs = getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, this.config.drmSystemOptions);\n    const keySystemAccessPromises = this.keySystemAccessPromises[keySystem];\n    let keySystemAccess = keySystemAccessPromises == null ? void 0 : keySystemAccessPromises.keySystemAccess;\n    if (!keySystemAccess) {\n      this.log(`Requesting encrypted media \"${keySystem}\" key-system access with config: ${JSON.stringify(mediaKeySystemConfigs)}`);\n      keySystemAccess = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);\n      const _keySystemAccessPromises = this.keySystemAccessPromises[keySystem] = {\n        keySystemAccess\n      };\n      keySystemAccess.catch(error => {\n        this.log(`Failed to obtain access to key-system \"${keySystem}\": ${error}`);\n      });\n      return keySystemAccess.then(mediaKeySystemAccess => {\n        this.log(`Access for key-system \"${mediaKeySystemAccess.keySystem}\" obtained`);\n        const certificateRequest = this.fetchServerCertificate(keySystem);\n        this.log(`Create media-keys for \"${keySystem}\"`);\n        _keySystemAccessPromises.mediaKeys = mediaKeySystemAccess.createMediaKeys().then(mediaKeys => {\n          this.log(`Media-keys created for \"${keySystem}\"`);\n          return certificateRequest.then(certificate => {\n            if (certificate) {\n              return this.setMediaKeysServerCertificate(mediaKeys, keySystem, certificate);\n            }\n            return mediaKeys;\n          });\n        });\n        _keySystemAccessPromises.mediaKeys.catch(error => {\n          this.error(`Failed to create media-keys for \"${keySystem}\"}: ${error}`);\n        });\n        return _keySystemAccessPromises.mediaKeys;\n      });\n    }\n    return keySystemAccess.then(() => keySystemAccessPromises.mediaKeys);\n  }\n  createMediaKeySessionContext({\n    decryptdata,\n    keySystem,\n    mediaKeys\n  }) {\n    this.log(`Creating key-system session \"${keySystem}\" keyId: ${Hex.hexDump(decryptdata.keyId || [])}`);\n    const mediaKeysSession = mediaKeys.createSession();\n    const mediaKeySessionContext = {\n      decryptdata,\n      keySystem,\n      mediaKeys,\n      mediaKeysSession,\n      keyStatus: 'status-pending'\n    };\n    this.mediaKeySessions.push(mediaKeySessionContext);\n    return mediaKeySessionContext;\n  }\n  renewKeySession(mediaKeySessionContext) {\n    const decryptdata = mediaKeySessionContext.decryptdata;\n    if (decryptdata.pssh) {\n      const keySessionContext = this.createMediaKeySessionContext(mediaKeySessionContext);\n      const keyId = this.getKeyIdString(decryptdata);\n      const scheme = 'cenc';\n      this.keyIdToKeySessionPromise[keyId] = this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh, 'expired');\n    } else {\n      this.warn(`Could not renew expired session. Missing pssh initData.`);\n    }\n    this.removeSession(mediaKeySessionContext);\n  }\n  getKeyIdString(decryptdata) {\n    if (!decryptdata) {\n      throw new Error('Could not read keyId of undefined decryptdata');\n    }\n    if (decryptdata.keyId === null) {\n      throw new Error('keyId is null');\n    }\n    return Hex.hexDump(decryptdata.keyId);\n  }\n  updateKeySession(mediaKeySessionContext, data) {\n    var _mediaKeySessionConte;\n    const keySession = mediaKeySessionContext.mediaKeysSession;\n    this.log(`Updating key-session \"${keySession.sessionId}\" for keyID ${Hex.hexDump(((_mediaKeySessionConte = mediaKeySessionContext.decryptdata) == null ? void 0 : _mediaKeySessionConte.keyId) || [])}\n      } (data length: ${data ? data.byteLength : data})`);\n    return keySession.update(data);\n  }\n  selectKeySystemFormat(frag) {\n    const keyFormats = Object.keys(frag.levelkeys || {});\n    if (!this.keyFormatPromise) {\n      this.log(`Selecting key-system from fragment (sn: ${frag.sn} ${frag.type}: ${frag.level}) key formats ${keyFormats.join(', ')}`);\n      this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n    }\n    return this.keyFormatPromise;\n  }\n  getKeyFormatPromise(keyFormats) {\n    return new Promise((resolve, reject) => {\n      const keySystemsInConfig = getKeySystemsForConfig(this.config);\n      const keySystemsToAttempt = keyFormats.map(keySystemFormatToKeySystemDomain).filter(value => !!value && keySystemsInConfig.indexOf(value) !== -1);\n      return this.getKeySystemSelectionPromise(keySystemsToAttempt).then(({\n        keySystem\n      }) => {\n        const keySystemFormat = keySystemDomainToKeySystemFormat(keySystem);\n        if (keySystemFormat) {\n          resolve(keySystemFormat);\n        } else {\n          reject(new Error(`Unable to find format for key-system \"${keySystem}\"`));\n        }\n      }).catch(reject);\n    });\n  }\n  loadKey(data) {\n    const decryptdata = data.keyInfo.decryptdata;\n    const keyId = this.getKeyIdString(decryptdata);\n    const keyDetails = `(keyId: ${keyId} format: \"${decryptdata.keyFormat}\" method: ${decryptdata.method} uri: ${decryptdata.uri})`;\n    this.log(`Starting session for key ${keyDetails}`);\n    let keySessionContextPromise = this.keyIdToKeySessionPromise[keyId];\n    if (!keySessionContextPromise) {\n      keySessionContextPromise = this.keyIdToKeySessionPromise[keyId] = this.getKeySystemForKeyPromise(decryptdata).then(({\n        keySystem,\n        mediaKeys\n      }) => {\n        this.throwIfDestroyed();\n        this.log(`Handle encrypted media sn: ${data.frag.sn} ${data.frag.type}: ${data.frag.level} using key ${keyDetails}`);\n        return this.attemptSetMediaKeys(keySystem, mediaKeys).then(() => {\n          this.throwIfDestroyed();\n          const keySessionContext = this.createMediaKeySessionContext({\n            keySystem,\n            mediaKeys,\n            decryptdata\n          });\n          const scheme = 'cenc';\n          return this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh, 'playlist-key');\n        });\n      });\n      keySessionContextPromise.catch(error => this.handleError(error));\n    }\n    return keySessionContextPromise;\n  }\n  throwIfDestroyed(message = 'Invalid state') {\n    if (!this.hls) {\n      throw new Error('invalid state');\n    }\n  }\n  handleError(error) {\n    if (!this.hls) {\n      return;\n    }\n    this.error(error.message);\n    if (error instanceof EMEKeyError) {\n      this.hls.trigger(Events.ERROR, error.data);\n    } else {\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_KEYS,\n        error,\n        fatal: true\n      });\n    }\n  }\n  getKeySystemForKeyPromise(decryptdata) {\n    const keyId = this.getKeyIdString(decryptdata);\n    const mediaKeySessionContext = this.keyIdToKeySessionPromise[keyId];\n    if (!mediaKeySessionContext) {\n      const keySystem = keySystemFormatToKeySystemDomain(decryptdata.keyFormat);\n      const keySystemsToAttempt = keySystem ? [keySystem] : getKeySystemsForConfig(this.config);\n      return this.attemptKeySystemAccess(keySystemsToAttempt);\n    }\n    return mediaKeySessionContext;\n  }\n  getKeySystemSelectionPromise(keySystemsToAttempt) {\n    if (!keySystemsToAttempt.length) {\n      keySystemsToAttempt = getKeySystemsForConfig(this.config);\n    }\n    if (keySystemsToAttempt.length === 0) {\n      throw new EMEKeyError({\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_CONFIGURED_LICENSE,\n        fatal: true\n      }, `Missing key-system license configuration options ${JSON.stringify({\n        drmSystems: this.config.drmSystems\n      })}`);\n    }\n    return this.attemptKeySystemAccess(keySystemsToAttempt);\n  }\n  _onMediaEncrypted(event) {\n    const {\n      initDataType,\n      initData\n    } = event;\n    this.debug(`\"${event.type}\" event: init data type: \"${initDataType}\"`);\n\n    // Ignore event when initData is null\n    if (initData === null) {\n      return;\n    }\n    let keyId;\n    let keySystemDomain;\n    if (initDataType === 'sinf' && this.config.drmSystems[KeySystems.FAIRPLAY]) {\n      // Match sinf keyId to playlist skd://keyId=\n      const json = bin2str(new Uint8Array(initData));\n      try {\n        const sinf = base64Decode(JSON.parse(json).sinf);\n        const tenc = parseSinf(new Uint8Array(sinf));\n        if (!tenc) {\n          return;\n        }\n        keyId = tenc.subarray(8, 24);\n        keySystemDomain = KeySystems.FAIRPLAY;\n      } catch (error) {\n        this.warn('Failed to parse sinf \"encrypted\" event message initData');\n        return;\n      }\n    } else {\n      // Support clear-lead key-session creation (otherwise depend on playlist keys)\n      const psshInfo = parsePssh(initData);\n      if (psshInfo === null) {\n        return;\n      }\n      if (psshInfo.version === 0 && psshInfo.systemId === KeySystemIds.WIDEVINE && psshInfo.data) {\n        keyId = psshInfo.data.subarray(8, 24);\n      }\n      keySystemDomain = keySystemIdToKeySystemDomain(psshInfo.systemId);\n    }\n    if (!keySystemDomain || !keyId) {\n      return;\n    }\n    const keyIdHex = Hex.hexDump(keyId);\n    const {\n      keyIdToKeySessionPromise,\n      mediaKeySessions\n    } = this;\n    let keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex];\n    for (let i = 0; i < mediaKeySessions.length; i++) {\n      // Match playlist key\n      const keyContext = mediaKeySessions[i];\n      const decryptdata = keyContext.decryptdata;\n      if (decryptdata.pssh || !decryptdata.keyId) {\n        continue;\n      }\n      const oldKeyIdHex = Hex.hexDump(decryptdata.keyId);\n      if (keyIdHex === oldKeyIdHex || decryptdata.uri.replace(/-/g, '').indexOf(keyIdHex) !== -1) {\n        keySessionContextPromise = keyIdToKeySessionPromise[oldKeyIdHex];\n        delete keyIdToKeySessionPromise[oldKeyIdHex];\n        decryptdata.pssh = new Uint8Array(initData);\n        decryptdata.keyId = keyId;\n        keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = keySessionContextPromise.then(() => {\n          return this.generateRequestWithPreferredKeySession(keyContext, initDataType, initData, 'encrypted-event-key-match');\n        });\n        break;\n      }\n    }\n    if (!keySessionContextPromise) {\n      // Clear-lead key (not encountered in playlist)\n      keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = this.getKeySystemSelectionPromise([keySystemDomain]).then(({\n        keySystem,\n        mediaKeys\n      }) => {\n        var _keySystemToKeySystem;\n        this.throwIfDestroyed();\n        const decryptdata = new LevelKey('ISO-23001-7', keyIdHex, (_keySystemToKeySystem = keySystemDomainToKeySystemFormat(keySystem)) != null ? _keySystemToKeySystem : '');\n        decryptdata.pssh = new Uint8Array(initData);\n        decryptdata.keyId = keyId;\n        return this.attemptSetMediaKeys(keySystem, mediaKeys).then(() => {\n          this.throwIfDestroyed();\n          const keySessionContext = this.createMediaKeySessionContext({\n            decryptdata,\n            keySystem,\n            mediaKeys\n          });\n          return this.generateRequestWithPreferredKeySession(keySessionContext, initDataType, initData, 'encrypted-event-no-match');\n        });\n      });\n    }\n    keySessionContextPromise.catch(error => this.handleError(error));\n  }\n  _onWaitingForKey(event) {\n    this.log(`\"${event.type}\" event`);\n  }\n  attemptSetMediaKeys(keySystem, mediaKeys) {\n    const queue = this.setMediaKeysQueue.slice();\n    this.log(`Setting media-keys for \"${keySystem}\"`);\n    // Only one setMediaKeys() can run at one time, and multiple setMediaKeys() operations\n    // can be queued for execution for multiple key sessions.\n    const setMediaKeysPromise = Promise.all(queue).then(() => {\n      if (!this.media) {\n        throw new Error('Attempted to set mediaKeys without media element attached');\n      }\n      return this.media.setMediaKeys(mediaKeys);\n    });\n    this.setMediaKeysQueue.push(setMediaKeysPromise);\n    return setMediaKeysPromise.then(() => {\n      this.log(`Media-keys set for \"${keySystem}\"`);\n      queue.push(setMediaKeysPromise);\n      this.setMediaKeysQueue = this.setMediaKeysQueue.filter(p => queue.indexOf(p) === -1);\n    });\n  }\n  generateRequestWithPreferredKeySession(context, initDataType, initData, reason) {\n    var _this$config$drmSyste, _this$config$drmSyste2;\n    const generateRequestFilter = (_this$config$drmSyste = this.config.drmSystems) == null ? void 0 : (_this$config$drmSyste2 = _this$config$drmSyste[context.keySystem]) == null ? void 0 : _this$config$drmSyste2.generateRequest;\n    if (generateRequestFilter) {\n      try {\n        const mappedInitData = generateRequestFilter.call(this.hls, initDataType, initData, context);\n        if (!mappedInitData) {\n          throw new Error('Invalid response from configured generateRequest filter');\n        }\n        initDataType = mappedInitData.initDataType;\n        initData = context.decryptdata.pssh = mappedInitData.initData ? new Uint8Array(mappedInitData.initData) : null;\n      } catch (error) {\n        var _this$hls;\n        this.warn(error.message);\n        if ((_this$hls = this.hls) != null && _this$hls.config.debug) {\n          throw error;\n        }\n      }\n    }\n    if (initData === null) {\n      this.log(`Skipping key-session request for \"${reason}\" (no initData)`);\n      return Promise.resolve(context);\n    }\n    const keyId = this.getKeyIdString(context.decryptdata);\n    this.log(`Generating key-session request for \"${reason}\": ${keyId} (init data type: ${initDataType} length: ${initData ? initData.byteLength : null})`);\n    const licenseStatus = new EventEmitter();\n    const onmessage = context._onmessage = event => {\n      const keySession = context.mediaKeysSession;\n      if (!keySession) {\n        licenseStatus.emit('error', new Error('invalid state'));\n        return;\n      }\n      const {\n        messageType,\n        message\n      } = event;\n      this.log(`\"${messageType}\" message event for session \"${keySession.sessionId}\" message size: ${message.byteLength}`);\n      if (messageType === 'license-request' || messageType === 'license-renewal') {\n        this.renewLicense(context, message).catch(error => {\n          this.handleError(error);\n          licenseStatus.emit('error', error);\n        });\n      } else if (messageType === 'license-release') {\n        if (context.keySystem === KeySystems.FAIRPLAY) {\n          this.updateKeySession(context, strToUtf8array('acknowledged'));\n          this.removeSession(context);\n        }\n      } else {\n        this.warn(`unhandled media key message type \"${messageType}\"`);\n      }\n    };\n    const onkeystatuseschange = context._onkeystatuseschange = event => {\n      const keySession = context.mediaKeysSession;\n      if (!keySession) {\n        licenseStatus.emit('error', new Error('invalid state'));\n        return;\n      }\n      this.onKeyStatusChange(context);\n      const keyStatus = context.keyStatus;\n      licenseStatus.emit('keyStatus', keyStatus);\n      if (keyStatus === 'expired') {\n        this.warn(`${context.keySystem} expired for key ${keyId}`);\n        this.renewKeySession(context);\n      }\n    };\n    context.mediaKeysSession.addEventListener('message', onmessage);\n    context.mediaKeysSession.addEventListener('keystatuseschange', onkeystatuseschange);\n    const keyUsablePromise = new Promise((resolve, reject) => {\n      licenseStatus.on('error', reject);\n      licenseStatus.on('keyStatus', keyStatus => {\n        if (keyStatus.startsWith('usable')) {\n          resolve();\n        } else if (keyStatus === 'output-restricted') {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED,\n            fatal: false\n          }, 'HDCP level output restricted'));\n        } else if (keyStatus === 'internal-error') {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR,\n            fatal: true\n          }, `key status changed to \"${keyStatus}\"`));\n        } else if (keyStatus === 'expired') {\n          reject(new Error('key expired while generating request'));\n        } else {\n          this.warn(`unhandled key status change \"${keyStatus}\"`);\n        }\n      });\n    });\n    return context.mediaKeysSession.generateRequest(initDataType, initData).then(() => {\n      var _context$mediaKeysSes;\n      this.log(`Request generated for key-session \"${(_context$mediaKeysSes = context.mediaKeysSession) == null ? void 0 : _context$mediaKeysSes.sessionId}\" keyId: ${keyId}`);\n    }).catch(error => {\n      throw new EMEKeyError({\n        type: ErrorTypes.KEY_SYSTEM_ERROR,\n        details: ErrorDetails.KEY_SYSTEM_NO_SESSION,\n        error,\n        fatal: false\n      }, `Error generating key-session request: ${error}`);\n    }).then(() => keyUsablePromise).catch(error => {\n      licenseStatus.removeAllListeners();\n      this.removeSession(context);\n      throw error;\n    }).then(() => {\n      licenseStatus.removeAllListeners();\n      return context;\n    });\n  }\n  onKeyStatusChange(mediaKeySessionContext) {\n    mediaKeySessionContext.mediaKeysSession.keyStatuses.forEach((status, keyId) => {\n      this.log(`key status change \"${status}\" for keyStatuses keyId: ${Hex.hexDump('buffer' in keyId ? new Uint8Array(keyId.buffer, keyId.byteOffset, keyId.byteLength) : new Uint8Array(keyId))} session keyId: ${Hex.hexDump(new Uint8Array(mediaKeySessionContext.decryptdata.keyId || []))} uri: ${mediaKeySessionContext.decryptdata.uri}`);\n      mediaKeySessionContext.keyStatus = status;\n    });\n  }\n  fetchServerCertificate(keySystem) {\n    const config = this.config;\n    const Loader = config.loader;\n    const certLoader = new Loader(config);\n    const url = this.getServerCertificateUrl(keySystem);\n    if (!url) {\n      return Promise.resolve();\n    }\n    this.log(`Fetching server certificate for \"${keySystem}\"`);\n    return new Promise((resolve, reject) => {\n      const loaderContext = {\n        responseType: 'arraybuffer',\n        url\n      };\n      const loadPolicy = config.certLoadPolicy.default;\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0\n      };\n      const loaderCallbacks = {\n        onSuccess: (response, stats, context, networkDetails) => {\n          resolve(response.data);\n        },\n        onError: (response, contex, networkDetails, stats) => {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,\n            fatal: true,\n            networkDetails,\n            response: _objectSpread2({\n              url: loaderContext.url,\n              data: undefined\n            }, response)\n          }, `\"${keySystem}\" certificate request failed (${url}). Status: ${response.code} (${response.text})`));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,\n            fatal: true,\n            networkDetails,\n            response: {\n              url: loaderContext.url,\n              data: undefined\n            }\n          }, `\"${keySystem}\" certificate request timed out (${url})`));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          reject(new Error('aborted'));\n        }\n      };\n      certLoader.load(loaderContext, loaderConfig, loaderCallbacks);\n    });\n  }\n  setMediaKeysServerCertificate(mediaKeys, keySystem, cert) {\n    return new Promise((resolve, reject) => {\n      mediaKeys.setServerCertificate(cert).then(success => {\n        this.log(`setServerCertificate ${success ? 'success' : 'not supported by CDM'} (${cert == null ? void 0 : cert.byteLength}) on \"${keySystem}\"`);\n        resolve(mediaKeys);\n      }).catch(error => {\n        reject(new EMEKeyError({\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED,\n          error,\n          fatal: true\n        }, error.message));\n      });\n    });\n  }\n  renewLicense(context, keyMessage) {\n    return this.requestLicense(context, new Uint8Array(keyMessage)).then(data => {\n      return this.updateKeySession(context, new Uint8Array(data)).catch(error => {\n        throw new EMEKeyError({\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED,\n          error,\n          fatal: true\n        }, error.message);\n      });\n    });\n  }\n  unpackPlayReadyKeyMessage(xhr, licenseChallenge) {\n    // On Edge, the raw license message is UTF-16-encoded XML.  We need\n    // to unpack the Challenge element (base64-encoded string containing the\n    // actual license request) and any HttpHeader elements (sent as request\n    // headers).\n    // For PlayReady CDMs, we need to dig the Challenge out of the XML.\n    const xmlString = String.fromCharCode.apply(null, new Uint16Array(licenseChallenge.buffer));\n    if (!xmlString.includes('PlayReadyKeyMessage')) {\n      // This does not appear to be a wrapped message as on Edge.  Some\n      // clients do not need this unwrapping, so we will assume this is one of\n      // them.  Note that \"xml\" at this point probably looks like random\n      // garbage, since we interpreted UTF-8 as UTF-16.\n      xhr.setRequestHeader('Content-Type', 'text/xml; charset=utf-8');\n      return licenseChallenge;\n    }\n    const keyMessageXml = new DOMParser().parseFromString(xmlString, 'application/xml');\n    // Set request headers.\n    const headers = keyMessageXml.querySelectorAll('HttpHeader');\n    if (headers.length > 0) {\n      let header;\n      for (let i = 0, len = headers.length; i < len; i++) {\n        var _header$querySelector, _header$querySelector2;\n        header = headers[i];\n        const name = (_header$querySelector = header.querySelector('name')) == null ? void 0 : _header$querySelector.textContent;\n        const value = (_header$querySelector2 = header.querySelector('value')) == null ? void 0 : _header$querySelector2.textContent;\n        if (name && value) {\n          xhr.setRequestHeader(name, value);\n        }\n      }\n    }\n    const challengeElement = keyMessageXml.querySelector('Challenge');\n    const challengeText = challengeElement == null ? void 0 : challengeElement.textContent;\n    if (!challengeText) {\n      throw new Error(`Cannot find <Challenge> in key message`);\n    }\n    return strToUtf8array(atob(challengeText));\n  }\n  setupLicenseXHR(xhr, url, keysListItem, licenseChallenge) {\n    const licenseXhrSetup = this.config.licenseXhrSetup;\n    if (!licenseXhrSetup) {\n      xhr.open('POST', url, true);\n      return Promise.resolve({\n        xhr,\n        licenseChallenge\n      });\n    }\n    return Promise.resolve().then(() => {\n      if (!keysListItem.decryptdata) {\n        throw new Error('Key removed');\n      }\n      return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);\n    }).catch(error => {\n      if (!keysListItem.decryptdata) {\n        // Key session removed. Cancel license request.\n        throw error;\n      }\n      // let's try to open before running setup\n      xhr.open('POST', url, true);\n      return licenseXhrSetup.call(this.hls, xhr, url, keysListItem, licenseChallenge);\n    }).then(licenseXhrSetupResult => {\n      // if licenseXhrSetup did not yet call open, let's do it now\n      if (!xhr.readyState) {\n        xhr.open('POST', url, true);\n      }\n      const finalLicenseChallenge = licenseXhrSetupResult ? licenseXhrSetupResult : licenseChallenge;\n      return {\n        xhr,\n        licenseChallenge: finalLicenseChallenge\n      };\n    });\n  }\n  requestLicense(keySessionContext, licenseChallenge) {\n    const keyLoadPolicy = this.config.keyLoadPolicy.default;\n    return new Promise((resolve, reject) => {\n      const url = this.getLicenseServerUrl(keySessionContext.keySystem);\n      this.log(`Sending license request to URL: ${url}`);\n      const xhr = new XMLHttpRequest();\n      xhr.responseType = 'arraybuffer';\n      xhr.onreadystatechange = () => {\n        if (!this.hls || !keySessionContext.mediaKeysSession) {\n          return reject(new Error('invalid state'));\n        }\n        if (xhr.readyState === 4) {\n          if (xhr.status === 200) {\n            this._requestLicenseFailureCount = 0;\n            let data = xhr.response;\n            this.log(`License received ${data instanceof ArrayBuffer ? data.byteLength : data}`);\n            const licenseResponseCallback = this.config.licenseResponseCallback;\n            if (licenseResponseCallback) {\n              try {\n                data = licenseResponseCallback.call(this.hls, xhr, url, keySessionContext);\n              } catch (error) {\n                this.error(error);\n              }\n            }\n            resolve(data);\n          } else {\n            const retryConfig = keyLoadPolicy.errorRetry;\n            const maxNumRetry = retryConfig ? retryConfig.maxNumRetry : 0;\n            this._requestLicenseFailureCount++;\n            if (this._requestLicenseFailureCount > maxNumRetry || xhr.status >= 400 && xhr.status < 500) {\n              reject(new EMEKeyError({\n                type: ErrorTypes.KEY_SYSTEM_ERROR,\n                details: ErrorDetails.KEY_SYSTEM_LICENSE_REQUEST_FAILED,\n                fatal: true,\n                networkDetails: xhr,\n                response: {\n                  url,\n                  data: undefined,\n                  code: xhr.status,\n                  text: xhr.statusText\n                }\n              }, `License Request XHR failed (${url}). Status: ${xhr.status} (${xhr.statusText})`));\n            } else {\n              const attemptsLeft = maxNumRetry - this._requestLicenseFailureCount + 1;\n              this.warn(`Retrying license request, ${attemptsLeft} attempts left`);\n              this.requestLicense(keySessionContext, licenseChallenge).then(resolve, reject);\n            }\n          }\n        }\n      };\n      if (keySessionContext.licenseXhr && keySessionContext.licenseXhr.readyState !== XMLHttpRequest.DONE) {\n        keySessionContext.licenseXhr.abort();\n      }\n      keySessionContext.licenseXhr = xhr;\n      this.setupLicenseXHR(xhr, url, keySessionContext, licenseChallenge).then(({\n        xhr,\n        licenseChallenge\n      }) => {\n        if (keySessionContext.keySystem == KeySystems.PLAYREADY) {\n          licenseChallenge = this.unpackPlayReadyKeyMessage(xhr, licenseChallenge);\n        }\n        xhr.send(licenseChallenge);\n      });\n    });\n  }\n  onMediaAttached(event, data) {\n    if (!this.config.emeEnabled) {\n      return;\n    }\n    const media = data.media;\n\n    // keep reference of media\n    this.media = media;\n    media.addEventListener('encrypted', this.onMediaEncrypted);\n    media.addEventListener('waitingforkey', this.onWaitingForKey);\n  }\n  onMediaDetached() {\n    const media = this.media;\n    const mediaKeysList = this.mediaKeySessions;\n    if (media) {\n      media.removeEventListener('encrypted', this.onMediaEncrypted);\n      media.removeEventListener('waitingforkey', this.onWaitingForKey);\n      this.media = null;\n    }\n    this._requestLicenseFailureCount = 0;\n    this.setMediaKeysQueue = [];\n    this.mediaKeySessions = [];\n    this.keyIdToKeySessionPromise = {};\n    LevelKey.clearKeyUriToKeyIdMap();\n\n    // Close all sessions and remove media keys from the video element.\n    const keySessionCount = mediaKeysList.length;\n    EMEController.CDMCleanupPromise = Promise.all(mediaKeysList.map(mediaKeySessionContext => this.removeSession(mediaKeySessionContext)).concat(media == null ? void 0 : media.setMediaKeys(null).catch(error => {\n      this.log(`Could not clear media keys: ${error}`);\n    }))).then(() => {\n      if (keySessionCount) {\n        this.log('finished closing key sessions and clearing media keys');\n        mediaKeysList.length = 0;\n      }\n    }).catch(error => {\n      this.log(`Could not close sessions and clear media keys: ${error}`);\n    });\n  }\n  onManifestLoading() {\n    this.keyFormatPromise = null;\n  }\n  onManifestLoaded(event, {\n    sessionKeys\n  }) {\n    if (!sessionKeys || !this.config.emeEnabled) {\n      return;\n    }\n    if (!this.keyFormatPromise) {\n      const keyFormats = sessionKeys.reduce((formats, sessionKey) => {\n        if (formats.indexOf(sessionKey.keyFormat) === -1) {\n          formats.push(sessionKey.keyFormat);\n        }\n        return formats;\n      }, []);\n      this.log(`Selecting key-system from session-keys ${keyFormats.join(', ')}`);\n      this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n    }\n  }\n  removeSession(mediaKeySessionContext) {\n    const {\n      mediaKeysSession,\n      licenseXhr\n    } = mediaKeySessionContext;\n    if (mediaKeysSession) {\n      this.log(`Remove licenses and keys and close session ${mediaKeysSession.sessionId}`);\n      if (mediaKeySessionContext._onmessage) {\n        mediaKeysSession.removeEventListener('message', mediaKeySessionContext._onmessage);\n        mediaKeySessionContext._onmessage = undefined;\n      }\n      if (mediaKeySessionContext._onkeystatuseschange) {\n        mediaKeysSession.removeEventListener('keystatuseschange', mediaKeySessionContext._onkeystatuseschange);\n        mediaKeySessionContext._onkeystatuseschange = undefined;\n      }\n      if (licenseXhr && licenseXhr.readyState !== XMLHttpRequest.DONE) {\n        licenseXhr.abort();\n      }\n      mediaKeySessionContext.mediaKeysSession = mediaKeySessionContext.decryptdata = mediaKeySessionContext.licenseXhr = undefined;\n      const index = this.mediaKeySessions.indexOf(mediaKeySessionContext);\n      if (index > -1) {\n        this.mediaKeySessions.splice(index, 1);\n      }\n      return mediaKeysSession.remove().catch(error => {\n        this.log(`Could not remove session: ${error}`);\n      }).then(() => {\n        return mediaKeysSession.close();\n      }).catch(error => {\n        this.log(`Could not close session: ${error}`);\n      });\n    }\n  }\n}\nEMEController.CDMCleanupPromise = void 0;\nclass EMEKeyError extends Error {\n  constructor(data, message) {\n    super(message);\n    this.data = void 0;\n    data.error || (data.error = new Error(message));\n    this.data = data;\n    data.err = data.error;\n  }\n}\n\n/**\n * Common Media Object Type\n *\n * @group CMCD\n * @group CMSD\n *\n * @beta\n */\nvar CmObjectType;\n(function (CmObjectType) {\n  /**\n   * text file, such as a manifest or playlist\n   */\n  CmObjectType[\"MANIFEST\"] = \"m\";\n  /**\n   * audio only\n   */\n  CmObjectType[\"AUDIO\"] = \"a\";\n  /**\n   * video only\n   */\n  CmObjectType[\"VIDEO\"] = \"v\";\n  /**\n   * muxed audio and video\n   */\n  CmObjectType[\"MUXED\"] = \"av\";\n  /**\n   * init segment\n   */\n  CmObjectType[\"INIT\"] = \"i\";\n  /**\n   * caption or subtitle\n   */\n  CmObjectType[\"CAPTION\"] = \"c\";\n  /**\n   * ISOBMFF timed text track\n   */\n  CmObjectType[\"TIMED_TEXT\"] = \"tt\";\n  /**\n   * cryptographic key, license or certificate.\n   */\n  CmObjectType[\"KEY\"] = \"k\";\n  /**\n   * other\n   */\n  CmObjectType[\"OTHER\"] = \"o\";\n})(CmObjectType || (CmObjectType = {}));\n\n/**\n * Common Media Streaming Format\n *\n * @group CMCD\n * @group CMSD\n *\n * @beta\n */\nvar CmStreamingFormat;\n(function (CmStreamingFormat) {\n  /**\n   * MPEG DASH\n   */\n  CmStreamingFormat[\"DASH\"] = \"d\";\n  /**\n   * HTTP Live Streaming (HLS)\n   */\n  CmStreamingFormat[\"HLS\"] = \"h\";\n  /**\n   * Smooth Streaming\n   */\n  CmStreamingFormat[\"SMOOTH\"] = \"s\";\n  /**\n   * Other\n   */\n  CmStreamingFormat[\"OTHER\"] = \"o\";\n})(CmStreamingFormat || (CmStreamingFormat = {}));\n\n/**\n * CMCD header fields.\n *\n * @group CMCD\n *\n * @beta\n */\nvar CmcdHeaderField;\n(function (CmcdHeaderField) {\n  /**\n   * keys whose values vary with the object being requested.\n   */\n  CmcdHeaderField[\"OBJECT\"] = \"CMCD-Object\";\n  /**\n   * keys whose values vary with each request.\n   */\n  CmcdHeaderField[\"REQUEST\"] = \"CMCD-Request\";\n  /**\n   * keys whose values are expected to be invariant over the life of the session.\n   */\n  CmcdHeaderField[\"SESSION\"] = \"CMCD-Session\";\n  /**\n   * keys whose values do not vary with every request or object.\n   */\n  CmcdHeaderField[\"STATUS\"] = \"CMCD-Status\";\n})(CmcdHeaderField || (CmcdHeaderField = {}));\n\n/**\n * The map of CMCD header fields to official CMCD keys.\n *\n * @internal\n *\n * @group CMCD\n */\nconst CmcdHeaderMap = {\n  [CmcdHeaderField.OBJECT]: ['br', 'd', 'ot', 'tb'],\n  [CmcdHeaderField.REQUEST]: ['bl', 'dl', 'mtp', 'nor', 'nrr', 'su'],\n  [CmcdHeaderField.SESSION]: ['cid', 'pr', 'sf', 'sid', 'st', 'v'],\n  [CmcdHeaderField.STATUS]: ['bs', 'rtp']\n};\n\n/**\n * Structured Field Item\n *\n * @group Structured Field\n *\n * @beta\n */\nclass SfItem {\n  constructor(value, params) {\n    this.value = void 0;\n    this.params = void 0;\n    if (Array.isArray(value)) {\n      value = value.map(v => v instanceof SfItem ? v : new SfItem(v));\n    }\n    this.value = value;\n    this.params = params;\n  }\n}\n\n/**\n * A class to represent structured field tokens when `Symbol` is not available.\n *\n * @group Structured Field\n *\n * @beta\n */\nclass SfToken {\n  constructor(description) {\n    this.description = void 0;\n    this.description = description;\n  }\n}\n\nconst DICT = 'Dict';\n\nfunction format(value) {\n  if (Array.isArray(value)) {\n    return JSON.stringify(value);\n  }\n  if (value instanceof Map) {\n    return 'Map{}';\n  }\n  if (value instanceof Set) {\n    return 'Set{}';\n  }\n  if (typeof value === 'object') {\n    return JSON.stringify(value);\n  }\n  return String(value);\n}\nfunction throwError(action, src, type, cause) {\n  return new Error(`failed to ${action} \"${format(src)}\" as ${type}`, {\n    cause\n  });\n}\n\nconst BARE_ITEM = 'Bare Item';\n\nconst BOOLEAN = 'Boolean';\n\nconst BYTES = 'Byte Sequence';\n\nconst DECIMAL = 'Decimal';\n\nconst INTEGER = 'Integer';\n\nfunction isInvalidInt(value) {\n  return value < -999999999999999 || 999999999999999 < value;\n}\n\nconst STRING_REGEX = /[\\x00-\\x1f\\x7f]+/; // eslint-disable-line no-control-regex\n\nconst TOKEN = 'Token';\n\nconst KEY = 'Key';\n\nfunction serializeError(src, type, cause) {\n  return throwError('serialize', src, type, cause);\n}\n\n// 4.1.9.  Serializing a Boolean\n//\n// Given a Boolean as input_boolean, return an ASCII string suitable for\n// use in a HTTP field value.\n//\n// 1.  If input_boolean is not a boolean, fail serialization.\n//\n// 2.  Let output be an empty string.\n//\n// 3.  Append \"?\" to output.\n//\n// 4.  If input_boolean is true, append \"1\" to output.\n//\n// 5.  If input_boolean is false, append \"0\" to output.\n//\n// 6.  Return output.\nfunction serializeBoolean(value) {\n  if (typeof value !== 'boolean') {\n    throw serializeError(value, BOOLEAN);\n  }\n  return value ? '?1' : '?0';\n}\n\n/**\n * Encodes binary data to base64\n *\n * @param binary - The binary data to encode\n * @returns The base64 encoded string\n *\n * @group Utils\n *\n * @beta\n */\nfunction base64encode(binary) {\n  return btoa(String.fromCharCode(...binary));\n}\n\n// 4.1.8.  Serializing a Byte Sequence\n//\n// Given a Byte Sequence as input_bytes, return an ASCII string suitable\n// for use in a HTTP field value.\n//\n// 1.  If input_bytes is not a sequence of bytes, fail serialization.\n//\n// 2.  Let output be an empty string.\n//\n// 3.  Append \":\" to output.\n//\n// 4.  Append the result of base64-encoding input_bytes as per\n//     [RFC4648], Section 4, taking account of the requirements below.\n//\n// 5.  Append \":\" to output.\n//\n// 6.  Return output.\n//\n// The encoded data is required to be padded with \"=\", as per [RFC4648],\n// Section 3.2.\n//\n// Likewise, encoded data SHOULD have pad bits set to zero, as per\n// [RFC4648], Section 3.5, unless it is not possible to do so due to\n// implementation constraints.\nfunction serializeByteSequence(value) {\n  if (ArrayBuffer.isView(value) === false) {\n    throw serializeError(value, BYTES);\n  }\n  return `:${base64encode(value)}:`;\n}\n\n// 4.1.4.  Serializing an Integer\n//\n// Given an Integer as input_integer, return an ASCII string suitable\n// for use in a HTTP field value.\n//\n// 1.  If input_integer is not an integer in the range of\n//     -999,999,999,999,999 to 999,999,999,999,999 inclusive, fail\n//     serialization.\n//\n// 2.  Let output be an empty string.\n//\n// 3.  If input_integer is less than (but not equal to) 0, append \"-\" to\n//     output.\n//\n// 4.  Append input_integer's numeric value represented in base 10 using\n//     only decimal digits to output.\n//\n// 5.  Return output.\nfunction serializeInteger(value) {\n  if (isInvalidInt(value)) {\n    throw serializeError(value, INTEGER);\n  }\n  return value.toString();\n}\n\n// 4.1.10.  Serializing a Date\n//\n// Given a Date as input_integer, return an ASCII string suitable for\n// use in an HTTP field value.\n// 1.  Let output be \"@\".\n// 2.  Append to output the result of running Serializing an Integer\n//     with input_date (Section 4.1.4).\n// 3.  Return output.\nfunction serializeDate(value) {\n  return `@${serializeInteger(value.getTime() / 1000)}`;\n}\n\n/**\n * This implements the rounding procedure described in step 2 of the \"Serializing a Decimal\" specification.\n * This rounding style is known as \"even rounding\", \"banker's rounding\", or \"commercial rounding\".\n *\n * @param value - The value to round\n * @param precision - The number of decimal places to round to\n * @returns The rounded value\n *\n * @group Utils\n *\n * @beta\n */\nfunction roundToEven(value, precision) {\n  if (value < 0) {\n    return -roundToEven(-value, precision);\n  }\n  const decimalShift = Math.pow(10, precision);\n  const isEquidistant = Math.abs(value * decimalShift % 1 - 0.5) < Number.EPSILON;\n  if (isEquidistant) {\n    // If the tail of the decimal place is 'equidistant' we round to the nearest even value\n    const flooredValue = Math.floor(value * decimalShift);\n    return (flooredValue % 2 === 0 ? flooredValue : flooredValue + 1) / decimalShift;\n  } else {\n    // Otherwise, proceed as normal\n    return Math.round(value * decimalShift) / decimalShift;\n  }\n}\n\n// 4.1.5.  Serializing a Decimal\n//\n// Given a decimal number as input_decimal, return an ASCII string\n// suitable for use in a HTTP field value.\n//\n// 1.   If input_decimal is not a decimal number, fail serialization.\n//\n// 2.   If input_decimal has more than three significant digits to the\n//      right of the decimal point, round it to three decimal places,\n//      rounding the final digit to the nearest value, or to the even\n//      value if it is equidistant.\n//\n// 3.   If input_decimal has more than 12 significant digits to the left\n//      of the decimal point after rounding, fail serialization.\n//\n// 4.   Let output be an empty string.\n//\n// 5.   If input_decimal is less than (but not equal to) 0, append \"-\"\n//      to output.\n//\n// 6.   Append input_decimal's integer component represented in base 10\n//      (using only decimal digits) to output; if it is zero, append\n//      \"0\".\n//\n// 7.   Append \".\" to output.\n//\n// 8.   If input_decimal's fractional component is zero, append \"0\" to\n//      output.\n//\n// 9.   Otherwise, append the significant digits of input_decimal's\n//      fractional component represented in base 10 (using only decimal\n//      digits) to output.\n//\n// 10.  Return output.\nfunction serializeDecimal(value) {\n  const roundedValue = roundToEven(value, 3); // round to 3 decimal places\n  if (Math.floor(Math.abs(roundedValue)).toString().length > 12) {\n    throw serializeError(value, DECIMAL);\n  }\n  const stringValue = roundedValue.toString();\n  return stringValue.includes('.') ? stringValue : `${stringValue}.0`;\n}\n\nconst STRING = 'String';\n\n// 4.1.6.  Serializing a String\n//\n// Given a String as input_string, return an ASCII string suitable for\n// use in a HTTP field value.\n//\n// 1.  Convert input_string into a sequence of ASCII characters; if\n//     conversion fails, fail serialization.\n//\n// 2.  If input_string contains characters in the range %x00-1f or %x7f\n//     (i.e., not in VCHAR or SP), fail serialization.\n//\n// 3.  Let output be the string DQUOTE.\n//\n// 4.  For each character char in input_string:\n//\n//     1.  If char is \"\\\" or DQUOTE:\n//\n//         1.  Append \"\\\" to output.\n//\n//     2.  Append char to output.\n//\n// 5.  Append DQUOTE to output.\n//\n// 6.  Return output.\nfunction serializeString(value) {\n  if (STRING_REGEX.test(value)) {\n    throw serializeError(value, STRING);\n  }\n  return `\"${value.replace(/\\\\/g, `\\\\\\\\`).replace(/\"/g, `\\\\\"`)}\"`;\n}\n\nfunction symbolToStr(symbol) {\n  return symbol.description || symbol.toString().slice(7, -1);\n}\n\nfunction serializeToken(token) {\n  const value = symbolToStr(token);\n  if (/^([a-zA-Z*])([!#$%&'*+\\-.^_`|~\\w:/]*)$/.test(value) === false) {\n    throw serializeError(value, TOKEN);\n  }\n  return value;\n}\n\n// 4.1.3.1.  Serializing a Bare Item\n//\n// Given an Item as input_item, return an ASCII string suitable for use\n// in a HTTP field value.\n//\n// 1.  If input_item is an Integer, return the result of running\n//     Serializing an Integer (Section 4.1.4) with input_item.\n//\n// 2.  If input_item is a Decimal, return the result of running\n//     Serializing a Decimal (Section 4.1.5) with input_item.\n//\n// 3.  If input_item is a String, return the result of running\n//     Serializing a String (Section 4.1.6) with input_item.\n//\n// 4.  If input_item is a Token, return the result of running\n//     Serializing a Token (Section 4.1.7) with input_item.\n//\n// 5.  If input_item is a Boolean, return the result of running\n//     Serializing a Boolean (Section 4.1.9) with input_item.\n//\n// 6.  If input_item is a Byte Sequence, return the result of running\n//     Serializing a Byte Sequence (Section 4.1.8) with input_item.\n//\n// 7.  If input_item is a Date, return the result of running Serializing\n//     a Date (Section 4.1.10) with input_item.\n//\n// 8.  Otherwise, fail serialization.\nfunction serializeBareItem(value) {\n  switch (typeof value) {\n    case 'number':\n      if (!isFiniteNumber(value)) {\n        throw serializeError(value, BARE_ITEM);\n      }\n      if (Number.isInteger(value)) {\n        return serializeInteger(value);\n      }\n      return serializeDecimal(value);\n    case 'string':\n      return serializeString(value);\n    case 'symbol':\n      return serializeToken(value);\n    case 'boolean':\n      return serializeBoolean(value);\n    case 'object':\n      if (value instanceof Date) {\n        return serializeDate(value);\n      }\n      if (value instanceof Uint8Array) {\n        return serializeByteSequence(value);\n      }\n      if (value instanceof SfToken) {\n        return serializeToken(value);\n      }\n    default:\n      // fail\n      throw serializeError(value, BARE_ITEM);\n  }\n}\n\n// 4.1.1.3.  Serializing a Key\n//\n// Given a key as input_key, return an ASCII string suitable for use in\n// a HTTP field value.\n//\n// 1.  Convert input_key into a sequence of ASCII characters; if\n//     conversion fails, fail serialization.\n//\n// 2.  If input_key contains characters not in lcalpha, DIGIT, \"_\", \"-\",\n//     \".\", or \"*\" fail serialization.\n//\n// 3.  If the first character of input_key is not lcalpha or \"*\", fail\n//     serialization.\n//\n// 4.  Let output be an empty string.\n//\n// 5.  Append input_key to output.\n//\n// 6.  Return output.\nfunction serializeKey(value) {\n  if (/^[a-z*][a-z0-9\\-_.*]*$/.test(value) === false) {\n    throw serializeError(value, KEY);\n  }\n  return value;\n}\n\n// 4.1.1.2.  Serializing Parameters\n//\n// Given an ordered Dictionary as input_parameters (each member having a\n// param_name and a param_value), return an ASCII string suitable for\n// use in a HTTP field value.\n//\n// 1.  Let output be an empty string.\n//\n// 2.  For each param_name with a value of param_value in\n//     input_parameters:\n//\n//     1.  Append \";\" to output.\n//\n//     2.  Append the result of running Serializing a Key\n//         (Section 4.1.1.3) with param_name to output.\n//\n//     3.  If param_value is not Boolean true:\n//\n//         1.  Append \"=\" to output.\n//\n//         2.  Append the result of running Serializing a bare Item\n//             (Section 4.1.3.1) with param_value to output.\n//\n// 3.  Return output.\nfunction serializeParams(params) {\n  if (params == null) {\n    return '';\n  }\n  return Object.entries(params).map(([key, value]) => {\n    if (value === true) {\n      return `;${serializeKey(key)}`; // omit true\n    }\n    return `;${serializeKey(key)}=${serializeBareItem(value)}`;\n  }).join('');\n}\n\n// 4.1.3.  Serializing an Item\n//\n// Given an Item as bare_item and Parameters as item_parameters, return\n// an ASCII string suitable for use in a HTTP field value.\n//\n// 1.  Let output be an empty string.\n//\n// 2.  Append the result of running Serializing a Bare Item\n//     Section 4.1.3.1 with bare_item to output.\n//\n// 3.  Append the result of running Serializing Parameters\n//     Section 4.1.1.2 with item_parameters to output.\n//\n// 4.  Return output.\nfunction serializeItem(value) {\n  if (value instanceof SfItem) {\n    return `${serializeBareItem(value.value)}${serializeParams(value.params)}`;\n  } else {\n    return serializeBareItem(value);\n  }\n}\n\n// 4.1.1.1.  Serializing an Inner List\n//\n// Given an array of (member_value, parameters) tuples as inner_list,\n// and parameters as list_parameters, return an ASCII string suitable\n// for use in a HTTP field value.\n//\n// 1.  Let output be the string \"(\".\n//\n// 2.  For each (member_value, parameters) of inner_list:\n//\n//     1.  Append the result of running Serializing an Item\n//         (Section 4.1.3) with (member_value, parameters) to output.\n//\n//     2.  If more values remain in inner_list, append a single SP to\n//         output.\n//\n// 3.  Append \")\" to output.\n//\n// 4.  Append the result of running Serializing Parameters\n//     (Section 4.1.1.2) with list_parameters to output.\n//\n// 5.  Return output.\nfunction serializeInnerList(value) {\n  return `(${value.value.map(serializeItem).join(' ')})${serializeParams(value.params)}`;\n}\n\n// 4.1.2.  Serializing a Dictionary\n//\n// Given an ordered Dictionary as input_dictionary (each member having a\n// member_name and a tuple value of (member_value, parameters)), return\n// an ASCII string suitable for use in a HTTP field value.\n//\n// 1.  Let output be an empty string.\n//\n// 2.  For each member_name with a value of (member_value, parameters)\n//     in input_dictionary:\n//\n//     1.  Append the result of running Serializing a Key\n//         (Section 4.1.1.3) with member's member_name to output.\n//\n//     2.  If member_value is Boolean true:\n//\n//         1.  Append the result of running Serializing Parameters\n//             (Section 4.1.1.2) with parameters to output.\n//\n//     3.  Otherwise:\n//\n//         1.  Append \"=\" to output.\n//\n//         2.  If member_value is an array, append the result of running\n//             Serializing an Inner List (Section 4.1.1.1) with\n//             (member_value, parameters) to output.\n//\n//         3.  Otherwise, append the result of running Serializing an\n//             Item (Section 4.1.3) with (member_value, parameters) to\n//             output.\n//\n//     4.  If more members remain in input_dictionary:\n//\n//         1.  Append \",\" to output.\n//\n//         2.  Append a single SP to output.\n//\n// 3.  Return output.\nfunction serializeDict(dict, options = {\n  whitespace: true\n}) {\n  if (typeof dict !== 'object') {\n    throw serializeError(dict, DICT);\n  }\n  const entries = dict instanceof Map ? dict.entries() : Object.entries(dict);\n  const optionalWhiteSpace = options != null && options.whitespace ? ' ' : '';\n  return Array.from(entries).map(([key, item]) => {\n    if (item instanceof SfItem === false) {\n      item = new SfItem(item);\n    }\n    let output = serializeKey(key);\n    if (item.value === true) {\n      output += serializeParams(item.params);\n    } else {\n      output += '=';\n      if (Array.isArray(item.value)) {\n        output += serializeInnerList(item);\n      } else {\n        output += serializeItem(item);\n      }\n    }\n    return output;\n  }).join(`,${optionalWhiteSpace}`);\n}\n\n/**\n * Encode an object into a structured field dictionary\n *\n * @param input - The structured field dictionary to encode\n * @returns The structured field string\n *\n * @group Structured Field\n *\n * @beta\n */\nfunction encodeSfDict(value, options) {\n  return serializeDict(value, options);\n}\n\n/**\n * Checks if the given key is a token field.\n *\n * @param key - The key to check.\n *\n * @returns `true` if the key is a token field.\n *\n * @internal\n *\n * @group CMCD\n */\nconst isTokenField = key => key === 'ot' || key === 'sf' || key === 'st';\n\nconst isValid = value => {\n  if (typeof value === 'number') {\n    return isFiniteNumber(value);\n  }\n  return value != null && value !== '' && value !== false;\n};\n\n/**\n * Constructs a relative path from a URL.\n *\n * @param url - The destination URL\n * @param base - The base URL\n * @returns The relative path\n *\n * @group Utils\n *\n * @beta\n */\nfunction urlToRelativePath(url, base) {\n  const to = new URL(url);\n  const from = new URL(base);\n  if (to.origin !== from.origin) {\n    return url;\n  }\n  const toPath = to.pathname.split('/').slice(1);\n  const fromPath = from.pathname.split('/').slice(1, -1);\n  // remove common parents\n  while (toPath[0] === fromPath[0]) {\n    toPath.shift();\n    fromPath.shift();\n  }\n  // add back paths\n  while (fromPath.length) {\n    fromPath.shift();\n    toPath.unshift('..');\n  }\n  return toPath.join('/');\n}\n\n/**\n * Generate a random v4 UUID\n *\n * @returns A random v4 UUID\n *\n * @group Utils\n *\n * @beta\n */\nfunction uuid() {\n  try {\n    return crypto.randomUUID();\n  } catch (error) {\n    try {\n      const url = URL.createObjectURL(new Blob());\n      const uuid = url.toString();\n      URL.revokeObjectURL(url);\n      return uuid.slice(uuid.lastIndexOf('/') + 1);\n    } catch (error) {\n      let dt = new Date().getTime();\n      const uuid = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, c => {\n        const r = (dt + Math.random() * 16) % 16 | 0;\n        dt = Math.floor(dt / 16);\n        return (c == 'x' ? r : r & 0x3 | 0x8).toString(16);\n      });\n      return uuid;\n    }\n  }\n}\n\nconst toRounded = value => Math.round(value);\nconst toUrlSafe = (value, options) => {\n  if (options != null && options.baseUrl) {\n    value = urlToRelativePath(value, options.baseUrl);\n  }\n  return encodeURIComponent(value);\n};\nconst toHundred = value => toRounded(value / 100) * 100;\n/**\n * The default formatters for CMCD values.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CmcdFormatters = {\n  /**\n   * Bitrate (kbps) rounded integer\n   */\n  br: toRounded,\n  /**\n   * Duration (milliseconds) rounded integer\n   */\n  d: toRounded,\n  /**\n   * Buffer Length (milliseconds) rounded nearest 100ms\n   */\n  bl: toHundred,\n  /**\n   * Deadline (milliseconds) rounded nearest 100ms\n   */\n  dl: toHundred,\n  /**\n   * Measured Throughput (kbps) rounded nearest 100kbps\n   */\n  mtp: toHundred,\n  /**\n   * Next Object Request URL encoded\n   */\n  nor: toUrlSafe,\n  /**\n   * Requested maximum throughput (kbps) rounded nearest 100kbps\n   */\n  rtp: toHundred,\n  /**\n   * Top Bitrate (kbps) rounded integer\n   */\n  tb: toRounded\n};\n\n/**\n * Internal CMCD processing function.\n *\n * @param obj - The CMCD object to process.\n * @param map - The mapping function to use.\n * @param options - Options for encoding.\n *\n * @internal\n *\n * @group CMCD\n */\nfunction processCmcd(obj, options) {\n  const results = {};\n  if (obj == null || typeof obj !== 'object') {\n    return results;\n  }\n  const keys = Object.keys(obj).sort();\n  const formatters = _extends({}, CmcdFormatters, options == null ? void 0 : options.formatters);\n  const filter = options == null ? void 0 : options.filter;\n  keys.forEach(key => {\n    if (filter != null && filter(key)) {\n      return;\n    }\n    let value = obj[key];\n    const formatter = formatters[key];\n    if (formatter) {\n      value = formatter(value, options);\n    }\n    // Version should only be reported if not equal to 1.\n    if (key === 'v' && value === 1) {\n      return;\n    }\n    // Playback rate should only be sent if not equal to 1.\n    if (key == 'pr' && value === 1) {\n      return;\n    }\n    // ignore invalid values\n    if (!isValid(value)) {\n      return;\n    }\n    if (isTokenField(key) && typeof value === 'string') {\n      value = new SfToken(value);\n    }\n    results[key] = value;\n  });\n  return results;\n}\n\n/**\n * Encode a CMCD object to a string.\n *\n * @param cmcd - The CMCD object to encode.\n * @param options - Options for encoding.\n *\n * @returns The encoded CMCD string.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction encodeCmcd(cmcd, options = {}) {\n  if (!cmcd) {\n    return '';\n  }\n  return encodeSfDict(processCmcd(cmcd, options), _extends({\n    whitespace: false\n  }, options));\n}\n\n/**\n * Convert a CMCD data object to request headers\n *\n * @param cmcd - The CMCD data object to convert.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The CMCD header shards.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction toCmcdHeaders(cmcd, options = {}) {\n  if (!cmcd) {\n    return {};\n  }\n  const entries = Object.entries(cmcd);\n  const headerMap = Object.entries(CmcdHeaderMap).concat(Object.entries((options == null ? void 0 : options.customHeaderMap) || {}));\n  const shards = entries.reduce((acc, entry) => {\n    var _headerMap$find, _acc$field;\n    const [key, value] = entry;\n    const field = ((_headerMap$find = headerMap.find(entry => entry[1].includes(key))) == null ? void 0 : _headerMap$find[0]) || CmcdHeaderField.REQUEST;\n    (_acc$field = acc[field]) != null ? _acc$field : acc[field] = {};\n    acc[field][key] = value;\n    return acc;\n  }, {});\n  return Object.entries(shards).reduce((acc, [field, value]) => {\n    acc[field] = encodeCmcd(value, options);\n    return acc;\n  }, {});\n}\n\n/**\n * Append CMCD query args to a header object.\n *\n * @param headers - The headers to append to.\n * @param cmcd - The CMCD object to append.\n * @param customHeaderMap - A map of custom CMCD keys to header fields.\n *\n * @returns The headers with the CMCD header shards appended.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction appendCmcdHeaders(headers, cmcd, options) {\n  return _extends(headers, toCmcdHeaders(cmcd, options));\n}\n\n/**\n * CMCD parameter name.\n *\n * @group CMCD\n *\n * @beta\n */\nconst CMCD_PARAM = 'CMCD';\n\n/**\n * Convert a CMCD data object to a query arg.\n *\n * @param cmcd - The CMCD object to convert.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The CMCD query arg.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction toCmcdQuery(cmcd, options = {}) {\n  if (!cmcd) {\n    return '';\n  }\n  const params = encodeCmcd(cmcd, options);\n  return `${CMCD_PARAM}=${encodeURIComponent(params)}`;\n}\n\nconst REGEX = /CMCD=[^&#]+/;\n/**\n * Append CMCD query args to a URL.\n *\n * @param url - The URL to append to.\n * @param cmcd - The CMCD object to append.\n * @param options - Options for encoding the CMCD object.\n *\n * @returns The URL with the CMCD query args appended.\n *\n * @group CMCD\n *\n * @beta\n */\nfunction appendCmcdQuery(url, cmcd, options) {\n  // TODO: Replace with URLSearchParams once we drop Safari < 10.1 & Chrome < 49 support.\n  // https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams\n  const query = toCmcdQuery(cmcd, options);\n  if (!query) {\n    return url;\n  }\n  if (REGEX.test(url)) {\n    return url.replace(REGEX, query);\n  }\n  const separator = url.includes('?') ? '&' : '?';\n  return `${url}${separator}${query}`;\n}\n\n/**\n * Controller to deal with Common Media Client Data (CMCD)\n * @see https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf\n */\nclass CMCDController {\n  // eslint-disable-line no-restricted-globals\n\n  constructor(hls) {\n    this.hls = void 0;\n    this.config = void 0;\n    this.media = void 0;\n    this.sid = void 0;\n    this.cid = void 0;\n    this.useHeaders = false;\n    this.includeKeys = void 0;\n    this.initialized = false;\n    this.starved = false;\n    this.buffering = true;\n    this.audioBuffer = void 0;\n    // eslint-disable-line no-restricted-globals\n    this.videoBuffer = void 0;\n    this.onWaiting = () => {\n      if (this.initialized) {\n        this.starved = true;\n      }\n      this.buffering = true;\n    };\n    this.onPlaying = () => {\n      if (!this.initialized) {\n        this.initialized = true;\n      }\n      this.buffering = false;\n    };\n    /**\n     * Apply CMCD data to a manifest request.\n     */\n    this.applyPlaylistData = context => {\n      try {\n        this.apply(context, {\n          ot: CmObjectType.MANIFEST,\n          su: !this.initialized\n        });\n      } catch (error) {\n        logger.warn('Could not generate manifest CMCD data.', error);\n      }\n    };\n    /**\n     * Apply CMCD data to a segment request\n     */\n    this.applyFragmentData = context => {\n      try {\n        const fragment = context.frag;\n        const level = this.hls.levels[fragment.level];\n        const ot = this.getObjectType(fragment);\n        const data = {\n          d: fragment.duration * 1000,\n          ot\n        };\n        if (ot === CmObjectType.VIDEO || ot === CmObjectType.AUDIO || ot == CmObjectType.MUXED) {\n          data.br = level.bitrate / 1000;\n          data.tb = this.getTopBandwidth(ot) / 1000;\n          data.bl = this.getBufferLength(ot);\n        }\n        this.apply(context, data);\n      } catch (error) {\n        logger.warn('Could not generate segment CMCD data.', error);\n      }\n    };\n    this.hls = hls;\n    const config = this.config = hls.config;\n    const {\n      cmcd\n    } = config;\n    if (cmcd != null) {\n      config.pLoader = this.createPlaylistLoader();\n      config.fLoader = this.createFragmentLoader();\n      this.sid = cmcd.sessionId || uuid();\n      this.cid = cmcd.contentId;\n      this.useHeaders = cmcd.useHeaders === true;\n      this.includeKeys = cmcd.includeKeys;\n      this.registerListeners();\n    }\n  }\n  registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.onMediaDetached();\n\n    // @ts-ignore\n    this.hls = this.config = this.audioBuffer = this.videoBuffer = null;\n    // @ts-ignore\n    this.onWaiting = this.onPlaying = null;\n  }\n  onMediaAttached(event, data) {\n    this.media = data.media;\n    this.media.addEventListener('waiting', this.onWaiting);\n    this.media.addEventListener('playing', this.onPlaying);\n  }\n  onMediaDetached() {\n    if (!this.media) {\n      return;\n    }\n    this.media.removeEventListener('waiting', this.onWaiting);\n    this.media.removeEventListener('playing', this.onPlaying);\n\n    // @ts-ignore\n    this.media = null;\n  }\n  onBufferCreated(event, data) {\n    var _data$tracks$audio, _data$tracks$video;\n    this.audioBuffer = (_data$tracks$audio = data.tracks.audio) == null ? void 0 : _data$tracks$audio.buffer;\n    this.videoBuffer = (_data$tracks$video = data.tracks.video) == null ? void 0 : _data$tracks$video.buffer;\n  }\n  /**\n   * Create baseline CMCD data\n   */\n  createData() {\n    var _this$media;\n    return {\n      v: 1,\n      sf: CmStreamingFormat.HLS,\n      sid: this.sid,\n      cid: this.cid,\n      pr: (_this$media = this.media) == null ? void 0 : _this$media.playbackRate,\n      mtp: this.hls.bandwidthEstimate / 1000\n    };\n  }\n\n  /**\n   * Apply CMCD data to a request.\n   */\n  apply(context, data = {}) {\n    // apply baseline data\n    _extends(data, this.createData());\n    const isVideo = data.ot === CmObjectType.INIT || data.ot === CmObjectType.VIDEO || data.ot === CmObjectType.MUXED;\n    if (this.starved && isVideo) {\n      data.bs = true;\n      data.su = true;\n      this.starved = false;\n    }\n    if (data.su == null) {\n      data.su = this.buffering;\n    }\n\n    // TODO: Implement rtp, nrr, nor, dl\n\n    const {\n      includeKeys\n    } = this;\n    if (includeKeys) {\n      data = Object.keys(data).reduce((acc, key) => {\n        includeKeys.includes(key) && (acc[key] = data[key]);\n        return acc;\n      }, {});\n    }\n    if (this.useHeaders) {\n      if (!context.headers) {\n        context.headers = {};\n      }\n      appendCmcdHeaders(context.headers, data);\n    } else {\n      context.url = appendCmcdQuery(context.url, data);\n    }\n  }\n  /**\n   * The CMCD object type.\n   */\n  getObjectType(fragment) {\n    const {\n      type\n    } = fragment;\n    if (type === 'subtitle') {\n      return CmObjectType.TIMED_TEXT;\n    }\n    if (fragment.sn === 'initSegment') {\n      return CmObjectType.INIT;\n    }\n    if (type === 'audio') {\n      return CmObjectType.AUDIO;\n    }\n    if (type === 'main') {\n      if (!this.hls.audioTracks.length) {\n        return CmObjectType.MUXED;\n      }\n      return CmObjectType.VIDEO;\n    }\n    return undefined;\n  }\n\n  /**\n   * Get the highest bitrate.\n   */\n  getTopBandwidth(type) {\n    let bitrate = 0;\n    let levels;\n    const hls = this.hls;\n    if (type === CmObjectType.AUDIO) {\n      levels = hls.audioTracks;\n    } else {\n      const max = hls.maxAutoLevel;\n      const len = max > -1 ? max + 1 : hls.levels.length;\n      levels = hls.levels.slice(0, len);\n    }\n    for (const level of levels) {\n      if (level.bitrate > bitrate) {\n        bitrate = level.bitrate;\n      }\n    }\n    return bitrate > 0 ? bitrate : NaN;\n  }\n\n  /**\n   * Get the buffer length for a media type in milliseconds\n   */\n  getBufferLength(type) {\n    const media = this.hls.media;\n    const buffer = type === CmObjectType.AUDIO ? this.audioBuffer : this.videoBuffer;\n    if (!buffer || !media) {\n      return NaN;\n    }\n    const info = BufferHelper.bufferInfo(buffer, media.currentTime, this.config.maxBufferHole);\n    return info.len * 1000;\n  }\n\n  /**\n   * Create a playlist loader\n   */\n  createPlaylistLoader() {\n    const {\n      pLoader\n    } = this.config;\n    const apply = this.applyPlaylistData;\n    const Ctor = pLoader || this.config.loader;\n    return class CmcdPlaylistLoader {\n      constructor(config) {\n        this.loader = void 0;\n        this.loader = new Ctor(config);\n      }\n      get stats() {\n        return this.loader.stats;\n      }\n      get context() {\n        return this.loader.context;\n      }\n      destroy() {\n        this.loader.destroy();\n      }\n      abort() {\n        this.loader.abort();\n      }\n      load(context, config, callbacks) {\n        apply(context);\n        this.loader.load(context, config, callbacks);\n      }\n    };\n  }\n\n  /**\n   * Create a playlist loader\n   */\n  createFragmentLoader() {\n    const {\n      fLoader\n    } = this.config;\n    const apply = this.applyFragmentData;\n    const Ctor = fLoader || this.config.loader;\n    return class CmcdFragmentLoader {\n      constructor(config) {\n        this.loader = void 0;\n        this.loader = new Ctor(config);\n      }\n      get stats() {\n        return this.loader.stats;\n      }\n      get context() {\n        return this.loader.context;\n      }\n      destroy() {\n        this.loader.destroy();\n      }\n      abort() {\n        this.loader.abort();\n      }\n      load(context, config, callbacks) {\n        apply(context);\n        this.loader.load(context, config, callbacks);\n      }\n    };\n  }\n}\n\nconst PATHWAY_PENALTY_DURATION_MS = 300000;\nclass ContentSteeringController {\n  constructor(hls) {\n    this.hls = void 0;\n    this.log = void 0;\n    this.loader = null;\n    this.uri = null;\n    this.pathwayId = '.';\n    this.pathwayPriority = null;\n    this.timeToLoad = 300;\n    this.reloadTimer = -1;\n    this.updated = 0;\n    this.started = false;\n    this.enabled = true;\n    this.levels = null;\n    this.audioTracks = null;\n    this.subtitleTracks = null;\n    this.penalizedPathways = {};\n    this.hls = hls;\n    this.log = logger.log.bind(logger, `[content-steering]:`);\n    this.registerListeners();\n  }\n  registerListeners() {\n    const hls = this.hls;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  unregisterListeners() {\n    const hls = this.hls;\n    if (!hls) {\n      return;\n    }\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  startLoad() {\n    this.started = true;\n    this.clearTimeout();\n    if (this.enabled && this.uri) {\n      if (this.updated) {\n        const ttl = this.timeToLoad * 1000 - (performance.now() - this.updated);\n        if (ttl > 0) {\n          this.scheduleRefresh(this.uri, ttl);\n          return;\n        }\n      }\n      this.loadSteeringManifest(this.uri);\n    }\n  }\n  stopLoad() {\n    this.started = false;\n    if (this.loader) {\n      this.loader.destroy();\n      this.loader = null;\n    }\n    this.clearTimeout();\n  }\n  clearTimeout() {\n    if (this.reloadTimer !== -1) {\n      self.clearTimeout(this.reloadTimer);\n      this.reloadTimer = -1;\n    }\n  }\n  destroy() {\n    this.unregisterListeners();\n    this.stopLoad();\n    // @ts-ignore\n    this.hls = null;\n    this.levels = this.audioTracks = this.subtitleTracks = null;\n  }\n  removeLevel(levelToRemove) {\n    const levels = this.levels;\n    if (levels) {\n      this.levels = levels.filter(level => level !== levelToRemove);\n    }\n  }\n  onManifestLoading() {\n    this.stopLoad();\n    this.enabled = true;\n    this.timeToLoad = 300;\n    this.updated = 0;\n    this.uri = null;\n    this.pathwayId = '.';\n    this.levels = this.audioTracks = this.subtitleTracks = null;\n  }\n  onManifestLoaded(event, data) {\n    const {\n      contentSteering\n    } = data;\n    if (contentSteering === null) {\n      return;\n    }\n    this.pathwayId = contentSteering.pathwayId;\n    this.uri = contentSteering.uri;\n    if (this.started) {\n      this.startLoad();\n    }\n  }\n  onManifestParsed(event, data) {\n    this.audioTracks = data.audioTracks;\n    this.subtitleTracks = data.subtitleTracks;\n  }\n  onError(event, data) {\n    const {\n      errorAction\n    } = data;\n    if ((errorAction == null ? void 0 : errorAction.action) === NetworkErrorAction.SendAlternateToPenaltyBox && errorAction.flags === ErrorActionFlags.MoveAllAlternatesMatchingHost) {\n      const levels = this.levels;\n      let pathwayPriority = this.pathwayPriority;\n      let errorPathway = this.pathwayId;\n      if (data.context) {\n        const {\n          groupId,\n          pathwayId,\n          type\n        } = data.context;\n        if (groupId && levels) {\n          errorPathway = this.getPathwayForGroupId(groupId, type, errorPathway);\n        } else if (pathwayId) {\n          errorPathway = pathwayId;\n        }\n      }\n      if (!(errorPathway in this.penalizedPathways)) {\n        this.penalizedPathways[errorPathway] = performance.now();\n      }\n      if (!pathwayPriority && levels) {\n        // If PATHWAY-PRIORITY was not provided, list pathways for error handling\n        pathwayPriority = levels.reduce((pathways, level) => {\n          if (pathways.indexOf(level.pathwayId) === -1) {\n            pathways.push(level.pathwayId);\n          }\n          return pathways;\n        }, []);\n      }\n      if (pathwayPriority && pathwayPriority.length > 1) {\n        this.updatePathwayPriority(pathwayPriority);\n        errorAction.resolved = this.pathwayId !== errorPathway;\n      }\n      if (!errorAction.resolved) {\n        logger.warn(`Could not resolve ${data.details} (\"${data.error.message}\") with content-steering for Pathway: ${errorPathway} levels: ${levels ? levels.length : levels} priorities: ${JSON.stringify(pathwayPriority)} penalized: ${JSON.stringify(this.penalizedPathways)}`);\n      }\n    }\n  }\n  filterParsedLevels(levels) {\n    // Filter levels to only include those that are in the initial pathway\n    this.levels = levels;\n    let pathwayLevels = this.getLevelsForPathway(this.pathwayId);\n    if (pathwayLevels.length === 0) {\n      const pathwayId = levels[0].pathwayId;\n      this.log(`No levels found in Pathway ${this.pathwayId}. Setting initial Pathway to \"${pathwayId}\"`);\n      pathwayLevels = this.getLevelsForPathway(pathwayId);\n      this.pathwayId = pathwayId;\n    }\n    if (pathwayLevels.length !== levels.length) {\n      this.log(`Found ${pathwayLevels.length}/${levels.length} levels in Pathway \"${this.pathwayId}\"`);\n      return pathwayLevels;\n    }\n    return levels;\n  }\n  getLevelsForPathway(pathwayId) {\n    if (this.levels === null) {\n      return [];\n    }\n    return this.levels.filter(level => pathwayId === level.pathwayId);\n  }\n  updatePathwayPriority(pathwayPriority) {\n    this.pathwayPriority = pathwayPriority;\n    let levels;\n\n    // Evaluate if we should remove the pathway from the penalized list\n    const penalizedPathways = this.penalizedPathways;\n    const now = performance.now();\n    Object.keys(penalizedPathways).forEach(pathwayId => {\n      if (now - penalizedPathways[pathwayId] > PATHWAY_PENALTY_DURATION_MS) {\n        delete penalizedPathways[pathwayId];\n      }\n    });\n    for (let i = 0; i < pathwayPriority.length; i++) {\n      const pathwayId = pathwayPriority[i];\n      if (pathwayId in penalizedPathways) {\n        continue;\n      }\n      if (pathwayId === this.pathwayId) {\n        return;\n      }\n      const selectedIndex = this.hls.nextLoadLevel;\n      const selectedLevel = this.hls.levels[selectedIndex];\n      levels = this.getLevelsForPathway(pathwayId);\n      if (levels.length > 0) {\n        this.log(`Setting Pathway to \"${pathwayId}\"`);\n        this.pathwayId = pathwayId;\n        reassignFragmentLevelIndexes(levels);\n        this.hls.trigger(Events.LEVELS_UPDATED, {\n          levels\n        });\n        // Set LevelController's level to trigger LEVEL_SWITCHING which loads playlist if needed\n        const levelAfterChange = this.hls.levels[selectedIndex];\n        if (selectedLevel && levelAfterChange && this.levels) {\n          if (levelAfterChange.attrs['STABLE-VARIANT-ID'] !== selectedLevel.attrs['STABLE-VARIANT-ID'] && levelAfterChange.bitrate !== selectedLevel.bitrate) {\n            this.log(`Unstable Pathways change from bitrate ${selectedLevel.bitrate} to ${levelAfterChange.bitrate}`);\n          }\n          this.hls.nextLoadLevel = selectedIndex;\n        }\n        break;\n      }\n    }\n  }\n  getPathwayForGroupId(groupId, type, defaultPathway) {\n    const levels = this.getLevelsForPathway(defaultPathway).concat(this.levels || []);\n    for (let i = 0; i < levels.length; i++) {\n      if (type === PlaylistContextType.AUDIO_TRACK && levels[i].hasAudioGroup(groupId) || type === PlaylistContextType.SUBTITLE_TRACK && levels[i].hasSubtitleGroup(groupId)) {\n        return levels[i].pathwayId;\n      }\n    }\n    return defaultPathway;\n  }\n  clonePathways(pathwayClones) {\n    const levels = this.levels;\n    if (!levels) {\n      return;\n    }\n    const audioGroupCloneMap = {};\n    const subtitleGroupCloneMap = {};\n    pathwayClones.forEach(pathwayClone => {\n      const {\n        ID: cloneId,\n        'BASE-ID': baseId,\n        'URI-REPLACEMENT': uriReplacement\n      } = pathwayClone;\n      if (levels.some(level => level.pathwayId === cloneId)) {\n        return;\n      }\n      const clonedVariants = this.getLevelsForPathway(baseId).map(baseLevel => {\n        const attributes = new AttrList(baseLevel.attrs);\n        attributes['PATHWAY-ID'] = cloneId;\n        const clonedAudioGroupId = attributes.AUDIO && `${attributes.AUDIO}_clone_${cloneId}`;\n        const clonedSubtitleGroupId = attributes.SUBTITLES && `${attributes.SUBTITLES}_clone_${cloneId}`;\n        if (clonedAudioGroupId) {\n          audioGroupCloneMap[attributes.AUDIO] = clonedAudioGroupId;\n          attributes.AUDIO = clonedAudioGroupId;\n        }\n        if (clonedSubtitleGroupId) {\n          subtitleGroupCloneMap[attributes.SUBTITLES] = clonedSubtitleGroupId;\n          attributes.SUBTITLES = clonedSubtitleGroupId;\n        }\n        const url = performUriReplacement(baseLevel.uri, attributes['STABLE-VARIANT-ID'], 'PER-VARIANT-URIS', uriReplacement);\n        const clonedLevel = new Level({\n          attrs: attributes,\n          audioCodec: baseLevel.audioCodec,\n          bitrate: baseLevel.bitrate,\n          height: baseLevel.height,\n          name: baseLevel.name,\n          url,\n          videoCodec: baseLevel.videoCodec,\n          width: baseLevel.width\n        });\n        if (baseLevel.audioGroups) {\n          for (let i = 1; i < baseLevel.audioGroups.length; i++) {\n            clonedLevel.addGroupId('audio', `${baseLevel.audioGroups[i]}_clone_${cloneId}`);\n          }\n        }\n        if (baseLevel.subtitleGroups) {\n          for (let i = 1; i < baseLevel.subtitleGroups.length; i++) {\n            clonedLevel.addGroupId('text', `${baseLevel.subtitleGroups[i]}_clone_${cloneId}`);\n          }\n        }\n        return clonedLevel;\n      });\n      levels.push(...clonedVariants);\n      cloneRenditionGroups(this.audioTracks, audioGroupCloneMap, uriReplacement, cloneId);\n      cloneRenditionGroups(this.subtitleTracks, subtitleGroupCloneMap, uriReplacement, cloneId);\n    });\n  }\n  loadSteeringManifest(uri) {\n    const config = this.hls.config;\n    const Loader = config.loader;\n    if (this.loader) {\n      this.loader.destroy();\n    }\n    this.loader = new Loader(config);\n    let url;\n    try {\n      url = new self.URL(uri);\n    } catch (error) {\n      this.enabled = false;\n      this.log(`Failed to parse Steering Manifest URI: ${uri}`);\n      return;\n    }\n    if (url.protocol !== 'data:') {\n      const throughput = (this.hls.bandwidthEstimate || config.abrEwmaDefaultEstimate) | 0;\n      url.searchParams.set('_HLS_pathway', this.pathwayId);\n      url.searchParams.set('_HLS_throughput', '' + throughput);\n    }\n    const context = {\n      responseType: 'json',\n      url: url.href\n    };\n    const loadPolicy = config.steeringManifestLoadPolicy.default;\n    const legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n    const loaderConfig = {\n      loadPolicy,\n      timeout: loadPolicy.maxLoadTimeMs,\n      maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n      retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n      maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0\n    };\n    const callbacks = {\n      onSuccess: (response, stats, context, networkDetails) => {\n        this.log(`Loaded steering manifest: \"${url}\"`);\n        const steeringData = response.data;\n        if (steeringData.VERSION !== 1) {\n          this.log(`Steering VERSION ${steeringData.VERSION} not supported!`);\n          return;\n        }\n        this.updated = performance.now();\n        this.timeToLoad = steeringData.TTL;\n        const {\n          'RELOAD-URI': reloadUri,\n          'PATHWAY-CLONES': pathwayClones,\n          'PATHWAY-PRIORITY': pathwayPriority\n        } = steeringData;\n        if (reloadUri) {\n          try {\n            this.uri = new self.URL(reloadUri, url).href;\n          } catch (error) {\n            this.enabled = false;\n            this.log(`Failed to parse Steering Manifest RELOAD-URI: ${reloadUri}`);\n            return;\n          }\n        }\n        this.scheduleRefresh(this.uri || context.url);\n        if (pathwayClones) {\n          this.clonePathways(pathwayClones);\n        }\n        const loadedSteeringData = {\n          steeringManifest: steeringData,\n          url: url.toString()\n        };\n        this.hls.trigger(Events.STEERING_MANIFEST_LOADED, loadedSteeringData);\n        if (pathwayPriority) {\n          this.updatePathwayPriority(pathwayPriority);\n        }\n      },\n      onError: (error, context, networkDetails, stats) => {\n        this.log(`Error loading steering manifest: ${error.code} ${error.text} (${context.url})`);\n        this.stopLoad();\n        if (error.code === 410) {\n          this.enabled = false;\n          this.log(`Steering manifest ${context.url} no longer available`);\n          return;\n        }\n        let ttl = this.timeToLoad * 1000;\n        if (error.code === 429) {\n          const loader = this.loader;\n          if (typeof (loader == null ? void 0 : loader.getResponseHeader) === 'function') {\n            const retryAfter = loader.getResponseHeader('Retry-After');\n            if (retryAfter) {\n              ttl = parseFloat(retryAfter) * 1000;\n            }\n          }\n          this.log(`Steering manifest ${context.url} rate limited`);\n          return;\n        }\n        this.scheduleRefresh(this.uri || context.url, ttl);\n      },\n      onTimeout: (stats, context, networkDetails) => {\n        this.log(`Timeout loading steering manifest (${context.url})`);\n        this.scheduleRefresh(this.uri || context.url);\n      }\n    };\n    this.log(`Requesting steering manifest: ${url}`);\n    this.loader.load(context, loaderConfig, callbacks);\n  }\n  scheduleRefresh(uri, ttlMs = this.timeToLoad * 1000) {\n    this.clearTimeout();\n    this.reloadTimer = self.setTimeout(() => {\n      var _this$hls;\n      const media = (_this$hls = this.hls) == null ? void 0 : _this$hls.media;\n      if (media && !media.ended) {\n        this.loadSteeringManifest(uri);\n        return;\n      }\n      this.scheduleRefresh(uri, this.timeToLoad * 1000);\n    }, ttlMs);\n  }\n}\nfunction cloneRenditionGroups(tracks, groupCloneMap, uriReplacement, cloneId) {\n  if (!tracks) {\n    return;\n  }\n  Object.keys(groupCloneMap).forEach(audioGroupId => {\n    const clonedTracks = tracks.filter(track => track.groupId === audioGroupId).map(track => {\n      const clonedTrack = _extends({}, track);\n      clonedTrack.details = undefined;\n      clonedTrack.attrs = new AttrList(clonedTrack.attrs);\n      clonedTrack.url = clonedTrack.attrs.URI = performUriReplacement(track.url, track.attrs['STABLE-RENDITION-ID'], 'PER-RENDITION-URIS', uriReplacement);\n      clonedTrack.groupId = clonedTrack.attrs['GROUP-ID'] = groupCloneMap[audioGroupId];\n      clonedTrack.attrs['PATHWAY-ID'] = cloneId;\n      return clonedTrack;\n    });\n    tracks.push(...clonedTracks);\n  });\n}\nfunction performUriReplacement(uri, stableId, perOptionKey, uriReplacement) {\n  const {\n    HOST: host,\n    PARAMS: params,\n    [perOptionKey]: perOptionUris\n  } = uriReplacement;\n  let perVariantUri;\n  if (stableId) {\n    perVariantUri = perOptionUris == null ? void 0 : perOptionUris[stableId];\n    if (perVariantUri) {\n      uri = perVariantUri;\n    }\n  }\n  const url = new self.URL(uri);\n  if (host && !perVariantUri) {\n    url.host = host;\n  }\n  if (params) {\n    Object.keys(params).sort().forEach(key => {\n      if (key) {\n        url.searchParams.set(key, params[key]);\n      }\n    });\n  }\n  return url.href;\n}\n\nconst AGE_HEADER_LINE_REGEX = /^age:\\s*[\\d.]+\\s*$/im;\nclass XhrLoader {\n  constructor(config) {\n    this.xhrSetup = void 0;\n    this.requestTimeout = void 0;\n    this.retryTimeout = void 0;\n    this.retryDelay = void 0;\n    this.config = null;\n    this.callbacks = null;\n    this.context = null;\n    this.loader = null;\n    this.stats = void 0;\n    this.xhrSetup = config ? config.xhrSetup || null : null;\n    this.stats = new LoadStats();\n    this.retryDelay = 0;\n  }\n  destroy() {\n    this.callbacks = null;\n    this.abortInternal();\n    this.loader = null;\n    this.config = null;\n    this.context = null;\n    this.xhrSetup = null;\n  }\n  abortInternal() {\n    const loader = this.loader;\n    self.clearTimeout(this.requestTimeout);\n    self.clearTimeout(this.retryTimeout);\n    if (loader) {\n      loader.onreadystatechange = null;\n      loader.onprogress = null;\n      if (loader.readyState !== 4) {\n        this.stats.aborted = true;\n        loader.abort();\n      }\n    }\n  }\n  abort() {\n    var _this$callbacks;\n    this.abortInternal();\n    if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {\n      this.callbacks.onAbort(this.stats, this.context, this.loader);\n    }\n  }\n  load(context, config, callbacks) {\n    if (this.stats.loading.start) {\n      throw new Error('Loader can only be used once.');\n    }\n    this.stats.loading.start = self.performance.now();\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.loadInternal();\n  }\n  loadInternal() {\n    const {\n      config,\n      context\n    } = this;\n    if (!config || !context) {\n      return;\n    }\n    const xhr = this.loader = new self.XMLHttpRequest();\n    const stats = this.stats;\n    stats.loading.first = 0;\n    stats.loaded = 0;\n    stats.aborted = false;\n    const xhrSetup = this.xhrSetup;\n    if (xhrSetup) {\n      Promise.resolve().then(() => {\n        if (this.loader !== xhr || this.stats.aborted) return;\n        return xhrSetup(xhr, context.url);\n      }).catch(error => {\n        if (this.loader !== xhr || this.stats.aborted) return;\n        xhr.open('GET', context.url, true);\n        return xhrSetup(xhr, context.url);\n      }).then(() => {\n        if (this.loader !== xhr || this.stats.aborted) return;\n        this.openAndSendXhr(xhr, context, config);\n      }).catch(error => {\n        // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\n        this.callbacks.onError({\n          code: xhr.status,\n          text: error.message\n        }, context, xhr, stats);\n        return;\n      });\n    } else {\n      this.openAndSendXhr(xhr, context, config);\n    }\n  }\n  openAndSendXhr(xhr, context, config) {\n    if (!xhr.readyState) {\n      xhr.open('GET', context.url, true);\n    }\n    const headers = context.headers;\n    const {\n      maxTimeToFirstByteMs,\n      maxLoadTimeMs\n    } = config.loadPolicy;\n    if (headers) {\n      for (const header in headers) {\n        xhr.setRequestHeader(header, headers[header]);\n      }\n    }\n    if (context.rangeEnd) {\n      xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));\n    }\n    xhr.onreadystatechange = this.readystatechange.bind(this);\n    xhr.onprogress = this.loadprogress.bind(this);\n    xhr.responseType = context.responseType;\n    // setup timeout before we perform request\n    self.clearTimeout(this.requestTimeout);\n    config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;\n    this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);\n    xhr.send();\n  }\n  readystatechange() {\n    const {\n      context,\n      loader: xhr,\n      stats\n    } = this;\n    if (!context || !xhr) {\n      return;\n    }\n    const readyState = xhr.readyState;\n    const config = this.config;\n\n    // don't proceed if xhr has been aborted\n    if (stats.aborted) {\n      return;\n    }\n\n    // >= HEADERS_RECEIVED\n    if (readyState >= 2) {\n      if (stats.loading.first === 0) {\n        stats.loading.first = Math.max(self.performance.now(), stats.loading.start);\n        // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet\n        if (config.timeout !== config.loadPolicy.maxLoadTimeMs) {\n          self.clearTimeout(this.requestTimeout);\n          config.timeout = config.loadPolicy.maxLoadTimeMs;\n          this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.loadPolicy.maxLoadTimeMs - (stats.loading.first - stats.loading.start));\n        }\n      }\n      if (readyState === 4) {\n        self.clearTimeout(this.requestTimeout);\n        xhr.onreadystatechange = null;\n        xhr.onprogress = null;\n        const status = xhr.status;\n        // http status between 200 to 299 are all successful\n        const useResponse = xhr.responseType !== 'text';\n        if (status >= 200 && status < 300 && (useResponse && xhr.response || xhr.responseText !== null)) {\n          stats.loading.end = Math.max(self.performance.now(), stats.loading.first);\n          const data = useResponse ? xhr.response : xhr.responseText;\n          const len = xhr.responseType === 'arraybuffer' ? data.byteLength : data.length;\n          stats.loaded = stats.total = len;\n          stats.bwEstimate = stats.total * 8000 / (stats.loading.end - stats.loading.first);\n          if (!this.callbacks) {\n            return;\n          }\n          const onProgress = this.callbacks.onProgress;\n          if (onProgress) {\n            onProgress(stats, context, data, xhr);\n          }\n          if (!this.callbacks) {\n            return;\n          }\n          const response = {\n            url: xhr.responseURL,\n            data: data,\n            code: status\n          };\n          this.callbacks.onSuccess(response, stats, context, xhr);\n        } else {\n          const retryConfig = config.loadPolicy.errorRetry;\n          const retryCount = stats.retry;\n          // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error\n          const response = {\n            url: context.url,\n            data: undefined,\n            code: status\n          };\n          if (shouldRetry(retryConfig, retryCount, false, response)) {\n            this.retry(retryConfig);\n          } else {\n            logger.error(`${status} while loading ${context.url}`);\n            this.callbacks.onError({\n              code: status,\n              text: xhr.statusText\n            }, context, xhr, stats);\n          }\n        }\n      }\n    }\n  }\n  loadtimeout() {\n    if (!this.config) return;\n    const retryConfig = this.config.loadPolicy.timeoutRetry;\n    const retryCount = this.stats.retry;\n    if (shouldRetry(retryConfig, retryCount, true)) {\n      this.retry(retryConfig);\n    } else {\n      var _this$context;\n      logger.warn(`timeout while loading ${(_this$context = this.context) == null ? void 0 : _this$context.url}`);\n      const callbacks = this.callbacks;\n      if (callbacks) {\n        this.abortInternal();\n        callbacks.onTimeout(this.stats, this.context, this.loader);\n      }\n    }\n  }\n  retry(retryConfig) {\n    const {\n      context,\n      stats\n    } = this;\n    this.retryDelay = getRetryDelay(retryConfig, stats.retry);\n    stats.retry++;\n    logger.warn(`${status ? 'HTTP Status ' + status : 'Timeout'} while loading ${context == null ? void 0 : context.url}, retrying ${stats.retry}/${retryConfig.maxNumRetry} in ${this.retryDelay}ms`);\n    // abort and reset internal state\n    this.abortInternal();\n    this.loader = null;\n    // schedule retry\n    self.clearTimeout(this.retryTimeout);\n    this.retryTimeout = self.setTimeout(this.loadInternal.bind(this), this.retryDelay);\n  }\n  loadprogress(event) {\n    const stats = this.stats;\n    stats.loaded = event.loaded;\n    if (event.lengthComputable) {\n      stats.total = event.total;\n    }\n  }\n  getCacheAge() {\n    let result = null;\n    if (this.loader && AGE_HEADER_LINE_REGEX.test(this.loader.getAllResponseHeaders())) {\n      const ageHeader = this.loader.getResponseHeader('age');\n      result = ageHeader ? parseFloat(ageHeader) : null;\n    }\n    return result;\n  }\n  getResponseHeader(name) {\n    if (this.loader && new RegExp(`^${name}:\\\\s*[\\\\d.]+\\\\s*$`, 'im').test(this.loader.getAllResponseHeaders())) {\n      return this.loader.getResponseHeader(name);\n    }\n    return null;\n  }\n}\n\nfunction fetchSupported() {\n  if (\n  // @ts-ignore\n  self.fetch && self.AbortController && self.ReadableStream && self.Request) {\n    try {\n      new self.ReadableStream({}); // eslint-disable-line no-new\n      return true;\n    } catch (e) {\n      /* noop */\n    }\n  }\n  return false;\n}\nconst BYTERANGE = /(\\d+)-(\\d+)\\/(\\d+)/;\nclass FetchLoader {\n  constructor(config /* HlsConfig */) {\n    this.fetchSetup = void 0;\n    this.requestTimeout = void 0;\n    this.request = null;\n    this.response = null;\n    this.controller = void 0;\n    this.context = null;\n    this.config = null;\n    this.callbacks = null;\n    this.stats = void 0;\n    this.loader = null;\n    this.fetchSetup = config.fetchSetup || getRequest;\n    this.controller = new self.AbortController();\n    this.stats = new LoadStats();\n  }\n  destroy() {\n    this.loader = this.callbacks = this.context = this.config = this.request = null;\n    this.abortInternal();\n    this.response = null;\n    // @ts-ignore\n    this.fetchSetup = this.controller = this.stats = null;\n  }\n  abortInternal() {\n    if (this.controller && !this.stats.loading.end) {\n      this.stats.aborted = true;\n      this.controller.abort();\n    }\n  }\n  abort() {\n    var _this$callbacks;\n    this.abortInternal();\n    if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {\n      this.callbacks.onAbort(this.stats, this.context, this.response);\n    }\n  }\n  load(context, config, callbacks) {\n    const stats = this.stats;\n    if (stats.loading.start) {\n      throw new Error('Loader can only be used once.');\n    }\n    stats.loading.start = self.performance.now();\n    const initParams = getRequestParameters(context, this.controller.signal);\n    const onProgress = callbacks.onProgress;\n    const isArrayBuffer = context.responseType === 'arraybuffer';\n    const LENGTH = isArrayBuffer ? 'byteLength' : 'length';\n    const {\n      maxTimeToFirstByteMs,\n      maxLoadTimeMs\n    } = config.loadPolicy;\n    this.context = context;\n    this.config = config;\n    this.callbacks = callbacks;\n    this.request = this.fetchSetup(context, initParams);\n    self.clearTimeout(this.requestTimeout);\n    config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;\n    this.requestTimeout = self.setTimeout(() => {\n      this.abortInternal();\n      callbacks.onTimeout(stats, context, this.response);\n    }, config.timeout);\n    self.fetch(this.request).then(response => {\n      this.response = this.loader = response;\n      const first = Math.max(self.performance.now(), stats.loading.start);\n      self.clearTimeout(this.requestTimeout);\n      config.timeout = maxLoadTimeMs;\n      this.requestTimeout = self.setTimeout(() => {\n        this.abortInternal();\n        callbacks.onTimeout(stats, context, this.response);\n      }, maxLoadTimeMs - (first - stats.loading.start));\n      if (!response.ok) {\n        const {\n          status,\n          statusText\n        } = response;\n        throw new FetchError(statusText || 'fetch, bad network response', status, response);\n      }\n      stats.loading.first = first;\n      stats.total = getContentLength(response.headers) || stats.total;\n      if (onProgress && isFiniteNumber(config.highWaterMark)) {\n        return this.loadProgressively(response, stats, context, config.highWaterMark, onProgress);\n      }\n      if (isArrayBuffer) {\n        return response.arrayBuffer();\n      }\n      if (context.responseType === 'json') {\n        return response.json();\n      }\n      return response.text();\n    }).then(responseData => {\n      const response = this.response;\n      if (!response) {\n        throw new Error('loader destroyed');\n      }\n      self.clearTimeout(this.requestTimeout);\n      stats.loading.end = Math.max(self.performance.now(), stats.loading.first);\n      const total = responseData[LENGTH];\n      if (total) {\n        stats.loaded = stats.total = total;\n      }\n      const loaderResponse = {\n        url: response.url,\n        data: responseData,\n        code: response.status\n      };\n      if (onProgress && !isFiniteNumber(config.highWaterMark)) {\n        onProgress(stats, context, responseData, response);\n      }\n      callbacks.onSuccess(loaderResponse, stats, context, response);\n    }).catch(error => {\n      self.clearTimeout(this.requestTimeout);\n      if (stats.aborted) {\n        return;\n      }\n      // CORS errors result in an undefined code. Set it to 0 here to align with XHR's behavior\n      // when destroying, 'error' itself can be undefined\n      const code = !error ? 0 : error.code || 0;\n      const text = !error ? null : error.message;\n      callbacks.onError({\n        code,\n        text\n      }, context, error ? error.details : null, stats);\n    });\n  }\n  getCacheAge() {\n    let result = null;\n    if (this.response) {\n      const ageHeader = this.response.headers.get('age');\n      result = ageHeader ? parseFloat(ageHeader) : null;\n    }\n    return result;\n  }\n  getResponseHeader(name) {\n    return this.response ? this.response.headers.get(name) : null;\n  }\n  loadProgressively(response, stats, context, highWaterMark = 0, onProgress) {\n    const chunkCache = new ChunkCache();\n    const reader = response.body.getReader();\n    const pump = () => {\n      return reader.read().then(data => {\n        if (data.done) {\n          if (chunkCache.dataLength) {\n            onProgress(stats, context, chunkCache.flush(), response);\n          }\n          return Promise.resolve(new ArrayBuffer(0));\n        }\n        const chunk = data.value;\n        const len = chunk.length;\n        stats.loaded += len;\n        if (len < highWaterMark || chunkCache.dataLength) {\n          // The current chunk is too small to to be emitted or the cache already has data\n          // Push it to the cache\n          chunkCache.push(chunk);\n          if (chunkCache.dataLength >= highWaterMark) {\n            // flush in order to join the typed arrays\n            onProgress(stats, context, chunkCache.flush(), response);\n          }\n        } else {\n          // If there's nothing cached already, and the chache is large enough\n          // just emit the progress event\n          onProgress(stats, context, chunk, response);\n        }\n        return pump();\n      }).catch(() => {\n        /* aborted */\n        return Promise.reject();\n      });\n    };\n    return pump();\n  }\n}\nfunction getRequestParameters(context, signal) {\n  const initParams = {\n    method: 'GET',\n    mode: 'cors',\n    credentials: 'same-origin',\n    signal,\n    headers: new self.Headers(_extends({}, context.headers))\n  };\n  if (context.rangeEnd) {\n    initParams.headers.set('Range', 'bytes=' + context.rangeStart + '-' + String(context.rangeEnd - 1));\n  }\n  return initParams;\n}\nfunction getByteRangeLength(byteRangeHeader) {\n  const result = BYTERANGE.exec(byteRangeHeader);\n  if (result) {\n    return parseInt(result[2]) - parseInt(result[1]) + 1;\n  }\n}\nfunction getContentLength(headers) {\n  const contentRange = headers.get('Content-Range');\n  if (contentRange) {\n    const byteRangeLength = getByteRangeLength(contentRange);\n    if (isFiniteNumber(byteRangeLength)) {\n      return byteRangeLength;\n    }\n  }\n  const contentLength = headers.get('Content-Length');\n  if (contentLength) {\n    return parseInt(contentLength);\n  }\n}\nfunction getRequest(context, initParams) {\n  return new self.Request(context.url, initParams);\n}\nclass FetchError extends Error {\n  constructor(message, code, details) {\n    super(message);\n    this.code = void 0;\n    this.details = void 0;\n    this.code = code;\n    this.details = details;\n  }\n}\n\nconst WHITESPACE_CHAR = /\\s/;\nconst Cues = {\n  newCue(track, startTime, endTime, captionScreen) {\n    const result = [];\n    let row;\n    // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers\n    let cue;\n    let indenting;\n    let indent;\n    let text;\n    const Cue = self.VTTCue || self.TextTrackCue;\n    for (let r = 0; r < captionScreen.rows.length; r++) {\n      row = captionScreen.rows[r];\n      indenting = true;\n      indent = 0;\n      text = '';\n      if (!row.isEmpty()) {\n        var _track$cues;\n        for (let c = 0; c < row.chars.length; c++) {\n          if (WHITESPACE_CHAR.test(row.chars[c].uchar) && indenting) {\n            indent++;\n          } else {\n            text += row.chars[c].uchar;\n            indenting = false;\n          }\n        }\n        // To be used for cleaning-up orphaned roll-up captions\n        row.cueStartTime = startTime;\n\n        // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\n        if (startTime === endTime) {\n          endTime += 0.0001;\n        }\n        if (indent >= 16) {\n          indent--;\n        } else {\n          indent++;\n        }\n        const cueText = fixLineBreaks(text.trim());\n        const id = generateCueId(startTime, endTime, cueText);\n\n        // If this cue already exists in the track do not push it\n        if (!(track != null && (_track$cues = track.cues) != null && _track$cues.getCueById(id))) {\n          cue = new Cue(startTime, endTime, cueText);\n          cue.id = id;\n          cue.line = r + 1;\n          cue.align = 'left';\n          // Clamp the position between 10 and 80 percent (CEA-608 PAC indent code)\n          // https://dvcs.w3.org/hg/text-tracks/raw-file/default/608toVTT/608toVTT.html#positioning-in-cea-608\n          // Firefox throws an exception and captions break with out of bounds 0-100 values\n          cue.position = 10 + Math.min(80, Math.floor(indent * 8 / 32) * 10);\n          result.push(cue);\n        }\n      }\n    }\n    if (track && result.length) {\n      // Sort bottom cues in reverse order so that they render in line order when overlapping in Chrome\n      result.sort((cueA, cueB) => {\n        if (cueA.line === 'auto' || cueB.line === 'auto') {\n          return 0;\n        }\n        if (cueA.line > 8 && cueB.line > 8) {\n          return cueB.line - cueA.line;\n        }\n        return cueA.line - cueB.line;\n      });\n      result.forEach(cue => addCueToTrack(track, cue));\n    }\n    return result;\n  }\n};\n\n/**\n * @deprecated use fragLoadPolicy.default\n */\n\n/**\n * @deprecated use manifestLoadPolicy.default and playlistLoadPolicy.default\n */\n\nconst defaultLoadPolicy = {\n  maxTimeToFirstByteMs: 8000,\n  maxLoadTimeMs: 20000,\n  timeoutRetry: null,\n  errorRetry: null\n};\n\n/**\n * @ignore\n * If possible, keep hlsDefaultConfig shallow\n * It is cloned whenever a new Hls instance is created, by keeping the config\n * shallow the properties are cloned, and we don't end up manipulating the default\n */\nconst hlsDefaultConfig = _objectSpread2(_objectSpread2({\n  autoStartLoad: true,\n  // used by stream-controller\n  startPosition: -1,\n  // used by stream-controller\n  defaultAudioCodec: undefined,\n  // used by stream-controller\n  debug: false,\n  // used by logger\n  capLevelOnFPSDrop: false,\n  // used by fps-controller\n  capLevelToPlayerSize: false,\n  // used by cap-level-controller\n  ignoreDevicePixelRatio: false,\n  // used by cap-level-controller\n  preferManagedMediaSource: true,\n  initialLiveManifestSize: 1,\n  // used by stream-controller\n  maxBufferLength: 30,\n  // used by stream-controller\n  backBufferLength: Infinity,\n  // used by buffer-controller\n  frontBufferFlushThreshold: Infinity,\n  maxBufferSize: 60 * 1000 * 1000,\n  // used by stream-controller\n  maxBufferHole: 0.1,\n  // used by stream-controller\n  highBufferWatchdogPeriod: 2,\n  // used by stream-controller\n  nudgeOffset: 0.1,\n  // used by stream-controller\n  nudgeMaxRetry: 3,\n  // used by stream-controller\n  maxFragLookUpTolerance: 0.25,\n  // used by stream-controller\n  liveSyncDurationCount: 3,\n  // used by latency-controller\n  liveMaxLatencyDurationCount: Infinity,\n  // used by latency-controller\n  liveSyncDuration: undefined,\n  // used by latency-controller\n  liveMaxLatencyDuration: undefined,\n  // used by latency-controller\n  maxLiveSyncPlaybackRate: 1,\n  // used by latency-controller\n  liveDurationInfinity: false,\n  // used by buffer-controller\n  /**\n   * @deprecated use backBufferLength\n   */\n  liveBackBufferLength: null,\n  // used by buffer-controller\n  maxMaxBufferLength: 600,\n  // used by stream-controller\n  enableWorker: true,\n  // used by transmuxer\n  workerPath: null,\n  // used by transmuxer\n  enableSoftwareAES: true,\n  // used by decrypter\n  startLevel: undefined,\n  // used by level-controller\n  startFragPrefetch: false,\n  // used by stream-controller\n  fpsDroppedMonitoringPeriod: 5000,\n  // used by fps-controller\n  fpsDroppedMonitoringThreshold: 0.2,\n  // used by fps-controller\n  appendErrorMaxRetry: 3,\n  // used by buffer-controller\n  loader: XhrLoader,\n  // loader: FetchLoader,\n  fLoader: undefined,\n  // used by fragment-loader\n  pLoader: undefined,\n  // used by playlist-loader\n  xhrSetup: undefined,\n  // used by xhr-loader\n  licenseXhrSetup: undefined,\n  // used by eme-controller\n  licenseResponseCallback: undefined,\n  // used by eme-controller\n  abrController: AbrController,\n  bufferController: BufferController,\n  capLevelController: CapLevelController,\n  errorController: ErrorController,\n  fpsController: FPSController,\n  stretchShortVideoTrack: false,\n  // used by mp4-remuxer\n  maxAudioFramesDrift: 1,\n  // used by mp4-remuxer\n  forceKeyFrameOnDiscontinuity: true,\n  // used by ts-demuxer\n  abrEwmaFastLive: 3,\n  // used by abr-controller\n  abrEwmaSlowLive: 9,\n  // used by abr-controller\n  abrEwmaFastVoD: 3,\n  // used by abr-controller\n  abrEwmaSlowVoD: 9,\n  // used by abr-controller\n  abrEwmaDefaultEstimate: 5e5,\n  // 500 kbps  // used by abr-controller\n  abrEwmaDefaultEstimateMax: 5e6,\n  // 5 mbps\n  abrBandWidthFactor: 0.95,\n  // used by abr-controller\n  abrBandWidthUpFactor: 0.7,\n  // used by abr-controller\n  abrMaxWithRealBitrate: false,\n  // used by abr-controller\n  maxStarvationDelay: 4,\n  // used by abr-controller\n  maxLoadingDelay: 4,\n  // used by abr-controller\n  minAutoBitrate: 0,\n  // used by hls\n  emeEnabled: false,\n  // used by eme-controller\n  widevineLicenseUrl: undefined,\n  // used by eme-controller\n  drmSystems: {},\n  // used by eme-controller\n  drmSystemOptions: {},\n  // used by eme-controller\n  requestMediaKeySystemAccessFunc: requestMediaKeySystemAccess ,\n  // used by eme-controller\n  testBandwidth: true,\n  progressive: false,\n  lowLatencyMode: true,\n  cmcd: undefined,\n  enableDateRangeMetadataCues: true,\n  enableEmsgMetadataCues: true,\n  enableID3MetadataCues: true,\n  useMediaCapabilities: true,\n  certLoadPolicy: {\n    default: defaultLoadPolicy\n  },\n  keyLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 8000,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 1,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 20000,\n        backoff: 'linear'\n      },\n      errorRetry: {\n        maxNumRetry: 8,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 20000,\n        backoff: 'linear'\n      }\n    }\n  },\n  manifestLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: Infinity,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 1,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    }\n  },\n  playlistLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    }\n  },\n  fragLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 120000,\n      timeoutRetry: {\n        maxNumRetry: 4,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 6,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    }\n  },\n  steeringManifestLoadPolicy: {\n    default: {\n      maxTimeToFirstByteMs: 10000,\n      maxLoadTimeMs: 20000,\n      timeoutRetry: {\n        maxNumRetry: 2,\n        retryDelayMs: 0,\n        maxRetryDelayMs: 0\n      },\n      errorRetry: {\n        maxNumRetry: 1,\n        retryDelayMs: 1000,\n        maxRetryDelayMs: 8000\n      }\n    } \n  },\n  // These default settings are deprecated in favor of the above policies\n  // and are maintained for backwards compatibility\n  manifestLoadingTimeOut: 10000,\n  manifestLoadingMaxRetry: 1,\n  manifestLoadingRetryDelay: 1000,\n  manifestLoadingMaxRetryTimeout: 64000,\n  levelLoadingTimeOut: 10000,\n  levelLoadingMaxRetry: 4,\n  levelLoadingRetryDelay: 1000,\n  levelLoadingMaxRetryTimeout: 64000,\n  fragLoadingTimeOut: 20000,\n  fragLoadingMaxRetry: 6,\n  fragLoadingRetryDelay: 1000,\n  fragLoadingMaxRetryTimeout: 64000\n}, timelineConfig()), {}, {\n  subtitleStreamController: SubtitleStreamController ,\n  subtitleTrackController: SubtitleTrackController ,\n  timelineController: TimelineController ,\n  audioStreamController: AudioStreamController ,\n  audioTrackController: AudioTrackController ,\n  emeController: EMEController ,\n  cmcdController: CMCDController ,\n  contentSteeringController: ContentSteeringController \n});\nfunction timelineConfig() {\n  return {\n    cueHandler: Cues,\n    // used by timeline-controller\n    enableWebVTT: true,\n    // used by timeline-controller\n    enableIMSC1: true,\n    // used by timeline-controller\n    enableCEA708Captions: true,\n    // used by timeline-controller\n    captionsTextTrack1Label: 'English',\n    // used by timeline-controller\n    captionsTextTrack1LanguageCode: 'en',\n    // used by timeline-controller\n    captionsTextTrack2Label: 'Spanish',\n    // used by timeline-controller\n    captionsTextTrack2LanguageCode: 'es',\n    // used by timeline-controller\n    captionsTextTrack3Label: 'Unknown CC',\n    // used by timeline-controller\n    captionsTextTrack3LanguageCode: '',\n    // used by timeline-controller\n    captionsTextTrack4Label: 'Unknown CC',\n    // used by timeline-controller\n    captionsTextTrack4LanguageCode: '',\n    // used by timeline-controller\n    renderTextTracksNatively: true\n  };\n}\n\n/**\n * @ignore\n */\nfunction mergeConfig(defaultConfig, userConfig) {\n  if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {\n    throw new Error(\"Illegal hls.js config: don't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration\");\n  }\n  if (userConfig.liveMaxLatencyDurationCount !== undefined && (userConfig.liveSyncDurationCount === undefined || userConfig.liveMaxLatencyDurationCount <= userConfig.liveSyncDurationCount)) {\n    throw new Error('Illegal hls.js config: \"liveMaxLatencyDurationCount\" must be greater than \"liveSyncDurationCount\"');\n  }\n  if (userConfig.liveMaxLatencyDuration !== undefined && (userConfig.liveSyncDuration === undefined || userConfig.liveMaxLatencyDuration <= userConfig.liveSyncDuration)) {\n    throw new Error('Illegal hls.js config: \"liveMaxLatencyDuration\" must be greater than \"liveSyncDuration\"');\n  }\n  const defaultsCopy = deepCpy(defaultConfig);\n\n  // Backwards compatibility with deprecated config values\n  const deprecatedSettingTypes = ['manifest', 'level', 'frag'];\n  const deprecatedSettings = ['TimeOut', 'MaxRetry', 'RetryDelay', 'MaxRetryTimeout'];\n  deprecatedSettingTypes.forEach(type => {\n    const policyName = `${type === 'level' ? 'playlist' : type}LoadPolicy`;\n    const policyNotSet = userConfig[policyName] === undefined;\n    const report = [];\n    deprecatedSettings.forEach(setting => {\n      const deprecatedSetting = `${type}Loading${setting}`;\n      const value = userConfig[deprecatedSetting];\n      if (value !== undefined && policyNotSet) {\n        report.push(deprecatedSetting);\n        const settings = defaultsCopy[policyName].default;\n        userConfig[policyName] = {\n          default: settings\n        };\n        switch (setting) {\n          case 'TimeOut':\n            settings.maxLoadTimeMs = value;\n            settings.maxTimeToFirstByteMs = value;\n            break;\n          case 'MaxRetry':\n            settings.errorRetry.maxNumRetry = value;\n            settings.timeoutRetry.maxNumRetry = value;\n            break;\n          case 'RetryDelay':\n            settings.errorRetry.retryDelayMs = value;\n            settings.timeoutRetry.retryDelayMs = value;\n            break;\n          case 'MaxRetryTimeout':\n            settings.errorRetry.maxRetryDelayMs = value;\n            settings.timeoutRetry.maxRetryDelayMs = value;\n            break;\n        }\n      }\n    });\n    if (report.length) {\n      logger.warn(`hls.js config: \"${report.join('\", \"')}\" setting(s) are deprecated, use \"${policyName}\": ${JSON.stringify(userConfig[policyName])}`);\n    }\n  });\n  return _objectSpread2(_objectSpread2({}, defaultsCopy), userConfig);\n}\nfunction deepCpy(obj) {\n  if (obj && typeof obj === 'object') {\n    if (Array.isArray(obj)) {\n      return obj.map(deepCpy);\n    }\n    return Object.keys(obj).reduce((result, key) => {\n      result[key] = deepCpy(obj[key]);\n      return result;\n    }, {});\n  }\n  return obj;\n}\n\n/**\n * @ignore\n */\nfunction enableStreamingMode(config) {\n  const currentLoader = config.loader;\n  if (currentLoader !== FetchLoader && currentLoader !== XhrLoader) {\n    // If a developer has configured their own loader, respect that choice\n    logger.log('[config]: Custom loader detected, cannot enable progressive streaming');\n    config.progressive = false;\n  } else {\n    const canStreamProgressively = fetchSupported();\n    if (canStreamProgressively) {\n      config.loader = FetchLoader;\n      config.progressive = true;\n      config.enableSoftwareAES = true;\n      logger.log('[config]: Progressive streaming enabled, using FetchLoader');\n    }\n  }\n}\n\nlet chromeOrFirefox;\nclass LevelController extends BasePlaylistController {\n  constructor(hls, contentSteeringController) {\n    super(hls, '[level-controller]');\n    this._levels = [];\n    this._firstLevel = -1;\n    this._maxAutoLevel = -1;\n    this._startLevel = void 0;\n    this.currentLevel = null;\n    this.currentLevelIndex = -1;\n    this.manualLevelIndex = -1;\n    this.steering = void 0;\n    this.onParsedComplete = void 0;\n    this.steering = contentSteeringController;\n    this._registerListeners();\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.on(Events.ERROR, this.onError, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    hls.off(Events.ERROR, this.onError, this);\n  }\n  destroy() {\n    this._unregisterListeners();\n    this.steering = null;\n    this.resetLevels();\n    super.destroy();\n  }\n  stopLoad() {\n    const levels = this._levels;\n\n    // clean up live level details to force reload them, and reset load errors\n    levels.forEach(level => {\n      level.loadError = 0;\n      level.fragmentError = 0;\n    });\n    super.stopLoad();\n  }\n  resetLevels() {\n    this._startLevel = undefined;\n    this.manualLevelIndex = -1;\n    this.currentLevelIndex = -1;\n    this.currentLevel = null;\n    this._levels = [];\n    this._maxAutoLevel = -1;\n  }\n  onManifestLoading(event, data) {\n    this.resetLevels();\n  }\n  onManifestLoaded(event, data) {\n    const preferManagedMediaSource = this.hls.config.preferManagedMediaSource;\n    const levels = [];\n    const redundantSet = {};\n    const generatePathwaySet = {};\n    let resolutionFound = false;\n    let videoCodecFound = false;\n    let audioCodecFound = false;\n    data.levels.forEach(levelParsed => {\n      var _audioCodec, _videoCodec;\n      const attributes = levelParsed.attrs;\n\n      // erase audio codec info if browser does not support mp4a.40.34.\n      // demuxer will autodetect codec and fallback to mpeg/audio\n      let {\n        audioCodec,\n        videoCodec\n      } = levelParsed;\n      if (((_audioCodec = audioCodec) == null ? void 0 : _audioCodec.indexOf('mp4a.40.34')) !== -1) {\n        chromeOrFirefox || (chromeOrFirefox = /chrome|firefox/i.test(navigator.userAgent));\n        if (chromeOrFirefox) {\n          levelParsed.audioCodec = audioCodec = undefined;\n        }\n      }\n      if (audioCodec) {\n        levelParsed.audioCodec = audioCodec = getCodecCompatibleName(audioCodec, preferManagedMediaSource);\n      }\n      if (((_videoCodec = videoCodec) == null ? void 0 : _videoCodec.indexOf('avc1')) === 0) {\n        videoCodec = levelParsed.videoCodec = convertAVC1ToAVCOTI(videoCodec);\n      }\n\n      // only keep levels with supported audio/video codecs\n      const {\n        width,\n        height,\n        unknownCodecs\n      } = levelParsed;\n      resolutionFound || (resolutionFound = !!(width && height));\n      videoCodecFound || (videoCodecFound = !!videoCodec);\n      audioCodecFound || (audioCodecFound = !!audioCodec);\n      if (unknownCodecs != null && unknownCodecs.length || audioCodec && !areCodecsMediaSourceSupported(audioCodec, 'audio', preferManagedMediaSource) || videoCodec && !areCodecsMediaSourceSupported(videoCodec, 'video', preferManagedMediaSource)) {\n        return;\n      }\n      const {\n        CODECS,\n        'FRAME-RATE': FRAMERATE,\n        'HDCP-LEVEL': HDCP,\n        'PATHWAY-ID': PATHWAY,\n        RESOLUTION,\n        'VIDEO-RANGE': VIDEO_RANGE\n      } = attributes;\n      const contentSteeringPrefix = `${PATHWAY || '.'}-`;\n      const levelKey = `${contentSteeringPrefix}${levelParsed.bitrate}-${RESOLUTION}-${FRAMERATE}-${CODECS}-${VIDEO_RANGE}-${HDCP}`;\n      if (!redundantSet[levelKey]) {\n        const level = new Level(levelParsed);\n        redundantSet[levelKey] = level;\n        generatePathwaySet[levelKey] = 1;\n        levels.push(level);\n      } else if (redundantSet[levelKey].uri !== levelParsed.url && !levelParsed.attrs['PATHWAY-ID']) {\n        // Assign Pathway IDs to Redundant Streams (default Pathways is \".\". Redundant Streams \"..\", \"...\", and so on.)\n        // Content Steering controller to handles Pathway fallback on error\n        const pathwayCount = generatePathwaySet[levelKey] += 1;\n        levelParsed.attrs['PATHWAY-ID'] = new Array(pathwayCount + 1).join('.');\n        const level = new Level(levelParsed);\n        redundantSet[levelKey] = level;\n        levels.push(level);\n      } else {\n        redundantSet[levelKey].addGroupId('audio', attributes.AUDIO);\n        redundantSet[levelKey].addGroupId('text', attributes.SUBTITLES);\n      }\n    });\n    this.filterAndSortMediaOptions(levels, data, resolutionFound, videoCodecFound, audioCodecFound);\n  }\n  filterAndSortMediaOptions(filteredLevels, data, resolutionFound, videoCodecFound, audioCodecFound) {\n    let audioTracks = [];\n    let subtitleTracks = [];\n    let levels = filteredLevels;\n\n    // remove audio-only and invalid video-range levels if we also have levels with video codecs or RESOLUTION signalled\n    if ((resolutionFound || videoCodecFound) && audioCodecFound) {\n      levels = levels.filter(({\n        videoCodec,\n        videoRange,\n        width,\n        height\n      }) => (!!videoCodec || !!(width && height)) && isVideoRange(videoRange));\n    }\n    if (levels.length === 0) {\n      // Dispatch error after MANIFEST_LOADED is done propagating\n      Promise.resolve().then(() => {\n        if (this.hls) {\n          if (data.levels.length) {\n            this.warn(`One or more CODECS in variant not supported: ${JSON.stringify(data.levels[0].attrs)}`);\n          }\n          const error = new Error('no level with compatible codecs found in manifest');\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.MANIFEST_INCOMPATIBLE_CODECS_ERROR,\n            fatal: true,\n            url: data.url,\n            error,\n            reason: error.message\n          });\n        }\n      });\n      return;\n    }\n    if (data.audioTracks) {\n      const {\n        preferManagedMediaSource\n      } = this.hls.config;\n      audioTracks = data.audioTracks.filter(track => !track.audioCodec || areCodecsMediaSourceSupported(track.audioCodec, 'audio', preferManagedMediaSource));\n      // Assign ids after filtering as array indices by group-id\n      assignTrackIdsByGroup(audioTracks);\n    }\n    if (data.subtitles) {\n      subtitleTracks = data.subtitles;\n      assignTrackIdsByGroup(subtitleTracks);\n    }\n    // start bitrate is the first bitrate of the manifest\n    const unsortedLevels = levels.slice(0);\n    // sort levels from lowest to highest\n    levels.sort((a, b) => {\n      if (a.attrs['HDCP-LEVEL'] !== b.attrs['HDCP-LEVEL']) {\n        return (a.attrs['HDCP-LEVEL'] || '') > (b.attrs['HDCP-LEVEL'] || '') ? 1 : -1;\n      }\n      // sort on height before bitrate for cap-level-controller\n      if (resolutionFound && a.height !== b.height) {\n        return a.height - b.height;\n      }\n      if (a.frameRate !== b.frameRate) {\n        return a.frameRate - b.frameRate;\n      }\n      if (a.videoRange !== b.videoRange) {\n        return VideoRangeValues.indexOf(a.videoRange) - VideoRangeValues.indexOf(b.videoRange);\n      }\n      if (a.videoCodec !== b.videoCodec) {\n        const valueA = videoCodecPreferenceValue(a.videoCodec);\n        const valueB = videoCodecPreferenceValue(b.videoCodec);\n        if (valueA !== valueB) {\n          return valueB - valueA;\n        }\n      }\n      if (a.uri === b.uri && a.codecSet !== b.codecSet) {\n        const valueA = codecsSetSelectionPreferenceValue(a.codecSet);\n        const valueB = codecsSetSelectionPreferenceValue(b.codecSet);\n        if (valueA !== valueB) {\n          return valueB - valueA;\n        }\n      }\n      if (a.averageBitrate !== b.averageBitrate) {\n        return a.averageBitrate - b.averageBitrate;\n      }\n      return 0;\n    });\n    let firstLevelInPlaylist = unsortedLevels[0];\n    if (this.steering) {\n      levels = this.steering.filterParsedLevels(levels);\n      if (levels.length !== unsortedLevels.length) {\n        for (let i = 0; i < unsortedLevels.length; i++) {\n          if (unsortedLevels[i].pathwayId === levels[0].pathwayId) {\n            firstLevelInPlaylist = unsortedLevels[i];\n            break;\n          }\n        }\n      }\n    }\n    this._levels = levels;\n\n    // find index of first level in sorted levels\n    for (let i = 0; i < levels.length; i++) {\n      if (levels[i] === firstLevelInPlaylist) {\n        var _this$hls$userConfig;\n        this._firstLevel = i;\n        const firstLevelBitrate = firstLevelInPlaylist.bitrate;\n        const bandwidthEstimate = this.hls.bandwidthEstimate;\n        this.log(`manifest loaded, ${levels.length} level(s) found, first bitrate: ${firstLevelBitrate}`);\n        // Update default bwe to first variant bitrate as long it has not been configured or set\n        if (((_this$hls$userConfig = this.hls.userConfig) == null ? void 0 : _this$hls$userConfig.abrEwmaDefaultEstimate) === undefined) {\n          const startingBwEstimate = Math.min(firstLevelBitrate, this.hls.config.abrEwmaDefaultEstimateMax);\n          if (startingBwEstimate > bandwidthEstimate && bandwidthEstimate === hlsDefaultConfig.abrEwmaDefaultEstimate) {\n            this.hls.bandwidthEstimate = startingBwEstimate;\n          }\n        }\n        break;\n      }\n    }\n\n    // Audio is only alternate if manifest include a URI along with the audio group tag,\n    // and this is not an audio-only stream where levels contain audio-only\n    const audioOnly = audioCodecFound && !videoCodecFound;\n    const edata = {\n      levels,\n      audioTracks,\n      subtitleTracks,\n      sessionData: data.sessionData,\n      sessionKeys: data.sessionKeys,\n      firstLevel: this._firstLevel,\n      stats: data.stats,\n      audio: audioCodecFound,\n      video: videoCodecFound,\n      altAudio: !audioOnly && audioTracks.some(t => !!t.url)\n    };\n    this.hls.trigger(Events.MANIFEST_PARSED, edata);\n\n    // Initiate loading after all controllers have received MANIFEST_PARSED\n    if (this.hls.config.autoStartLoad || this.hls.forceStartLoad) {\n      this.hls.startLoad(this.hls.config.startPosition);\n    }\n  }\n  get levels() {\n    if (this._levels.length === 0) {\n      return null;\n    }\n    return this._levels;\n  }\n  get level() {\n    return this.currentLevelIndex;\n  }\n  set level(newLevel) {\n    const levels = this._levels;\n    if (levels.length === 0) {\n      return;\n    }\n    // check if level idx is valid\n    if (newLevel < 0 || newLevel >= levels.length) {\n      // invalid level id given, trigger error\n      const error = new Error('invalid level idx');\n      const fatal = newLevel < 0;\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.OTHER_ERROR,\n        details: ErrorDetails.LEVEL_SWITCH_ERROR,\n        level: newLevel,\n        fatal,\n        error,\n        reason: error.message\n      });\n      if (fatal) {\n        return;\n      }\n      newLevel = Math.min(newLevel, levels.length - 1);\n    }\n    const lastLevelIndex = this.currentLevelIndex;\n    const lastLevel = this.currentLevel;\n    const lastPathwayId = lastLevel ? lastLevel.attrs['PATHWAY-ID'] : undefined;\n    const level = levels[newLevel];\n    const pathwayId = level.attrs['PATHWAY-ID'];\n    this.currentLevelIndex = newLevel;\n    this.currentLevel = level;\n    if (lastLevelIndex === newLevel && level.details && lastLevel && lastPathwayId === pathwayId) {\n      return;\n    }\n    this.log(`Switching to level ${newLevel} (${level.height ? level.height + 'p ' : ''}${level.videoRange ? level.videoRange + ' ' : ''}${level.codecSet ? level.codecSet + ' ' : ''}@${level.bitrate})${pathwayId ? ' with Pathway ' + pathwayId : ''} from level ${lastLevelIndex}${lastPathwayId ? ' with Pathway ' + lastPathwayId : ''}`);\n    const levelSwitchingData = {\n      level: newLevel,\n      attrs: level.attrs,\n      details: level.details,\n      bitrate: level.bitrate,\n      averageBitrate: level.averageBitrate,\n      maxBitrate: level.maxBitrate,\n      realBitrate: level.realBitrate,\n      width: level.width,\n      height: level.height,\n      codecSet: level.codecSet,\n      audioCodec: level.audioCodec,\n      videoCodec: level.videoCodec,\n      audioGroups: level.audioGroups,\n      subtitleGroups: level.subtitleGroups,\n      loaded: level.loaded,\n      loadError: level.loadError,\n      fragmentError: level.fragmentError,\n      name: level.name,\n      id: level.id,\n      uri: level.uri,\n      url: level.url,\n      urlId: 0,\n      audioGroupIds: level.audioGroupIds,\n      textGroupIds: level.textGroupIds\n    };\n    this.hls.trigger(Events.LEVEL_SWITCHING, levelSwitchingData);\n    // check if we need to load playlist for this level\n    const levelDetails = level.details;\n    if (!levelDetails || levelDetails.live) {\n      // level not retrieved yet, or live playlist we need to (re)load it\n      const hlsUrlParameters = this.switchParams(level.uri, lastLevel == null ? void 0 : lastLevel.details, levelDetails);\n      this.loadPlaylist(hlsUrlParameters);\n    }\n  }\n  get manualLevel() {\n    return this.manualLevelIndex;\n  }\n  set manualLevel(newLevel) {\n    this.manualLevelIndex = newLevel;\n    if (this._startLevel === undefined) {\n      this._startLevel = newLevel;\n    }\n    if (newLevel !== -1) {\n      this.level = newLevel;\n    }\n  }\n  get firstLevel() {\n    return this._firstLevel;\n  }\n  set firstLevel(newLevel) {\n    this._firstLevel = newLevel;\n  }\n  get startLevel() {\n    // Setting hls.startLevel (this._startLevel) overrides config.startLevel\n    if (this._startLevel === undefined) {\n      const configStartLevel = this.hls.config.startLevel;\n      if (configStartLevel !== undefined) {\n        return configStartLevel;\n      }\n      return this.hls.firstAutoLevel;\n    }\n    return this._startLevel;\n  }\n  set startLevel(newLevel) {\n    this._startLevel = newLevel;\n  }\n  onError(event, data) {\n    if (data.fatal || !data.context) {\n      return;\n    }\n    if (data.context.type === PlaylistContextType.LEVEL && data.context.level === this.level) {\n      this.checkRetry(data);\n    }\n  }\n\n  // reset errors on the successful load of a fragment\n  onFragBuffered(event, {\n    frag\n  }) {\n    if (frag !== undefined && frag.type === PlaylistLevelType.MAIN) {\n      const el = frag.elementaryStreams;\n      if (!Object.keys(el).some(type => !!el[type])) {\n        return;\n      }\n      const level = this._levels[frag.level];\n      if (level != null && level.loadError) {\n        this.log(`Resetting level error count of ${level.loadError} on frag buffered`);\n        level.loadError = 0;\n      }\n    }\n  }\n  onLevelLoaded(event, data) {\n    var _data$deliveryDirecti2;\n    const {\n      level,\n      details\n    } = data;\n    const curLevel = this._levels[level];\n    if (!curLevel) {\n      var _data$deliveryDirecti;\n      this.warn(`Invalid level index ${level}`);\n      if ((_data$deliveryDirecti = data.deliveryDirectives) != null && _data$deliveryDirecti.skip) {\n        details.deltaUpdateFailed = true;\n      }\n      return;\n    }\n\n    // only process level loaded events matching with expected level\n    if (level === this.currentLevelIndex) {\n      // reset level load error counter on successful level loaded only if there is no issues with fragments\n      if (curLevel.fragmentError === 0) {\n        curLevel.loadError = 0;\n      }\n      this.playlistLoaded(level, data, curLevel.details);\n    } else if ((_data$deliveryDirecti2 = data.deliveryDirectives) != null && _data$deliveryDirecti2.skip) {\n      // received a delta playlist update that cannot be merged\n      details.deltaUpdateFailed = true;\n    }\n  }\n  loadPlaylist(hlsUrlParameters) {\n    super.loadPlaylist();\n    const currentLevelIndex = this.currentLevelIndex;\n    const currentLevel = this.currentLevel;\n    if (currentLevel && this.shouldLoadPlaylist(currentLevel)) {\n      let url = currentLevel.uri;\n      if (hlsUrlParameters) {\n        try {\n          url = hlsUrlParameters.addDirectives(url);\n        } catch (error) {\n          this.warn(`Could not construct new URL with HLS Delivery Directives: ${error}`);\n        }\n      }\n      const pathwayId = currentLevel.attrs['PATHWAY-ID'];\n      this.log(`Loading level index ${currentLevelIndex}${(hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : ''} with${pathwayId ? ' Pathway ' + pathwayId : ''} ${url}`);\n\n      // console.log('Current audio track group ID:', this.hls.audioTracks[this.hls.audioTrack].groupId);\n      // console.log('New video quality level audio group id:', levelObject.attrs.AUDIO, level);\n      this.clearTimer();\n      this.hls.trigger(Events.LEVEL_LOADING, {\n        url,\n        level: currentLevelIndex,\n        pathwayId: currentLevel.attrs['PATHWAY-ID'],\n        id: 0,\n        // Deprecated Level urlId\n        deliveryDirectives: hlsUrlParameters || null\n      });\n    }\n  }\n  get nextLoadLevel() {\n    if (this.manualLevelIndex !== -1) {\n      return this.manualLevelIndex;\n    } else {\n      return this.hls.nextAutoLevel;\n    }\n  }\n  set nextLoadLevel(nextLevel) {\n    this.level = nextLevel;\n    if (this.manualLevelIndex === -1) {\n      this.hls.nextAutoLevel = nextLevel;\n    }\n  }\n  removeLevel(levelIndex) {\n    var _this$currentLevel;\n    const levels = this._levels.filter((level, index) => {\n      if (index !== levelIndex) {\n        return true;\n      }\n      if (this.steering) {\n        this.steering.removeLevel(level);\n      }\n      if (level === this.currentLevel) {\n        this.currentLevel = null;\n        this.currentLevelIndex = -1;\n        if (level.details) {\n          level.details.fragments.forEach(f => f.level = -1);\n        }\n      }\n      return false;\n    });\n    reassignFragmentLevelIndexes(levels);\n    this._levels = levels;\n    if (this.currentLevelIndex > -1 && (_this$currentLevel = this.currentLevel) != null && _this$currentLevel.details) {\n      this.currentLevelIndex = this.currentLevel.details.fragments[0].level;\n    }\n    this.hls.trigger(Events.LEVELS_UPDATED, {\n      levels\n    });\n  }\n  onLevelsUpdated(event, {\n    levels\n  }) {\n    this._levels = levels;\n  }\n  checkMaxAutoUpdated() {\n    const {\n      autoLevelCapping,\n      maxAutoLevel,\n      maxHdcpLevel\n    } = this.hls;\n    if (this._maxAutoLevel !== maxAutoLevel) {\n      this._maxAutoLevel = maxAutoLevel;\n      this.hls.trigger(Events.MAX_AUTO_LEVEL_UPDATED, {\n        autoLevelCapping,\n        levels: this.levels,\n        maxAutoLevel,\n        minAutoLevel: this.hls.minAutoLevel,\n        maxHdcpLevel\n      });\n    }\n  }\n}\nfunction assignTrackIdsByGroup(tracks) {\n  const groups = {};\n  tracks.forEach(track => {\n    const groupId = track.groupId || '';\n    track.id = groups[groupId] = groups[groupId] || 0;\n    groups[groupId]++;\n  });\n}\n\nclass KeyLoader {\n  constructor(config) {\n    this.config = void 0;\n    this.keyUriToKeyInfo = {};\n    this.emeController = null;\n    this.config = config;\n  }\n  abort(type) {\n    for (const uri in this.keyUriToKeyInfo) {\n      const loader = this.keyUriToKeyInfo[uri].loader;\n      if (loader) {\n        var _loader$context;\n        if (type && type !== ((_loader$context = loader.context) == null ? void 0 : _loader$context.frag.type)) {\n          return;\n        }\n        loader.abort();\n      }\n    }\n  }\n  detach() {\n    for (const uri in this.keyUriToKeyInfo) {\n      const keyInfo = this.keyUriToKeyInfo[uri];\n      // Remove cached EME keys on detach\n      if (keyInfo.mediaKeySessionContext || keyInfo.decryptdata.isCommonEncryption) {\n        delete this.keyUriToKeyInfo[uri];\n      }\n    }\n  }\n  destroy() {\n    this.detach();\n    for (const uri in this.keyUriToKeyInfo) {\n      const loader = this.keyUriToKeyInfo[uri].loader;\n      if (loader) {\n        loader.destroy();\n      }\n    }\n    this.keyUriToKeyInfo = {};\n  }\n  createKeyLoadError(frag, details = ErrorDetails.KEY_LOAD_ERROR, error, networkDetails, response) {\n    return new LoadError({\n      type: ErrorTypes.NETWORK_ERROR,\n      details,\n      fatal: false,\n      frag,\n      response,\n      error,\n      networkDetails\n    });\n  }\n  loadClear(loadingFrag, encryptedFragments) {\n    if (this.emeController && this.config.emeEnabled) {\n      // access key-system with nearest key on start (loaidng frag is unencrypted)\n      const {\n        sn,\n        cc\n      } = loadingFrag;\n      for (let i = 0; i < encryptedFragments.length; i++) {\n        const frag = encryptedFragments[i];\n        if (cc <= frag.cc && (sn === 'initSegment' || frag.sn === 'initSegment' || sn < frag.sn)) {\n          this.emeController.selectKeySystemFormat(frag).then(keySystemFormat => {\n            frag.setKeyFormat(keySystemFormat);\n          });\n          break;\n        }\n      }\n    }\n  }\n  load(frag) {\n    if (!frag.decryptdata && frag.encrypted && this.emeController) {\n      // Multiple keys, but none selected, resolve in eme-controller\n      return this.emeController.selectKeySystemFormat(frag).then(keySystemFormat => {\n        return this.loadInternal(frag, keySystemFormat);\n      });\n    }\n    return this.loadInternal(frag);\n  }\n  loadInternal(frag, keySystemFormat) {\n    var _keyInfo, _keyInfo2;\n    if (keySystemFormat) {\n      frag.setKeyFormat(keySystemFormat);\n    }\n    const decryptdata = frag.decryptdata;\n    if (!decryptdata) {\n      const error = new Error(keySystemFormat ? `Expected frag.decryptdata to be defined after setting format ${keySystemFormat}` : 'Missing decryption data on fragment in onKeyLoading');\n      return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, error));\n    }\n    const uri = decryptdata.uri;\n    if (!uri) {\n      return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`Invalid key URI: \"${uri}\"`)));\n    }\n    let keyInfo = this.keyUriToKeyInfo[uri];\n    if ((_keyInfo = keyInfo) != null && _keyInfo.decryptdata.key) {\n      decryptdata.key = keyInfo.decryptdata.key;\n      return Promise.resolve({\n        frag,\n        keyInfo\n      });\n    }\n    // Return key load promise as long as it does not have a mediakey session with an unusable key status\n    if ((_keyInfo2 = keyInfo) != null && _keyInfo2.keyLoadPromise) {\n      var _keyInfo$mediaKeySess;\n      switch ((_keyInfo$mediaKeySess = keyInfo.mediaKeySessionContext) == null ? void 0 : _keyInfo$mediaKeySess.keyStatus) {\n        case undefined:\n        case 'status-pending':\n        case 'usable':\n        case 'usable-in-future':\n          return keyInfo.keyLoadPromise.then(keyLoadedData => {\n            // Return the correct fragment with updated decryptdata key and loaded keyInfo\n            decryptdata.key = keyLoadedData.keyInfo.decryptdata.key;\n            return {\n              frag,\n              keyInfo\n            };\n          });\n      }\n      // If we have a key session and status and it is not pending or usable, continue\n      // This will go back to the eme-controller for expired keys to get a new keyLoadPromise\n    }\n\n    // Load the key or return the loading promise\n    keyInfo = this.keyUriToKeyInfo[uri] = {\n      decryptdata,\n      keyLoadPromise: null,\n      loader: null,\n      mediaKeySessionContext: null\n    };\n    switch (decryptdata.method) {\n      case 'ISO-23001-7':\n      case 'SAMPLE-AES':\n      case 'SAMPLE-AES-CENC':\n      case 'SAMPLE-AES-CTR':\n        if (decryptdata.keyFormat === 'identity') {\n          // loadKeyHTTP handles http(s) and data URLs\n          return this.loadKeyHTTP(keyInfo, frag);\n        }\n        return this.loadKeyEME(keyInfo, frag);\n      case 'AES-128':\n        return this.loadKeyHTTP(keyInfo, frag);\n      default:\n        return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`Key supplied with unsupported METHOD: \"${decryptdata.method}\"`)));\n    }\n  }\n  loadKeyEME(keyInfo, frag) {\n    const keyLoadedData = {\n      frag,\n      keyInfo\n    };\n    if (this.emeController && this.config.emeEnabled) {\n      const keySessionContextPromise = this.emeController.loadKey(keyLoadedData);\n      if (keySessionContextPromise) {\n        return (keyInfo.keyLoadPromise = keySessionContextPromise.then(keySessionContext => {\n          keyInfo.mediaKeySessionContext = keySessionContext;\n          return keyLoadedData;\n        })).catch(error => {\n          // Remove promise for license renewal or retry\n          keyInfo.keyLoadPromise = null;\n          throw error;\n        });\n      }\n    }\n    return Promise.resolve(keyLoadedData);\n  }\n  loadKeyHTTP(keyInfo, frag) {\n    const config = this.config;\n    const Loader = config.loader;\n    const keyLoader = new Loader(config);\n    frag.keyLoader = keyInfo.loader = keyLoader;\n    return keyInfo.keyLoadPromise = new Promise((resolve, reject) => {\n      const loaderContext = {\n        keyInfo,\n        frag,\n        responseType: 'arraybuffer',\n        url: keyInfo.decryptdata.uri\n      };\n\n      // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,\n      // key-loader will trigger an error and rely on stream-controller to handle retry logic.\n      // this will also align retry logic with fragment-loader\n      const loadPolicy = config.keyLoadPolicy.default;\n      const loaderConfig = {\n        loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: 0,\n        retryDelay: 0,\n        maxRetryDelay: 0\n      };\n      const loaderCallbacks = {\n        onSuccess: (response, stats, context, networkDetails) => {\n          const {\n            frag,\n            keyInfo,\n            url: uri\n          } = context;\n          if (!frag.decryptdata || keyInfo !== this.keyUriToKeyInfo[uri]) {\n            return reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error('after key load, decryptdata unset or changed'), networkDetails));\n          }\n          keyInfo.decryptdata.key = frag.decryptdata.key = new Uint8Array(response.data);\n\n          // detach fragment key loader on load success\n          frag.keyLoader = null;\n          keyInfo.loader = null;\n          resolve({\n            frag,\n            keyInfo\n          });\n        },\n        onError: (response, context, networkDetails, stats) => {\n          this.resetLoader(context);\n          reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(`HTTP Error ${response.code} loading key ${response.text}`), networkDetails, _objectSpread2({\n            url: loaderContext.url,\n            data: undefined\n          }, response)));\n        },\n        onTimeout: (stats, context, networkDetails) => {\n          this.resetLoader(context);\n          reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_TIMEOUT, new Error('key loading timed out'), networkDetails));\n        },\n        onAbort: (stats, context, networkDetails) => {\n          this.resetLoader(context);\n          reject(this.createKeyLoadError(frag, ErrorDetails.INTERNAL_ABORTED, new Error('key loading aborted'), networkDetails));\n        }\n      };\n      keyLoader.load(loaderContext, loaderConfig, loaderCallbacks);\n    });\n  }\n  resetLoader(context) {\n    const {\n      frag,\n      keyInfo,\n      url: uri\n    } = context;\n    const loader = keyInfo.loader;\n    if (frag.keyLoader === loader) {\n      frag.keyLoader = null;\n      keyInfo.loader = null;\n    }\n    delete this.keyUriToKeyInfo[uri];\n    if (loader) {\n      loader.destroy();\n    }\n  }\n}\n\nfunction getSourceBuffer() {\n  return self.SourceBuffer || self.WebKitSourceBuffer;\n}\nfunction isMSESupported() {\n  const mediaSource = getMediaSource();\n  if (!mediaSource) {\n    return false;\n  }\n\n  // if SourceBuffer is exposed ensure its API is valid\n  // Older browsers do not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible\n  const sourceBuffer = getSourceBuffer();\n  return !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';\n}\nfunction isSupported() {\n  if (!isMSESupported()) {\n    return false;\n  }\n  const mediaSource = getMediaSource();\n  return typeof (mediaSource == null ? void 0 : mediaSource.isTypeSupported) === 'function' && (['avc1.42E01E,mp4a.40.2', 'av01.0.01M.08', 'vp09.00.50.08'].some(codecsForVideoContainer => mediaSource.isTypeSupported(mimeTypeForCodec(codecsForVideoContainer, 'video'))) || ['mp4a.40.2', 'fLaC'].some(codecForAudioContainer => mediaSource.isTypeSupported(mimeTypeForCodec(codecForAudioContainer, 'audio'))));\n}\nfunction changeTypeSupported() {\n  var _sourceBuffer$prototy;\n  const sourceBuffer = getSourceBuffer();\n  return typeof (sourceBuffer == null ? void 0 : (_sourceBuffer$prototy = sourceBuffer.prototype) == null ? void 0 : _sourceBuffer$prototy.changeType) === 'function';\n}\n\nconst STALL_MINIMUM_DURATION_MS = 250;\nconst MAX_START_GAP_JUMP = 2.0;\nconst SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;\nconst SKIP_BUFFER_RANGE_START = 0.05;\nclass GapController {\n  constructor(config, media, fragmentTracker, hls) {\n    this.config = void 0;\n    this.media = null;\n    this.fragmentTracker = void 0;\n    this.hls = void 0;\n    this.nudgeRetry = 0;\n    this.stallReported = false;\n    this.stalled = null;\n    this.moved = false;\n    this.seeking = false;\n    this.config = config;\n    this.media = media;\n    this.fragmentTracker = fragmentTracker;\n    this.hls = hls;\n  }\n  destroy() {\n    this.media = null;\n    // @ts-ignore\n    this.hls = this.fragmentTracker = null;\n  }\n\n  /**\n   * Checks if the playhead is stuck within a gap, and if so, attempts to free it.\n   * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).\n   *\n   * @param lastCurrentTime - Previously read playhead position\n   */\n  poll(lastCurrentTime, activeFrag) {\n    const {\n      config,\n      media,\n      stalled\n    } = this;\n    if (media === null) {\n      return;\n    }\n    const {\n      currentTime,\n      seeking\n    } = media;\n    const seeked = this.seeking && !seeking;\n    const beginSeek = !this.seeking && seeking;\n    this.seeking = seeking;\n\n    // The playhead is moving, no-op\n    if (currentTime !== lastCurrentTime) {\n      this.moved = true;\n      if (!seeking) {\n        this.nudgeRetry = 0;\n      }\n      if (stalled !== null) {\n        // The playhead is now moving, but was previously stalled\n        if (this.stallReported) {\n          const _stalledDuration = self.performance.now() - stalled;\n          logger.warn(`playback not stuck anymore @${currentTime}, after ${Math.round(_stalledDuration)}ms`);\n          this.stallReported = false;\n        }\n        this.stalled = null;\n      }\n      return;\n    }\n\n    // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek\n    if (beginSeek || seeked) {\n      this.stalled = null;\n      return;\n    }\n\n    // The playhead should not be moving\n    if (media.paused && !seeking || media.ended || media.playbackRate === 0 || !BufferHelper.getBuffered(media).length) {\n      this.nudgeRetry = 0;\n      return;\n    }\n    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n    const nextStart = bufferInfo.nextStart || 0;\n    if (seeking) {\n      // Waiting for seeking in a buffered range to complete\n      const hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP;\n      // Next buffered range is too far ahead to jump to while still seeking\n      const noBufferGap = !nextStart || activeFrag && activeFrag.start <= currentTime || nextStart - currentTime > MAX_START_GAP_JUMP && !this.fragmentTracker.getPartialFragment(currentTime);\n      if (hasEnoughBuffer || noBufferGap) {\n        return;\n      }\n      // Reset moved state when seeking to a point in or before a gap\n      this.moved = false;\n    }\n\n    // Skip start gaps if we haven't played, but the last poll detected the start of a stall\n    // The addition poll gives the browser a chance to jump the gap for us\n    if (!this.moved && this.stalled !== null) {\n      var _level$details;\n      // There is no playable buffer (seeked, waiting for buffer)\n      const isBuffered = bufferInfo.len > 0;\n      if (!isBuffered && !nextStart) {\n        return;\n      }\n      // Jump start gaps within jump threshold\n      const startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime;\n\n      // When joining a live stream with audio tracks, account for live playlist window sliding by allowing\n      // a larger jump over start gaps caused by the audio-stream-controller buffering a start fragment\n      // that begins over 1 target duration after the video start position.\n      const level = this.hls.levels ? this.hls.levels[this.hls.currentLevel] : null;\n      const isLive = level == null ? void 0 : (_level$details = level.details) == null ? void 0 : _level$details.live;\n      const maxStartGapJump = isLive ? level.details.targetduration * 2 : MAX_START_GAP_JUMP;\n      const partialOrGap = this.fragmentTracker.getPartialFragment(currentTime);\n      if (startJump > 0 && (startJump <= maxStartGapJump || partialOrGap)) {\n        if (!media.paused) {\n          this._trySkipBufferHole(partialOrGap);\n        }\n        return;\n      }\n    }\n\n    // Start tracking stall time\n    const tnow = self.performance.now();\n    if (stalled === null) {\n      this.stalled = tnow;\n      return;\n    }\n    const stalledDuration = tnow - stalled;\n    if (!seeking && stalledDuration >= STALL_MINIMUM_DURATION_MS) {\n      // Report stalling after trying to fix\n      this._reportStall(bufferInfo);\n      if (!this.media) {\n        return;\n      }\n    }\n    const bufferedWithHoles = BufferHelper.bufferInfo(media, currentTime, config.maxBufferHole);\n    this._tryFixBufferStall(bufferedWithHoles, stalledDuration);\n  }\n\n  /**\n   * Detects and attempts to fix known buffer stalling issues.\n   * @param bufferInfo - The properties of the current buffer.\n   * @param stalledDurationMs - The amount of time Hls.js has been stalling for.\n   * @private\n   */\n  _tryFixBufferStall(bufferInfo, stalledDurationMs) {\n    const {\n      config,\n      fragmentTracker,\n      media\n    } = this;\n    if (media === null) {\n      return;\n    }\n    const currentTime = media.currentTime;\n    const partial = fragmentTracker.getPartialFragment(currentTime);\n    if (partial) {\n      // Try to skip over the buffer hole caused by a partial fragment\n      // This method isn't limited by the size of the gap between buffered ranges\n      const targetTime = this._trySkipBufferHole(partial);\n      // we return here in this case, meaning\n      // the branch below only executes when we haven't seeked to a new position\n      if (targetTime || !this.media) {\n        return;\n      }\n    }\n\n    // if we haven't had to skip over a buffer hole of a partial fragment\n    // we may just have to \"nudge\" the playlist as the browser decoding/rendering engine\n    // needs to cross some sort of threshold covering all source-buffers content\n    // to start playing properly.\n    if ((bufferInfo.len > config.maxBufferHole || bufferInfo.nextStart && bufferInfo.nextStart - currentTime < config.maxBufferHole) && stalledDurationMs > config.highBufferWatchdogPeriod * 1000) {\n      logger.warn('Trying to nudge playhead over buffer-hole');\n      // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds\n      // We only try to jump the hole if it's under the configured size\n      // Reset stalled so to rearm watchdog timer\n      this.stalled = null;\n      this._tryNudgeBuffer();\n    }\n  }\n\n  /**\n   * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.\n   * @param bufferLen - The playhead distance from the end of the current buffer segment.\n   * @private\n   */\n  _reportStall(bufferInfo) {\n    const {\n      hls,\n      media,\n      stallReported\n    } = this;\n    if (!stallReported && media) {\n      // Report stalled error once\n      this.stallReported = true;\n      const error = new Error(`Playback stalling at @${media.currentTime} due to low buffer (${JSON.stringify(bufferInfo)})`);\n      logger.warn(error.message);\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_STALLED_ERROR,\n        fatal: false,\n        error,\n        buffer: bufferInfo.len\n      });\n    }\n  }\n\n  /**\n   * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments\n   * @param partial - The partial fragment found at the current time (where playback is stalling).\n   * @private\n   */\n  _trySkipBufferHole(partial) {\n    const {\n      config,\n      hls,\n      media\n    } = this;\n    if (media === null) {\n      return 0;\n    }\n\n    // Check if currentTime is between unbuffered regions of partial fragments\n    const currentTime = media.currentTime;\n    const bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n    const startTime = currentTime < bufferInfo.start ? bufferInfo.start : bufferInfo.nextStart;\n    if (startTime) {\n      const bufferStarved = bufferInfo.len <= config.maxBufferHole;\n      const waiting = bufferInfo.len > 0 && bufferInfo.len < 1 && media.readyState < 3;\n      const gapLength = startTime - currentTime;\n      if (gapLength > 0 && (bufferStarved || waiting)) {\n        // Only allow large gaps to be skipped if it is a start gap, or all fragments in skip range are partial\n        if (gapLength > config.maxBufferHole) {\n          const {\n            fragmentTracker\n          } = this;\n          let startGap = false;\n          if (currentTime === 0) {\n            const startFrag = fragmentTracker.getAppendedFrag(0, PlaylistLevelType.MAIN);\n            if (startFrag && startTime < startFrag.end) {\n              startGap = true;\n            }\n          }\n          if (!startGap) {\n            const startProvisioned = partial || fragmentTracker.getAppendedFrag(currentTime, PlaylistLevelType.MAIN);\n            if (startProvisioned) {\n              let moreToLoad = false;\n              let pos = startProvisioned.end;\n              while (pos < startTime) {\n                const provisioned = fragmentTracker.getPartialFragment(pos);\n                if (provisioned) {\n                  pos += provisioned.duration;\n                } else {\n                  moreToLoad = true;\n                  break;\n                }\n              }\n              if (moreToLoad) {\n                return 0;\n              }\n            }\n          }\n        }\n        const targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);\n        logger.warn(`skipping hole, adjusting currentTime from ${currentTime} to ${targetTime}`);\n        this.moved = true;\n        this.stalled = null;\n        media.currentTime = targetTime;\n        if (partial && !partial.gap) {\n          const error = new Error(`fragment loaded with buffer holes, seeking from ${currentTime} to ${targetTime}`);\n          hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.BUFFER_SEEK_OVER_HOLE,\n            fatal: false,\n            error,\n            reason: error.message,\n            frag: partial\n          });\n        }\n        return targetTime;\n      }\n    }\n    return 0;\n  }\n\n  /**\n   * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.\n   * @private\n   */\n  _tryNudgeBuffer() {\n    const {\n      config,\n      hls,\n      media,\n      nudgeRetry\n    } = this;\n    if (media === null) {\n      return;\n    }\n    const currentTime = media.currentTime;\n    this.nudgeRetry++;\n    if (nudgeRetry < config.nudgeMaxRetry) {\n      const targetTime = currentTime + (nudgeRetry + 1) * config.nudgeOffset;\n      // playback stalled in buffered area ... let's nudge currentTime to try to overcome this\n      const error = new Error(`Nudging 'currentTime' from ${currentTime} to ${targetTime}`);\n      logger.warn(error.message);\n      media.currentTime = targetTime;\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_NUDGE_ON_STALL,\n        error,\n        fatal: false\n      });\n    } else {\n      const error = new Error(`Playhead still not moving while enough data buffered @${currentTime} after ${config.nudgeMaxRetry} nudges`);\n      logger.error(error.message);\n      hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_STALLED_ERROR,\n        error,\n        fatal: true\n      });\n    }\n  }\n}\n\nconst TICK_INTERVAL = 100; // how often to tick in ms\n\nclass StreamController extends BaseStreamController {\n  constructor(hls, fragmentTracker, keyLoader) {\n    super(hls, fragmentTracker, keyLoader, '[stream-controller]', PlaylistLevelType.MAIN);\n    this.audioCodecSwap = false;\n    this.gapController = null;\n    this.level = -1;\n    this._forceStartLoad = false;\n    this.altAudio = false;\n    this.audioOnly = false;\n    this.fragPlaying = null;\n    this.onvplaying = null;\n    this.onvseeked = null;\n    this.fragLastKbps = 0;\n    this.couldBacktrack = false;\n    this.backtrackFragment = null;\n    this.audioCodecSwitch = false;\n    this.videoBuffer = null;\n    this._registerListeners();\n  }\n  _registerListeners() {\n    const {\n      hls\n    } = this;\n    hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n    hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.on(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);\n    hls.on(Events.ERROR, this.onError, this);\n    hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.on(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);\n    hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  _unregisterListeners() {\n    const {\n      hls\n    } = this;\n    hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n    hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n    hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n    hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n    hls.off(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);\n    hls.off(Events.ERROR, this.onError, this);\n    hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n    hls.off(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);\n    hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n    hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n    hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n  }\n  onHandlerDestroying() {\n    this._unregisterListeners();\n    super.onHandlerDestroying();\n  }\n  startLoad(startPosition) {\n    if (this.levels) {\n      const {\n        lastCurrentTime,\n        hls\n      } = this;\n      this.stopLoad();\n      this.setInterval(TICK_INTERVAL);\n      this.level = -1;\n      if (!this.startFragRequested) {\n        // determine load level\n        let startLevel = hls.startLevel;\n        if (startLevel === -1) {\n          if (hls.config.testBandwidth && this.levels.length > 1) {\n            // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level\n            startLevel = 0;\n            this.bitrateTest = true;\n          } else {\n            startLevel = hls.firstAutoLevel;\n          }\n        }\n        // set new level to playlist loader : this will trigger start level load\n        // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded\n        hls.nextLoadLevel = startLevel;\n        this.level = hls.loadLevel;\n        this.loadedmetadata = false;\n      }\n      // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime\n      if (lastCurrentTime > 0 && startPosition === -1) {\n        this.log(`Override startPosition with lastCurrentTime @${lastCurrentTime.toFixed(3)}`);\n        startPosition = lastCurrentTime;\n      }\n      this.state = State.IDLE;\n      this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n      this.tick();\n    } else {\n      this._forceStartLoad = true;\n      this.state = State.STOPPED;\n    }\n  }\n  stopLoad() {\n    this._forceStartLoad = false;\n    super.stopLoad();\n  }\n  doTick() {\n    switch (this.state) {\n      case State.WAITING_LEVEL:\n        {\n          const {\n            levels,\n            level\n          } = this;\n          const currentLevel = levels == null ? void 0 : levels[level];\n          const details = currentLevel == null ? void 0 : currentLevel.details;\n          if (details && (!details.live || this.levelLastLoaded === currentLevel)) {\n            if (this.waitForCdnTuneIn(details)) {\n              break;\n            }\n            this.state = State.IDLE;\n            break;\n          } else if (this.hls.nextLoadLevel !== this.level) {\n            this.state = State.IDLE;\n            break;\n          }\n          break;\n        }\n      case State.FRAG_LOADING_WAITING_RETRY:\n        {\n          var _this$media;\n          const now = self.performance.now();\n          const retryDate = this.retryDate;\n          // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n          if (!retryDate || now >= retryDate || (_this$media = this.media) != null && _this$media.seeking) {\n            const {\n              levels,\n              level\n            } = this;\n            const currentLevel = levels == null ? void 0 : levels[level];\n            this.resetStartWhenNotLoaded(currentLevel || null);\n            this.state = State.IDLE;\n          }\n        }\n        break;\n    }\n    if (this.state === State.IDLE) {\n      this.doTickIdle();\n    }\n    this.onTickEnd();\n  }\n  onTickEnd() {\n    super.onTickEnd();\n    this.checkBuffer();\n    this.checkFragmentChanged();\n  }\n  doTickIdle() {\n    const {\n      hls,\n      levelLastLoaded,\n      levels,\n      media\n    } = this;\n\n    // if start level not parsed yet OR\n    // if video not attached AND start fragment already requested OR start frag prefetch not enabled\n    // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment\n    if (levelLastLoaded === null || !media && (this.startFragRequested || !hls.config.startFragPrefetch)) {\n      return;\n    }\n\n    // If the \"main\" level is audio-only but we are loading an alternate track in the same group, do not load anything\n    if (this.altAudio && this.audioOnly) {\n      return;\n    }\n    const level = hls.nextLoadLevel;\n    if (!(levels != null && levels[level])) {\n      return;\n    }\n    const levelInfo = levels[level];\n\n    // if buffer length is less than maxBufLen try to load a new fragment\n\n    const bufferInfo = this.getMainFwdBufferInfo();\n    if (bufferInfo === null) {\n      return;\n    }\n    const lastDetails = this.getLevelDetails();\n    if (lastDetails && this._streamEnded(bufferInfo, lastDetails)) {\n      const data = {};\n      if (this.altAudio) {\n        data.type = 'video';\n      }\n      this.hls.trigger(Events.BUFFER_EOS, data);\n      this.state = State.ENDED;\n      return;\n    }\n\n    // set next load level : this will trigger a playlist load if needed\n    if (hls.loadLevel !== level && hls.manualLevel === -1) {\n      this.log(`Adapting to level ${level} from level ${this.level}`);\n    }\n    this.level = hls.nextLoadLevel = level;\n    const levelDetails = levelInfo.details;\n    // if level info not retrieved yet, switch state and wait for level retrieval\n    // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load\n    // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)\n    if (!levelDetails || this.state === State.WAITING_LEVEL || levelDetails.live && this.levelLastLoaded !== levelInfo) {\n      this.level = level;\n      this.state = State.WAITING_LEVEL;\n      return;\n    }\n    const bufferLen = bufferInfo.len;\n\n    // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s\n    const maxBufLen = this.getMaxBufferLength(levelInfo.maxBitrate);\n\n    // Stay idle if we are still with buffer margins\n    if (bufferLen >= maxBufLen) {\n      return;\n    }\n    if (this.backtrackFragment && this.backtrackFragment.start > bufferInfo.end) {\n      this.backtrackFragment = null;\n    }\n    const targetBufferTime = this.backtrackFragment ? this.backtrackFragment.start : bufferInfo.end;\n    let frag = this.getNextFragment(targetBufferTime, levelDetails);\n    // Avoid backtracking by loading an earlier segment in streams with segments that do not start with a key frame (flagged by `couldBacktrack`)\n    if (this.couldBacktrack && !this.fragPrevious && frag && frag.sn !== 'initSegment' && this.fragmentTracker.getState(frag) !== FragmentState.OK) {\n      var _this$backtrackFragme;\n      const backtrackSn = ((_this$backtrackFragme = this.backtrackFragment) != null ? _this$backtrackFragme : frag).sn;\n      const fragIdx = backtrackSn - levelDetails.startSN;\n      const backtrackFrag = levelDetails.fragments[fragIdx - 1];\n      if (backtrackFrag && frag.cc === backtrackFrag.cc) {\n        frag = backtrackFrag;\n        this.fragmentTracker.removeFragment(backtrackFrag);\n      }\n    } else if (this.backtrackFragment && bufferInfo.len) {\n      this.backtrackFragment = null;\n    }\n    // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags\n    if (frag && this.isLoopLoading(frag, targetBufferTime)) {\n      const gapStart = frag.gap;\n      if (!gapStart) {\n        // Cleanup the fragment tracker before trying to find the next unbuffered fragment\n        const type = this.audioOnly && !this.altAudio ? ElementaryStreamTypes.AUDIO : ElementaryStreamTypes.VIDEO;\n        const mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;\n        if (mediaBuffer) {\n          this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);\n        }\n      }\n      frag = this.getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);\n    }\n    if (!frag) {\n      return;\n    }\n    if (frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {\n      frag = frag.initSegment;\n    }\n    this.loadFragment(frag, levelInfo, targetBufferTime);\n  }\n  loadFragment(frag, level, targetBufferTime) {\n    // Check if fragment is not loaded\n    const fragState = this.fragmentTracker.getState(frag);\n    this.fragCurrent = frag;\n    if (fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\n      if (frag.sn === 'initSegment') {\n        this._loadInitSegment(frag, level);\n      } else if (this.bitrateTest) {\n        this.log(`Fragment ${frag.sn} of level ${frag.level} is being downloaded to test bitrate and will not be buffered`);\n        this._loadBitrateTestFrag(frag, level);\n      } else {\n        this.startFragRequested = true;\n        super.loadFragment(frag, level, targetBufferTime);\n      }\n    } else {\n      this.clearTrackerIfNeeded(frag);\n    }\n  }\n  getBufferedFrag(position) {\n    return this.fragmentTracker.getBufferedFrag(position, PlaylistLevelType.MAIN);\n  }\n  followingBufferedFrag(frag) {\n    if (frag) {\n      // try to get range of next fragment (500ms after this range)\n      return this.getBufferedFrag(frag.end + 0.5);\n    }\n    return null;\n  }\n\n  /*\n    on immediate level switch :\n     - pause playback if playing\n     - cancel any pending load request\n     - and trigger a buffer flush\n  */\n  immediateLevelSwitch() {\n    this.abortCurrentFrag();\n    this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n  }\n\n  /**\n   * try to switch ASAP without breaking video playback:\n   * in order to ensure smooth but quick level switching,\n   * we need to find the next flushable buffer range\n   * we should take into account new segment fetch time\n   */\n  nextLevelSwitch() {\n    const {\n      levels,\n      media\n    } = this;\n    // ensure that media is defined and that metadata are available (to retrieve currentTime)\n    if (media != null && media.readyState) {\n      let fetchdelay;\n      const fragPlayingCurrent = this.getAppendedFrag(media.currentTime);\n      if (fragPlayingCurrent && fragPlayingCurrent.start > 1) {\n        // flush buffer preceding current fragment (flush until current fragment start offset)\n        // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...\n        this.flushMainBuffer(0, fragPlayingCurrent.start - 1);\n      }\n      const levelDetails = this.getLevelDetails();\n      if (levelDetails != null && levelDetails.live) {\n        const bufferInfo = this.getMainFwdBufferInfo();\n        // Do not flush in live stream with low buffer\n        if (!bufferInfo || bufferInfo.len < levelDetails.targetduration * 2) {\n          return;\n        }\n      }\n      if (!media.paused && levels) {\n        // add a safety delay of 1s\n        const nextLevelId = this.hls.nextLoadLevel;\n        const nextLevel = levels[nextLevelId];\n        const fragLastKbps = this.fragLastKbps;\n        if (fragLastKbps && this.fragCurrent) {\n          fetchdelay = this.fragCurrent.duration * nextLevel.maxBitrate / (1000 * fragLastKbps) + 1;\n        } else {\n          fetchdelay = 0;\n        }\n      } else {\n        fetchdelay = 0;\n      }\n      // this.log('fetchdelay:'+fetchdelay);\n      // find buffer range that will be reached once new fragment will be fetched\n      const bufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);\n      if (bufferedFrag) {\n        // we can flush buffer range following this one without stalling playback\n        const nextBufferedFrag = this.followingBufferedFrag(bufferedFrag);\n        if (nextBufferedFrag) {\n          // if we are here, we can also cancel any loading/demuxing in progress, as they are useless\n          this.abortCurrentFrag();\n          // start flush position is in next buffered frag. Leave some padding for non-independent segments and smoother playback.\n          const maxStart = nextBufferedFrag.maxStartPTS ? nextBufferedFrag.maxStartPTS : nextBufferedFrag.start;\n          const fragDuration = nextBufferedFrag.duration;\n          const startPts = Math.max(bufferedFrag.end, maxStart + Math.min(Math.max(fragDuration - this.config.maxFragLookUpTolerance, fragDuration * (this.couldBacktrack ? 0.5 : 0.125)), fragDuration * (this.couldBacktrack ? 0.75 : 0.25)));\n          this.flushMainBuffer(startPts, Number.POSITIVE_INFINITY);\n        }\n      }\n    }\n  }\n  abortCurrentFrag() {\n    const fragCurrent = this.fragCurrent;\n    this.fragCurrent = null;\n    this.backtrackFragment = null;\n    if (fragCurrent) {\n      fragCurrent.abortRequests();\n      this.fragmentTracker.removeFragment(fragCurrent);\n    }\n    switch (this.state) {\n      case State.KEY_LOADING:\n      case State.FRAG_LOADING:\n      case State.FRAG_LOADING_WAITING_RETRY:\n      case State.PARSING:\n      case State.PARSED:\n        this.state = State.IDLE;\n        break;\n    }\n    this.nextLoadPosition = this.getLoadPosition();\n  }\n  flushMainBuffer(startOffset, endOffset) {\n    super.flushMainBuffer(startOffset, endOffset, this.altAudio ? 'video' : null);\n  }\n  onMediaAttached(event, data) {\n    super.onMediaAttached(event, data);\n    const media = data.media;\n    this.onvplaying = this.onMediaPlaying.bind(this);\n    this.onvseeked = this.onMediaSeeked.bind(this);\n    media.addEventListener('playing', this.onvplaying);\n    media.addEventListener('seeked', this.onvseeked);\n    this.gapController = new GapController(this.config, media, this.fragmentTracker, this.hls);\n  }\n  onMediaDetaching() {\n    const {\n      media\n    } = this;\n    if (media && this.onvplaying && this.onvseeked) {\n      media.removeEventListener('playing', this.onvplaying);\n      media.removeEventListener('seeked', this.onvseeked);\n      this.onvplaying = this.onvseeked = null;\n      this.videoBuffer = null;\n    }\n    this.fragPlaying = null;\n    if (this.gapController) {\n      this.gapController.destroy();\n      this.gapController = null;\n    }\n    super.onMediaDetaching();\n  }\n  onMediaPlaying() {\n    // tick to speed up FRAG_CHANGED triggering\n    this.tick();\n  }\n  onMediaSeeked() {\n    const media = this.media;\n    const currentTime = media ? media.currentTime : null;\n    if (isFiniteNumber(currentTime)) {\n      this.log(`Media seeked to ${currentTime.toFixed(3)}`);\n    }\n\n    // If seeked was issued before buffer was appended do not tick immediately\n    const bufferInfo = this.getMainFwdBufferInfo();\n    if (bufferInfo === null || bufferInfo.len === 0) {\n      this.warn(`Main forward buffer length on \"seeked\" event ${bufferInfo ? bufferInfo.len : 'empty'})`);\n      return;\n    }\n\n    // tick to speed up FRAG_CHANGED triggering\n    this.tick();\n  }\n  onManifestLoading() {\n    // reset buffer on manifest loading\n    this.log('Trigger BUFFER_RESET');\n    this.hls.trigger(Events.BUFFER_RESET, undefined);\n    this.fragmentTracker.removeAllFragments();\n    this.couldBacktrack = false;\n    this.startPosition = this.lastCurrentTime = this.fragLastKbps = 0;\n    this.levels = this.fragPlaying = this.backtrackFragment = this.levelLastLoaded = null;\n    this.altAudio = this.audioOnly = this.startFragRequested = false;\n  }\n  onManifestParsed(event, data) {\n    // detect if we have different kind of audio codecs used amongst playlists\n    let aac = false;\n    let heaac = false;\n    data.levels.forEach(level => {\n      const codec = level.audioCodec;\n      if (codec) {\n        aac = aac || codec.indexOf('mp4a.40.2') !== -1;\n        heaac = heaac || codec.indexOf('mp4a.40.5') !== -1;\n      }\n    });\n    this.audioCodecSwitch = aac && heaac && !changeTypeSupported();\n    if (this.audioCodecSwitch) {\n      this.log('Both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');\n    }\n    this.levels = data.levels;\n    this.startFragRequested = false;\n  }\n  onLevelLoading(event, data) {\n    const {\n      levels\n    } = this;\n    if (!levels || this.state !== State.IDLE) {\n      return;\n    }\n    const level = levels[data.level];\n    if (!level.details || level.details.live && this.levelLastLoaded !== level || this.waitForCdnTuneIn(level.details)) {\n      this.state = State.WAITING_LEVEL;\n    }\n  }\n  onLevelLoaded(event, data) {\n    var _curLevel$details;\n    const {\n      levels\n    } = this;\n    const newLevelId = data.level;\n    const newDetails = data.details;\n    const duration = newDetails.totalduration;\n    if (!levels) {\n      this.warn(`Levels were reset while loading level ${newLevelId}`);\n      return;\n    }\n    this.log(`Level ${newLevelId} loaded [${newDetails.startSN},${newDetails.endSN}]${newDetails.lastPartSn ? `[part-${newDetails.lastPartSn}-${newDetails.lastPartIndex}]` : ''}, cc [${newDetails.startCC}, ${newDetails.endCC}] duration:${duration}`);\n    const curLevel = levels[newLevelId];\n    const fragCurrent = this.fragCurrent;\n    if (fragCurrent && (this.state === State.FRAG_LOADING || this.state === State.FRAG_LOADING_WAITING_RETRY)) {\n      if (fragCurrent.level !== data.level && fragCurrent.loader) {\n        this.abortCurrentFrag();\n      }\n    }\n    let sliding = 0;\n    if (newDetails.live || (_curLevel$details = curLevel.details) != null && _curLevel$details.live) {\n      var _this$levelLastLoaded;\n      this.checkLiveUpdate(newDetails);\n      if (newDetails.deltaUpdateFailed) {\n        return;\n      }\n      sliding = this.alignPlaylists(newDetails, curLevel.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n    }\n    // override level info\n    curLevel.details = newDetails;\n    this.levelLastLoaded = curLevel;\n    this.hls.trigger(Events.LEVEL_UPDATED, {\n      details: newDetails,\n      level: newLevelId\n    });\n\n    // only switch back to IDLE state if we were waiting for level to start downloading a new fragment\n    if (this.state === State.WAITING_LEVEL) {\n      if (this.waitForCdnTuneIn(newDetails)) {\n        // Wait for Low-Latency CDN Tune-in\n        return;\n      }\n      this.state = State.IDLE;\n    }\n    if (!this.startFragRequested) {\n      this.setStartPosition(newDetails, sliding);\n    } else if (newDetails.live) {\n      this.synchronizeToLiveEdge(newDetails);\n    }\n\n    // trigger handler right now\n    this.tick();\n  }\n  _handleFragmentLoadProgress(data) {\n    var _frag$initSegment;\n    const {\n      frag,\n      part,\n      payload\n    } = data;\n    const {\n      levels\n    } = this;\n    if (!levels) {\n      this.warn(`Levels were reset while fragment load was in progress. Fragment ${frag.sn} of level ${frag.level} will not be buffered`);\n      return;\n    }\n    const currentLevel = levels[frag.level];\n    const details = currentLevel.details;\n    if (!details) {\n      this.warn(`Dropping fragment ${frag.sn} of level ${frag.level} after level details were reset`);\n      this.fragmentTracker.removeFragment(frag);\n      return;\n    }\n    const videoCodec = currentLevel.videoCodec;\n\n    // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n    const accurateTimeOffset = details.PTSKnown || !details.live;\n    const initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;\n    const audioCodec = this._getAudioCodec(currentLevel);\n\n    // transmux the MPEG-TS data to ISO-BMFF segments\n    // this.log(`Transmuxing ${frag.sn} of [${details.startSN} ,${details.endSN}],level ${frag.level}, cc ${frag.cc}`);\n    const transmuxer = this.transmuxer = this.transmuxer || new TransmuxerInterface(this.hls, PlaylistLevelType.MAIN, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));\n    const partIndex = part ? part.index : -1;\n    const partial = partIndex !== -1;\n    const chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);\n    const initPTS = this.initPTS[frag.cc];\n    transmuxer.push(payload, initSegmentData, audioCodec, videoCodec, frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);\n  }\n  onAudioTrackSwitching(event, data) {\n    // if any URL found on new audio track, it is an alternate audio track\n    const fromAltAudio = this.altAudio;\n    const altAudio = !!data.url;\n    // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered\n    // don't do anything if we switch to alt audio: audio stream controller is handling it.\n    // we will just have to change buffer scheduling on audioTrackSwitched\n    if (!altAudio) {\n      if (this.mediaBuffer !== this.media) {\n        this.log('Switching on main audio, use media.buffered to schedule main fragment loading');\n        this.mediaBuffer = this.media;\n        const fragCurrent = this.fragCurrent;\n        // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch\n        if (fragCurrent) {\n          this.log('Switching to main audio track, cancel main fragment load');\n          fragCurrent.abortRequests();\n          this.fragmentTracker.removeFragment(fragCurrent);\n        }\n        // destroy transmuxer to force init segment generation (following audio switch)\n        this.resetTransmuxer();\n        // switch to IDLE state to load new fragment\n        this.resetLoadingState();\n      } else if (this.audioOnly) {\n        // Reset audio transmuxer so when switching back to main audio we're not still appending where we left off\n        this.resetTransmuxer();\n      }\n      const hls = this.hls;\n      // If switching from alt to main audio, flush all audio and trigger track switched\n      if (fromAltAudio) {\n        hls.trigger(Events.BUFFER_FLUSHING, {\n          startOffset: 0,\n          endOffset: Number.POSITIVE_INFINITY,\n          type: null\n        });\n        this.fragmentTracker.removeAllFragments();\n      }\n      hls.trigger(Events.AUDIO_TRACK_SWITCHED, data);\n    }\n  }\n  onAudioTrackSwitched(event, data) {\n    const trackId = data.id;\n    const altAudio = !!this.hls.audioTracks[trackId].url;\n    if (altAudio) {\n      const videoBuffer = this.videoBuffer;\n      // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered\n      if (videoBuffer && this.mediaBuffer !== videoBuffer) {\n        this.log('Switching on alternate audio, use video.buffered to schedule main fragment loading');\n        this.mediaBuffer = videoBuffer;\n      }\n    }\n    this.altAudio = altAudio;\n    this.tick();\n  }\n  onBufferCreated(event, data) {\n    const tracks = data.tracks;\n    let mediaTrack;\n    let name;\n    let alternate = false;\n    for (const type in tracks) {\n      const track = tracks[type];\n      if (track.id === 'main') {\n        name = type;\n        mediaTrack = track;\n        // keep video source buffer reference\n        if (type === 'video') {\n          const videoTrack = tracks[type];\n          if (videoTrack) {\n            this.videoBuffer = videoTrack.buffer;\n          }\n        }\n      } else {\n        alternate = true;\n      }\n    }\n    if (alternate && mediaTrack) {\n      this.log(`Alternate track found, use ${name}.buffered to schedule main fragment loading`);\n      this.mediaBuffer = mediaTrack.buffer;\n    } else {\n      this.mediaBuffer = this.media;\n    }\n  }\n  onFragBuffered(event, data) {\n    const {\n      frag,\n      part\n    } = data;\n    if (frag && frag.type !== PlaylistLevelType.MAIN) {\n      return;\n    }\n    if (this.fragContextChanged(frag)) {\n      // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion\n      // Avoid setting state back to IDLE, since that will interfere with a level switch\n      this.warn(`Fragment ${frag.sn}${part ? ' p: ' + part.index : ''} of level ${frag.level} finished buffering, but was aborted. state: ${this.state}`);\n      if (this.state === State.PARSED) {\n        this.state = State.IDLE;\n      }\n      return;\n    }\n    const stats = part ? part.stats : frag.stats;\n    this.fragLastKbps = Math.round(8 * stats.total / (stats.buffering.end - stats.loading.first));\n    if (frag.sn !== 'initSegment') {\n      this.fragPrevious = frag;\n    }\n    this.fragBufferedComplete(frag, part);\n  }\n  onError(event, data) {\n    var _data$context;\n    if (data.fatal) {\n      this.state = State.ERROR;\n      return;\n    }\n    switch (data.details) {\n      case ErrorDetails.FRAG_GAP:\n      case ErrorDetails.FRAG_PARSING_ERROR:\n      case ErrorDetails.FRAG_DECRYPT_ERROR:\n      case ErrorDetails.FRAG_LOAD_ERROR:\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_ERROR:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n        this.onFragmentOrKeyLoadError(PlaylistLevelType.MAIN, data);\n        break;\n      case ErrorDetails.LEVEL_LOAD_ERROR:\n      case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n      case ErrorDetails.LEVEL_PARSING_ERROR:\n        // in case of non fatal error while loading level, if level controller is not retrying to load level, switch back to IDLE\n        if (!data.levelRetry && this.state === State.WAITING_LEVEL && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.LEVEL) {\n          this.state = State.IDLE;\n        }\n        break;\n      case ErrorDetails.BUFFER_APPEND_ERROR:\n      case ErrorDetails.BUFFER_FULL_ERROR:\n        if (!data.parent || data.parent !== 'main') {\n          return;\n        }\n        if (data.details === ErrorDetails.BUFFER_APPEND_ERROR) {\n          this.resetLoadingState();\n          return;\n        }\n        if (this.reduceLengthAndFlushBuffer(data)) {\n          this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n        }\n        break;\n      case ErrorDetails.INTERNAL_EXCEPTION:\n        this.recoverWorkerError(data);\n        break;\n    }\n  }\n\n  // Checks the health of the buffer and attempts to resolve playback stalls.\n  checkBuffer() {\n    const {\n      media,\n      gapController\n    } = this;\n    if (!media || !gapController || !media.readyState) {\n      // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)\n      return;\n    }\n    if (this.loadedmetadata || !BufferHelper.getBuffered(media).length) {\n      // Resolve gaps using the main buffer, whose ranges are the intersections of the A/V sourcebuffers\n      const activeFrag = this.state !== State.IDLE ? this.fragCurrent : null;\n      gapController.poll(this.lastCurrentTime, activeFrag);\n    }\n    this.lastCurrentTime = media.currentTime;\n  }\n  onFragLoadEmergencyAborted() {\n    this.state = State.IDLE;\n    // if loadedmetadata is not set, it means that we are emergency switch down on first frag\n    // in that case, reset startFragRequested flag\n    if (!this.loadedmetadata) {\n      this.startFragRequested = false;\n      this.nextLoadPosition = this.startPosition;\n    }\n    this.tickImmediate();\n  }\n  onBufferFlushed(event, {\n    type\n  }) {\n    if (type !== ElementaryStreamTypes.AUDIO || this.audioOnly && !this.altAudio) {\n      const mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;\n      this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);\n      this.tick();\n    }\n  }\n  onLevelsUpdated(event, data) {\n    if (this.level > -1 && this.fragCurrent) {\n      this.level = this.fragCurrent.level;\n    }\n    this.levels = data.levels;\n  }\n  swapAudioCodec() {\n    this.audioCodecSwap = !this.audioCodecSwap;\n  }\n\n  /**\n   * Seeks to the set startPosition if not equal to the mediaElement's current time.\n   */\n  seekToStartPos() {\n    const {\n      media\n    } = this;\n    if (!media) {\n      return;\n    }\n    const currentTime = media.currentTime;\n    let startPosition = this.startPosition;\n    // only adjust currentTime if different from startPosition or if startPosition not buffered\n    // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered\n    if (startPosition >= 0 && currentTime < startPosition) {\n      if (media.seeking) {\n        this.log(`could not seek to ${startPosition}, already seeking at ${currentTime}`);\n        return;\n      }\n      const buffered = BufferHelper.getBuffered(media);\n      const bufferStart = buffered.length ? buffered.start(0) : 0;\n      const delta = bufferStart - startPosition;\n      if (delta > 0 && (delta < this.config.maxBufferHole || delta < this.config.maxFragLookUpTolerance)) {\n        this.log(`adjusting start position by ${delta} to match buffer start`);\n        startPosition += delta;\n        this.startPosition = startPosition;\n      }\n      this.log(`seek to target start position ${startPosition} from current time ${currentTime}`);\n      media.currentTime = startPosition;\n    }\n  }\n  _getAudioCodec(currentLevel) {\n    let audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;\n    if (this.audioCodecSwap && audioCodec) {\n      this.log('Swapping audio codec');\n      if (audioCodec.indexOf('mp4a.40.5') !== -1) {\n        audioCodec = 'mp4a.40.2';\n      } else {\n        audioCodec = 'mp4a.40.5';\n      }\n    }\n    return audioCodec;\n  }\n  _loadBitrateTestFrag(frag, level) {\n    frag.bitrateTest = true;\n    this._doFragLoad(frag, level).then(data => {\n      const {\n        hls\n      } = this;\n      if (!data || this.fragContextChanged(frag)) {\n        return;\n      }\n      level.fragmentError = 0;\n      this.state = State.IDLE;\n      this.startFragRequested = false;\n      this.bitrateTest = false;\n      const stats = frag.stats;\n      // Bitrate tests fragments are neither parsed nor buffered\n      stats.parsing.start = stats.parsing.end = stats.buffering.start = stats.buffering.end = self.performance.now();\n      hls.trigger(Events.FRAG_LOADED, data);\n      frag.bitrateTest = false;\n    });\n  }\n  _handleTransmuxComplete(transmuxResult) {\n    var _id3$samples;\n    const id = 'main';\n    const {\n      hls\n    } = this;\n    const {\n      remuxResult,\n      chunkMeta\n    } = transmuxResult;\n    const context = this.getCurrentContext(chunkMeta);\n    if (!context) {\n      this.resetWhenMissingContext(chunkMeta);\n      return;\n    }\n    const {\n      frag,\n      part,\n      level\n    } = context;\n    const {\n      video,\n      text,\n      id3,\n      initSegment\n    } = remuxResult;\n    const {\n      details\n    } = level;\n    // The audio-stream-controller handles audio buffering if Hls.js is playing an alternate audio track\n    const audio = this.altAudio ? undefined : remuxResult.audio;\n\n    // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.\n    // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.\n    if (this.fragContextChanged(frag)) {\n      this.fragmentTracker.removeFragment(frag);\n      return;\n    }\n    this.state = State.PARSING;\n    if (initSegment) {\n      if (initSegment != null && initSegment.tracks) {\n        const mapFragment = frag.initSegment || frag;\n        this._bufferInitSegment(level, initSegment.tracks, mapFragment, chunkMeta);\n        hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {\n          frag: mapFragment,\n          id,\n          tracks: initSegment.tracks\n        });\n      }\n\n      // This would be nice if Number.isFinite acted as a typeguard, but it doesn't. See: https://github.com/Microsoft/TypeScript/issues/10038\n      const initPTS = initSegment.initPTS;\n      const timescale = initSegment.timescale;\n      if (isFiniteNumber(initPTS)) {\n        this.initPTS[frag.cc] = {\n          baseTime: initPTS,\n          timescale\n        };\n        hls.trigger(Events.INIT_PTS_FOUND, {\n          frag,\n          id,\n          initPTS,\n          timescale\n        });\n      }\n    }\n\n    // Avoid buffering if backtracking this fragment\n    if (video && details && frag.sn !== 'initSegment') {\n      const prevFrag = details.fragments[frag.sn - 1 - details.startSN];\n      const isFirstFragment = frag.sn === details.startSN;\n      const isFirstInDiscontinuity = !prevFrag || frag.cc > prevFrag.cc;\n      if (remuxResult.independent !== false) {\n        const {\n          startPTS,\n          endPTS,\n          startDTS,\n          endDTS\n        } = video;\n        if (part) {\n          part.elementaryStreams[video.type] = {\n            startPTS,\n            endPTS,\n            startDTS,\n            endDTS\n          };\n        } else {\n          if (video.firstKeyFrame && video.independent && chunkMeta.id === 1 && !isFirstInDiscontinuity) {\n            this.couldBacktrack = true;\n          }\n          if (video.dropped && video.independent) {\n            // Backtrack if dropped frames create a gap after currentTime\n\n            const bufferInfo = this.getMainFwdBufferInfo();\n            const targetBufferTime = (bufferInfo ? bufferInfo.end : this.getLoadPosition()) + this.config.maxBufferHole;\n            const startTime = video.firstKeyFramePTS ? video.firstKeyFramePTS : startPTS;\n            if (!isFirstFragment && targetBufferTime < startTime - this.config.maxBufferHole && !isFirstInDiscontinuity) {\n              this.backtrack(frag);\n              return;\n            } else if (isFirstInDiscontinuity) {\n              // Mark segment with a gap to avoid loop loading\n              frag.gap = true;\n            }\n            // Set video stream start to fragment start so that truncated samples do not distort the timeline, and mark it partial\n            frag.setElementaryStreamInfo(video.type, frag.start, endPTS, frag.start, endDTS, true);\n          } else if (isFirstFragment && startPTS > MAX_START_GAP_JUMP) {\n            // Mark segment with a gap to skip large start gap\n            frag.gap = true;\n          }\n        }\n        frag.setElementaryStreamInfo(video.type, startPTS, endPTS, startDTS, endDTS);\n        if (this.backtrackFragment) {\n          this.backtrackFragment = frag;\n        }\n        this.bufferFragmentData(video, frag, part, chunkMeta, isFirstFragment || isFirstInDiscontinuity);\n      } else if (isFirstFragment || isFirstInDiscontinuity) {\n        // Mark segment with a gap to avoid loop loading\n        frag.gap = true;\n      } else {\n        this.backtrack(frag);\n        return;\n      }\n    }\n    if (audio) {\n      const {\n        startPTS,\n        endPTS,\n        startDTS,\n        endDTS\n      } = audio;\n      if (part) {\n        part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {\n          startPTS,\n          endPTS,\n          startDTS,\n          endDTS\n        };\n      }\n      frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);\n      this.bufferFragmentData(audio, frag, part, chunkMeta);\n    }\n    if (details && id3 != null && (_id3$samples = id3.samples) != null && _id3$samples.length) {\n      const emittedID3 = {\n        id,\n        frag,\n        details,\n        samples: id3.samples\n      };\n      hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);\n    }\n    if (details && text) {\n      const emittedText = {\n        id,\n        frag,\n        details,\n        samples: text.samples\n      };\n      hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);\n    }\n  }\n  _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {\n    if (this.state !== State.PARSING) {\n      return;\n    }\n    this.audioOnly = !!tracks.audio && !tracks.video;\n\n    // if audio track is expected to come from audio stream controller, discard any coming from main\n    if (this.altAudio && !this.audioOnly) {\n      delete tracks.audio;\n    }\n    // include levelCodec in audio and video tracks\n    const {\n      audio,\n      video,\n      audiovideo\n    } = tracks;\n    if (audio) {\n      let audioCodec = currentLevel.audioCodec;\n      const ua = navigator.userAgent.toLowerCase();\n      if (this.audioCodecSwitch) {\n        if (audioCodec) {\n          if (audioCodec.indexOf('mp4a.40.5') !== -1) {\n            audioCodec = 'mp4a.40.2';\n          } else {\n            audioCodec = 'mp4a.40.5';\n          }\n        }\n        // In the case that AAC and HE-AAC audio codecs are signalled in manifest,\n        // force HE-AAC, as it seems that most browsers prefers it.\n        // don't force HE-AAC if mono stream, or in Firefox\n        const audioMetadata = audio.metadata;\n        if (audioMetadata && 'channelCount' in audioMetadata && (audioMetadata.channelCount || 1) !== 1 && ua.indexOf('firefox') === -1) {\n          audioCodec = 'mp4a.40.5';\n        }\n      }\n      // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise\n      if (audioCodec && audioCodec.indexOf('mp4a.40.5') !== -1 && ua.indexOf('android') !== -1 && audio.container !== 'audio/mpeg') {\n        // Exclude mpeg audio\n        audioCodec = 'mp4a.40.2';\n        this.log(`Android: force audio codec to ${audioCodec}`);\n      }\n      if (currentLevel.audioCodec && currentLevel.audioCodec !== audioCodec) {\n        this.log(`Swapping manifest audio codec \"${currentLevel.audioCodec}\" for \"${audioCodec}\"`);\n      }\n      audio.levelCodec = audioCodec;\n      audio.id = 'main';\n      this.log(`Init audio buffer, container:${audio.container}, codecs[selected/level/parsed]=[${audioCodec || ''}/${currentLevel.audioCodec || ''}/${audio.codec}]`);\n    }\n    if (video) {\n      video.levelCodec = currentLevel.videoCodec;\n      video.id = 'main';\n      this.log(`Init video buffer, container:${video.container}, codecs[level/parsed]=[${currentLevel.videoCodec || ''}/${video.codec}]`);\n    }\n    if (audiovideo) {\n      this.log(`Init audiovideo buffer, container:${audiovideo.container}, codecs[level/parsed]=[${currentLevel.codecs}/${audiovideo.codec}]`);\n    }\n    this.hls.trigger(Events.BUFFER_CODECS, tracks);\n    // loop through tracks that are going to be provided to bufferController\n    Object.keys(tracks).forEach(trackName => {\n      const track = tracks[trackName];\n      const initSegment = track.initSegment;\n      if (initSegment != null && initSegment.byteLength) {\n        this.hls.trigger(Events.BUFFER_APPENDING, {\n          type: trackName,\n          data: initSegment,\n          frag,\n          part: null,\n          chunkMeta,\n          parent: frag.type\n        });\n      }\n    });\n    // trigger handler right now\n    this.tickImmediate();\n  }\n  getMainFwdBufferInfo() {\n    return this.getFwdBufferInfo(this.mediaBuffer ? this.mediaBuffer : this.media, PlaylistLevelType.MAIN);\n  }\n  backtrack(frag) {\n    this.couldBacktrack = true;\n    // Causes findFragments to backtrack through fragments to find the keyframe\n    this.backtrackFragment = frag;\n    this.resetTransmuxer();\n    this.flushBufferGap(frag);\n    this.fragmentTracker.removeFragment(frag);\n    this.fragPrevious = null;\n    this.nextLoadPosition = frag.start;\n    this.state = State.IDLE;\n  }\n  checkFragmentChanged() {\n    const video = this.media;\n    let fragPlayingCurrent = null;\n    if (video && video.readyState > 1 && video.seeking === false) {\n      const currentTime = video.currentTime;\n      /* if video element is in seeked state, currentTime can only increase.\n        (assuming that playback rate is positive ...)\n        As sometimes currentTime jumps back to zero after a\n        media decode error, check this, to avoid seeking back to\n        wrong position after a media decode error\n      */\n\n      if (BufferHelper.isBuffered(video, currentTime)) {\n        fragPlayingCurrent = this.getAppendedFrag(currentTime);\n      } else if (BufferHelper.isBuffered(video, currentTime + 0.1)) {\n        /* ensure that FRAG_CHANGED event is triggered at startup,\n          when first video frame is displayed and playback is paused.\n          add a tolerance of 100ms, in case current position is not buffered,\n          check if current pos+100ms is buffered and use that buffer range\n          for FRAG_CHANGED event reporting */\n        fragPlayingCurrent = this.getAppendedFrag(currentTime + 0.1);\n      }\n      if (fragPlayingCurrent) {\n        this.backtrackFragment = null;\n        const fragPlaying = this.fragPlaying;\n        const fragCurrentLevel = fragPlayingCurrent.level;\n        if (!fragPlaying || fragPlayingCurrent.sn !== fragPlaying.sn || fragPlaying.level !== fragCurrentLevel) {\n          this.fragPlaying = fragPlayingCurrent;\n          this.hls.trigger(Events.FRAG_CHANGED, {\n            frag: fragPlayingCurrent\n          });\n          if (!fragPlaying || fragPlaying.level !== fragCurrentLevel) {\n            this.hls.trigger(Events.LEVEL_SWITCHED, {\n              level: fragCurrentLevel\n            });\n          }\n        }\n      }\n    }\n  }\n  get nextLevel() {\n    const frag = this.nextBufferedFrag;\n    if (frag) {\n      return frag.level;\n    }\n    return -1;\n  }\n  get currentFrag() {\n    const media = this.media;\n    if (media) {\n      return this.fragPlaying || this.getAppendedFrag(media.currentTime);\n    }\n    return null;\n  }\n  get currentProgramDateTime() {\n    const media = this.media;\n    if (media) {\n      const currentTime = media.currentTime;\n      const frag = this.currentFrag;\n      if (frag && isFiniteNumber(currentTime) && isFiniteNumber(frag.programDateTime)) {\n        const epocMs = frag.programDateTime + (currentTime - frag.start) * 1000;\n        return new Date(epocMs);\n      }\n    }\n    return null;\n  }\n  get currentLevel() {\n    const frag = this.currentFrag;\n    if (frag) {\n      return frag.level;\n    }\n    return -1;\n  }\n  get nextBufferedFrag() {\n    const frag = this.currentFrag;\n    if (frag) {\n      return this.followingBufferedFrag(frag);\n    }\n    return null;\n  }\n  get forceStartLoad() {\n    return this._forceStartLoad;\n  }\n}\n\n/**\n * The `Hls` class is the core of the HLS.js library used to instantiate player instances.\n * @public\n */\nclass Hls {\n  /**\n   * Get the video-dev/hls.js package version.\n   */\n  static get version() {\n    return \"1.5.13\";\n  }\n\n  /**\n   * Check if the required MediaSource Extensions are available.\n   */\n  static isMSESupported() {\n    return isMSESupported();\n  }\n\n  /**\n   * Check if MediaSource Extensions are available and isTypeSupported checks pass for any baseline codecs.\n   */\n  static isSupported() {\n    return isSupported();\n  }\n\n  /**\n   * Get the MediaSource global used for MSE playback (ManagedMediaSource, MediaSource, or WebKitMediaSource).\n   */\n  static getMediaSource() {\n    return getMediaSource();\n  }\n  static get Events() {\n    return Events;\n  }\n  static get ErrorTypes() {\n    return ErrorTypes;\n  }\n  static get ErrorDetails() {\n    return ErrorDetails;\n  }\n\n  /**\n   * Get the default configuration applied to new instances.\n   */\n  static get DefaultConfig() {\n    if (!Hls.defaultConfig) {\n      return hlsDefaultConfig;\n    }\n    return Hls.defaultConfig;\n  }\n\n  /**\n   * Replace the default configuration applied to new instances.\n   */\n  static set DefaultConfig(defaultConfig) {\n    Hls.defaultConfig = defaultConfig;\n  }\n\n  /**\n   * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.\n   * @param userConfig - Configuration options applied over `Hls.DefaultConfig`\n   */\n  constructor(userConfig = {}) {\n    /**\n     * The runtime configuration used by the player. At instantiation this is combination of `hls.userConfig` merged over `Hls.DefaultConfig`.\n     */\n    this.config = void 0;\n    /**\n     * The configuration object provided on player instantiation.\n     */\n    this.userConfig = void 0;\n    this.coreComponents = void 0;\n    this.networkControllers = void 0;\n    this.started = false;\n    this._emitter = new EventEmitter();\n    this._autoLevelCapping = -1;\n    this._maxHdcpLevel = null;\n    this.abrController = void 0;\n    this.bufferController = void 0;\n    this.capLevelController = void 0;\n    this.latencyController = void 0;\n    this.levelController = void 0;\n    this.streamController = void 0;\n    this.audioTrackController = void 0;\n    this.subtitleTrackController = void 0;\n    this.emeController = void 0;\n    this.cmcdController = void 0;\n    this._media = null;\n    this.url = null;\n    this.triggeringException = void 0;\n    enableLogs(userConfig.debug || false, 'Hls instance');\n    const config = this.config = mergeConfig(Hls.DefaultConfig, userConfig);\n    this.userConfig = userConfig;\n    if (config.progressive) {\n      enableStreamingMode(config);\n    }\n\n    // core controllers and network loaders\n    const {\n      abrController: ConfigAbrController,\n      bufferController: ConfigBufferController,\n      capLevelController: ConfigCapLevelController,\n      errorController: ConfigErrorController,\n      fpsController: ConfigFpsController\n    } = config;\n    const errorController = new ConfigErrorController(this);\n    const abrController = this.abrController = new ConfigAbrController(this);\n    const bufferController = this.bufferController = new ConfigBufferController(this);\n    const capLevelController = this.capLevelController = new ConfigCapLevelController(this);\n    const fpsController = new ConfigFpsController(this);\n    const playListLoader = new PlaylistLoader(this);\n    const id3TrackController = new ID3TrackController(this);\n    const ConfigContentSteeringController = config.contentSteeringController;\n    // ConentSteeringController is defined before LevelController to receive Multivariant Playlist events first\n    const contentSteering = ConfigContentSteeringController ? new ConfigContentSteeringController(this) : null;\n    const levelController = this.levelController = new LevelController(this, contentSteering);\n    // FragmentTracker must be defined before StreamController because the order of event handling is important\n    const fragmentTracker = new FragmentTracker(this);\n    const keyLoader = new KeyLoader(this.config);\n    const streamController = this.streamController = new StreamController(this, fragmentTracker, keyLoader);\n\n    // Cap level controller uses streamController to flush the buffer\n    capLevelController.setStreamController(streamController);\n    // fpsController uses streamController to switch when frames are being dropped\n    fpsController.setStreamController(streamController);\n    const networkControllers = [playListLoader, levelController, streamController];\n    if (contentSteering) {\n      networkControllers.splice(1, 0, contentSteering);\n    }\n    this.networkControllers = networkControllers;\n    const coreComponents = [abrController, bufferController, capLevelController, fpsController, id3TrackController, fragmentTracker];\n    this.audioTrackController = this.createController(config.audioTrackController, networkControllers);\n    const AudioStreamControllerClass = config.audioStreamController;\n    if (AudioStreamControllerClass) {\n      networkControllers.push(new AudioStreamControllerClass(this, fragmentTracker, keyLoader));\n    }\n    // subtitleTrackController must be defined before subtitleStreamController because the order of event handling is important\n    this.subtitleTrackController = this.createController(config.subtitleTrackController, networkControllers);\n    const SubtitleStreamControllerClass = config.subtitleStreamController;\n    if (SubtitleStreamControllerClass) {\n      networkControllers.push(new SubtitleStreamControllerClass(this, fragmentTracker, keyLoader));\n    }\n    this.createController(config.timelineController, coreComponents);\n    keyLoader.emeController = this.emeController = this.createController(config.emeController, coreComponents);\n    this.cmcdController = this.createController(config.cmcdController, coreComponents);\n    this.latencyController = this.createController(LatencyController, coreComponents);\n    this.coreComponents = coreComponents;\n\n    // Error controller handles errors before and after all other controllers\n    // This listener will be invoked after all other controllers error listeners\n    networkControllers.push(errorController);\n    const onErrorOut = errorController.onErrorOut;\n    if (typeof onErrorOut === 'function') {\n      this.on(Events.ERROR, onErrorOut, errorController);\n    }\n  }\n  createController(ControllerClass, components) {\n    if (ControllerClass) {\n      const controllerInstance = new ControllerClass(this);\n      if (components) {\n        components.push(controllerInstance);\n      }\n      return controllerInstance;\n    }\n    return null;\n  }\n\n  // Delegate the EventEmitter through the public API of Hls.js\n  on(event, listener, context = this) {\n    this._emitter.on(event, listener, context);\n  }\n  once(event, listener, context = this) {\n    this._emitter.once(event, listener, context);\n  }\n  removeAllListeners(event) {\n    this._emitter.removeAllListeners(event);\n  }\n  off(event, listener, context = this, once) {\n    this._emitter.off(event, listener, context, once);\n  }\n  listeners(event) {\n    return this._emitter.listeners(event);\n  }\n  emit(event, name, eventObject) {\n    return this._emitter.emit(event, name, eventObject);\n  }\n  trigger(event, eventObject) {\n    if (this.config.debug) {\n      return this.emit(event, event, eventObject);\n    } else {\n      try {\n        return this.emit(event, event, eventObject);\n      } catch (error) {\n        logger.error('An internal error happened while handling event ' + event + '. Error message: \"' + error.message + '\". Here is a stacktrace:', error);\n        // Prevent recursion in error event handlers that throw #5497\n        if (!this.triggeringException) {\n          this.triggeringException = true;\n          const fatal = event === Events.ERROR;\n          this.trigger(Events.ERROR, {\n            type: ErrorTypes.OTHER_ERROR,\n            details: ErrorDetails.INTERNAL_EXCEPTION,\n            fatal,\n            event,\n            error\n          });\n          this.triggeringException = false;\n        }\n      }\n    }\n    return false;\n  }\n  listenerCount(event) {\n    return this._emitter.listenerCount(event);\n  }\n\n  /**\n   * Dispose of the instance\n   */\n  destroy() {\n    logger.log('destroy');\n    this.trigger(Events.DESTROYING, undefined);\n    this.detachMedia();\n    this.removeAllListeners();\n    this._autoLevelCapping = -1;\n    this.url = null;\n    this.networkControllers.forEach(component => component.destroy());\n    this.networkControllers.length = 0;\n    this.coreComponents.forEach(component => component.destroy());\n    this.coreComponents.length = 0;\n    // Remove any references that could be held in config options or callbacks\n    const config = this.config;\n    config.xhrSetup = config.fetchSetup = undefined;\n    // @ts-ignore\n    this.userConfig = null;\n  }\n\n  /**\n   * Attaches Hls.js to a media element\n   */\n  attachMedia(media) {\n    logger.log('attachMedia');\n    this._media = media;\n    this.trigger(Events.MEDIA_ATTACHING, {\n      media: media\n    });\n  }\n\n  /**\n   * Detach Hls.js from the media\n   */\n  detachMedia() {\n    logger.log('detachMedia');\n    this.trigger(Events.MEDIA_DETACHING, undefined);\n    this._media = null;\n  }\n\n  /**\n   * Set the source URL. Can be relative or absolute.\n   */\n  loadSource(url) {\n    this.stopLoad();\n    const media = this.media;\n    const loadedSource = this.url;\n    const loadingSource = this.url = urlToolkitExports.buildAbsoluteURL(self.location.href, url, {\n      alwaysNormalize: true\n    });\n    this._autoLevelCapping = -1;\n    this._maxHdcpLevel = null;\n    logger.log(`loadSource:${loadingSource}`);\n    if (media && loadedSource && (loadedSource !== loadingSource || this.bufferController.hasSourceTypes())) {\n      this.detachMedia();\n      this.attachMedia(media);\n    }\n    // when attaching to a source URL, trigger a playlist load\n    this.trigger(Events.MANIFEST_LOADING, {\n      url: url\n    });\n  }\n\n  /**\n   * Start loading data from the stream source.\n   * Depending on default config, client starts loading automatically when a source is set.\n   *\n   * @param startPosition - Set the start position to stream from.\n   * Defaults to -1 (None: starts from earliest point)\n   */\n  startLoad(startPosition = -1) {\n    logger.log(`startLoad(${startPosition})`);\n    this.started = true;\n    this.networkControllers.forEach(controller => {\n      controller.startLoad(startPosition);\n    });\n  }\n\n  /**\n   * Stop loading of any stream data.\n   */\n  stopLoad() {\n    logger.log('stopLoad');\n    this.started = false;\n    this.networkControllers.forEach(controller => {\n      controller.stopLoad();\n    });\n  }\n\n  /**\n   * Resumes stream controller segment loading if previously started.\n   */\n  resumeBuffering() {\n    if (this.started) {\n      this.networkControllers.forEach(controller => {\n        if ('fragmentLoader' in controller) {\n          controller.startLoad(-1);\n        }\n      });\n    }\n  }\n\n  /**\n   * Stops stream controller segment loading without changing 'started' state like stopLoad().\n   * This allows for media buffering to be paused without interupting playlist loading.\n   */\n  pauseBuffering() {\n    this.networkControllers.forEach(controller => {\n      if ('fragmentLoader' in controller) {\n        controller.stopLoad();\n      }\n    });\n  }\n\n  /**\n   * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)\n   */\n  swapAudioCodec() {\n    logger.log('swapAudioCodec');\n    this.streamController.swapAudioCodec();\n  }\n\n  /**\n   * When the media-element fails, this allows to detach and then re-attach it\n   * as one call (convenience method).\n   *\n   * Automatic recovery of media-errors by this process is configurable.\n   */\n  recoverMediaError() {\n    logger.log('recoverMediaError');\n    const media = this._media;\n    this.detachMedia();\n    if (media) {\n      this.attachMedia(media);\n    }\n  }\n  removeLevel(levelIndex) {\n    this.levelController.removeLevel(levelIndex);\n  }\n\n  /**\n   * @returns an array of levels (variants) sorted by HDCP-LEVEL, RESOLUTION (height), FRAME-RATE, CODECS, VIDEO-RANGE, and BANDWIDTH\n   */\n  get levels() {\n    const levels = this.levelController.levels;\n    return levels ? levels : [];\n  }\n\n  /**\n   * Index of quality level (variant) currently played\n   */\n  get currentLevel() {\n    return this.streamController.currentLevel;\n  }\n\n  /**\n   * Set quality level index immediately. This will flush the current buffer to replace the quality asap. That means playback will interrupt at least shortly to re-buffer and re-sync eventually. Set to -1 for automatic level selection.\n   */\n  set currentLevel(newLevel) {\n    logger.log(`set currentLevel:${newLevel}`);\n    this.levelController.manualLevel = newLevel;\n    this.streamController.immediateLevelSwitch();\n  }\n\n  /**\n   * Index of next quality level loaded as scheduled by stream controller.\n   */\n  get nextLevel() {\n    return this.streamController.nextLevel;\n  }\n\n  /**\n   * Set quality level index for next loaded data.\n   * This will switch the video quality asap, without interrupting playback.\n   * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).\n   * @param newLevel - Pass -1 for automatic level selection\n   */\n  set nextLevel(newLevel) {\n    logger.log(`set nextLevel:${newLevel}`);\n    this.levelController.manualLevel = newLevel;\n    this.streamController.nextLevelSwitch();\n  }\n\n  /**\n   * Return the quality level of the currently or last (of none is loaded currently) segment\n   */\n  get loadLevel() {\n    return this.levelController.level;\n  }\n\n  /**\n   * Set quality level index for next loaded data in a conservative way.\n   * This will switch the quality without flushing, but interrupt current loading.\n   * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.\n   * @param newLevel - Pass -1 for automatic level selection\n   */\n  set loadLevel(newLevel) {\n    logger.log(`set loadLevel:${newLevel}`);\n    this.levelController.manualLevel = newLevel;\n  }\n\n  /**\n   * get next quality level loaded\n   */\n  get nextLoadLevel() {\n    return this.levelController.nextLoadLevel;\n  }\n\n  /**\n   * Set quality level of next loaded segment in a fully \"non-destructive\" way.\n   * Same as `loadLevel` but will wait for next switch (until current loading is done).\n   */\n  set nextLoadLevel(level) {\n    this.levelController.nextLoadLevel = level;\n  }\n\n  /**\n   * Return \"first level\": like a default level, if not set,\n   * falls back to index of first level referenced in manifest\n   */\n  get firstLevel() {\n    return Math.max(this.levelController.firstLevel, this.minAutoLevel);\n  }\n\n  /**\n   * Sets \"first-level\", see getter.\n   */\n  set firstLevel(newLevel) {\n    logger.log(`set firstLevel:${newLevel}`);\n    this.levelController.firstLevel = newLevel;\n  }\n\n  /**\n   * Return the desired start level for the first fragment that will be loaded.\n   * The default value of -1 indicates automatic start level selection.\n   * Setting hls.nextAutoLevel without setting a startLevel will result in\n   * the nextAutoLevel value being used for one fragment load.\n   */\n  get startLevel() {\n    const startLevel = this.levelController.startLevel;\n    if (startLevel === -1 && this.abrController.forcedAutoLevel > -1) {\n      return this.abrController.forcedAutoLevel;\n    }\n    return startLevel;\n  }\n\n  /**\n   * set  start level (level of first fragment that will be played back)\n   * if not overrided by user, first level appearing in manifest will be used as start level\n   * if -1 : automatic start level selection, playback will start from level matching download bandwidth\n   * (determined from download of first segment)\n   */\n  set startLevel(newLevel) {\n    logger.log(`set startLevel:${newLevel}`);\n    // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel\n    if (newLevel !== -1) {\n      newLevel = Math.max(newLevel, this.minAutoLevel);\n    }\n    this.levelController.startLevel = newLevel;\n  }\n\n  /**\n   * Whether level capping is enabled.\n   * Default value is set via `config.capLevelToPlayerSize`.\n   */\n  get capLevelToPlayerSize() {\n    return this.config.capLevelToPlayerSize;\n  }\n\n  /**\n   * Enables or disables level capping. If disabled after previously enabled, `nextLevelSwitch` will be immediately called.\n   */\n  set capLevelToPlayerSize(shouldStartCapping) {\n    const newCapLevelToPlayerSize = !!shouldStartCapping;\n    if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {\n      if (newCapLevelToPlayerSize) {\n        this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.\n      } else {\n        this.capLevelController.stopCapping();\n        this.autoLevelCapping = -1;\n        this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.\n      }\n      this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;\n    }\n  }\n\n  /**\n   * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n   */\n  get autoLevelCapping() {\n    return this._autoLevelCapping;\n  }\n\n  /**\n   * Returns the current bandwidth estimate in bits per second, when available. Otherwise, `NaN` is returned.\n   */\n  get bandwidthEstimate() {\n    const {\n      bwEstimator\n    } = this.abrController;\n    if (!bwEstimator) {\n      return NaN;\n    }\n    return bwEstimator.getEstimate();\n  }\n  set bandwidthEstimate(abrEwmaDefaultEstimate) {\n    this.abrController.resetEstimator(abrEwmaDefaultEstimate);\n  }\n\n  /**\n   * get time to first byte estimate\n   * @type {number}\n   */\n  get ttfbEstimate() {\n    const {\n      bwEstimator\n    } = this.abrController;\n    if (!bwEstimator) {\n      return NaN;\n    }\n    return bwEstimator.getEstimateTTFB();\n  }\n\n  /**\n   * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n   */\n  set autoLevelCapping(newLevel) {\n    if (this._autoLevelCapping !== newLevel) {\n      logger.log(`set autoLevelCapping:${newLevel}`);\n      this._autoLevelCapping = newLevel;\n      this.levelController.checkMaxAutoUpdated();\n    }\n  }\n  get maxHdcpLevel() {\n    return this._maxHdcpLevel;\n  }\n  set maxHdcpLevel(value) {\n    if (isHdcpLevel(value) && this._maxHdcpLevel !== value) {\n      this._maxHdcpLevel = value;\n      this.levelController.checkMaxAutoUpdated();\n    }\n  }\n\n  /**\n   * True when automatic level selection enabled\n   */\n  get autoLevelEnabled() {\n    return this.levelController.manualLevel === -1;\n  }\n\n  /**\n   * Level set manually (if any)\n   */\n  get manualLevel() {\n    return this.levelController.manualLevel;\n  }\n\n  /**\n   * min level selectable in auto mode according to config.minAutoBitrate\n   */\n  get minAutoLevel() {\n    const {\n      levels,\n      config: {\n        minAutoBitrate\n      }\n    } = this;\n    if (!levels) return 0;\n    const len = levels.length;\n    for (let i = 0; i < len; i++) {\n      if (levels[i].maxBitrate >= minAutoBitrate) {\n        return i;\n      }\n    }\n    return 0;\n  }\n\n  /**\n   * max level selectable in auto mode according to autoLevelCapping\n   */\n  get maxAutoLevel() {\n    const {\n      levels,\n      autoLevelCapping,\n      maxHdcpLevel\n    } = this;\n    let maxAutoLevel;\n    if (autoLevelCapping === -1 && levels != null && levels.length) {\n      maxAutoLevel = levels.length - 1;\n    } else {\n      maxAutoLevel = autoLevelCapping;\n    }\n    if (maxHdcpLevel) {\n      for (let i = maxAutoLevel; i--;) {\n        const hdcpLevel = levels[i].attrs['HDCP-LEVEL'];\n        if (hdcpLevel && hdcpLevel <= maxHdcpLevel) {\n          return i;\n        }\n      }\n    }\n    return maxAutoLevel;\n  }\n  get firstAutoLevel() {\n    return this.abrController.firstAutoLevel;\n  }\n\n  /**\n   * next automatically selected quality level\n   */\n  get nextAutoLevel() {\n    return this.abrController.nextAutoLevel;\n  }\n\n  /**\n   * this setter is used to force next auto level.\n   * this is useful to force a switch down in auto mode:\n   * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)\n   * forced value is valid for one fragment. upon successful frag loading at forced level,\n   * this value will be resetted to -1 by ABR controller.\n   */\n  set nextAutoLevel(nextLevel) {\n    this.abrController.nextAutoLevel = nextLevel;\n  }\n\n  /**\n   * get the datetime value relative to media.currentTime for the active level Program Date Time if present\n   */\n  get playingDate() {\n    return this.streamController.currentProgramDateTime;\n  }\n  get mainForwardBufferInfo() {\n    return this.streamController.getMainFwdBufferInfo();\n  }\n\n  /**\n   * Find and select the best matching audio track, making a level switch when a Group change is necessary.\n   * Updates `hls.config.audioPreference`. Returns the selected track, or null when no matching track is found.\n   */\n  setAudioOption(audioOption) {\n    var _this$audioTrackContr;\n    return (_this$audioTrackContr = this.audioTrackController) == null ? void 0 : _this$audioTrackContr.setAudioOption(audioOption);\n  }\n  /**\n   * Find and select the best matching subtitle track, making a level switch when a Group change is necessary.\n   * Updates `hls.config.subtitlePreference`. Returns the selected track, or null when no matching track is found.\n   */\n  setSubtitleOption(subtitleOption) {\n    var _this$subtitleTrackCo;\n    (_this$subtitleTrackCo = this.subtitleTrackController) == null ? void 0 : _this$subtitleTrackCo.setSubtitleOption(subtitleOption);\n    return null;\n  }\n\n  /**\n   * Get the complete list of audio tracks across all media groups\n   */\n  get allAudioTracks() {\n    const audioTrackController = this.audioTrackController;\n    return audioTrackController ? audioTrackController.allAudioTracks : [];\n  }\n\n  /**\n   * Get the list of selectable audio tracks\n   */\n  get audioTracks() {\n    const audioTrackController = this.audioTrackController;\n    return audioTrackController ? audioTrackController.audioTracks : [];\n  }\n\n  /**\n   * index of the selected audio track (index in audio track lists)\n   */\n  get audioTrack() {\n    const audioTrackController = this.audioTrackController;\n    return audioTrackController ? audioTrackController.audioTrack : -1;\n  }\n\n  /**\n   * selects an audio track, based on its index in audio track lists\n   */\n  set audioTrack(audioTrackId) {\n    const audioTrackController = this.audioTrackController;\n    if (audioTrackController) {\n      audioTrackController.audioTrack = audioTrackId;\n    }\n  }\n\n  /**\n   * get the complete list of subtitle tracks across all media groups\n   */\n  get allSubtitleTracks() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.allSubtitleTracks : [];\n  }\n\n  /**\n   * get alternate subtitle tracks list from playlist\n   */\n  get subtitleTracks() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];\n  }\n\n  /**\n   * index of the selected subtitle track (index in subtitle track lists)\n   */\n  get subtitleTrack() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;\n  }\n  get media() {\n    return this._media;\n  }\n\n  /**\n   * select an subtitle track, based on its index in subtitle track lists\n   */\n  set subtitleTrack(subtitleTrackId) {\n    const subtitleTrackController = this.subtitleTrackController;\n    if (subtitleTrackController) {\n      subtitleTrackController.subtitleTrack = subtitleTrackId;\n    }\n  }\n\n  /**\n   * Whether subtitle display is enabled or not\n   */\n  get subtitleDisplay() {\n    const subtitleTrackController = this.subtitleTrackController;\n    return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;\n  }\n\n  /**\n   * Enable/disable subtitle display rendering\n   */\n  set subtitleDisplay(value) {\n    const subtitleTrackController = this.subtitleTrackController;\n    if (subtitleTrackController) {\n      subtitleTrackController.subtitleDisplay = value;\n    }\n  }\n\n  /**\n   * get mode for Low-Latency HLS loading\n   */\n  get lowLatencyMode() {\n    return this.config.lowLatencyMode;\n  }\n\n  /**\n   * Enable/disable Low-Latency HLS part playlist and segment loading, and start live streams at playlist PART-HOLD-BACK rather than HOLD-BACK.\n   */\n  set lowLatencyMode(mode) {\n    this.config.lowLatencyMode = mode;\n  }\n\n  /**\n   * Position (in seconds) of live sync point (ie edge of live position minus safety delay defined by ```hls.config.liveSyncDuration```)\n   * @returns null prior to loading live Playlist\n   */\n  get liveSyncPosition() {\n    return this.latencyController.liveSyncPosition;\n  }\n\n  /**\n   * Estimated position (in seconds) of live edge (ie edge of live playlist plus time sync playlist advanced)\n   * @returns 0 before first playlist is loaded\n   */\n  get latency() {\n    return this.latencyController.latency;\n  }\n\n  /**\n   * maximum distance from the edge before the player seeks forward to ```hls.liveSyncPosition```\n   * configured using ```liveMaxLatencyDurationCount``` (multiple of target duration) or ```liveMaxLatencyDuration```\n   * @returns 0 before first playlist is loaded\n   */\n  get maxLatency() {\n    return this.latencyController.maxLatency;\n  }\n\n  /**\n   * target distance from the edge as calculated by the latency controller\n   */\n  get targetLatency() {\n    return this.latencyController.targetLatency;\n  }\n\n  /**\n   * the rate at which the edge of the current live playlist is advancing or 1 if there is none\n   */\n  get drift() {\n    return this.latencyController.drift;\n  }\n\n  /**\n   * set to true when startLoad is called before MANIFEST_PARSED event\n   */\n  get forceStartLoad() {\n    return this.streamController.forceStartLoad;\n  }\n}\nHls.defaultConfig = void 0;\n\n\n//# sourceMappingURL=hls.mjs.map\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/hls.js/dist/hls.mjs?");

/***/ }),

/***/ "./node_modules/socket.io-client/build/esm/contrib/backo2.js":
/*!*******************************************************************!*\
  !*** ./node_modules/socket.io-client/build/esm/contrib/backo2.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Backoff: () => (/* binding */ Backoff)\n/* harmony export */ });\n/**\n * Initialize backoff timer with `opts`.\n *\n * - `min` initial timeout in milliseconds [100]\n * - `max` max timeout [10000]\n * - `jitter` [0]\n * - `factor` [2]\n *\n * @param {Object} opts\n * @api public\n */\nfunction Backoff(opts) {\n    opts = opts || {};\n    this.ms = opts.min || 100;\n    this.max = opts.max || 10000;\n    this.factor = opts.factor || 2;\n    this.jitter = opts.jitter > 0 && opts.jitter <= 1 ? opts.jitter : 0;\n    this.attempts = 0;\n}\n/**\n * Return the backoff duration.\n *\n * @return {Number}\n * @api public\n */\nBackoff.prototype.duration = function () {\n    var ms = this.ms * Math.pow(this.factor, this.attempts++);\n    if (this.jitter) {\n        var rand = Math.random();\n        var deviation = Math.floor(rand * this.jitter * ms);\n        ms = (Math.floor(rand * 10) & 1) == 0 ? ms - deviation : ms + deviation;\n    }\n    return Math.min(ms, this.max) | 0;\n};\n/**\n * Reset the number of attempts.\n *\n * @api public\n */\nBackoff.prototype.reset = function () {\n    this.attempts = 0;\n};\n/**\n * Set the minimum duration\n *\n * @api public\n */\nBackoff.prototype.setMin = function (min) {\n    this.ms = min;\n};\n/**\n * Set the maximum duration\n *\n * @api public\n */\nBackoff.prototype.setMax = function (max) {\n    this.max = max;\n};\n/**\n * Set the jitter\n *\n * @api public\n */\nBackoff.prototype.setJitter = function (jitter) {\n    this.jitter = jitter;\n};\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-client/build/esm/contrib/backo2.js?");

/***/ }),

/***/ "./node_modules/socket.io-client/build/esm/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/socket.io-client/build/esm/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Manager: () => (/* reexport safe */ _manager_js__WEBPACK_IMPORTED_MODULE_1__.Manager),\n/* harmony export */   Socket: () => (/* reexport safe */ _socket_js__WEBPACK_IMPORTED_MODULE_2__.Socket),\n/* harmony export */   connect: () => (/* binding */ lookup),\n/* harmony export */   \"default\": () => (/* binding */ lookup),\n/* harmony export */   io: () => (/* binding */ lookup),\n/* harmony export */   protocol: () => (/* reexport safe */ socket_io_parser__WEBPACK_IMPORTED_MODULE_3__.protocol)\n/* harmony export */ });\n/* harmony import */ var _url_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./url.js */ \"./node_modules/socket.io-client/build/esm/url.js\");\n/* harmony import */ var _manager_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./manager.js */ \"./node_modules/socket.io-client/build/esm/manager.js\");\n/* harmony import */ var _socket_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./socket.js */ \"./node_modules/socket.io-client/build/esm/socket.js\");\n/* harmony import */ var socket_io_parser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! socket.io-parser */ \"./node_modules/socket.io-parser/build/esm/index.js\");\n\n\n\n/**\n * Managers cache.\n */\nconst cache = {};\nfunction lookup(uri, opts) {\n    if (typeof uri === \"object\") {\n        opts = uri;\n        uri = undefined;\n    }\n    opts = opts || {};\n    const parsed = (0,_url_js__WEBPACK_IMPORTED_MODULE_0__.url)(uri, opts.path || \"/socket.io\");\n    const source = parsed.source;\n    const id = parsed.id;\n    const path = parsed.path;\n    const sameNamespace = cache[id] && path in cache[id][\"nsps\"];\n    const newConnection = opts.forceNew ||\n        opts[\"force new connection\"] ||\n        false === opts.multiplex ||\n        sameNamespace;\n    let io;\n    if (newConnection) {\n        io = new _manager_js__WEBPACK_IMPORTED_MODULE_1__.Manager(source, opts);\n    }\n    else {\n        if (!cache[id]) {\n            cache[id] = new _manager_js__WEBPACK_IMPORTED_MODULE_1__.Manager(source, opts);\n        }\n        io = cache[id];\n    }\n    if (parsed.query && !opts.query) {\n        opts.query = parsed.queryKey;\n    }\n    return io.socket(parsed.path, opts);\n}\n// so that \"lookup\" can be used both as a function (e.g. `io(...)`) and as a\n// namespace (e.g. `io.connect(...)`), for backward compatibility\nObject.assign(lookup, {\n    Manager: _manager_js__WEBPACK_IMPORTED_MODULE_1__.Manager,\n    Socket: _socket_js__WEBPACK_IMPORTED_MODULE_2__.Socket,\n    io: lookup,\n    connect: lookup,\n});\n/**\n * Protocol version.\n *\n * @public\n */\n\n/**\n * Expose constructors for standalone build.\n *\n * @public\n */\n\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-client/build/esm/index.js?");

/***/ }),

/***/ "./node_modules/socket.io-client/build/esm/manager.js":
/*!************************************************************!*\
  !*** ./node_modules/socket.io-client/build/esm/manager.js ***!
  \************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Manager: () => (/* binding */ Manager)\n/* harmony export */ });\n/* harmony import */ var engine_io_client__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! engine.io-client */ \"./node_modules/engine.io-client/build/esm/index.js\");\n/* harmony import */ var _socket_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./socket.js */ \"./node_modules/socket.io-client/build/esm/socket.js\");\n/* harmony import */ var socket_io_parser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! socket.io-parser */ \"./node_modules/socket.io-parser/build/esm/index.js\");\n/* harmony import */ var _on_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./on.js */ \"./node_modules/socket.io-client/build/esm/on.js\");\n/* harmony import */ var _contrib_backo2_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./contrib/backo2.js */ \"./node_modules/socket.io-client/build/esm/contrib/backo2.js\");\n/* harmony import */ var _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @socket.io/component-emitter */ \"./node_modules/@socket.io/component-emitter/lib/esm/index.js\");\n\n\n\n\n\n\nclass Manager extends _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_5__.Emitter {\n    constructor(uri, opts) {\n        var _a;\n        super();\n        this.nsps = {};\n        this.subs = [];\n        if (uri && \"object\" === typeof uri) {\n            opts = uri;\n            uri = undefined;\n        }\n        opts = opts || {};\n        opts.path = opts.path || \"/socket.io\";\n        this.opts = opts;\n        (0,engine_io_client__WEBPACK_IMPORTED_MODULE_0__.installTimerFunctions)(this, opts);\n        this.reconnection(opts.reconnection !== false);\n        this.reconnectionAttempts(opts.reconnectionAttempts || Infinity);\n        this.reconnectionDelay(opts.reconnectionDelay || 1000);\n        this.reconnectionDelayMax(opts.reconnectionDelayMax || 5000);\n        this.randomizationFactor((_a = opts.randomizationFactor) !== null && _a !== void 0 ? _a : 0.5);\n        this.backoff = new _contrib_backo2_js__WEBPACK_IMPORTED_MODULE_4__.Backoff({\n            min: this.reconnectionDelay(),\n            max: this.reconnectionDelayMax(),\n            jitter: this.randomizationFactor(),\n        });\n        this.timeout(null == opts.timeout ? 20000 : opts.timeout);\n        this._readyState = \"closed\";\n        this.uri = uri;\n        const _parser = opts.parser || socket_io_parser__WEBPACK_IMPORTED_MODULE_2__;\n        this.encoder = new _parser.Encoder();\n        this.decoder = new _parser.Decoder();\n        this._autoConnect = opts.autoConnect !== false;\n        if (this._autoConnect)\n            this.open();\n    }\n    reconnection(v) {\n        if (!arguments.length)\n            return this._reconnection;\n        this._reconnection = !!v;\n        return this;\n    }\n    reconnectionAttempts(v) {\n        if (v === undefined)\n            return this._reconnectionAttempts;\n        this._reconnectionAttempts = v;\n        return this;\n    }\n    reconnectionDelay(v) {\n        var _a;\n        if (v === undefined)\n            return this._reconnectionDelay;\n        this._reconnectionDelay = v;\n        (_a = this.backoff) === null || _a === void 0 ? void 0 : _a.setMin(v);\n        return this;\n    }\n    randomizationFactor(v) {\n        var _a;\n        if (v === undefined)\n            return this._randomizationFactor;\n        this._randomizationFactor = v;\n        (_a = this.backoff) === null || _a === void 0 ? void 0 : _a.setJitter(v);\n        return this;\n    }\n    reconnectionDelayMax(v) {\n        var _a;\n        if (v === undefined)\n            return this._reconnectionDelayMax;\n        this._reconnectionDelayMax = v;\n        (_a = this.backoff) === null || _a === void 0 ? void 0 : _a.setMax(v);\n        return this;\n    }\n    timeout(v) {\n        if (!arguments.length)\n            return this._timeout;\n        this._timeout = v;\n        return this;\n    }\n    /**\n     * Starts trying to reconnect if reconnection is enabled and we have not\n     * started reconnecting yet\n     *\n     * @private\n     */\n    maybeReconnectOnOpen() {\n        // Only try to reconnect if it's the first time we're connecting\n        if (!this._reconnecting &&\n            this._reconnection &&\n            this.backoff.attempts === 0) {\n            // keeps reconnection from firing twice for the same reconnection loop\n            this.reconnect();\n        }\n    }\n    /**\n     * Sets the current transport `socket`.\n     *\n     * @param {Function} fn - optional, callback\n     * @return self\n     * @public\n     */\n    open(fn) {\n        if (~this._readyState.indexOf(\"open\"))\n            return this;\n        this.engine = new engine_io_client__WEBPACK_IMPORTED_MODULE_0__.Socket(this.uri, this.opts);\n        const socket = this.engine;\n        const self = this;\n        this._readyState = \"opening\";\n        this.skipReconnect = false;\n        // emit `open`\n        const openSubDestroy = (0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(socket, \"open\", function () {\n            self.onopen();\n            fn && fn();\n        });\n        const onError = (err) => {\n            this.cleanup();\n            this._readyState = \"closed\";\n            this.emitReserved(\"error\", err);\n            if (fn) {\n                fn(err);\n            }\n            else {\n                // Only do this if there is no fn to handle the error\n                this.maybeReconnectOnOpen();\n            }\n        };\n        // emit `error`\n        const errorSub = (0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(socket, \"error\", onError);\n        if (false !== this._timeout) {\n            const timeout = this._timeout;\n            // set timer\n            const timer = this.setTimeoutFn(() => {\n                openSubDestroy();\n                onError(new Error(\"timeout\"));\n                socket.close();\n            }, timeout);\n            if (this.opts.autoUnref) {\n                timer.unref();\n            }\n            this.subs.push(() => {\n                this.clearTimeoutFn(timer);\n            });\n        }\n        this.subs.push(openSubDestroy);\n        this.subs.push(errorSub);\n        return this;\n    }\n    /**\n     * Alias for open()\n     *\n     * @return self\n     * @public\n     */\n    connect(fn) {\n        return this.open(fn);\n    }\n    /**\n     * Called upon transport open.\n     *\n     * @private\n     */\n    onopen() {\n        // clear old subs\n        this.cleanup();\n        // mark as open\n        this._readyState = \"open\";\n        this.emitReserved(\"open\");\n        // add new subs\n        const socket = this.engine;\n        this.subs.push((0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(socket, \"ping\", this.onping.bind(this)), (0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(socket, \"data\", this.ondata.bind(this)), (0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(socket, \"error\", this.onerror.bind(this)), (0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(socket, \"close\", this.onclose.bind(this)), (0,_on_js__WEBPACK_IMPORTED_MODULE_3__.on)(this.decoder, \"decoded\", this.ondecoded.bind(this)));\n    }\n    /**\n     * Called upon a ping.\n     *\n     * @private\n     */\n    onping() {\n        this.emitReserved(\"ping\");\n    }\n    /**\n     * Called with data.\n     *\n     * @private\n     */\n    ondata(data) {\n        try {\n            this.decoder.add(data);\n        }\n        catch (e) {\n            this.onclose(\"parse error\", e);\n        }\n    }\n    /**\n     * Called when parser fully decodes a packet.\n     *\n     * @private\n     */\n    ondecoded(packet) {\n        // the nextTick call prevents an exception in a user-provided event listener from triggering a disconnection due to a \"parse error\"\n        (0,engine_io_client__WEBPACK_IMPORTED_MODULE_0__.nextTick)(() => {\n            this.emitReserved(\"packet\", packet);\n        }, this.setTimeoutFn);\n    }\n    /**\n     * Called upon socket error.\n     *\n     * @private\n     */\n    onerror(err) {\n        this.emitReserved(\"error\", err);\n    }\n    /**\n     * Creates a new socket for the given `nsp`.\n     *\n     * @return {Socket}\n     * @public\n     */\n    socket(nsp, opts) {\n        let socket = this.nsps[nsp];\n        if (!socket) {\n            socket = new _socket_js__WEBPACK_IMPORTED_MODULE_1__.Socket(this, nsp, opts);\n            this.nsps[nsp] = socket;\n        }\n        else if (this._autoConnect && !socket.active) {\n            socket.connect();\n        }\n        return socket;\n    }\n    /**\n     * Called upon a socket close.\n     *\n     * @param socket\n     * @private\n     */\n    _destroy(socket) {\n        const nsps = Object.keys(this.nsps);\n        for (const nsp of nsps) {\n            const socket = this.nsps[nsp];\n            if (socket.active) {\n                return;\n            }\n        }\n        this._close();\n    }\n    /**\n     * Writes a packet.\n     *\n     * @param packet\n     * @private\n     */\n    _packet(packet) {\n        const encodedPackets = this.encoder.encode(packet);\n        for (let i = 0; i < encodedPackets.length; i++) {\n            this.engine.write(encodedPackets[i], packet.options);\n        }\n    }\n    /**\n     * Clean up transport subscriptions and packet buffer.\n     *\n     * @private\n     */\n    cleanup() {\n        this.subs.forEach((subDestroy) => subDestroy());\n        this.subs.length = 0;\n        this.decoder.destroy();\n    }\n    /**\n     * Close the current socket.\n     *\n     * @private\n     */\n    _close() {\n        this.skipReconnect = true;\n        this._reconnecting = false;\n        this.onclose(\"forced close\");\n        if (this.engine)\n            this.engine.close();\n    }\n    /**\n     * Alias for close()\n     *\n     * @private\n     */\n    disconnect() {\n        return this._close();\n    }\n    /**\n     * Called upon engine close.\n     *\n     * @private\n     */\n    onclose(reason, description) {\n        this.cleanup();\n        this.backoff.reset();\n        this._readyState = \"closed\";\n        this.emitReserved(\"close\", reason, description);\n        if (this._reconnection && !this.skipReconnect) {\n            this.reconnect();\n        }\n    }\n    /**\n     * Attempt a reconnection.\n     *\n     * @private\n     */\n    reconnect() {\n        if (this._reconnecting || this.skipReconnect)\n            return this;\n        const self = this;\n        if (this.backoff.attempts >= this._reconnectionAttempts) {\n            this.backoff.reset();\n            this.emitReserved(\"reconnect_failed\");\n            this._reconnecting = false;\n        }\n        else {\n            const delay = this.backoff.duration();\n            this._reconnecting = true;\n            const timer = this.setTimeoutFn(() => {\n                if (self.skipReconnect)\n                    return;\n                this.emitReserved(\"reconnect_attempt\", self.backoff.attempts);\n                // check again for the case socket closed in above events\n                if (self.skipReconnect)\n                    return;\n                self.open((err) => {\n                    if (err) {\n                        self._reconnecting = false;\n                        self.reconnect();\n                        this.emitReserved(\"reconnect_error\", err);\n                    }\n                    else {\n                        self.onreconnect();\n                    }\n                });\n            }, delay);\n            if (this.opts.autoUnref) {\n                timer.unref();\n            }\n            this.subs.push(() => {\n                this.clearTimeoutFn(timer);\n            });\n        }\n    }\n    /**\n     * Called upon successful reconnect.\n     *\n     * @private\n     */\n    onreconnect() {\n        const attempt = this.backoff.attempts;\n        this._reconnecting = false;\n        this.backoff.reset();\n        this.emitReserved(\"reconnect\", attempt);\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-client/build/esm/manager.js?");

/***/ }),

/***/ "./node_modules/socket.io-client/build/esm/on.js":
/*!*******************************************************!*\
  !*** ./node_modules/socket.io-client/build/esm/on.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   on: () => (/* binding */ on)\n/* harmony export */ });\nfunction on(obj, ev, fn) {\n    obj.on(ev, fn);\n    return function subDestroy() {\n        obj.off(ev, fn);\n    };\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-client/build/esm/on.js?");

/***/ }),

/***/ "./node_modules/socket.io-client/build/esm/socket.js":
/*!***********************************************************!*\
  !*** ./node_modules/socket.io-client/build/esm/socket.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Socket: () => (/* binding */ Socket)\n/* harmony export */ });\n/* harmony import */ var socket_io_parser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! socket.io-parser */ \"./node_modules/socket.io-parser/build/esm/index.js\");\n/* harmony import */ var _on_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./on.js */ \"./node_modules/socket.io-client/build/esm/on.js\");\n/* harmony import */ var _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @socket.io/component-emitter */ \"./node_modules/@socket.io/component-emitter/lib/esm/index.js\");\n\n\n\n/**\n * Internal events.\n * These events can't be emitted by the user.\n */\nconst RESERVED_EVENTS = Object.freeze({\n    connect: 1,\n    connect_error: 1,\n    disconnect: 1,\n    disconnecting: 1,\n    // EventEmitter reserved events: https://nodejs.org/api/events.html#events_event_newlistener\n    newListener: 1,\n    removeListener: 1,\n});\n/**\n * A Socket is the fundamental class for interacting with the server.\n *\n * A Socket belongs to a certain Namespace (by default /) and uses an underlying {@link Manager} to communicate.\n *\n * @example\n * const socket = io();\n *\n * socket.on(\"connect\", () => {\n *   console.log(\"connected\");\n * });\n *\n * // send an event to the server\n * socket.emit(\"foo\", \"bar\");\n *\n * socket.on(\"foobar\", () => {\n *   // an event was received from the server\n * });\n *\n * // upon disconnection\n * socket.on(\"disconnect\", (reason) => {\n *   console.log(`disconnected due to ${reason}`);\n * });\n */\nclass Socket extends _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_2__.Emitter {\n    /**\n     * `Socket` constructor.\n     */\n    constructor(io, nsp, opts) {\n        super();\n        /**\n         * Whether the socket is currently connected to the server.\n         *\n         * @example\n         * const socket = io();\n         *\n         * socket.on(\"connect\", () => {\n         *   console.log(socket.connected); // true\n         * });\n         *\n         * socket.on(\"disconnect\", () => {\n         *   console.log(socket.connected); // false\n         * });\n         */\n        this.connected = false;\n        /**\n         * Whether the connection state was recovered after a temporary disconnection. In that case, any missed packets will\n         * be transmitted by the server.\n         */\n        this.recovered = false;\n        /**\n         * Buffer for packets received before the CONNECT packet\n         */\n        this.receiveBuffer = [];\n        /**\n         * Buffer for packets that will be sent once the socket is connected\n         */\n        this.sendBuffer = [];\n        /**\n         * The queue of packets to be sent with retry in case of failure.\n         *\n         * Packets are sent one by one, each waiting for the server acknowledgement, in order to guarantee the delivery order.\n         * @private\n         */\n        this._queue = [];\n        /**\n         * A sequence to generate the ID of the {@link QueuedPacket}.\n         * @private\n         */\n        this._queueSeq = 0;\n        this.ids = 0;\n        /**\n         * A map containing acknowledgement handlers.\n         *\n         * The `withError` attribute is used to differentiate handlers that accept an error as first argument:\n         *\n         * - `socket.emit(\"test\", (err, value) => { ... })` with `ackTimeout` option\n         * - `socket.timeout(5000).emit(\"test\", (err, value) => { ... })`\n         * - `const value = await socket.emitWithAck(\"test\")`\n         *\n         * From those that don't:\n         *\n         * - `socket.emit(\"test\", (value) => { ... });`\n         *\n         * In the first case, the handlers will be called with an error when:\n         *\n         * - the timeout is reached\n         * - the socket gets disconnected\n         *\n         * In the second case, the handlers will be simply discarded upon disconnection, since the client will never receive\n         * an acknowledgement from the server.\n         *\n         * @private\n         */\n        this.acks = {};\n        this.flags = {};\n        this.io = io;\n        this.nsp = nsp;\n        if (opts && opts.auth) {\n            this.auth = opts.auth;\n        }\n        this._opts = Object.assign({}, opts);\n        if (this.io._autoConnect)\n            this.open();\n    }\n    /**\n     * Whether the socket is currently disconnected\n     *\n     * @example\n     * const socket = io();\n     *\n     * socket.on(\"connect\", () => {\n     *   console.log(socket.disconnected); // false\n     * });\n     *\n     * socket.on(\"disconnect\", () => {\n     *   console.log(socket.disconnected); // true\n     * });\n     */\n    get disconnected() {\n        return !this.connected;\n    }\n    /**\n     * Subscribe to open, close and packet events\n     *\n     * @private\n     */\n    subEvents() {\n        if (this.subs)\n            return;\n        const io = this.io;\n        this.subs = [\n            (0,_on_js__WEBPACK_IMPORTED_MODULE_1__.on)(io, \"open\", this.onopen.bind(this)),\n            (0,_on_js__WEBPACK_IMPORTED_MODULE_1__.on)(io, \"packet\", this.onpacket.bind(this)),\n            (0,_on_js__WEBPACK_IMPORTED_MODULE_1__.on)(io, \"error\", this.onerror.bind(this)),\n            (0,_on_js__WEBPACK_IMPORTED_MODULE_1__.on)(io, \"close\", this.onclose.bind(this)),\n        ];\n    }\n    /**\n     * Whether the Socket will try to reconnect when its Manager connects or reconnects.\n     *\n     * @example\n     * const socket = io();\n     *\n     * console.log(socket.active); // true\n     *\n     * socket.on(\"disconnect\", (reason) => {\n     *   if (reason === \"io server disconnect\") {\n     *     // the disconnection was initiated by the server, you need to manually reconnect\n     *     console.log(socket.active); // false\n     *   }\n     *   // else the socket will automatically try to reconnect\n     *   console.log(socket.active); // true\n     * });\n     */\n    get active() {\n        return !!this.subs;\n    }\n    /**\n     * \"Opens\" the socket.\n     *\n     * @example\n     * const socket = io({\n     *   autoConnect: false\n     * });\n     *\n     * socket.connect();\n     */\n    connect() {\n        if (this.connected)\n            return this;\n        this.subEvents();\n        if (!this.io[\"_reconnecting\"])\n            this.io.open(); // ensure open\n        if (\"open\" === this.io._readyState)\n            this.onopen();\n        return this;\n    }\n    /**\n     * Alias for {@link connect()}.\n     */\n    open() {\n        return this.connect();\n    }\n    /**\n     * Sends a `message` event.\n     *\n     * This method mimics the WebSocket.send() method.\n     *\n     * @see https://developer.mozilla.org/en-US/docs/Web/API/WebSocket/send\n     *\n     * @example\n     * socket.send(\"hello\");\n     *\n     * // this is equivalent to\n     * socket.emit(\"message\", \"hello\");\n     *\n     * @return self\n     */\n    send(...args) {\n        args.unshift(\"message\");\n        this.emit.apply(this, args);\n        return this;\n    }\n    /**\n     * Override `emit`.\n     * If the event is in `events`, it's emitted normally.\n     *\n     * @example\n     * socket.emit(\"hello\", \"world\");\n     *\n     * // all serializable datastructures are supported (no need to call JSON.stringify)\n     * socket.emit(\"hello\", 1, \"2\", { 3: [\"4\"], 5: Uint8Array.from([6]) });\n     *\n     * // with an acknowledgement from the server\n     * socket.emit(\"hello\", \"world\", (val) => {\n     *   // ...\n     * });\n     *\n     * @return self\n     */\n    emit(ev, ...args) {\n        if (RESERVED_EVENTS.hasOwnProperty(ev)) {\n            throw new Error('\"' + ev.toString() + '\" is a reserved event name');\n        }\n        args.unshift(ev);\n        if (this._opts.retries && !this.flags.fromQueue && !this.flags.volatile) {\n            this._addToQueue(args);\n            return this;\n        }\n        const packet = {\n            type: socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.EVENT,\n            data: args,\n        };\n        packet.options = {};\n        packet.options.compress = this.flags.compress !== false;\n        // event ack callback\n        if (\"function\" === typeof args[args.length - 1]) {\n            const id = this.ids++;\n            const ack = args.pop();\n            this._registerAckCallback(id, ack);\n            packet.id = id;\n        }\n        const isTransportWritable = this.io.engine &&\n            this.io.engine.transport &&\n            this.io.engine.transport.writable;\n        const discardPacket = this.flags.volatile && (!isTransportWritable || !this.connected);\n        if (discardPacket) {\n        }\n        else if (this.connected) {\n            this.notifyOutgoingListeners(packet);\n            this.packet(packet);\n        }\n        else {\n            this.sendBuffer.push(packet);\n        }\n        this.flags = {};\n        return this;\n    }\n    /**\n     * @private\n     */\n    _registerAckCallback(id, ack) {\n        var _a;\n        const timeout = (_a = this.flags.timeout) !== null && _a !== void 0 ? _a : this._opts.ackTimeout;\n        if (timeout === undefined) {\n            this.acks[id] = ack;\n            return;\n        }\n        // @ts-ignore\n        const timer = this.io.setTimeoutFn(() => {\n            delete this.acks[id];\n            for (let i = 0; i < this.sendBuffer.length; i++) {\n                if (this.sendBuffer[i].id === id) {\n                    this.sendBuffer.splice(i, 1);\n                }\n            }\n            ack.call(this, new Error(\"operation has timed out\"));\n        }, timeout);\n        const fn = (...args) => {\n            // @ts-ignore\n            this.io.clearTimeoutFn(timer);\n            ack.apply(this, args);\n        };\n        fn.withError = true;\n        this.acks[id] = fn;\n    }\n    /**\n     * Emits an event and waits for an acknowledgement\n     *\n     * @example\n     * // without timeout\n     * const response = await socket.emitWithAck(\"hello\", \"world\");\n     *\n     * // with a specific timeout\n     * try {\n     *   const response = await socket.timeout(1000).emitWithAck(\"hello\", \"world\");\n     * } catch (err) {\n     *   // the server did not acknowledge the event in the given delay\n     * }\n     *\n     * @return a Promise that will be fulfilled when the server acknowledges the event\n     */\n    emitWithAck(ev, ...args) {\n        return new Promise((resolve, reject) => {\n            const fn = (arg1, arg2) => {\n                return arg1 ? reject(arg1) : resolve(arg2);\n            };\n            fn.withError = true;\n            args.push(fn);\n            this.emit(ev, ...args);\n        });\n    }\n    /**\n     * Add the packet to the queue.\n     * @param args\n     * @private\n     */\n    _addToQueue(args) {\n        let ack;\n        if (typeof args[args.length - 1] === \"function\") {\n            ack = args.pop();\n        }\n        const packet = {\n            id: this._queueSeq++,\n            tryCount: 0,\n            pending: false,\n            args,\n            flags: Object.assign({ fromQueue: true }, this.flags),\n        };\n        args.push((err, ...responseArgs) => {\n            if (packet !== this._queue[0]) {\n                // the packet has already been acknowledged\n                return;\n            }\n            const hasError = err !== null;\n            if (hasError) {\n                if (packet.tryCount > this._opts.retries) {\n                    this._queue.shift();\n                    if (ack) {\n                        ack(err);\n                    }\n                }\n            }\n            else {\n                this._queue.shift();\n                if (ack) {\n                    ack(null, ...responseArgs);\n                }\n            }\n            packet.pending = false;\n            return this._drainQueue();\n        });\n        this._queue.push(packet);\n        this._drainQueue();\n    }\n    /**\n     * Send the first packet of the queue, and wait for an acknowledgement from the server.\n     * @param force - whether to resend a packet that has not been acknowledged yet\n     *\n     * @private\n     */\n    _drainQueue(force = false) {\n        if (!this.connected || this._queue.length === 0) {\n            return;\n        }\n        const packet = this._queue[0];\n        if (packet.pending && !force) {\n            return;\n        }\n        packet.pending = true;\n        packet.tryCount++;\n        this.flags = packet.flags;\n        this.emit.apply(this, packet.args);\n    }\n    /**\n     * Sends a packet.\n     *\n     * @param packet\n     * @private\n     */\n    packet(packet) {\n        packet.nsp = this.nsp;\n        this.io._packet(packet);\n    }\n    /**\n     * Called upon engine `open`.\n     *\n     * @private\n     */\n    onopen() {\n        if (typeof this.auth == \"function\") {\n            this.auth((data) => {\n                this._sendConnectPacket(data);\n            });\n        }\n        else {\n            this._sendConnectPacket(this.auth);\n        }\n    }\n    /**\n     * Sends a CONNECT packet to initiate the Socket.IO session.\n     *\n     * @param data\n     * @private\n     */\n    _sendConnectPacket(data) {\n        this.packet({\n            type: socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.CONNECT,\n            data: this._pid\n                ? Object.assign({ pid: this._pid, offset: this._lastOffset }, data)\n                : data,\n        });\n    }\n    /**\n     * Called upon engine or manager `error`.\n     *\n     * @param err\n     * @private\n     */\n    onerror(err) {\n        if (!this.connected) {\n            this.emitReserved(\"connect_error\", err);\n        }\n    }\n    /**\n     * Called upon engine `close`.\n     *\n     * @param reason\n     * @param description\n     * @private\n     */\n    onclose(reason, description) {\n        this.connected = false;\n        delete this.id;\n        this.emitReserved(\"disconnect\", reason, description);\n        this._clearAcks();\n    }\n    /**\n     * Clears the acknowledgement handlers upon disconnection, since the client will never receive an acknowledgement from\n     * the server.\n     *\n     * @private\n     */\n    _clearAcks() {\n        Object.keys(this.acks).forEach((id) => {\n            const isBuffered = this.sendBuffer.some((packet) => String(packet.id) === id);\n            if (!isBuffered) {\n                // note: handlers that do not accept an error as first argument are ignored here\n                const ack = this.acks[id];\n                delete this.acks[id];\n                if (ack.withError) {\n                    ack.call(this, new Error(\"socket has been disconnected\"));\n                }\n            }\n        });\n    }\n    /**\n     * Called with socket packet.\n     *\n     * @param packet\n     * @private\n     */\n    onpacket(packet) {\n        const sameNamespace = packet.nsp === this.nsp;\n        if (!sameNamespace)\n            return;\n        switch (packet.type) {\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.CONNECT:\n                if (packet.data && packet.data.sid) {\n                    this.onconnect(packet.data.sid, packet.data.pid);\n                }\n                else {\n                    this.emitReserved(\"connect_error\", new Error(\"It seems you are trying to reach a Socket.IO server in v2.x with a v3.x client, but they are not compatible (more information here: https://socket.io/docs/v3/migrating-from-2-x-to-3-0/)\"));\n                }\n                break;\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.EVENT:\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.BINARY_EVENT:\n                this.onevent(packet);\n                break;\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.ACK:\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.BINARY_ACK:\n                this.onack(packet);\n                break;\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.DISCONNECT:\n                this.ondisconnect();\n                break;\n            case socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.CONNECT_ERROR:\n                this.destroy();\n                const err = new Error(packet.data.message);\n                // @ts-ignore\n                err.data = packet.data.data;\n                this.emitReserved(\"connect_error\", err);\n                break;\n        }\n    }\n    /**\n     * Called upon a server event.\n     *\n     * @param packet\n     * @private\n     */\n    onevent(packet) {\n        const args = packet.data || [];\n        if (null != packet.id) {\n            args.push(this.ack(packet.id));\n        }\n        if (this.connected) {\n            this.emitEvent(args);\n        }\n        else {\n            this.receiveBuffer.push(Object.freeze(args));\n        }\n    }\n    emitEvent(args) {\n        if (this._anyListeners && this._anyListeners.length) {\n            const listeners = this._anyListeners.slice();\n            for (const listener of listeners) {\n                listener.apply(this, args);\n            }\n        }\n        super.emit.apply(this, args);\n        if (this._pid && args.length && typeof args[args.length - 1] === \"string\") {\n            this._lastOffset = args[args.length - 1];\n        }\n    }\n    /**\n     * Produces an ack callback to emit with an event.\n     *\n     * @private\n     */\n    ack(id) {\n        const self = this;\n        let sent = false;\n        return function (...args) {\n            // prevent double callbacks\n            if (sent)\n                return;\n            sent = true;\n            self.packet({\n                type: socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.ACK,\n                id: id,\n                data: args,\n            });\n        };\n    }\n    /**\n     * Called upon a server acknowledgement.\n     *\n     * @param packet\n     * @private\n     */\n    onack(packet) {\n        const ack = this.acks[packet.id];\n        if (typeof ack !== \"function\") {\n            return;\n        }\n        delete this.acks[packet.id];\n        // @ts-ignore FIXME ack is incorrectly inferred as 'never'\n        if (ack.withError) {\n            packet.data.unshift(null);\n        }\n        // @ts-ignore\n        ack.apply(this, packet.data);\n    }\n    /**\n     * Called upon server connect.\n     *\n     * @private\n     */\n    onconnect(id, pid) {\n        this.id = id;\n        this.recovered = pid && this._pid === pid;\n        this._pid = pid; // defined only if connection state recovery is enabled\n        this.connected = true;\n        this.emitBuffered();\n        this.emitReserved(\"connect\");\n        this._drainQueue(true);\n    }\n    /**\n     * Emit buffered events (received and emitted).\n     *\n     * @private\n     */\n    emitBuffered() {\n        this.receiveBuffer.forEach((args) => this.emitEvent(args));\n        this.receiveBuffer = [];\n        this.sendBuffer.forEach((packet) => {\n            this.notifyOutgoingListeners(packet);\n            this.packet(packet);\n        });\n        this.sendBuffer = [];\n    }\n    /**\n     * Called upon server disconnect.\n     *\n     * @private\n     */\n    ondisconnect() {\n        this.destroy();\n        this.onclose(\"io server disconnect\");\n    }\n    /**\n     * Called upon forced client/server side disconnections,\n     * this method ensures the manager stops tracking us and\n     * that reconnections don't get triggered for this.\n     *\n     * @private\n     */\n    destroy() {\n        if (this.subs) {\n            // clean subscriptions to avoid reconnections\n            this.subs.forEach((subDestroy) => subDestroy());\n            this.subs = undefined;\n        }\n        this.io[\"_destroy\"](this);\n    }\n    /**\n     * Disconnects the socket manually. In that case, the socket will not try to reconnect.\n     *\n     * If this is the last active Socket instance of the {@link Manager}, the low-level connection will be closed.\n     *\n     * @example\n     * const socket = io();\n     *\n     * socket.on(\"disconnect\", (reason) => {\n     *   // console.log(reason); prints \"io client disconnect\"\n     * });\n     *\n     * socket.disconnect();\n     *\n     * @return self\n     */\n    disconnect() {\n        if (this.connected) {\n            this.packet({ type: socket_io_parser__WEBPACK_IMPORTED_MODULE_0__.PacketType.DISCONNECT });\n        }\n        // remove socket from pool\n        this.destroy();\n        if (this.connected) {\n            // fire events\n            this.onclose(\"io client disconnect\");\n        }\n        return this;\n    }\n    /**\n     * Alias for {@link disconnect()}.\n     *\n     * @return self\n     */\n    close() {\n        return this.disconnect();\n    }\n    /**\n     * Sets the compress flag.\n     *\n     * @example\n     * socket.compress(false).emit(\"hello\");\n     *\n     * @param compress - if `true`, compresses the sending data\n     * @return self\n     */\n    compress(compress) {\n        this.flags.compress = compress;\n        return this;\n    }\n    /**\n     * Sets a modifier for a subsequent event emission that the event message will be dropped when this socket is not\n     * ready to send messages.\n     *\n     * @example\n     * socket.volatile.emit(\"hello\"); // the server may or may not receive it\n     *\n     * @returns self\n     */\n    get volatile() {\n        this.flags.volatile = true;\n        return this;\n    }\n    /**\n     * Sets a modifier for a subsequent event emission that the callback will be called with an error when the\n     * given number of milliseconds have elapsed without an acknowledgement from the server:\n     *\n     * @example\n     * socket.timeout(5000).emit(\"my-event\", (err) => {\n     *   if (err) {\n     *     // the server did not acknowledge the event in the given delay\n     *   }\n     * });\n     *\n     * @returns self\n     */\n    timeout(timeout) {\n        this.flags.timeout = timeout;\n        return this;\n    }\n    /**\n     * Adds a listener that will be fired when any event is emitted. The event name is passed as the first argument to the\n     * callback.\n     *\n     * @example\n     * socket.onAny((event, ...args) => {\n     *   console.log(`got ${event}`);\n     * });\n     *\n     * @param listener\n     */\n    onAny(listener) {\n        this._anyListeners = this._anyListeners || [];\n        this._anyListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds a listener that will be fired when any event is emitted. The event name is passed as the first argument to the\n     * callback. The listener is added to the beginning of the listeners array.\n     *\n     * @example\n     * socket.prependAny((event, ...args) => {\n     *   console.log(`got event ${event}`);\n     * });\n     *\n     * @param listener\n     */\n    prependAny(listener) {\n        this._anyListeners = this._anyListeners || [];\n        this._anyListeners.unshift(listener);\n        return this;\n    }\n    /**\n     * Removes the listener that will be fired when any event is emitted.\n     *\n     * @example\n     * const catchAllListener = (event, ...args) => {\n     *   console.log(`got event ${event}`);\n     * }\n     *\n     * socket.onAny(catchAllListener);\n     *\n     * // remove a specific listener\n     * socket.offAny(catchAllListener);\n     *\n     * // or remove all listeners\n     * socket.offAny();\n     *\n     * @param listener\n     */\n    offAny(listener) {\n        if (!this._anyListeners) {\n            return this;\n        }\n        if (listener) {\n            const listeners = this._anyListeners;\n            for (let i = 0; i < listeners.length; i++) {\n                if (listener === listeners[i]) {\n                    listeners.splice(i, 1);\n                    return this;\n                }\n            }\n        }\n        else {\n            this._anyListeners = [];\n        }\n        return this;\n    }\n    /**\n     * Returns an array of listeners that are listening for any event that is specified. This array can be manipulated,\n     * e.g. to remove listeners.\n     */\n    listenersAny() {\n        return this._anyListeners || [];\n    }\n    /**\n     * Adds a listener that will be fired when any event is emitted. The event name is passed as the first argument to the\n     * callback.\n     *\n     * Note: acknowledgements sent to the server are not included.\n     *\n     * @example\n     * socket.onAnyOutgoing((event, ...args) => {\n     *   console.log(`sent event ${event}`);\n     * });\n     *\n     * @param listener\n     */\n    onAnyOutgoing(listener) {\n        this._anyOutgoingListeners = this._anyOutgoingListeners || [];\n        this._anyOutgoingListeners.push(listener);\n        return this;\n    }\n    /**\n     * Adds a listener that will be fired when any event is emitted. The event name is passed as the first argument to the\n     * callback. The listener is added to the beginning of the listeners array.\n     *\n     * Note: acknowledgements sent to the server are not included.\n     *\n     * @example\n     * socket.prependAnyOutgoing((event, ...args) => {\n     *   console.log(`sent event ${event}`);\n     * });\n     *\n     * @param listener\n     */\n    prependAnyOutgoing(listener) {\n        this._anyOutgoingListeners = this._anyOutgoingListeners || [];\n        this._anyOutgoingListeners.unshift(listener);\n        return this;\n    }\n    /**\n     * Removes the listener that will be fired when any event is emitted.\n     *\n     * @example\n     * const catchAllListener = (event, ...args) => {\n     *   console.log(`sent event ${event}`);\n     * }\n     *\n     * socket.onAnyOutgoing(catchAllListener);\n     *\n     * // remove a specific listener\n     * socket.offAnyOutgoing(catchAllListener);\n     *\n     * // or remove all listeners\n     * socket.offAnyOutgoing();\n     *\n     * @param [listener] - the catch-all listener (optional)\n     */\n    offAnyOutgoing(listener) {\n        if (!this._anyOutgoingListeners) {\n            return this;\n        }\n        if (listener) {\n            const listeners = this._anyOutgoingListeners;\n            for (let i = 0; i < listeners.length; i++) {\n                if (listener === listeners[i]) {\n                    listeners.splice(i, 1);\n                    return this;\n                }\n            }\n        }\n        else {\n            this._anyOutgoingListeners = [];\n        }\n        return this;\n    }\n    /**\n     * Returns an array of listeners that are listening for any event that is specified. This array can be manipulated,\n     * e.g. to remove listeners.\n     */\n    listenersAnyOutgoing() {\n        return this._anyOutgoingListeners || [];\n    }\n    /**\n     * Notify the listeners for each packet sent\n     *\n     * @param packet\n     *\n     * @private\n     */\n    notifyOutgoingListeners(packet) {\n        if (this._anyOutgoingListeners && this._anyOutgoingListeners.length) {\n            const listeners = this._anyOutgoingListeners.slice();\n            for (const listener of listeners) {\n                listener.apply(this, packet.data);\n            }\n        }\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-client/build/esm/socket.js?");

/***/ }),

/***/ "./node_modules/socket.io-client/build/esm/url.js":
/*!********************************************************!*\
  !*** ./node_modules/socket.io-client/build/esm/url.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   url: () => (/* binding */ url)\n/* harmony export */ });\n/* harmony import */ var engine_io_client__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! engine.io-client */ \"./node_modules/engine.io-client/build/esm/index.js\");\n\n/**\n * URL parser.\n *\n * @param uri - url\n * @param path - the request path of the connection\n * @param loc - An object meant to mimic window.location.\n *        Defaults to window.location.\n * @public\n */\nfunction url(uri, path = \"\", loc) {\n    let obj = uri;\n    // default to window.location\n    loc = loc || (typeof location !== \"undefined\" && location);\n    if (null == uri)\n        uri = loc.protocol + \"//\" + loc.host;\n    // relative path support\n    if (typeof uri === \"string\") {\n        if (\"/\" === uri.charAt(0)) {\n            if (\"/\" === uri.charAt(1)) {\n                uri = loc.protocol + uri;\n            }\n            else {\n                uri = loc.host + uri;\n            }\n        }\n        if (!/^(https?|wss?):\\/\\//.test(uri)) {\n            if (\"undefined\" !== typeof loc) {\n                uri = loc.protocol + \"//\" + uri;\n            }\n            else {\n                uri = \"https://\" + uri;\n            }\n        }\n        // parse\n        obj = (0,engine_io_client__WEBPACK_IMPORTED_MODULE_0__.parse)(uri);\n    }\n    // make sure we treat `localhost:80` and `localhost` equally\n    if (!obj.port) {\n        if (/^(http|ws)$/.test(obj.protocol)) {\n            obj.port = \"80\";\n        }\n        else if (/^(http|ws)s$/.test(obj.protocol)) {\n            obj.port = \"443\";\n        }\n    }\n    obj.path = obj.path || \"/\";\n    const ipv6 = obj.host.indexOf(\":\") !== -1;\n    const host = ipv6 ? \"[\" + obj.host + \"]\" : obj.host;\n    // define unique id\n    obj.id = obj.protocol + \"://\" + host + \":\" + obj.port + path;\n    // define href\n    obj.href =\n        obj.protocol +\n            \"://\" +\n            host +\n            (loc && loc.port === obj.port ? \"\" : \":\" + obj.port);\n    return obj;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-client/build/esm/url.js?");

/***/ }),

/***/ "./node_modules/socket.io-parser/build/esm/binary.js":
/*!***********************************************************!*\
  !*** ./node_modules/socket.io-parser/build/esm/binary.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   deconstructPacket: () => (/* binding */ deconstructPacket),\n/* harmony export */   reconstructPacket: () => (/* binding */ reconstructPacket)\n/* harmony export */ });\n/* harmony import */ var _is_binary_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./is-binary.js */ \"./node_modules/socket.io-parser/build/esm/is-binary.js\");\n\n/**\n * Replaces every Buffer | ArrayBuffer | Blob | File in packet with a numbered placeholder.\n *\n * @param {Object} packet - socket.io event packet\n * @return {Object} with deconstructed packet and list of buffers\n * @public\n */\nfunction deconstructPacket(packet) {\n    const buffers = [];\n    const packetData = packet.data;\n    const pack = packet;\n    pack.data = _deconstructPacket(packetData, buffers);\n    pack.attachments = buffers.length; // number of binary 'attachments'\n    return { packet: pack, buffers: buffers };\n}\nfunction _deconstructPacket(data, buffers) {\n    if (!data)\n        return data;\n    if ((0,_is_binary_js__WEBPACK_IMPORTED_MODULE_0__.isBinary)(data)) {\n        const placeholder = { _placeholder: true, num: buffers.length };\n        buffers.push(data);\n        return placeholder;\n    }\n    else if (Array.isArray(data)) {\n        const newData = new Array(data.length);\n        for (let i = 0; i < data.length; i++) {\n            newData[i] = _deconstructPacket(data[i], buffers);\n        }\n        return newData;\n    }\n    else if (typeof data === \"object\" && !(data instanceof Date)) {\n        const newData = {};\n        for (const key in data) {\n            if (Object.prototype.hasOwnProperty.call(data, key)) {\n                newData[key] = _deconstructPacket(data[key], buffers);\n            }\n        }\n        return newData;\n    }\n    return data;\n}\n/**\n * Reconstructs a binary packet from its placeholder packet and buffers\n *\n * @param {Object} packet - event packet with placeholders\n * @param {Array} buffers - binary buffers to put in placeholder positions\n * @return {Object} reconstructed packet\n * @public\n */\nfunction reconstructPacket(packet, buffers) {\n    packet.data = _reconstructPacket(packet.data, buffers);\n    delete packet.attachments; // no longer useful\n    return packet;\n}\nfunction _reconstructPacket(data, buffers) {\n    if (!data)\n        return data;\n    if (data && data._placeholder === true) {\n        const isIndexValid = typeof data.num === \"number\" &&\n            data.num >= 0 &&\n            data.num < buffers.length;\n        if (isIndexValid) {\n            return buffers[data.num]; // appropriate buffer (should be natural order anyway)\n        }\n        else {\n            throw new Error(\"illegal attachments\");\n        }\n    }\n    else if (Array.isArray(data)) {\n        for (let i = 0; i < data.length; i++) {\n            data[i] = _reconstructPacket(data[i], buffers);\n        }\n    }\n    else if (typeof data === \"object\") {\n        for (const key in data) {\n            if (Object.prototype.hasOwnProperty.call(data, key)) {\n                data[key] = _reconstructPacket(data[key], buffers);\n            }\n        }\n    }\n    return data;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-parser/build/esm/binary.js?");

/***/ }),

/***/ "./node_modules/socket.io-parser/build/esm/index.js":
/*!**********************************************************!*\
  !*** ./node_modules/socket.io-parser/build/esm/index.js ***!
  \**********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Decoder: () => (/* binding */ Decoder),\n/* harmony export */   Encoder: () => (/* binding */ Encoder),\n/* harmony export */   PacketType: () => (/* binding */ PacketType),\n/* harmony export */   protocol: () => (/* binding */ protocol)\n/* harmony export */ });\n/* harmony import */ var _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @socket.io/component-emitter */ \"./node_modules/@socket.io/component-emitter/lib/esm/index.js\");\n/* harmony import */ var _binary_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./binary.js */ \"./node_modules/socket.io-parser/build/esm/binary.js\");\n/* harmony import */ var _is_binary_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./is-binary.js */ \"./node_modules/socket.io-parser/build/esm/is-binary.js\");\n\n\n\n/**\n * These strings must not be used as event names, as they have a special meaning.\n */\nconst RESERVED_EVENTS = [\n    \"connect\",\n    \"connect_error\",\n    \"disconnect\",\n    \"disconnecting\",\n    \"newListener\",\n    \"removeListener\", // used by the Node.js EventEmitter\n];\n/**\n * Protocol version.\n *\n * @public\n */\nconst protocol = 5;\nvar PacketType;\n(function (PacketType) {\n    PacketType[PacketType[\"CONNECT\"] = 0] = \"CONNECT\";\n    PacketType[PacketType[\"DISCONNECT\"] = 1] = \"DISCONNECT\";\n    PacketType[PacketType[\"EVENT\"] = 2] = \"EVENT\";\n    PacketType[PacketType[\"ACK\"] = 3] = \"ACK\";\n    PacketType[PacketType[\"CONNECT_ERROR\"] = 4] = \"CONNECT_ERROR\";\n    PacketType[PacketType[\"BINARY_EVENT\"] = 5] = \"BINARY_EVENT\";\n    PacketType[PacketType[\"BINARY_ACK\"] = 6] = \"BINARY_ACK\";\n})(PacketType || (PacketType = {}));\n/**\n * A socket.io Encoder instance\n */\nclass Encoder {\n    /**\n     * Encoder constructor\n     *\n     * @param {function} replacer - custom replacer to pass down to JSON.parse\n     */\n    constructor(replacer) {\n        this.replacer = replacer;\n    }\n    /**\n     * Encode a packet as a single string if non-binary, or as a\n     * buffer sequence, depending on packet type.\n     *\n     * @param {Object} obj - packet object\n     */\n    encode(obj) {\n        if (obj.type === PacketType.EVENT || obj.type === PacketType.ACK) {\n            if ((0,_is_binary_js__WEBPACK_IMPORTED_MODULE_2__.hasBinary)(obj)) {\n                return this.encodeAsBinary({\n                    type: obj.type === PacketType.EVENT\n                        ? PacketType.BINARY_EVENT\n                        : PacketType.BINARY_ACK,\n                    nsp: obj.nsp,\n                    data: obj.data,\n                    id: obj.id,\n                });\n            }\n        }\n        return [this.encodeAsString(obj)];\n    }\n    /**\n     * Encode packet as string.\n     */\n    encodeAsString(obj) {\n        // first is type\n        let str = \"\" + obj.type;\n        // attachments if we have them\n        if (obj.type === PacketType.BINARY_EVENT ||\n            obj.type === PacketType.BINARY_ACK) {\n            str += obj.attachments + \"-\";\n        }\n        // if we have a namespace other than `/`\n        // we append it followed by a comma `,`\n        if (obj.nsp && \"/\" !== obj.nsp) {\n            str += obj.nsp + \",\";\n        }\n        // immediately followed by the id\n        if (null != obj.id) {\n            str += obj.id;\n        }\n        // json data\n        if (null != obj.data) {\n            str += JSON.stringify(obj.data, this.replacer);\n        }\n        return str;\n    }\n    /**\n     * Encode packet as 'buffer sequence' by removing blobs, and\n     * deconstructing packet into object with placeholders and\n     * a list of buffers.\n     */\n    encodeAsBinary(obj) {\n        const deconstruction = (0,_binary_js__WEBPACK_IMPORTED_MODULE_1__.deconstructPacket)(obj);\n        const pack = this.encodeAsString(deconstruction.packet);\n        const buffers = deconstruction.buffers;\n        buffers.unshift(pack); // add packet info to beginning of data list\n        return buffers; // write all the buffers\n    }\n}\n// see https://stackoverflow.com/questions/8511281/check-if-a-value-is-an-object-in-javascript\nfunction isObject(value) {\n    return Object.prototype.toString.call(value) === \"[object Object]\";\n}\n/**\n * A socket.io Decoder instance\n *\n * @return {Object} decoder\n */\nclass Decoder extends _socket_io_component_emitter__WEBPACK_IMPORTED_MODULE_0__.Emitter {\n    /**\n     * Decoder constructor\n     *\n     * @param {function} reviver - custom reviver to pass down to JSON.stringify\n     */\n    constructor(reviver) {\n        super();\n        this.reviver = reviver;\n    }\n    /**\n     * Decodes an encoded packet string into packet JSON.\n     *\n     * @param {String} obj - encoded packet\n     */\n    add(obj) {\n        let packet;\n        if (typeof obj === \"string\") {\n            if (this.reconstructor) {\n                throw new Error(\"got plaintext data when reconstructing a packet\");\n            }\n            packet = this.decodeString(obj);\n            const isBinaryEvent = packet.type === PacketType.BINARY_EVENT;\n            if (isBinaryEvent || packet.type === PacketType.BINARY_ACK) {\n                packet.type = isBinaryEvent ? PacketType.EVENT : PacketType.ACK;\n                // binary packet's json\n                this.reconstructor = new BinaryReconstructor(packet);\n                // no attachments, labeled binary but no binary data to follow\n                if (packet.attachments === 0) {\n                    super.emitReserved(\"decoded\", packet);\n                }\n            }\n            else {\n                // non-binary full packet\n                super.emitReserved(\"decoded\", packet);\n            }\n        }\n        else if ((0,_is_binary_js__WEBPACK_IMPORTED_MODULE_2__.isBinary)(obj) || obj.base64) {\n            // raw binary data\n            if (!this.reconstructor) {\n                throw new Error(\"got binary data when not reconstructing a packet\");\n            }\n            else {\n                packet = this.reconstructor.takeBinaryData(obj);\n                if (packet) {\n                    // received final buffer\n                    this.reconstructor = null;\n                    super.emitReserved(\"decoded\", packet);\n                }\n            }\n        }\n        else {\n            throw new Error(\"Unknown type: \" + obj);\n        }\n    }\n    /**\n     * Decode a packet String (JSON data)\n     *\n     * @param {String} str\n     * @return {Object} packet\n     */\n    decodeString(str) {\n        let i = 0;\n        // look up type\n        const p = {\n            type: Number(str.charAt(0)),\n        };\n        if (PacketType[p.type] === undefined) {\n            throw new Error(\"unknown packet type \" + p.type);\n        }\n        // look up attachments if type binary\n        if (p.type === PacketType.BINARY_EVENT ||\n            p.type === PacketType.BINARY_ACK) {\n            const start = i + 1;\n            while (str.charAt(++i) !== \"-\" && i != str.length) { }\n            const buf = str.substring(start, i);\n            if (buf != Number(buf) || str.charAt(i) !== \"-\") {\n                throw new Error(\"Illegal attachments\");\n            }\n            p.attachments = Number(buf);\n        }\n        // look up namespace (if any)\n        if (\"/\" === str.charAt(i + 1)) {\n            const start = i + 1;\n            while (++i) {\n                const c = str.charAt(i);\n                if (\",\" === c)\n                    break;\n                if (i === str.length)\n                    break;\n            }\n            p.nsp = str.substring(start, i);\n        }\n        else {\n            p.nsp = \"/\";\n        }\n        // look up id\n        const next = str.charAt(i + 1);\n        if (\"\" !== next && Number(next) == next) {\n            const start = i + 1;\n            while (++i) {\n                const c = str.charAt(i);\n                if (null == c || Number(c) != c) {\n                    --i;\n                    break;\n                }\n                if (i === str.length)\n                    break;\n            }\n            p.id = Number(str.substring(start, i + 1));\n        }\n        // look up json data\n        if (str.charAt(++i)) {\n            const payload = this.tryParse(str.substr(i));\n            if (Decoder.isPayloadValid(p.type, payload)) {\n                p.data = payload;\n            }\n            else {\n                throw new Error(\"invalid payload\");\n            }\n        }\n        return p;\n    }\n    tryParse(str) {\n        try {\n            return JSON.parse(str, this.reviver);\n        }\n        catch (e) {\n            return false;\n        }\n    }\n    static isPayloadValid(type, payload) {\n        switch (type) {\n            case PacketType.CONNECT:\n                return isObject(payload);\n            case PacketType.DISCONNECT:\n                return payload === undefined;\n            case PacketType.CONNECT_ERROR:\n                return typeof payload === \"string\" || isObject(payload);\n            case PacketType.EVENT:\n            case PacketType.BINARY_EVENT:\n                return (Array.isArray(payload) &&\n                    (typeof payload[0] === \"number\" ||\n                        (typeof payload[0] === \"string\" &&\n                            RESERVED_EVENTS.indexOf(payload[0]) === -1)));\n            case PacketType.ACK:\n            case PacketType.BINARY_ACK:\n                return Array.isArray(payload);\n        }\n    }\n    /**\n     * Deallocates a parser's resources\n     */\n    destroy() {\n        if (this.reconstructor) {\n            this.reconstructor.finishedReconstruction();\n            this.reconstructor = null;\n        }\n    }\n}\n/**\n * A manager of a binary event's 'buffer sequence'. Should\n * be constructed whenever a packet of type BINARY_EVENT is\n * decoded.\n *\n * @param {Object} packet\n * @return {BinaryReconstructor} initialized reconstructor\n */\nclass BinaryReconstructor {\n    constructor(packet) {\n        this.packet = packet;\n        this.buffers = [];\n        this.reconPack = packet;\n    }\n    /**\n     * Method to be called when binary data received from connection\n     * after a BINARY_EVENT packet.\n     *\n     * @param {Buffer | ArrayBuffer} binData - the raw binary data received\n     * @return {null | Object} returns null if more binary data is expected or\n     *   a reconstructed packet object if all buffers have been received.\n     */\n    takeBinaryData(binData) {\n        this.buffers.push(binData);\n        if (this.buffers.length === this.reconPack.attachments) {\n            // done with buffer list\n            const packet = (0,_binary_js__WEBPACK_IMPORTED_MODULE_1__.reconstructPacket)(this.reconPack, this.buffers);\n            this.finishedReconstruction();\n            return packet;\n        }\n        return null;\n    }\n    /**\n     * Cleans up binary packet reconstruction variables.\n     */\n    finishedReconstruction() {\n        this.reconPack = null;\n        this.buffers = [];\n    }\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-parser/build/esm/index.js?");

/***/ }),

/***/ "./node_modules/socket.io-parser/build/esm/is-binary.js":
/*!**************************************************************!*\
  !*** ./node_modules/socket.io-parser/build/esm/is-binary.js ***!
  \**************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   hasBinary: () => (/* binding */ hasBinary),\n/* harmony export */   isBinary: () => (/* binding */ isBinary)\n/* harmony export */ });\nconst withNativeArrayBuffer = typeof ArrayBuffer === \"function\";\nconst isView = (obj) => {\n    return typeof ArrayBuffer.isView === \"function\"\n        ? ArrayBuffer.isView(obj)\n        : obj.buffer instanceof ArrayBuffer;\n};\nconst toString = Object.prototype.toString;\nconst withNativeBlob = typeof Blob === \"function\" ||\n    (typeof Blob !== \"undefined\" &&\n        toString.call(Blob) === \"[object BlobConstructor]\");\nconst withNativeFile = typeof File === \"function\" ||\n    (typeof File !== \"undefined\" &&\n        toString.call(File) === \"[object FileConstructor]\");\n/**\n * Returns true if obj is a Buffer, an ArrayBuffer, a Blob or a File.\n *\n * @private\n */\nfunction isBinary(obj) {\n    return ((withNativeArrayBuffer && (obj instanceof ArrayBuffer || isView(obj))) ||\n        (withNativeBlob && obj instanceof Blob) ||\n        (withNativeFile && obj instanceof File));\n}\nfunction hasBinary(obj, toJSON) {\n    if (!obj || typeof obj !== \"object\") {\n        return false;\n    }\n    if (Array.isArray(obj)) {\n        for (let i = 0, l = obj.length; i < l; i++) {\n            if (hasBinary(obj[i])) {\n                return true;\n            }\n        }\n        return false;\n    }\n    if (isBinary(obj)) {\n        return true;\n    }\n    if (obj.toJSON &&\n        typeof obj.toJSON === \"function\" &&\n        arguments.length === 1) {\n        return hasBinary(obj.toJSON(), true);\n    }\n    for (const key in obj) {\n        if (Object.prototype.hasOwnProperty.call(obj, key) && hasBinary(obj[key])) {\n            return true;\n        }\n    }\n    return false;\n}\n\n\n//# sourceURL=webpack://mediasoup-nodejs/./node_modules/socket.io-parser/build/esm/is-binary.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/amd options */
/******/ 	(() => {
/******/ 		__webpack_require__.amdO = {};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./public/index.js");
/******/ 	
/******/ })()
;